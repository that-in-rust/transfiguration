//! Minimal setup validation - bypasses all compilation issues
//! Just validates that our file structure is correct

use std::path::Path;
use std::fs;

fn main() {
    println!("ğŸš€ Validating Dobby Subagent Code Summarizer Setup");
    println!("=================================================");

    // Check model directory structure
    let model_path = Path::new("./models/qwen2.5-0.5b-int4");
    let model_file = model_path.join("model_quantized.onnx");

    println!("\nğŸ“ Checking model structure:");
    println!("   Model directory: {}", model_path.display());

    if model_path.exists() {
        println!("   âœ… Model directory exists");

        if model_file.exists() {
            let metadata = fs::metadata(&model_file).unwrap();
            let size_mb = metadata.len() / 1_000_000;
            println!("   âœ… Model file exists: {} MB", size_mb);
        } else {
            println!("   âŒ Model file missing: {}", model_file.display());
        }

        // List all files in model directory
        if let Ok(entries) = fs::read_dir(model_path) {
            println!("   ğŸ“‹ Model directory contents:");
            for entry in entries.flatten() {
                let path = entry.path();
                if path.is_file() {
                    let size = entry.metadata().unwrap().len();
                    println!("      - {} ({} bytes)", path.file_name().unwrap().to_string_lossy(), size);
                }
            }
        }
    } else {
        println!("   âŒ Model directory missing");
    }

    // Check tokenizer structure
    let tokenizer_path = Path::new("./tokenizer_dir");
    let tokenizer_file = tokenizer_path.join("tokenizer.json");

    println!("\nğŸ“ Checking tokenizer structure:");
    println!("   Tokenizer directory: {}", tokenizer_path.display());

    if tokenizer_path.exists() {
        println!("   âœ… Tokenizer directory exists");

        if tokenizer_file.exists() {
            let metadata = fs::metadata(&tokenizer_file).unwrap();
            let size_mb = metadata.len() / 1_000_000;
            println!("   âœ… Tokenizer file exists: {} MB", size_mb);
        } else {
            println!("   âŒ Tokenizer file missing: {}", tokenizer_file.display());
        }

        // List all files in tokenizer directory
        if let Ok(entries) = fs::read_dir(tokenizer_path) {
            println!("   ğŸ“‹ Tokenizer directory contents:");
            for entry in entries.flatten() {
                let path = entry.path();
                if path.is_file() {
                    let size = entry.metadata().unwrap().len();
                    println!("      - {} ({} bytes)", path.file_name().unwrap().to_string_lossy(), size);
                }
            }
        }
    } else {
        println!("   âŒ Tokenizer directory missing");
    }

    // Check if we have the right structure for the OptimizedInferenceEngine
    println!("\nğŸ¯ OptimizedInferenceEngine Requirements:");
    println!("   Expected model path: ./models/qwen2.5-0.5b-int4/model_quantized.onnx");
    println!("   Expected tokenizer path: ./tokenizer_dir/tokenizer.json");

    let model_ok = model_file.exists();
    let tokenizer_ok = tokenizer_file.exists();

    if model_ok && tokenizer_ok {
        println!("\nğŸ‰ SUCCESS: All required files are in place!");
        println!("   The OptimizedInferenceEngine should be able to load the models.");
        println!("   Ready to proceed with inference testing.");
    } else {
        println!("\nâŒ SETUP INCOMPLETE: Some required files are missing.");
        if !model_ok {
            println!("   - Missing: model_quantized.onnx");
        }
        if !tokenizer_ok {
            println!("   - Missing: tokenizer.json");
        }
    }

    println!("\nğŸ“ Next Steps:");
    println!("   1. âœ… File structure validation (this script)");
    println!("   2. â³ Fix compilation issues in trait system");
    println!("   3. â³ Test OptimizedInferenceEngine model loading");
    println!("   4. â³ Run basic inference test");
    println!("   5. â³ Validate end-to-end pipeline");
}