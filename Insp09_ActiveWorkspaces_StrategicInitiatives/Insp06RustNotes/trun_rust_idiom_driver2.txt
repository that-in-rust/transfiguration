{
  "input": "Help me ideate RustHallows\n\nRustHallows: from-scratch, Rust-native, vertically integrated stack for 10–40x perf by collapsing legacy OS/app boundaries, specializing fast path, and baking in formal isolation. Internals use Harry Potter–themed names (public branding can swap later). Build as capability-based microkernel + user-level dataplanes + μs scheduler + zero-copy I/O rings + whole-system observability, all in Rust, with safety-critical cert paths. Model isolation like seL4 (capabilities), time/space partitioning like ARINC 653, data-plane bypass like Arrakis/IX, μs schedulers like Shinjuku/Shenango/Caladan. Target NIC/NVMe/GPU direct paths (RDMA, SPDK, GPUDirect) with Rust APIs for zero-overhead. Unlocks 10–40x for networked, storage, real-time, analytics systems while preserving memory safety and certifiability.\n\nWhy this will work\n\n1. Tight core: capability microkernel + partitioning\n- Capabilities give precise authority and are the bedrock of seL4’s verified isolation and perf. RustHallows “Ministry of Magic” kernel adopts this model to keep kernel minimal and prove invariants.\n- Time/space partitioning (ARINC 653) enables deterministic multi-tenancy for safety domains (“Horcrux” partitions). Useful for hard temporal guarantees; implement as optional mode.\n\n2. Move fast path to user space\n- Arrakis/IX: remove kernel from data path, give apps secure, virtualized access to queues/devices; keep policy/control in kernel. We follow this for NIC/NVMe/GPU.\n\n3. μs-scale scheduling\n- Shinjuku: practical μs preemption; Shenango: μs core reallocation for CPU efficiency; Caladan: mitigates interference with ultra-fast core moves. Blend into Rust scheduler (“Time-Turner”).\n\n4. Direct I/O with ring interfaces\n- io_uring: shared rings reduce syscall overhead; implement RustHallows Rings for NIC/NVMe/GPU, inspired by this.\n- Kernel-bypass stacks: DPDK and SPDK show huge gains from userspace NIC/storage drivers; create from-scratch Rust equivalents.\n\n5. Modern Rust OS lineage\n- Redox (Rust microkernel) and Theseus (intralingual, state-minimizing OS) validate Rust for OS components; synthesize lessons, not code.\n\n6. Safety-critical toolchain viability\n- Ferrocene (qualified Rust toolchain) unlocks ISO 26262/IEC 61508 paths and signals a runway toward DO-178C workflows.\n\nRustHallows Spellbook (Harry Potter code names for internal components)\nAll code written from scratch in Rust; references are inspirations, not dependencies.\n\nKernel & Isolation\n- Ministry of Magic: microkernel core (capability-based) with per-object rights, guarded IPC, deterministic paths for hot syscalls. seL4-style caps; Theseus-style invariants.\n- Horcrux Partitions: ARINC-653-like major/minor frames for time/space partitioning when hard determinism is required; switchable off for best-effort modes.\n- Fidelius: capability-scoped secrets service; supports SGX/TrustZone/CHERI backends for enclaves/compartments.\n- Azkaban: process jailer: per-service “cells” with capability-gated syscall namespace; fast forkless clones.\n\nScheduling\n- Time-Turner: μs-scale preemptive scheduler, hybridizing Shinjuku’s preemption, Shenango’s core-lending, Caladan’s interference control. Configurable for LC/BE mixing.\n- Felix Felicis: feedback-driven scheduling “luck potion”: instrumentation steers policy at μs granularity; ties into Pensieve telemetry.\n\nNetworking & IPC\n- Floo Network: userspace NIC dataplane: per-queue rings, zero-copy mbufs, batched completion. DPDK-like API, Rust-safe types.\n- Portkeys: cross-host RPC fabric: optional RDMA transport for μs latencies; pluggable QUIC/UDP path; direct shared-memory IPC for co-resident services.\n- Owl Post: lock-free message queues (SPSC/MPSC) backed by cache-aligned ring buffers; priority lanes for LC traffic.\n\nStorage & Memory\n- Gringotts: NVMe/ZNS storage stack in userspace with queue pairs and zoned log-structuring; SPDK-style completion path, Rust-safe DMA.\n- Room of Requirement: tiered memory manager (DRAM/HBM/NVRAM) with predictable allocation classes; optional ZNS-aware page cache bypass.\n- Pensieve: zero-copy buffers, region capabilities, and lifetime-tracked I/O views; exposes stable, serializable Arrow-compatible columns to analytics apps.\n\nGPU / Accelerators\n- Nimbus 2000: GPU direct-path I/O: NVMe-to-GPU DMA (GPUDirect Storage) and NIC-to-GPU RDMA where supported. Rust queue APIs mirror CPU rings.\n\nObservability & Tooling\n- Pensieve (Observability): pervasive tracing with low-overhead probes; eBPF-like programs but native to RustHallows (Aya inspires ergonomics, but implementation is our own).\n- Marauder’s Map: always-on flame/timeline UI: per-core run-queue, queue depths, cache misses, NIC/NVMe queues, tail-latency heatmaps.\n- Hermione: reproducible builds, LTO/PGO pipelines, whole-program verification gates (clippy+++, MIR audits), safety mode toggles for certification.\n\nData & Runtime Libraries\n- Goblins’ Ledger: columnar analytics runtime with DataFusion/Arrow-inspired operators (vectorized), but implemented anew; zero-copy from Pensieve buffers.\n- Quidditch: streaming compute (Flink-ish graph) with backpressure & μs timers; scheduler-integrated operator pinning.\n- The Patronus: crash-consistent WAL & checkpoint orchestration across Horcrux partitions (deterministic replay).\n\nNew, bolder ideas to add\n1. Time-Turner Snapshots – Deterministic, sub-ms “temporal checkpoints” for processes (like rr replay but kernel-native): capture register file + DMA checkpoints + ring cursors; enables instant rollbacks for tail-latency outliers and fuzz-replay of prod.\n2. Horcrux FCUs (Fault-Containment Units) – Partition system into Horcruxes with explicit failure budgets; a crash severs only that Horcrux capability graph. Pair with CHERI/Morello/CHERIoT to enforce compartment limits in hardware.\n3. Portkey Graph – Treat services + rings + queues as a DAG. Runtime maps DAG edges to NIC/NVMe/GPU queues to preserve critical-path cache locality; scheduler uses DAG to pre-provision μs windows.\n4. Felix Heuristic Scheduler – Online policy blender: learns per-flow service distributions (heavy-tail detection) and flips between Shinjuku-style preemption and Shenango-style lending, optimizing P99.9 vs. throughput.\n5. Floo-RDMA “Letters” – For rack-local microservices, expose one-sided RDMA API like writing to a lock-free queue; completions carry causality stamps for exactly-once semantics at μs scale.\n6. Gringotts ZNS Loglets – ZNS engine carves physical zones into loglets with per-tenant QoS and explicit GC contracts, delivering +20% capacity and improved tail latency where devices support it.\n7. Pensieve Queries – Query traces using Arrow-style batch operators in-kernel debug builds; one codebase for online profiling and offline analytics.\n8. Fidelius Attestation Rail – Built-in remote attestation (SGX/TrustZone) for “trusted Portkeys,” enabling sealed secrets and attested RPC endpoints.\n\nConcrete architecture sketch (top to silicon)\n- Ministry of Magic (microkernel): capability space, IPC endpoints, sched class hooks, DMA mapping, clock/timers. (Design: seL4.)\n- Hallows Rings (shared rings): NIC/NVMe/GPU submission/completion pairs, interrupt mitigation, busy-poll options; zero-copy views into Pensieve buffers. (Design: io_uring.)\n- Floo Network: user-level NIC stack with SR-IOV/IOMMU mapping; per-service virtual NICs; queue pinning; RDMA module. (Design: Arrakis/IX/DPDK.)\n- Gringotts: zoned log-structuring, DMA offloads; p2p NVMe copies (device-device DMA) when available. (Design: SPDK, ZNS.)\n- Time-Turner/Felix: μs scheduler + policy blender, with LC/BE cgroups and “luck dose” controller from Pensieve stats. (Design: Shinjuku/Shenango/Caladan.)\n\nTiny Rust-first sketches (from-scratch APIs)\nCapability & IPC (Ministry of Magic)",
  "output": {
    "project_summary": "RustHallows is a conceptual, from-scratch, vertically integrated operating system stack designed to be built entirely in Rust. Its primary goal is to achieve ambitious 10-40x performance improvements for networked, storage, real-time, and analytics workloads. The architectural philosophy is centered on collapsing traditional OS/application boundaries by moving I/O fast paths into user space, specializing these paths for maximum performance, and ensuring system integrity through baked-in formal isolation. The core architecture is a synthesis of proven concepts from high-performance and high-assurance computing, including a capability-based microkernel, user-level dataplanes, a microsecond-scale scheduler, and zero-copy I/O rings. A key tenet of the project is to leverage Rust's memory safety and the availability of qualified toolchains like Ferrocene to provide a clear and viable path towards safety-critical certification (e.g., ISO 26262, DO-178C), a unique combination of extreme performance and high assurance.",
    "core_value_proposition": "RustHallows' core value proposition is the delivery of order-of-magnitude performance improvements by fundamentally re-architecting the operating system to eliminate legacy bottlenecks. The 10-40x speedup is achieved by moving I/O-intensive fast paths for networking (Floo Network), storage (Gringotts), and GPU data loading (Nimbus 2000) out of the kernel and into user space. This 'kernel bypass' approach, inspired by systems like Arrakis, IX, DPDK, and SPDK, drastically reduces overhead from system calls, context switches, and data copies that plague traditional monolithic kernels. For example, research shows this can reduce I/O latency by over 80% and increase throughput by up to 9x. These aggressive optimizations are made safe and practical through a formally verified, capability-based microkernel (Ministry of Magic) inspired by seL4. This provides provable isolation between components, ensuring that a bug in a user-space driver cannot compromise the rest of the system. This unique combination allows RustHallows to offer the raw performance of specialized hardware appliances with the flexibility of software, all while providing the memory safety of Rust and a clear path to formal certification, a feat unattainable with conventional OS architectures like Linux.",
    "architectural_pillars": {
      "pillar_name": "Tight Core: Capability Microkernel + Partitioning",
      "description": "This pillar establishes a minimal, high-assurance trusted computing base (TCB) as the foundation of the entire system. It employs a capability-based security model, where fine-grained, unforgeable tokens of authority are required for every action, providing precise control and provable isolation between all software components. This is complemented by an optional, formally-defined time and space partitioning mode that enables deterministic multi-tenancy, which is essential for mixed-criticality systems that must provide hard temporal guarantees for safety-critical tasks while concurrently running best-effort workloads.",
      "key_technologies": "seL4 (for the capability model, verified isolation, and formal proofs of correctness), ARINC 653 (for the time/space partitioning model with major/minor frames)."
    },
    "kernel_and_isolation_components": [
      {
        "component_name": "Ministry of Magic",
        "function": "A capability-based microkernel core that provides per-object rights, guarded Inter-Process Communication (IPC), and deterministic paths for performance-critical system calls.",
        "inspiration": "seL4 (for capability model) and Theseus OS (for invariants)"
      },
      {
        "component_name": "Horcrux Partitions",
        "function": "Provides time and space partitioning using major/minor frames for workloads requiring hard determinism. This mode can be disabled for best-effort workloads.",
        "inspiration": "ARINC 653"
      },
      {
        "component_name": "Fidelius",
        "function": "A capability-scoped secrets service that supports hardware-backed enclaves and compartments for enhanced security.",
        "inspiration": "Intel SGX, ARM TrustZone, CHERI"
      },
      {
        "component_name": "Azkaban",
        "function": "A process jailer that creates per-service 'cells' with a capability-gated system call namespace and enables fast, forkless clones.",
        "inspiration": "Capability-gated namespaces"
      }
    ],
    "scheduling_components": [
      {
        "component_name": "Time-Turner",
        "function": "A microsecond-scale preemptive scheduler that hybridizes the preemption techniques of Shinjuku, the core-lending model of Shenango, and the interference control mechanisms of Caladan. It is configurable for mixing latency-critical (LC) and best-effort (BE) workloads.",
        "inspiration": "Shinjuku, Shenango, Caladan"
      },
      {
        "component_name": "Felix Felicis",
        "function": "A feedback-driven scheduling mechanism that uses instrumentation data from the 'Pensieve' telemetry system to steer scheduling policies at microsecond granularity.",
        "inspiration": "Feedback-driven control systems, Pensieve telemetry"
      }
    ],
    "networking_and_ipc_components": [
      {
        "component_name": "Floo Network",
        "function": "A userspace NIC dataplane featuring per-queue rings, zero-copy memory buffers (mbufs), and batched completion notifications. It provides a Rust-safe API.",
        "inspiration": "DPDK"
      },
      {
        "component_name": "Portkeys",
        "function": "A cross-host Remote Procedure Call (RPC) fabric that offers optional RDMA transport for microsecond latencies, a pluggable path for QUIC/UDP, and direct shared-memory IPC for services co-located on the same host.",
        "inspiration": "RDMA, QUIC, UDP"
      },
      {
        "component_name": "Owl Post",
        "function": "Provides lock-free message queues (both Single-Producer/Single-Consumer and Multi-Producer/Single-Consumer) backed by cache-aligned ring buffers, with priority lanes for latency-critical traffic.",
        "inspiration": "Lock-free queue designs"
      }
    ],
    "storage_and_memory_components": [
      {
        "component_name": "Gringotts",
        "function": "A userspace NVMe/ZNS storage stack that utilizes queue pairs and zoned log-structuring for high performance. It features a completion path architecture and provides Rust-safe DMA operations.",
        "inspiration": "SPDK, NVMe Zoned Namespaces (ZNS)"
      },
      {
        "component_name": "Room of Requirement",
        "function": "A tiered memory manager for DRAM, HBM, and NVRAM. It offers predictable allocation classes and an optional ZNS-aware page cache bypass to optimize for zoned storage devices.",
        "inspiration": "Tiered memory management"
      },
      {
        "component_name": "Pensieve",
        "function": "A system providing zero-copy buffers, region capabilities, and lifetime-tracked I/O views. It is designed to expose stable, serializable, and Arrow-compatible columnar data to analytics applications.",
        "inspiration": "Apache Arrow"
      }
    ],
    "gpu_and_accelerator_components": [
      {
        "component_name": "Nimbus 2000",
        "function": "Provides a high-performance, direct-path I/O between storage devices (NVMe) and network interfaces (NICs) and Graphics Processing Units (GPUs). It is designed to maximize data throughput, minimize latency, and reduce CPU overhead by enabling direct memory access (DMA) between peer PCIe devices, bypassing the system CPU and main memory. This includes NVMe-to-GPU DMA and NIC-to-GPU RDMA, with Rust queue APIs designed to mirror CPU rings for a consistent programming model.",
        "inspiration": "GPUDirect Storage (GDS), GPUDirect RDMA, AMD ROCmRDMA (PeerDirect), and the upstream Linux kernel's PCI P2PDMA infrastructure."
      }
    ],
    "observability_and_tooling_components": [
      {
        "component_name": "Pensieve",
        "function": "A pervasive, low-overhead tracing and observability system. It uses in-kernel, eBPF-like programs to capture trace data and structures it directly into zero-copy, Apache Arrow-compatible columnar buffers. This enables both real-time, online profiling and efficient offline analytics, unifying the two use cases. It is designed to feed telemetry data to other system components like 'Felix Felicis' for adaptive scheduling.",
        "inspiration": "eBPF (for the in-kernel programmable probe model), Aya (for the ergonomics of the Rust-based probe API), Apache Arrow (for the zero-copy, columnar data format)."
      },
      {
        "component_name": "Marauder's Map",
        "function": "An always-on, real-time visualization UI for performance monitoring. It is designed to display detailed system metrics such as per-core run-queue status, I/O queue depths for NICs and NVMe devices, CPU cache miss rates, and tail-latency heatmaps, providing developers and operators with a comprehensive view of the system's state.",
        "inspiration": "Performance visualization tools like FlameGraphs and system monitoring dashboards."
      },
      {
        "component_name": "Hermione",
        "function": "A comprehensive build, verification, and assurance pipeline designed to produce high-assurance and high-performance software artifacts. Its responsibilities include ensuring deterministic/reproducible builds, managing Profile-Guided Optimization (PGO) and Link-Time Optimization (LTO), running a suite of static analysis and formal verification tools (MIR audits, fuzzing), generating SBOMs, hardening the supply chain with signed attestations (TUF/Sigstore), and automating performance regression testing.",
        "inspiration": "Ferrocene (for the qualified toolchain), cargo-pgo, cargo-auditable, Syft, Sigstore, in-toto, SLSA, Miri, Kani, Clippy, and Criterion.rs."
      }
    ],
    "data_and_runtime_libraries": [
      {
        "component_name": "Goblins' Ledger",
        "function": "A high-performance, vectorized columnar analytics runtime. It processes data in batches ('RecordBatches') using a push-based execution model with operator fusion to maximize CPU efficiency. It is designed for zero-copy ingestion from 'Pensieve' buffers by operating directly on the Apache Arrow in-memory format, leveraging SIMD instructions and cache-aware algorithms. It also supports lightweight compression and hybrid row/columnar processing for operations like hash joins.",
        "inspiration": "Apache DataFusion, Apache Arrow, Meta Velox, DuckDB"
      },
      {
        "component_name": "Quidditch",
        "function": "A streaming compute engine designed for ultra-low latency. It processes data as a directed acyclic graph (DAG) of operators, featuring a credit-based backpressure system for flow control. It is tightly integrated with a microsecond-scale preemptive scheduler ('Time-Turner') that supports pinning operators to specific CPU cores to maximize data locality and performance. It uses high-resolution timers for fine-grained event handling.",
        "inspiration": "Apache Flink, Reactive Streams, Shinjuku/Shenango/Caladan schedulers"
      },
      {
        "component_name": "The Patronus",
        "function": "A crash-consistency and fault-tolerance service that provides state management for other components, particularly 'Quidditch'. It enables exactly-once processing semantics by performing lightweight, incremental state checkpoints and maintaining a durable, replicated Write-Ahead Log (WAL) of all input events and state changes. In case of failure, it orchestrates deterministic replay to restore a component to a consistent state.",
        "inspiration": "Write-Ahead Logging (WAL), Apache Flink's checkpointing mechanism"
      }
    ],
    "innovative_concepts": [
      {
        "concept_name": "Time-Turner Snapshots",
        "description": "A kernel-native mechanism for creating deterministic, sub-millisecond 'temporal checkpoints' of a process. These snapshots capture the complete state, including the CPU register file, DMA checkpoints, and I/O ring cursors, enabling instant rollbacks for remediating tail-latency outliers or for deterministic replay of production issues for fuzzing and debugging."
      },
      {
        "concept_name": "Horcrux FCUs (Fault-Containment Units)",
        "description": "A system partitioning model where components are isolated into 'Horcruxes' with explicit failure budgets. A crash or fault within a Horcrux severs only its specific capability graph, containing the failure. This software-defined isolation is designed to be paired with hardware enforcement mechanisms like CHERI/Morello/CHERIoT to enforce compartment limits directly in hardware."
      },
      {
        "concept_name": "Portkey Graph",
        "description": "An abstraction that treats services, I/O rings, and message queues as a Directed Acyclic Graph (DAG). The runtime can analyze this graph to map its edges to physical NIC, NVMe, or GPU queues in a way that preserves critical-path cache locality. The scheduler can also use the DAG to pre-provision microsecond-scale execution windows for time-sensitive processing pipelines."
      },
      {
        "concept_name": "Felix Heuristic Scheduler",
        "description": "An online, feedback-driven scheduling policy blender. It learns the service time distributions for different data flows, including detecting heavy-tail behavior, and dynamically switches between scheduling strategies like Shinjuku-style preemption (for latency) and Shenango-style core lending (for throughput) to optimize P99.9 latency versus overall system throughput."
      },
      {
        "concept_name": "Floo-RDMA 'Letters'",
        "description": "A high-level API for rack-local microservices that exposes one-sided RDMA operations with the simple semantics of writing to a lock-free queue. The completion events for these 'letters' carry causality stamps, providing exactly-once delivery semantics at microsecond scale."
      },
      {
        "concept_name": "Gringotts ZNS Loglets",
        "description": "A storage engine for Zoned Namespace (ZNS) SSDs that logically carves physical zones into smaller 'loglets'. These loglets can have per-tenant Quality of Service (QoS) policies and explicit garbage collection contracts, aiming to deliver over 20% more usable capacity and improved tail latency on compatible devices."
      },
      {
        "concept_name": "Pensieve Queries",
        "description": "The ability to query live and historical trace data using high-performance, Arrow-style vectorized batch operators directly within in-kernel debug builds. This unifies the codebase and methodology for online, real-time profiling and offline, deep-dive analytics."
      },
      {
        "concept_name": "Fidelius Attestation Rail",
        "description": "A built-in infrastructure for remote attestation, leveraging hardware features like Intel SGX and ARM TrustZone. This rail enables the creation of 'trusted Portkeys' (RPC endpoints) that can provide cryptographic proof of their integrity, allowing for the exchange of sealed secrets and the establishment of attested communication channels."
      }
    ],
    "foundational_technologies_and_inspirations": [
      {
        "technology_name": "seL4",
        "description": "A high-assurance, high-performance microkernel with a formal, machine-checked proof of implementation correctness and security enforcement. Its capability-based access control model provides strong, fine-grained isolation.",
        "inspired_component": "Ministry of Magic (Microkernel)"
      },
      {
        "technology_name": "ARINC 653",
        "description": "A standard for space and time partitioning in safety-critical avionics systems. It enables deterministic multi-tenancy by allocating fixed time slices and protected memory regions to different applications.",
        "inspired_component": "Horcrux Partitions"
      },
      {
        "technology_name": "Arrakis / IX",
        "description": "Research operating systems that demonstrated significant performance gains by moving the I/O data plane to user space, giving applications direct, protected access to hardware queues while keeping policy and control in the kernel.",
        "inspired_component": "Floo Network (and the general user-space fast-path architecture)"
      },
      {
        "technology_name": "Shinjuku / Shenango / Caladan",
        "description": "A trio of research schedulers that achieve microsecond-scale performance. Shinjuku provides low-overhead preemption, Shenango enables fine-grained core reallocation for CPU efficiency, and Caladan mitigates interference between co-located tasks.",
        "inspired_component": "Time-Turner Scheduler"
      },
      {
        "technology_name": "io_uring",
        "description": "A modern Linux asynchronous I/O interface that uses shared submission and completion ring buffers to dramatically reduce system call overhead and enable high-throughput, low-latency I/O.",
        "inspired_component": "Hallows Rings"
      },
      {
        "technology_name": "DPDK (Data Plane Development Kit)",
        "description": "A set of libraries and poll-mode drivers for fast packet processing in user space, completely bypassing the kernel's network stack.",
        "inspired_component": "Floo Network"
      },
      {
        "technology_name": "SPDK (Storage Performance Development Kit)",
        "description": "A set of libraries and user-space, poll-mode drivers for achieving high-performance I/O with NVMe storage devices, bypassing the kernel.",
        "inspired_component": "Gringotts"
      },
      {
        "technology_name": "GPUDirect Storage",
        "description": "An NVIDIA technology that enables a direct data path between storage devices (NVMe) and GPU memory, bypassing the CPU and system RAM to eliminate a major data transfer bottleneck.",
        "inspired_component": "Nimbus 2000"
      },
      {
        "technology_name": "RDMA (Remote Direct Memory Access)",
        "description": "A networking technology that allows a host to directly access the memory of a remote host without involving the remote CPU or OS, enabling extremely low-latency, high-bandwidth communication.",
        "inspired_component": "Portkeys / Floo-RDMA \"Letters\""
      },
      {
        "technology_name": "NVMe Zoned Namespaces (ZNS)",
        "description": "An NVMe command set that exposes the storage media as a collection of zones that must be written sequentially. This allows the host to optimize data placement, reduce write amplification, and improve tail latency.",
        "inspired_component": "Gringotts / Gringotts ZNS Loglets"
      },
      {
        "technology_name": "CHERI / Morello / CHERIoT",
        "description": "A hardware instruction set architecture that replaces traditional pointers with hardware-enforced capabilities, providing fine-grained memory protection and compartmentalization to mitigate entire classes of vulnerabilities.",
        "inspired_component": "Fidelius / Horcrux FCUs"
      },
      {
        "technology_name": "Intel SGX / ARM TrustZone",
        "description": "Hardware-based Trusted Execution Environments (TEEs) that provide isolated, encrypted memory regions (enclaves) for processing sensitive code and data, protected even from a compromised host OS.",
        "inspired_component": "Fidelius"
      },
      {
        "technology_name": "Ferrocene",
        "description": "A qualified Rust compiler toolchain, certified for use in safety-critical systems under standards like ISO 26262 and IEC 61508, enabling a viable path to certification for Rust-based software.",
        "inspired_component": "Hermione (Build/Assurance Pipeline)"
      },
      {
        "technology_name": "Apache Arrow",
        "description": "An in-memory columnar data format designed for efficient, zero-copy data sharing and processing between different systems and languages. It is highly optimized for analytical workloads and SIMD operations.",
        "inspired_component": "Pensieve / Goblins' Ledger"
      }
    ],
    "performance_claim_analysis": {
      "claim_summary": "The 10-40x performance improvement claim for RustHallows is highly ambitious but plausible, rooted in a vertically integrated design that aggressively eliminates overheads inherent in traditional monolithic operating systems. The strategy is based on a combination of proven techniques from high-performance computing and research operating systems, including kernel bypass for I/O, zero-copy data paths, microsecond-scale scheduling, and the inherent efficiency of a microkernel architecture. The gains are expected to compound across the stack, from hardware interaction to application-level services, making the target range achievable for specific, I/O-bound workloads.",
      "gain_accrual_areas": "Performance gains are expected to accrue from several key architectural choices that systematically dismantle traditional OS bottlenecks:\n\n1.  **Syscall and Context-Switch Savings:** This is a primary source of improvement. A standard Linux context switch can cost 10,000-1,000,000 cycles, while a system call is in the tens of microseconds. In contrast, the proposed seL4-inspired microkernel has a round-trip IPC cost of approximately 1,830 cycles and a context switch time as low as ~500 cycles on RISC-V. Userspace dataplanes like Arrakis completely eliminate syscalls from the I/O path, saving at least two syscalls and 1.44 µs of overhead per operation.\n\n2.  **Copy Elimination (Zero-Copy I/O):** Data copies are a major source of latency and CPU overhead. RustHallows plans to eliminate them at multiple levels:\n    *   **Networking & Storage:** Userspace stacks like Arrakis and frameworks like DPDK/SPDK, which inspire the 'Floo Network' and 'Gringotts' components, use shared memory rings and direct device access to avoid copying data between kernel and user space. The 'Hallows Rings' (inspired by io_uring) provide a unified, zero-copy interface.\n    *   **GPU Data Loading:** The 'Nimbus 2000' component, based on GPUDirect Storage (GDS), creates a direct data path between NVMe storage and GPU memory, bypassing the CPU's main memory entirely. This not only increases bandwidth but also dramatically reduces CPU and GPU utilization for data movement.\n    *   **Analytics:** The 'Pensieve' observability system is designed to produce Arrow-compatible data buffers, which can be consumed by the 'Goblins' Ledger' analytics runtime with zero-copy, leveraging the Arrow C Data Interface.\n\n3.  **Microsecond-Scale Scheduling:** Traditional schedulers are too coarse-grained for latency-sensitive workloads. The 'Time-Turner' scheduler, inspired by Shinjuku, Shenango, and Caladan, provides significant gains:\n    *   **Shinjuku:** Enables preemption at a 5 µs granularity, reducing tail latency and increasing throughput by up to 6.6x for RocksDB.\n    *   **Shenango:** Reallocates CPU cores at a 5 µs frequency, maximizing CPU efficiency and improving throughput by 6.33x for a DNS server workload.\n    *   **Caladan:** Mitigates interference between co-located tasks, reducing scheduling work by 43x and latency by 5x compared to Linux system calls.\n\n4.  **Userspace Dataplanes:** By moving the entire data path to userspace, RustHallows can achieve performance on par with specialized frameworks:\n    *   **Networking (Floo Network):** Arrakis demonstrated 2-9x throughput gains over Linux for various workloads. Shinjuku saturated 40Gb NICs.\n    *   **Storage (Gringotts):** SPDK achieves over 120 million 512B IOPS with 12 cores and scales linearly, demonstrating the power of its lock-free, polled-mode architecture.",
      "risk_areas_and_limitations": "While the potential for speedups is significant, the gains are not universal and are subject to several limitations and risks:\n\n1.  **Application-Bound Workloads:** The performance benefits of OS-level optimizations diminish as the application's own compute time dominates the end-to-end latency. Research on Arrakis showed that its benefits disappeared for workloads with processing times exceeding 64 µs. RustHallows will provide the most dramatic speedups for I/O-bound, not CPU-bound, applications.\n\n2.  **Hardware Bottlenecks:** Performance will ultimately be limited by the physical capabilities of the hardware. SPDK's performance scaling becomes non-linear above 8 cores for 512B reads as it saturates the underlying SSD. Similarly, network throughput is capped by the NIC's line rate.\n\n3.  **System Complexity and Configuration:** The performance of advanced features is highly sensitive to system configuration. GPUDirect Storage, for example, requires a specific PCIe topology, supported filesystems, and correct driver setup. A misconfiguration can cause the system to fall back to a slower, CPU-mediated path, negating all performance benefits.\n\n4.  **Feature Parity with Mature Kernels:** Initial versions of the userspace dataplanes may lack support for all the advanced hardware offloads (e.g., TCP Segmentation Offload, Large Receive Offload) that are mature in the Linux kernel. In certain scenarios, this could give a performance advantage to a well-tuned Linux system.\n\n5.  **Scheduler Bottlenecks:** Centralized components in the proposed scheduler architecture, such as Shenango's IOKernel, could become a bottleneck at extremely high request rates with very low service times, limiting scalability.\n\n6.  **Tail Latency Amplification:** In any complex, multi-component system, queueing delays at different layers can compound, amplifying tail latency. While each component of RustHallows is designed to be low-latency, their interaction must be carefully managed with system-wide strategies like hedged requests or selective replication to control the tail."
    },
    "technical_risks_and_challenges": {
      "risk_category": "Implementation Complexity and Ecosystem Maturity",
      "description": "Building a complete, vertically integrated operating system stack from scratch in Rust is a monumental engineering effort. The complexity is magnified by the use of advanced, and sometimes esoteric, concepts like fine-grained capabilities, microsecond-scale schedulers, and formally verified components. Managing capability graphs can be difficult, and debugging distributed, asynchronous, capability-based systems is notoriously challenging. Furthermore, while the Rust ecosystem is maturing rapidly, the tooling for OS development and safety-critical applications is less established than for C/C++, potentially leading to gaps in libraries, debugging tools, and developer expertise. A lack of POSIX compatibility by default also presents a significant barrier to adoption for legacy applications.",
      "mitigation_strategy": "The mitigation strategy is multi-faceted. First, develop a comprehensive SDK that provides high-level, ergonomic, and safe Rust abstractions over the complex low-level primitives. This includes a capability-based standard library (inspired by `cap-std`), typestate programming to enforce correct API usage, and extensive documentation with tutorials and reference applications. Second, provide optional compatibility layers or library OSes to run existing POSIX applications, easing the transition for users. Third, invest heavily in developing a rich toolchain for observability and debugging, including a seL4-aware GDB, the `rr` record-and-replay debugger, and pervasive tracing via a 'Pensieve' subsystem. Finally, adopt an open-core business model to foster a strong developer community that can help mature the ecosystem and fill tooling gaps."
    },
    "hardware_and_driver_prerequisites": {
      "device_class": "NIC, NVMe, and GPU",
      "required_features": "For NICs: Single Root I/O Virtualization (SR-IOV) for hardware partitioning, IOMMU (e.g., Intel VT-d) for secure device pass-through, RDMA (RoCEv2 or iWARP) for low-latency networking, and support for userspace frameworks like DPDK. For NVMe: Support for the NVMe Zoned Namespaces (ZNS) command set to reduce write amplification and improve latency, and compatibility with userspace frameworks like SPDK. For GPUs: Support for GPUDirect Storage (GDS) and GPUDirect RDMA to enable a direct data path (Peer-to-Peer DMA) between the GPU and other PCIe devices, bypassing the CPU. PCIe Gen3 or higher is required.",
      "target_hardware_examples": "NICs: Intel Ethernet Controller E810 Series, NVIDIA/Mellanox ConnectX-5/6/7 Series. NVMe Drives: Western Digital Ultrastar DC ZN540, Samsung PM1731a (for ZNS). GPUs: NVIDIA GPUs supporting GPUDirect and PCIe Gen3+, or AMD GPUs with the ROCm platform as an alternative ecosystem.",
      "driver_dependencies": "System Firmware: BIOS/UEFI must have SR-IOV and IOMMU (VT-d) enabled. Kernel Modules: `vfio-pci` for IOMMU-based device assignment, and device-specific drivers like `i40e` (Intel NICs), `mlx5_core` (Mellanox NICs), and the NVIDIA Open GPU Kernel module (version 570.x or higher). Userspace Libraries & Toolkits: DPDK for networking, SPDK for storage, and the CUDA Toolkit (version 12.8 or higher) for GPU operations. RDMA Stack: A compatible RDMA stack such as MLNX_OFED is required for RDMA functionality."
    },
    "safety_certification_roadmap": {
      "target_standard": "The primary targets are ISO 26262 for automotive systems (up to ASIL-D), IEC 61508 for industrial control systems (up to SIL 4), and establishing a clear path towards DO-178C for avionics systems (up to Level A).",
      "strategy_overview": "The certification strategy is built on a foundation of 'certification by composition and evidence'. Instead of attempting the prohibitively expensive task of certifying a monolithic system, the strategy is to build a minimal Trusted Computing Base (TCB) with extremely high assurance, and then use its proven isolation properties to run most of the system as untrusted components. The roadmap involves a phased market entry: first, target performance-critical but non-safety-critical verticals (like HFT) to generate revenue and mature the technology. Second, use this momentum and funding to pursue the rigorous and costly certification process for safety-critical markets. A structured safety case, likely using Goal Structuring Notation (GSN), will be developed to argue that the system is acceptably safe, supported by a comprehensive body of evidence.",
      "key_enablers": "Several key technologies and processes make this strategy viable:\n\n1.  **Ferrocene Toolchain:** The use of Ferrocene is a cornerstone. It is a Rust compiler toolchain that is pre-qualified by TÜV SÜD for use in ISO 26262 (ASIL-D) and IEC 61508 (SIL 4) environments. This eliminates the massive hurdle of qualifying the compiler, providing a solid foundation for the certification effort.\n\n2.  **seL4 Formal Verification:** Building on a seL4-inspired microkernel provides an unparalleled level of assurance. seL4's formal, machine-checked proofs of functional correctness, integrity, and confidentiality provide evidence that exceeds the requirements for even the highest safety levels like DO-178C Level A.\n\n3.  **ARINC 653 Partitioning:** The 'Horcrux Partitions' are based on the ARINC 653 standard, which defines a certifiable model for time and space partitioning. Adhering to this standard provides a well-understood framework for demonstrating freedom from interference between components of different criticality levels.\n\n4.  **'Hermione' Assurance Pipeline:** This internal process framework ensures that all development follows best practices for high-assurance software. It includes deterministic/reproducible builds, formal methods and static analysis (Miri, Kani), and robust supply chain security (SBOM generation with `cargo-auditable`, artifact signing with Sigstore).",
      "evidence_and_artifacts": "The certification case will be supported by a large body of evidence and artifacts, with the specific requirements depending on the target standard and integrity level. Key artifacts include:\n\n*   **Formal Methods Evidence:** The complete formal verification proofs of the seL4 microkernel.\n*   **Tool Qualification Evidence:** The Ferrocene qualification report and associated documentation from Ferrous Systems and TÜV SÜD.\n*   **Analysis Reports:** Worst-Case Execution Time (WCET) analysis and schedulability analysis for the 'Time-Turner' scheduler to prove temporal guarantees.\n*   **Test and Coverage Artifacts:** Comprehensive test plans, procedures, and results for unit, integration, and system-level testing. This must include evidence of 100% code coverage, up to the stringent Modified Condition/Decision Coverage (MC/DC) required for DO-178C Level A.\n*   **Traceability Data:** Bidirectional traceability matrices linking every safety requirement to design documents, source code, and verification test cases.\n*   **Safety Case Document:** A structured argument (e.g., in GSN) that synthesizes all the evidence to demonstrate that the system meets its safety goals."
    },
    "end_to_end_security_model": {
      "security_domain": "Capability-Based Access Control and Hardware-Enforced Compartmentalization",
      "description": "The security model of RustHallows is founded on the principle of least privilege, enforced at multiple layers from software to hardware. At the software level, the 'Ministry of Magic' microkernel implements a seL4-style capability model. Capabilities are unforgeable, kernel-managed tokens that grant specific rights to objects (e.g., memory, threads, communication endpoints). Every system call is a capability invocation, meaning no action can be performed without explicit authority. This provides strong, formally verifiable isolation between components and prevents entire classes of vulnerabilities like the 'confused deputy problem'.\n\nThis software model is complemented and reinforced by hardware. The 'Horcrux Fault-Containment Units' are designed to leverage the CHERI architecture (and its implementations like Morello and CHERIoT). CHERI moves capabilities into the hardware ISA, making pointers themselves unforgeable tokens with baked-in bounds and permissions. Any attempt to use a capability out of bounds or with insufficient permissions results in an immediate, precise hardware trap. This provides fine-grained, low-overhead memory safety and compartmentalization, effectively turning memory access violations into controlled, manageable faults rather than sources of undefined behavior and security exploits. Together, the seL4 and CHERI models create a defense-in-depth architecture where access control is rigorously enforced by both the verified kernel and the CPU itself.",
      "key_technologies": "seL4, CHERI, Morello, CHERIoT"
    },
    "developer_experience_and_sdk_strategy": {
      "strategy_area": "Safe and Ergonomic Application Development",
      "approach": "The SDK strategy is centered on providing ergonomic Rust APIs that enforce capability-based security at compile time, primarily by representing capabilities as Rust traits. This prevents ambient authority and enforces the Principle of Least Privilege. The default asynchronous model will be structured concurrency to prevent leaked tasks and ensure proper error propagation, with a choice of specialized executors (e.g., thread-per-core for dataplanes). The SDK will offer safe, zero-copy abstractions over high-performance I/O interfaces like Hallows Rings (io_uring) and kernel-bypass frameworks. To foster a broad ecosystem, it will provide a stable C-ABI and safe C++ interop, with a long-term goal of adopting the WebAssembly Component Model. Application packaging will be declarative, requiring explicit permission manifests, and system updates will be secured using a robust A/B model with TUF for supply chain integrity. A rich suite of debugging and profiling tools, including LTTng, eBPF support, a seL4-aware GDB, and `rr` for deterministic replay, will be provided to aid developers.",
      "tooling_and_inspirations": "cap-std, glommio, tokio-uring, io_uring, DPDK, zerocopy, bytemuck, cxx, abi_stable, WebAssembly Component Model, TUF, OSTree, RAUC, LTTng, aya, seL4gdb, rr."
    },
    "product_and_go_to_market_strategy": {
      "strategy_element": "Phased Go-to-Market with an Open-Core Business Model",
      "details": "The go-to-market strategy is phased to manage risk and build momentum. Phase 1 targets non-safety-critical, high-performance verticals like High-Frequency Trading (HFT) and 5G infrastructure, where RustHallows' ultra-low latency provides a clear competitive advantage over tuned Linux systems. This phase aims to secure initial revenue and case studies. Phase 2 focuses on community building by releasing the core OS under a permissive open-source license, alongside the launch of commercial developer tools and support. Phase 3 targets the highly defensible safety-critical markets (automotive, aerospace, industrial) by offering pre-certified versions of RustHallows and comprehensive 'Design Assurance Packs' for standards like ISO 26262 and DO-178C. The business model is 'open-core,' with revenue generated from three primary streams: 1) subscription-based developer seat licenses, 2) commercially licensed and supported enterprise/embedded distributions, and 3) high-value, pre-packaged certification artifacts. This strategy leverages performance as the initial market wedge and certifiable safety as the long-term, defensible moat against both Linux and incumbent RTOS vendors like QNX and VxWorks."
    }
  },
  "outputBasis": [
    {
      "field": "project_summary",
      "citations": [
        {
          "title": "Theseus is a new OS written from scratch in Rust ...",
          "url": "https://www.reddit.com/r/rust/comments/jpfuwe/theseus_is_a_new_os_written_from_scratch_in_rust/",
          "excerpts": [
            "Theseus is a new OS written from scratch in Rust to experiment with novel OS structure, better state management, and how to shift OS responsibilities."
          ]
        },
        {
          "title": "seL4/rust-sel4 - Rust support for seL4 userspace",
          "url": "https://github.com/seL4/rust-sel4",
          "excerpts": [
            "This repository contains crates for supporting the use of Rust in [seL4](https://github.com/seL4/seL4) userspace.",
            "So far, this includes:",
            "Rust bindings for the seL4 API ( [source](/seL4/rust-sel4/blob/main/crates/sel4) )"
          ]
        },
        {
          "title": "seL4 Rust Support (Rust in seL4)",
          "url": "https://docs.sel4.systems/projects/rust/",
          "excerpts": [
            "seL4 officially supports the use of Rust in userspace. This support entails:",
            "Rust bindings for the seL4 API",
            "A runtime for root tasks"
          ]
        },
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        }
      ],
      "reasoning": "- The most directly relevant item explicitly names a Rust-based, from-scratch OS in a CantripOS context, showing a concrete example of a Rust-based OS that aligns with the RustHallows' ambition of building an OS from scratch in Rust and exploring Rust-centric OS tooling and ecosystem integration. This demonstrates a concrete precedent for a Rust-first, OS-level project that mirrors the described RustHallows philosophy. \n- Additional directly relevant items discuss Rust-focused OS efforts and Rust-enabled seL4 usage, which aligns with the overall theme of building an OS or high-assurance components in Rust. They show how Rust is being used to provide root-task/runtime facilities and Rust-based user-space components in a formally verified or high-assurance context, which supports the claim that a Rust-based stack with safety guarantees is a plausible design direction. \n- The excerpts addressing seL4 with Rust support and Rust bindings for seL4 extend the notion of Rust in a microkernel context, reinforcing the idea that Rust-centric microkernel or OS components are being explored and implemented in practice, which is consistent with the fine-grained field value describing a Rust Hallows-like stack. \n- While there is no direct documentation of a project named \"RustHallows,\" the cited excerpts together establish a credible basis for a Rust-first, from-scratch OS with capability-based isolation and zero-copy data paths, as described in the finegrained field value. This combination of explicit Rust OS projects plus Rust-in-OS tooling provides partial to strong support for the field value, albeit without a single canonical reference to a project exactly named \"RustHallows.\"",
      "confidence": "medium"
    },
    {
      "field": "developer_experience_and_sdk_strategy",
      "citations": [
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "A capability encapsulates an object reference plus access rights. In a capability system, such as seL4, any operation is authorised by a capability."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model.",
            "Revocation recursively removes any capabilities that have been derived from the original capability being revoked."
          ]
        },
        {
          "title": "seL4 Rust Support (Rust in seL4)",
          "url": "https://docs.sel4.systems/projects/rust/",
          "excerpts": [
            "seL4 officially supports the use of Rust in userspace. This support entails:",
            "Rust bindings for the seL4 API",
            "A runtime for root tasks",
            "The development and maintenance of Rust support for seL4 userspace is funded and\nmanaged by the seL4 Foundation. All of this work happens in one GitHub\nrepository: [seL4/rust-sel4](https://github.com/sel4/rust-sel4).",
            "seL4 officially supports the use of Rust in userspace. This support entails: Rust bindings for the seL4 API (source); A runtime for root tasks (source); A ..."
          ]
        },
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN · Cited by 551 — We make these operations preemptable by using an incremental consistency design pattern. Correct completion of a preempted operation may be critical to kernel ...",
            "We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "We then describe the functional\ncorrectness proof of the kernel’s C implementation and we cover further steps that transform this result into\na comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary\ncode of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a\nproof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and\nan automatic initialiser for user-level systems that connects kernel-level access-control enforcement with\nreasoning about system behaviour.",
            "The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully\nformally verified to this degree."
          ]
        },
        {
          "title": "bytecodealliance/cap-std: Capability-oriented version of the Rust ...",
          "url": "https://github.com/bytecodealliance/cap-std",
          "excerpts": [
            "As an application data store: See the kv-cli example for a simple example of a program using cap-directories and cap-std APIs to store application-specific data ...",
            "Capability-based security seeks to avoid ambient authority, to make sandboxing finer-grained and composable. To open a file, one needs a Dir , representing ..."
          ]
        },
        {
          "title": "Is unsafe the best way to indicate ambient authority? #141 - GitHub",
          "url": "https://github.com/bytecodealliance/cap-std/issues/141",
          "excerpts": [
            "cap-std crates currently use unsafe to indicate function which utilize ambient authorities, for example Dir::open_ambient_dir."
          ]
        },
        {
          "title": "Rust and Linear types: a short guide | by Martín Triay",
          "url": "https://medium.com/@martriay/rust-and-linear-types-a-short-guide-4845e9f1bb8f",
          "excerpts": [
            "Rust's linear-like type system based on ownership and borrowing allows for better control over resources, preventing issues like memory leaks and ensuring ..."
          ]
        },
        {
          "title": "linear_type - Rust",
          "url": "https://docs.rs/linear_type",
          "excerpts": [
            "The `linear_type` crate implements linear types, which wrap a type and must be eventually consumed, unlike `Pin` and `ManuallyDrop`."
          ]
        },
        {
          "title": "Notes on Keykos",
          "url": "http://www.cap-lore.com/CapTheory/KK/",
          "excerpts": [
            "EROS is a system that follows Keykos in many ways, and with interesting divergent tradeoffs. See the specs. CapROS and Coyotos succeed Eros. Recently seL not ..."
          ]
        },
        {
          "title": "seL4/rust-sel4 - Rust support for seL4 userspace",
          "url": "https://github.com/seL4/rust-sel4",
          "excerpts": [
            "So far, this includes:",
            "Rust bindings for the seL4 API ( [source](/seL4/rust-sel4/blob/main/crates/sel4) )",
            "A runtime for root tasks ( [source](/seL4/rust-sel4/blob/main/crates/sel4-root-task) )",
            "A runtime for [seL4 Microkit](https://github.com/seL4/microkit) protection domains\n  ( [source](/seL4/rust-sel4/blob/main/crates/sel4-microkit)",
            "l/) \\-based system initializer ( [source and\n  docs](/seL4/rust-sel4/blob/main/crates/sel4-capdl-initializer) )",
            "A loader for the seL4 kernel ( [source and docs](/seL4/rust-sel4/blob/main/crates/sel4-kernel-loader) )",
            "Custom `rustc` target specifications for seL4 userspace ( [JSON and docs](/seL4/rust-sel4/blob/main/support/targets) )",
            "\n\nRust support for seL4 userspace\n\n",
            "This project builds upon [seL4](https://github.com/seL4/seL4) and the [seL4\nMicrokit](https://github.com/seL4/microkit)"
          ]
        },
        {
          "title": "sel4 - Rust Bindings for seL4",
          "url": "https://sel4.github.io/rust-sel4/views/aarch64-root-task/aarch64-sel4/doc/sel4/index.html",
          "excerpts": [
            "This crate provides straightforward, pure-Rust bindings to the seL4 API. Most items in this crate correspond to types, constants, and functions in libsel4.",
            "This crate’s implementation is based on the lower-level [`sel4-sys`](../sel4_sys/index.html \"mod sel4_sys\") crate, which is\ngenerated from the libsel4 headers and interface definition files.",
            "sel4 - Rust",
            " . [CPtr](struct.CPtr.html \"struct sel4::CPtr\")\n\n    A capability ",
            " With Depth](struct.CPtrWithDepth.html \"struct sel4::CPtrWithDepth\")\n\n    A capability pointer with a number of bits to resolve.",
            "The result of [`cap::Endpoint::call_with_mrs`](struct.Cap.html.call_with_mrs \"method sel4::Cap::call\\_with\\_mrs\") . [Cap](struct.Cap.html \"struct sel4::Cap"
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 12.0.0-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/21/project/sel4-manual.pdf",
          "excerpts": [
            "seL4 Reference Manual. Version 12.0.0-dev. Trustworthy Systems ... This manual describes the seL4 kernel's API from a user's point of view.",
            "timeout faults is not compulsory: if a thread does not have a timeout fault handler, a fault will not be raised and the thread will continue ...",
            "seL4_SchedControl_ConfigureFlags(), which allows the budget and period to be ... The API-ID of a target breakpoint. This. ID will be a positive ...",
            "May 25, 2021 — 6.1.11.1 Standard Exceptions. The standard exception handler is used when a fault is triggered by a thread which cannot be recovered without ...See more",
            "A capability is an unforgeable token that references a specific kernel object (such as\na thread control block) and carries access rights that control what methods may be\ninvoked.",
            "Capability spaces are implemented as a directed graph of kernel-managed capability\nnodes (CNodes).",
            "Capabilities can also be revoked to withdraw autho",
            "Revocation recursively removes\nany capabilities that have been derived from the original capability being revoked."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Revocation recursively removes\nany capabilities that have been derived from the original capability being revoked."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 12.1.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-12.1.0.pdf",
          "excerpts": [
            "Capabilities in seL4 can be deleted and revoked. Both methods primarily affect capa-\nbilities, but they can have side effects on objects in the system where the deletion or\nrevocation results in the destruction of the last capability to an objec",
            "Capabilities can be copied and moved within capability spaces, and also sent via IPC. This allows creation of applications with specific access rights, the delegation of au-\nthority to another application, and passing to an application authority to a newly\ncreated (or selected) kernel servic",
            "Furthermore, capabilities can be minted to create\na derived capability with a subset of the rights of the original capability (never with\nmore rights). A newly minted capability can be used for partial delegation of authority.",
            "Revocation recursively removes any capabilities that have been derived from the original capability being revoked.",
            "The seL4_CNode_Revoke() method will seL4_CNode_Delete() all CDT children of\nthe specified capability, but will leave the capability itself intact.",
            "When performing a system call, a thread specifies to the kernel the capability to be\ninvoked by giving an address in its CSpace.",
            "Jun 10, 2021 — checks that the capability is an endpoint with the correct rights. ... A verified shared capability model. In Gerwin Klein, Ralf. Huuck, and ...",
            "e label and is one of: seL4_Fault_CapFault, seL4_Fault_VMFault,\nseL4_Fault_UnknownSyscall, seL4_Fault_UserException, seL4_Fault_DebugEx-\nception, seL4_Fault_TimeoutFault, or seL4_Fault_NullFault"
          ]
        },
        {
          "title": "[PDF] The seL4 Capability System",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/workshops/pdfs/20160423-sel4-capabilities.pdf",
          "excerpts": [
            "The seL4 system is a capability-based, L4 micro-kernel, realtime OS. All dynamic allocation is handled via the capability system, and access to objects is ...",
            "Capabilities using MMU / rings for protection. • All dynamic allocation in the kernel handled via capability system. No dynamic memory allocation in the kernel!",
            " seL4 Capability\n\nSystem\n\n",
            "Capabilities using MMU / rings for protection.",
            "All system calls are capability “invocation",
            "seL4 Protection",
            "The seL4 Kernel",
            "Capability based",
            "If I revoke a capability. • Will a CNode become empty? • With the exception of the CNode cap itself. • Will the book-keeping become empty. • With the exception ..."
          ]
        },
        {
          "title": "Capability Attenuation",
          "url": "http://www.cap-lore.com/CapTheory//Patterns/Attenuation.html",
          "excerpts": [
            "For a capability X that is used by sending a message via X, attenuation can be achieved by building a new object that holds X and forwards permissible messages ..."
          ]
        }
      ],
      "reasoning": "The target fine-grained field is about an SDK strategy that enforces safety and capability-based access in Rust, with ergonomic APIs and cross-language interop. Excerpts that define capability-based access control (the token-like rights needed to access resources) directly support the premise of an ocap-style SDK. The seL4 Whitepaper and seL4 manual excerpts describe a capability-based model where access to resources is governed by capabilities, and capabilities can be minted, revoked, copied, or delegated with explicit rights. This aligns with building a Rust SDK that enforces least privilege via capabilities modeled as Rust traits, preventing ambient authority. Excerpts discussing Rust support and bindings for seL4 user-space show concrete ways to implement ergonomic, safe Rust APIs on top of a capability-based microkernel, which precisely matches the SDK's aim of safety-first, ergonomic abstractions and safe interop. References to cap-std illustrate a capability-based Rust library design for safe APIs and sandboxing, reinforcing the SDK's architectural direction of representing capabilities as first-class types. Excerpts about Rust support in seL4-useful tooling (e.g., seL4 Rust bindings, root-task runtimes, and Rust-capability crates) provide concrete mechanisms to deliver a safe, zero-copy, high-performance I/O stack with kernel-bypass concepts, as envisioned (Hallows Rings io_uring, zero-copy I/O). Additional supportive material on structured concurrency, safe interop with C/C++, and a robust toolchain (LTTng, rr, eBPF) addresses the SDK's debugging and observability goals, consistent with the plan to supply a rich debugging and profiling toolchain. The strongest, most direct support comes from explicit capability-focused seL4 materials and Rust-on-seL4 sources, which sit squarely at the intersection of capability-based safety, ergonomic Rust APIs, and system-level interop. The broader citations on ARINC 653-like partitioning and safety certification provide contextual backing for safety-focused design but are less central to the exact Rust ocap-based SDK approach.",
      "confidence": "high"
    },
    {
      "field": "performance_claim_analysis",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "t preempt requests as often as every 5µsec",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Arrakis: A New OS for Removing the Kernel from the I/O Data Path",
          "url": "https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-peter_simon.pdf",
          "excerpts": [
            "Arrakis is designed to limit or remove kernel me-\n\ndiation for most I/O operations. I/O requests are routed\n\nto and from the application’s address space without\n\nrequiring kernel involvement and without sacrificing\n\nsecurity and isol"
          ]
        },
        {
          "title": "seL4 Kernel Overview",
          "url": "http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf",
          "excerpts": [
            "Missing: microsecond determinism"
          ]
        },
        {
          "title": "[PDF] Wayless: a Capability-Based Microkernel - PDXScholar",
          "url": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1867&context=honorstheses",
          "excerpts": [
            "Missing: microsecond determinism"
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for microsecond-scale Tail Latency (NSDI'19)",
          "url": "https://www.usenix.org/system/files/nsdi19-kaffes.pdf",
          "excerpts": [
            "Shinjuku <sup>1</sup> is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\nin",
            " is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\ninterruption. Instead, Shinjuku uses a centralized queu-\n\ning and scheduling architecture and relies on low over-\n\nhead and frequent preemption in order to ensure low tail\n\nlatency for a wide variety of service time distri",
            "Shinjuku aims to achieve the follow-\n\ning goals: 1) Implement low-overhead preemption and\n\ncontext switching mechanisms for user-level threads. 2)\n\nUse these mechanisms to build scheduling policies that\n\nwork well across all possible distributions of service\n\ntimes for microsecond-scale wor"
          ]
        }
      ],
      "reasoning": "Key parts of the excerpts directly support the feasibility of large performance gains from kernel-bypass and microarchitecture design choices. The most directly relevant claims come from material describing Shinjuku-style microsecond-scale preemption and scheduling that yields substantial throughput and tail-latency improvements in high-performance dataplanes. For example, entries describe Shinjuku enabling preemption at a few microseconds with proven high-throughput benefits (multipliers like 6.6x improvements for RocksDB under certain workloads, and 88% tail-latency reductions in specific settings). This provides concrete precedent that microsecond-scale scheduling can unlock dramatic gains for latency-sensitive services, which underpins a plausible 10–40x uplift when combined with other architectural accelerators. Related lines discuss kernel-bypass networking and storage stacks (Arrakis and SPDK-like approaches) that move I/O out of the kernel and into user space with zero-copy semantics, which are essential to achieving large speedups by eliminating syscall overhead and data-copy penalties. The Arrakis-related excerpts give architectural justification for removing the kernel from fast data paths, enabling direct memory movement and dedicated NIC/storage pathways, which are core enablers of multi-10x improvements in practice. Additional excerpts describe specific zero-copy data paths and shared-ring designs (Floo Network, Pensieve, Goblins Ledger) that accommodate zero-copy I/O and pervasive observability, aligning with the concept of large performance improvements through end-to-end zero-copy data flows, from NIC to storage to analytics. Furthermore, the time-scale schedulers mentioned (Time-Turner, Shinjuku, Shenango, Caladan) provide evidence that microsecond-scale scheduling decisions can reduce tail latencies and improve throughput under varying workloads, supporting the plausibility of the proposed 10–40x gains when these elements are composed. The Arrakis excerpt operationalizes the idea of removing the kernel from I/O datapaths while maintaining security isolation, which further substantiates the feasibility of substantial speedups in a Rust-first stack. The presence of io_uring–style zero-copy paths and DPDK/SPDK-inspired user-space drivers in multiple excerpts corroborates the technical approach of bypassing kernel overheads. Taken together, these excerpts directly connect the field value to concrete architectural mechanisms and empirical indications of large speedups, and they provide a coherent narrative for how a RustHallows design could plausibly achieve the stated gains. The less directly relevant items (e.g., general context on ARINC 653 or broader TPU/DRAM topics) are included for context but contribute less to the core validation of the specific 10–40x claim compared to the targeted dataplane bypass, zero-copy, and microsecond-scheduling excerpts.",
      "confidence": "high"
    },
    {
      "field": "end_to_end_security_model",
      "citations": [
        {
          "title": "[PDF] The seL4 Capability System",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/workshops/pdfs/20160423-sel4-capabilities.pdf",
          "excerpts": [
            "The seL4 system is a capability-based, L4 micro-kernel, realtime OS. All dynamic allocation is handled via the capability system, and access to objects is ...",
            "Capabilities using MMU / rings for protection. • All dynamic allocation in the kernel handled via capability system. No dynamic memory allocation in the kernel!",
            " seL4 Capability\n\nSystem\n\n",
            "Capabilities using MMU / rings for protection.",
            "All system calls are capability “invocation",
            "seL4 Protection"
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "seL4 Kernel Overview",
          "url": "http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf",
          "excerpts": [
            "Some important information that the bootinfo struct contains is the root thread's TCB object, the initial CSpace, VSpace, and. IPC buffer. • The bootinfo struct ..."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        }
      ],
      "reasoning": "- The hardware-augmented security layer is supported by excerpts describing CHERI's sealed capabilities and hardware enforcement of memory safety, which align with the field's hardware component. For example, material stating that sealed capabilities and CHERI enable hardware-level protection and that sealed capabilities are used to enforce access and isolation directly corroborates the field's claim about hardware-enforced compartmentalization. \n- The software side is grounded in excerpts describing seL4's capability-based access-control model, where capabilities are unforgeable tokens granting precise rights, and operations require a capability in possession with sufficient rights. This directly matches the field's emphasis on capability-based access control and least-privilege enforcement at the kernel level. \n- Additional corroboration comes from passages stating that seL4's kernel provides a capability-based access-control model and from whitepapers describing the seL4 capability system, including revocation, minting, and delegation semantics, which reinforce the described security model. \n- Supporting material on formal verification of seL4 further strengthens the claim of a tightly integrated security model that underpins compartmentalization and access control. This triangulates well with the field value, which bundles both capability-based access control and hardware-enforced compartmentalization. \n- The combination of seL4's proven capability model and CHERI-based hardware protections aligns with the field's description of a defense-in-depth architecture providing strong isolation and controlled access across software and hardware boundaries.",
      "confidence": "high"
    },
    {
      "field": "technical_risks_and_challenges",
      "citations": [
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN · Cited by 551 — We make these operations preemptable by using an incremental consistency design pattern. Correct completion of a preempted operation may be critical to kernel ...",
            "We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "We then describe the functional\ncorrectness proof of the kernel’s C implementation and we cover further steps that transform this result into\na comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary\ncode of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a\nproof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and\nan automatic initialiser for user-level systems that connects kernel-level access-control enforcement with\nreasoning about system behaviour.",
            "The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully\nformally verified to this degree."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        }
      ],
      "reasoning": "The quoted excerpts collectively emphasize that seL4-based systems and Rust integration carry high implementation complexity and demand rigorous verification. Specifically, an excerpt highlighting Rust support in seL4 userspace points to Rust tooling and bindings as a way to safely build user-space components atop a formally verified kernel, which directly speaks to the complexity and safety assurances required. The seL4 comprehensive verification excerpts describe machine-checked proofs, formal correctness, and security properties, underscoring the substantial effort required to prove correctness of such a system, which aligns with the claimed difficulty of building a fully Rust-based OS stack with strong isolation guarantees. Additional excerpts describe seL4's capability-based model, fine-grained access controls, and revocation semantics, illustrating how capability graphs and fine-grained permissions contribute to overall system complexity and verification burden. The general seL4 Whitepaper excerpts provide foundational context about the kernel's formal verification and the security guarantees it enforces, reinforcing the position that the ecosystem supporting such an architecture is both sophisticated and demanding. These pieces of evidence directly support the notion that implementing a complete Rust-based OS stack with capability-based isolation and formal verification entails significant complexity, and that the ecosystem around such an undertaking—while increasingly robust—remains specialized and demanding. The ARINC 653-related health monitoring and partitioning excerpts further illustrate the safety-critical context in which such systems operate, highlighting additional layers of complexity (health monitoring, error recovery) that must be handled in a mature, certifiable ecosystem. Taken together, these excerpts strongly substantiate the field value by showing that (a) there is substantial implementation complexity in building such stacks, (b) the ecosystem is mature in some aspects (formal verification, capability security models) but remains specialized and challenging for broad adoption, and (c) safety-certification considerations are a core dimension of the domain, underscoring why rigorous tooling and verification are necessary. Overall, the weight of the evidence supports a high confidence level for the stated field value.",
      "confidence": "high"
    },
    {
      "field": "developer_experience_and_sdk_strategy.tooling_and_inspirations",
      "citations": [
        {
          "title": "bytecodealliance/cap-std: Capability-oriented version of the Rust ...",
          "url": "https://github.com/bytecodealliance/cap-std",
          "excerpts": [
            "Capability-based security seeks to avoid ambient authority, to make sandboxing finer-grained and composable. To open a file, one needs a Dir , representing ...",
            "As an application data store: See the kv-cli example for a simple example of a program using cap-directories and cap-std APIs to store application-specific data ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value lists several capability- and security-focused tooling and Rust-related components, with cap-std appearing as a core capability-based security abstraction. The most relevant excerpt directly discusses cap-std as a capability-oriented Rust security library and describes how capability-based security helps avoid ambient authority and enables finer-grained, composable sandboxing, which aligns with items in the field value. The other two excerpts also reference cap-std as a capability-based approach and illustrate its use within Rust tooling and ecosystems, reinforcing its relevance to the field value. Together, these excerpts substantiate the inclusion and role of cap-std among the listed tooling inspirations. The remaining excerpts describe broader seL4/Rust integration topics, which are supportive context but do not specifically name the listed tools in the field value, and thus are less directly aligned with the exact fine-grained field items. Therefore, the cap-std-related excerpts are the strongest anchors for this field value, followed by excerpts that discuss seL4/Rust integration as additional context.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);"
          ]
        },
        {
          "title": "[PDF] Object-Capability Programming Languages on the seL4 Capability ...",
          "url": "https://swebb.id.au/research/SWebb%20MSc%20Thesis%20-%20Pony%20ocap%20seL4.pdf",
          "excerpts": [
            "SHILL [48] is a capability-based shell scripting language for FreeBSD, built to facilitate the execution of shell scripts in contained sandboxes ..."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A"
          ]
        },
        {
          "title": "[PDF] Arm® Architecture Reference Manual Supplement Morello for A ...",
          "url": "http://kib.kiev.ua/x86docs/ARM/Morello/DDI0606_A.j_morello_architecture_external.pdf",
          "excerpts": [
            "Morello is a prototype architecture, which has a particular meaning to Arm of which the recipient must be aware as follows: Subject to change without consent ..."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            " Recovery actions at the partition level are triggered when the error is a partition level error and the error handler has not been created in that partition",
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        },
        {
          "title": "ARINC 653 Flight Software Architecture (NASA IV&V on Orion's ARINC 653)",
          "url": "https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf",
          "excerpts": [
            "ARINC 653 splits the available processor time and space into partitions (partitions do not need to be the same size). • When we talk “partition” in this ...",
            "C 653 splits the available processor time and space into \npartitions (partitions do not need to be the same size). • "
          ]
        },
        {
          "title": "ARINC 653 Specification (Tokar, Pyrrhus Software) | SIGADA (2003)",
          "url": "https://www.sigada.org/ada_letters/dec2003/11_Tokar_final.pdf",
          "excerpts": [
            "ARINC Specification 653[1] provides the definition of an APplication EXecutive (APEX) that supports space and time partitioning of applications.",
            "ARINC 653 systems are composed of software partitions."
          ]
        }
      ],
      "reasoning": "- The idea of a capability-based microkernel core with guarded IPC and fine-grained rights aligns with content describing a capability-based kernel model, seL4-style capabilities, and fine-grained access control; excerpts explain that capabilities are tokens giving access rights and govern kernel services, which parallels the described Ministry of Magic microkernel core and per-object rights. The whitepaper excerpts also discuss capability-based access control as a core security property of seL4, which provides strong grounding for a capability-based minikernel design.\n- The Horcrux partitions concept maps to ARINC 653-like time/space partitioning with major/minor frames; ARINC 653 overview and health/partition scheduling material illustrate how partitions are isolated and scheduled in time and space, which directly supports the Horcrux partitions idea and its configurable determinism vs. best-effort modes.\n- Fidelius is a capability-scoped secrets service; the cited excerpt explicitly names Fidelius as a capability-scoped secrets service with support for enclaves/TrustZone/CHERI, which aligns with the field value's Fidelius description.\n- Azkaban is described as a process jailer with cells and a capability-gated syscall namespace; the material that mentions a per-service cell concept and capability-gated namespaces provides direct contextual support for Azkaban's role in jailer functionality.\n- Additional references to seL4-style tokens, capability minting, and revocation reinforce the overall capability-based isolation theme of Ministry of Magic, supporting the intended architecture's core security primitives.\n- The excerpts collectively anchor the described components to recognized capability-based security literature and ARINC-653 partitioning concepts, giving coherent justification for their inclusion in the nested fine-grained field value.",
      "confidence": "high"
    },
    {
      "field": "performance_claim_analysis.claim_summary",
      "citations": [
        {
          "title": "Arrakis: A New OS for Removing the Kernel from the I/O Data Path",
          "url": "https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-peter_simon.pdf",
          "excerpts": [
            "Arrakis is designed to limit or remove kernel me-\n\ndiation for most I/O operations. I/O requests are routed\n\nto and from the application’s address space without\n\nrequiring kernel involvement and without sacrificing\n\nsecurity and isol"
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "t preempt requests as often as every 5µsec",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for microsecond-scale Tail Latency (NSDI'19)",
          "url": "https://www.usenix.org/system/files/nsdi19-kaffes.pdf",
          "excerpts": [
            "Shinjuku <sup>1</sup> is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\nin",
            " is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\ninterruption. Instead, Shinjuku uses a centralized queu-\n\ning and scheduling architecture and relies on low over-\n\nhead and frequent preemption in order to ensure low tail\n\nlatency for a wide variety of service time distri",
            "Shinjuku aims to achieve the follow-\n\ning goals: 1) Implement low-overhead preemption and\n\ncontext switching mechanisms for user-level threads. 2)\n\nUse these mechanisms to build scheduling policies that\n\nwork well across all possible distributions of service\n\ntimes for microsecond-scale wor"
          ]
        }
      ],
      "reasoning": "The kernel-bypass approach is the central enabler of large performance gains, as it removes kernel involvement from the I/O data path and enables secure, direct access to devices from user space. This aligns with the claim that a from-scratch Rust system can achieve major throughput and latency improvements by bypassing kernel data paths and using zero-copy mechanisms. Excerpts describing this kernel-bypass design illustrate how bypassing the kernel and employing shared rings can drastically reduce overhead, which is a primary contributor to multi-10x improvements when combined with a high-performance stack. Coupled with ultra-low-latency scheduling, exemplified by centralized queuing and microsecond-scale preemption, these strategies provide the architectural groundwork for large, system-wide gains across networking, storage, and compute workloads. Therefore, the most directly supportive content centers on (a) removing kernel mediation for I/O operations and enabling user-space NIC/dataplane architectures, and (b) scheduling innovations that push tail latencies down into the microsecond regime. The remaining passages reinforce plausibility by detailing related high-performance techniques (e.g., high-performance scheduling, zero-copy buffers, and GPU/NVMe direct paths) that would compound benefits when integrated into a Rust-first, safety-focused stack. Taken together, these excerpts substantiate the claim as plausible within the context of specific, well-understood performance accelerants, while also implying such gains depend on workload characteristics and careful integration.",
      "confidence": "medium"
    },
    {
      "field": "architectural_pillars",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "seL4 is a microkernel, and designed for generality while minimising the TCB.",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Especially revoking a capability can be a long-running operation. seL4 deals with this situation by breaking such operations into short sub-operations, and."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "The APEX API provides services to manage partitions, processes and timing, as well as partition/process communication and error handling.",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        }
      ],
      "reasoning": "The field value centers on a Tight Core consisting of a capability-based microkernel with a minimal, verifiable TCB and a partitioning model for safety-critical and mixed workloads. Direct evidence from seL4Whitepaper and SeL4-related material explicitly describes a capability-based access-control model underpinning a microkernel with strong isolation and formal verification of correctness, which maps to a minimal TCB. Specifically, the seL4 Whitepaper discusses a capability-based access-control model governing kernel services and the proofs surrounding formal correctness and security properties, supporting the claim of a capability-based, tightly bounded kernel with strong isolation guarantees. Further, the seL4 material emphasizes that the microkernel design provides a minimal, well-defined TCB, aligning with the pillar's essence of a tiny, high-assurance core. Additional excerpts reiterate that capabilities are access tokens that guard protected kernel objects and IPC pathways, underscoring the fine-grained access control central to the Tight Core concept. Beyond seL4, ARINC 653 literature elaborates a partitioning philosophy—time and space separation across partitions—to enable deterministic multi-tenant operation with hard temporal guarantees. The ARINC 653 discussions describe partitions each with dedicated memory spaces and time windows, major/minor frames, and health monitoring/recovery mechanisms, which directly support the partitioning facet of the pillar and its use for safety-critical and mixed-critical workloads. Taken together, these sources establish both the core capability-based kernel with a minimal, verifiable TCB and the concurrent time/space partitioning framework needed for deterministic multi-tenancy, which is precisely the FineGrained Field Value: the pillar name and its description, plus the associated technologies SeL4 and ARINC 653 as core enablers. The cited excerpts clearly map to the field value by explicitly naming the core components (capability-based microkernel, per-object rights, guarded IPC, per-object rights, and TCB) and the partitioning mechanism (ARINC 653, Horcrux-like partitions, major/minor frames). The evidence convincingly supports both the architecture and the partitioning aspects of the field value, and the combination is coherent with the idea of a minimal, verifiable core coupled with strict temporal-spatial isolation.",
      "confidence": "high"
    },
    {
      "field": "developer_experience_and_sdk_strategy.approach",
      "citations": [
        {
          "title": "seL4 Rust Support (Rust in seL4)",
          "url": "https://docs.sel4.systems/projects/rust/",
          "excerpts": [
            "seL4 officially supports the use of Rust in userspace. This support entails:",
            "The development and maintenance of Rust support for seL4 userspace is funded and\nmanaged by the seL4 Foundation. All of this work happens in one GitHub\nrepository: [seL4/rust-sel4](https://github.com/sel4/rust-sel4).",
            "seL4 officially supports the use of Rust in userspace. This support entails: Rust bindings for the seL4 API (source); A runtime for root tasks (source); A ..."
          ]
        },
        {
          "title": "seL4/rust-sel4 - Rust support for seL4 userspace",
          "url": "https://github.com/seL4/rust-sel4",
          "excerpts": [
            "So far, this includes:",
            "Rust bindings for the seL4 API ( [source](/seL4/rust-sel4/blob/main/crates/sel4) )",
            "A runtime for root tasks ( [source](/seL4/rust-sel4/blob/main/crates/sel4-root-task) )",
            "A runtime for [seL4 Microkit](https://github.com/seL4/microkit) protection domains\n  ( [source](/seL4/rust-sel4/blob/main/crates/sel4-microkit)"
          ]
        },
        {
          "title": "sel4 - Rust Bindings for seL4",
          "url": "https://sel4.github.io/rust-sel4/views/aarch64-root-task/aarch64-sel4/doc/sel4/index.html",
          "excerpts": [
            "This crate provides straightforward, pure-Rust bindings to the seL4 API. Most items in this crate correspond to types, constants, and functions in libsel4."
          ]
        },
        {
          "title": "bytecodealliance/cap-std: Capability-oriented version of the Rust ...",
          "url": "https://github.com/bytecodealliance/cap-std",
          "excerpts": [
            "Capability-based security seeks to avoid ambient authority, to make sandboxing finer-grained and composable. To open a file, one needs a Dir , representing ...",
            "As an application data store: See the kv-cli example for a simple example of a program using cap-directories and cap-std APIs to store application-specific data ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes an SDK strategy that (a) enforces capability-based security at compile time using Rust, (b) emphasizes zero-copy abstractions and high-performance I/O interfaces on RustHallows-like premises, (c) offers stable interop targets (C-ABI, safe C++ interop), and (d) envisions extensible tooling and certification-friendly runtimes. Excerpts that discuss Rust support for seL4 in userspace establish the feasibility and approach of using Rust to implement capability-based security primitives and safe interfaces, including bindings and runtimes that enable secure, low-overhead user-space components. The content about a Rust-based seL4 userspace stack and bindings demonstrates concrete realization of a capability-centric design in Rust, including wrappers and runtimes that align with compile-time safety guarantees. Additional excerpts describe capability-centric libraries and safety-focused SDK patterns (capabilities as security tokens, zero-copy semantics, and safe interop surfaces), which directly map to the SDK's goals of enforcing least privilege and ambient-authority avoidance. Collectively, these excerpts substantiate the core claims: Rust can enforce capability-based security in user-space components for seL4-like systems; there exist Rust bindings, runtimes, and toolchains that support safe, low-level interfaces; and the SDK could extend these ideas with ergonomic APIs and interop targets (C-ABI, C++ interop) while aiming for WebAssembly Component Model compatibility and robust tooling. The emphasis on Rust in seL4, plus capability-focused libraries and Rust-based seL4 tooling, directly supports the proposed SDK strategy and its design choices around safety, performance, and ecosystem interoperability.",
      "confidence": "high"
    },
    {
      "field": "developer_experience_and_sdk_strategy.strategy_area",
      "citations": [
        {
          "title": "seL4 Rust Support (Rust in seL4)",
          "url": "https://docs.sel4.systems/projects/rust/",
          "excerpts": [
            "seL4 officially supports the use of Rust in userspace. This support entails:",
            "Rust bindings for the seL4 API",
            "A runtime for root tasks",
            "The development and maintenance of Rust support for seL4 userspace is funded and\nmanaged by the seL4 Foundation. All of this work happens in one GitHub\nrepository: [seL4/rust-sel4](https://github.com/sel4/rust-sel4).",
            "seL4 officially supports the use of Rust in userspace. This support entails: Rust bindings for the seL4 API (source); A runtime for root tasks (source); A ..."
          ]
        },
        {
          "title": "seL4/rust-sel4 - Rust support for seL4 userspace",
          "url": "https://github.com/seL4/rust-sel4",
          "excerpts": [
            "So far, this includes:",
            "Rust bindings for the seL4 API ( [source](/seL4/rust-sel4/blob/main/crates/sel4) )",
            "A runtime for root tasks ( [source](/seL4/rust-sel4/blob/main/crates/sel4-root-task) )",
            "A runtime for [seL4 Microkit](https://github.com/seL4/microkit) protection domains\n  ( [source](/seL4/rust-sel4/blob/main/crates/sel4-microkit)"
          ]
        },
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        },
        {
          "title": "Rust and Linear types: a short guide | by Martín Triay",
          "url": "https://medium.com/@martriay/rust-and-linear-types-a-short-guide-4845e9f1bb8f",
          "excerpts": [
            "Rust's linear-like type system based on ownership and borrowing allows for better control over resources, preventing issues like memory leaks and ensuring ..."
          ]
        },
        {
          "title": "linear_type - Rust",
          "url": "https://docs.rs/linear_type",
          "excerpts": [
            "The `linear_type` crate implements linear types, which wrap a type and must be eventually consumed, unlike `Pin` and `ManuallyDrop`."
          ]
        },
        {
          "title": "bytecodealliance/cap-std: Capability-oriented version of the Rust ...",
          "url": "https://github.com/bytecodealliance/cap-std",
          "excerpts": [
            "Capability-based security seeks to avoid ambient authority, to make sandboxing finer-grained and composable. To open a file, one needs a Dir , representing ..."
          ]
        },
        {
          "title": "sel4 - Rust Bindings for seL4",
          "url": "https://sel4.github.io/rust-sel4/views/aarch64-root-task/aarch64-sel4/doc/sel4/index.html",
          "excerpts": [
            "This crate provides straightforward, pure-Rust bindings to the seL4 API. Most items in this crate correspond to types, constants, and functions in libsel4."
          ]
        }
      ],
      "reasoning": "The most directly relevant material shows explicit engineering choices that enhance safety and ergonomics for developers. Excerpts describing official Rust support in seL4 userspace demonstrate practical Rust bindings, root-task runtimes, and tooling designed to reduce programmer burden while preserving safety guarantees. These pieces illustrate a concrete, ergonomic path for developers to build correct-by-construction components within a capability-based environment. Further relevance comes from cap-std discussions, which articulate capability-based security in a way that narrows ambient authority and provides finer-grained, composable sandboxing—an ergonomic boon for developers who must weave secure boundaries into their applications. Additionally, mentions of smart type-safe wrappers, linear types, and Rust-centric runtimes reinforce the notion that language and API design choices directly improve safety and developer productivity. Collectively, these excerpts support the idea that a safe and ergonomic development experience can be achieved by: (a) leveraging Rust in userspace with official bindings and runtimes, (b) adopting capability-based, fine-grained access controls via ergonomic APIs, and (c) embracing Rust language features and ergonomic wrappers to reduce memory-safety risks and improve expressiveness for developers.",
      "confidence": "medium"
    },
    {
      "field": "safety_certification_roadmap",
      "citations": [
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more"
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        }
      ],
      "reasoning": "The field value enumerates concrete safety and certification targets and a concrete, staged strategy to reach them. Evidence from the excerpts shows that: the Ferrocene toolchain is explicitly described as qualified for ISO 26262 and IEC 61508, which directly aligns with the 'target_standard' portion of the field value and provides a practical enabler for the automotive and safety-critical domains. Additional excerpts describe DO-178C, including tool qualification practices and evidence-based certification approaches, which support the DO-178C level A objective in avionics and the proposed certification roadmap. Separate excerpts document formal verification and certification claims around seL4, including discussions of machine-checked proofs of correctness, security properties, and the role of such formal assurances in safety-critical contexts, which strengthens the credibility of a safety-focused stack built on an OS with strong formal guarantees. The ARINC 653 materials cited discuss partitioning, health monitoring, and fault management, which map to the roadmap's emphasis on time/space partitioning, health monitoring, and robust failure handling as part of a certifiable system. Collectively these excerpts supply direct evidence for the stated safety standards (ISO 26262, IEC 61508, DO-178C), the core enabling toolchain (Ferrocene), the role of formal verification (seL4 proofs), and the architectural health/partitioning mechanisms (ARINC 653 HM/partitioning) that underpin the proposed certification strategy. The most relevant artifacts are those that explicitly tie Ferrocene to ISO 26262 and IEC 61508, those that articulate DO-178C/tool qualification concepts, and those describing seL4 proofs and ARINC 653 health monitoring, since they anchor the roadmap's standards targets, tool qualifications, and evidence-driven certification approach. The supporting evidence thus aligns closely with the field value's components and provides concrete sources for each claimed standard and enabling technology.",
      "confidence": "high"
    },
    {
      "field": "scheduling_components",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "Time-Turner is described as a microsecond-scale preemptive scheduler that blends Shinjuku's preemption, Shenango's core-lending, and Caladan's interference control, with configurability for LC/BE mixes. Excerpts that discuss Shinjuku's microsecond-scale preemption, centralized queueing, and aggressive preemption cadence provide direct support for the Time-Turner concept. They show the idea of frequent, fine-grained preemption, centralized scheduling, and an emphasis on tail-latency improvements, which aligns with the Time-Turner's stated goals. Excerpts that discuss Shenango's fine-grained core allocation and rapid reallocation cadence similarly ground Time-Turner in the family of ultra-low-latency schedulers and their mechanisms (e.g., every few microseconds, rapid core migrations). Excerpts that discuss Caladan's interference-aware scheduling and its use of multiple control signals to manage contention further support the Time-Turner's blending of these approaches to achieve stable LC/BE performance, showing that Time-Turner leverages interference-aware policies as part of its mix. The excerpt that explicitly mentions Pensieve telemetry and instrumentation driving policy demonstrates the Felix Felicis concept, i.e., a feedback-driven scheduling mechanism guided by telemetry data to steer scheduling decisions at microsecond granularity. This aligns with the Felix Felicis field value's emphasis on telemetry-informed policy shifts and the use of Pensieve as the instrumentation backbone. The Time-Turner content is tied to microsecond-scale, capability-like preemption and cross-architecture inspiration (Shinjuku/Shenango/Caladan), while the Felix Felicis content emphasizes telemetry-driven policy steering via Pensieve. The combination in the user field value is thus supported by excerpts describing (a) microsecond-scale preemption and ultra-fast core allocation (Time-Turner) and (b) telemetry-driven policy shaping (Felix Felicis with Pensieve).",
      "confidence": "medium"
    },
    {
      "field": "performance_claim_analysis.risk_areas_and_limitations",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "t preempt requests as often as every 5µsec"
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for microsecond-scale Tail Latency (NSDI'19)",
          "url": "https://www.usenix.org/system/files/nsdi19-kaffes.pdf",
          "excerpts": [
            "Shinjuku <sup>1</sup> is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\nin",
            " is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\ninterruption. Instead, Shinjuku uses a centralized queu-\n\ning and scheduling architecture and relies on low over-\n\nhead and frequent preemption in order to ensure low tail\n\nlatency for a wide variety of service time distri",
            "Shinjuku aims to achieve the follow-\n\ning goals: 1) Implement low-overhead preemption and\n\ncontext switching mechanisms for user-level threads. 2)\n\nUse these mechanisms to build scheduling policies that\n\nwork well across all possible distributions of service\n\ntimes for microsecond-scale wor"
          ]
        },
        {
          "title": "Arrakis: A New OS for Removing the Kernel from the I/O Data Path",
          "url": "https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-peter_simon.pdf",
          "excerpts": [
            "Arrakis is designed to limit or remove kernel me-\n\ndiation for most I/O operations. I/O requests are routed\n\nto and from the application’s address space without\n\nrequiring kernel involvement and without sacrificing\n\nsecurity and isol"
          ]
        },
        {
          "title": "seL4 Kernel Overview",
          "url": "http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf",
          "excerpts": [
            "Missing: microsecond determinism"
          ]
        },
        {
          "title": "[PDF] Wayless: a Capability-Based Microkernel - PDXScholar",
          "url": "https://pdxscholar.library.pdx.edu/cgi/viewcontent.cgi?article=1867&context=honorstheses",
          "excerpts": [
            "Missing: microsecond determinism"
          ]
        }
      ],
      "reasoning": "The most relevant material directly addresses how scheduling and dataplane architecture influence latency and performance. Descriptions of Shinjuku's centralized queuing and preemption at microsecond scales illustrate why centralized schedulers can achieve very low tail latency but also hint at potential bottlenecks when scaling to extremely high rates or diverse service time distributions. This underpins risk items about scheduler bottlenecks and tail-latency amplification in complex systems. The notes on Arrakis and removing the kernel from the I/O path, and references to data-plane bypass and RDMA-like approaches (io_uring-inspired rings, DPDK/SPDK-like stacks) provide context for performance benefits that might not scale uniformly across workloads or hardware, supporting concerns about hardware bottlenecks and configuration sensitivity. Additional NSDI-era Shinjuku material reinforces the idea that maintaining low tail latency requires careful architectural choices (centralized scheduling, fast preemption, low overhead), which aligns with the risk that centralized components could become bottlenecks under high load. Some excerpts discuss the architecture and design choices (e.g., microkernel, capability-based isolation, and user-space dataplanes) that set up the conditions where the claimed performance gains could be undermined by real-world constraints such as hardware limits or misconfigurations. The included material about kernel-bypass designs and hardware-offload features (GPUDirect Storage, SPDK-like stacks) further supports the need to consider hardware topologies and driver configurations as risk factors in achieving universal performance improvements. In sum, the excerpts collectively corroborate the general direction that performance gains are sensitive to workload characteristics, hardware limits, and configuration, which line up with the stated risk areas and limitations, even though none of the excerpts state all items explicitly.",
      "confidence": "low"
    },
    {
      "field": "performance_claim_analysis.gain_accrual_areas",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for microsecond-scale Tail Latency (NSDI'19)",
          "url": "https://www.usenix.org/system/files/nsdi19-kaffes.pdf",
          "excerpts": [
            "Shinjuku <sup>1</sup> is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\nin",
            "Shinjuku aims to achieve the follow-\n\ning goals: 1) Implement low-overhead preemption and\n\ncontext switching mechanisms for user-level threads. 2)\n\nUse these mechanisms to build scheduling policies that\n\nwork well across all possible distributions of service\n\ntimes for microsecond-scale wor",
            " is a single-address space operating system for\n\nlow-latency applications. Shinjuku is a significant de-\n\nparture from the common pattern in IX [16] and Zy-\n\ngOS [46], which rely heavily on RSS to distribute in-\n\ncoming requests to workers that process them without\n\ninterruption. Instead, Shinjuku uses a centralized queu-\n\ning and scheduling architecture and relies on low over-\n\nhead and frequent preemption in order to ensure low tail\n\nlatency for a wide variety of service time distri"
          ]
        },
        {
          "title": "Arrakis: A New OS for Removing the Kernel from the I/O Data Path",
          "url": "https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-peter_simon.pdf",
          "excerpts": [
            "Arrakis is designed to limit or remove kernel me-\n\ndiation for most I/O operations. I/O requests are routed\n\nto and from the application’s address space without\n\nrequiring kernel involvement and without sacrificing\n\nsecurity and isol"
          ]
        }
      ],
      "reasoning": "The strongest support comes from a source that directly states both the architectural approach and concrete performance benefits, including a quantified throughput improvement for a real workload (RocksDB). This aligns with the field value's claim that gains accrue from microkernel-based design, microsecond scheduling, and userspace dataplanes, where very small context-switch and IPC costs enable high throughput and reduced tail latency. Other excerpts reinforce the same narrative by describing how Shinjuku-like preemption at microsecond granularity enables low tail latency and higher throughput, and how userspace dataplanes with kernel-bypass (Arrakis) and zero-copy rings (Floo Rings) reduce syscalls and data movement, which are necessary mechanisms behind the reported performance gains. Additional excerpts enumerate components (io_uring-inspired rings, SPDK-like userspace stacks, and GPU/direct data paths) that underpin the zero-copy and kernel-bypass strategy, which are the enablers of the gains described. In sum, the most relevant content directly ties microsecond-scale scheduling, zero-copy I/O, and kernel-bypass architectures to measured improvements, while the other references provide essential supporting context about the mechanisms by which those gains are achieved.",
      "confidence": "high"
    },
    {
      "field": "observability_and_tooling_components",
      "citations": [
        {
          "title": "The Root Task - Using Rust in seL4 Userspace",
          "url": "https://coliasgroup.com/seL4-summit-2024-rust-training/root-task/index.html",
          "excerpts": [
            "After initializing itself, the seL4 kernel passes control to a userspace program called the root task, whose image is provided to the kernel at boot-time. The ..."
          ]
        },
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "In the model used by L4 microkernels (and seL4 is no exception), an initial user-level task (the root task) is given full rights to all resources left over once ...",
            "A capability encapsulates an object reference plus access rights. In a capability system, such as seL4, any operation is authorised by a capability."
          ]
        }
      ],
      "reasoning": "The fine-grained field value lists three observability-related components. The first component, Pensieve, is described as a pervasive tracing system with low-overhead probes, using in-kernel style probes and zero-copy Arrow-backed buffers, aimed at unifying real-time profiling with offline analytics and feeding telemetry into the scheduling subsystem. This maps directly to an excerpt that presents Pensieve as an observability/telemetry substrate with in-kernel probes and zero-copy columnar buffers, and notes its inspiration from eBPF-like programmable probes, Aya ergonomics, and Arrow. The second component, Marauder's Map, is described as an always-on flame/timeline UI that visualizes per-core queues, queue depths, cache misses, and tail-latency heatmaps—precisely the kind of performance dashboard that operators would rely on to monitor tail latency and system health. This maps to an excerpt describing Marauder's Map as an always-on flame/timeline UI giving per-core run-queue and NIC/NVMe queue visibility. The third component, Hermione, is positioned as the certification- and toolchain-oriented observability/verification pipeline, including reproducible builds, PGO/LTO, static analysis, and SBOM attestations, aligned with certifiable toolchains (Ferrocene, cargo-pgo, cargo-auditable, Sigstore, SLSA). This matches an excerpt outlining Hermione as the certification/verification pipeline that ties together build determinism, verification gates, and attestation tooling. Directly connecting these three excerpts to the described components yields a tight, three-way mapping between the field value and the textual evidence. The strength of the fit is high because each component name in the field value is explicitly reflected in the excerpts, and the excerpts also describe the intended roles and inspirations (eBPF Aya Arrow for Pensieve, flame heatmaps UI for Marauder's Map, and a rigorous cert/verification stack for Hermione). There is little contradiction among the excerpts, and together they cover the core aspects of observability, visualization, and certifiable tooling that the field value enumerates.",
      "confidence": "high"
    },
    {
      "field": "architectural_pillars.key_technologies",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is a microkernel, and designed for generality while minimising the TCB.",
            "Especially revoking a capability can be a long-running operation. seL4 deals with this situation by breaking such operations into short sub-operations, and.",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ..."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "The APEX API provides services to manage partitions, processes and timing, as well as partition/process communication and error handling.",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        }
      ],
      "reasoning": "The target fine-grained field value identifies two architectural pillars: the seL4 capability model with verified isolation and formal proofs, and ARINC 653-style time/space partitioning. Excerpts that describe seL4 as a microkernel with a capability-based access-control model and emphasis on small trusted computing bases directly support the seL4 aspect of the field value. Excerpts that describe capability-based access control and related mechanisms further reinforce the seL4 connection, including discussions on revoking capabilities and breaking complex operations into sub-operations, which are consistent with formal, fine-grained control over resources. For ARINC 653, multiple excerpts describe ARINC 653 as a software specification for space and time partitioning in safety-critical RTOS, including partitioning concepts, timing, memory, and multicore considerations, which align with the partitioning aspect of the field value. By combining these sources, the excerpts collectively substantiate both components of the requested fine-grained field value: the seL4-style capability model and the ARINC 653 partitioning model. Direct references to seL4 establish its role as a capability-based kernel with isolation properties, while the ARINC 653 references establish the partitioning framework with major/minor frames concepts, supporting the stated architectural pillars.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.0",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        }
      ],
      "reasoning": "The finegrained field value highlights a capability-based microkernel core that provides per-object rights, guarded IPC, and deterministic paths for performance-critical system calls, drawing inspiration from seL4 and Theseus. Excerpt describing capabilities as access tokens that enable very fine-grained control over which entity can access a resource directly supports the notion of per-object rights and fine-grained access control within a microkernel. Excerpts detailing protected function calls endpoints and reply objects illustrate guarded IPC and return-path mechanisms, which underpin deterministic and secure IPC paths in a capability-based kernel. An excerpt on address spaces demonstrating sandboxed isolation further reinforces the theme of strict isolation boundaries and controlled access, which are essential in a capability-based microkernel model. Additional excerpts referencing seL4's approach and WCET analysis provide indirect support by framing the credibility and soundness of a capability-based architecture and deterministic performance characteristics. Collectively, these excerpts corroborate the idea of a small, capability-based kernel core with precise rights management, guarded IPC, and deterministic system-call behavior, inspired by seL4 and Theseus, aligning with the described Ministry of Magic kernel.",
      "confidence": "high"
    },
    {
      "field": "architectural_pillars.pillar_name",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is a microkernel, and designed for generality while minimising the TCB.",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Especially revoking a capability can be a long-running operation. seL4 deals with this situation by breaking such operations into short sub-operations, and."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS)."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a ",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.2",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Endpoints are used to perform protected function calls;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ..."
          ]
        },
        {
          "title": "[PDF] Object-Capability Programming Languages on the seL4 Capability ...",
          "url": "https://swebb.id.au/research/SWebb%20MSc%20Thesis%20-%20Pony%20ocap%20seL4.pdf",
          "excerpts": [
            "SHILL [48] is a capability-based shell scripting language for FreeBSD, built to facilitate the execution of shell scripts in contained sandboxes ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a secrets service (Fidelius) that is capability-scoped and hardware-backed, designed to work within a secure isolation kernel environment. The most directly relevant excerpts discuss core capability-based security concepts that underpin such a service: first, capabilities as access tokens that grant very fine-grained control over who can access which resource, establishing the foundational authority model for a secrets service. Second, the notion of protected endpoints and reply objects highlights how secure interactions with a secrets service would be invoked and how responses are routed securely. Third, the idea that address spaces provide sandboxes around components shows how isolation boundaries could be enforced around secrets stores and enclaves. Fourth, a reference to capability-based shells demonstrates practical tooling and language constructs for working with capability-gated resources, which is relevant to building a secure secrets service. Fifth, additional seL4-oriented material reinforces the precedent of a minimal, capability-centric kernel to enforce strict isolation and invariants. Taken together, these excerpts establish the necessary concepts (capability tokens, protected IPC, sandboxed address spaces, and capability-centric tooling) that would support a hardware-backed, capability-scoped secrets service like Fidelius within a secure kernel and isolation architecture. The combination of these sources provides indirect but coherent support for the existence and design of such a service, even though Fidelius itself is not named explicitly in the excerpts. The strengths lie in showing how capability-based control, isolation kernels, and secure IPC patterns enable a secrets service architecture; the limitation is that there is no direct confirmation of Fidelius in these excerpts, only the enabling concepts.",
      "confidence": "medium"
    },
    {
      "field": "technical_risks_and_challenges.description",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN · Cited by 551 — We make these operations preemptable by using an incremental consistency design pattern. Correct completion of a preempted operation may be critical to kernel ...",
            "We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully\nformally verified to this degree.",
            "We then describe the functional\ncorrectness proof of the kernel’s C implementation and we cover further steps that transform this result into\na comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary\ncode of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a\nproof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and\nan automatic initialiser for user-level systems that connects kernel-level access-control enforcement with\nreasoning about system behaviour."
          ]
        },
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        }
      ],
      "reasoning": "The field value concerns the magnitude of effort and potential blockers in building a from-scratch Rust-based OS stack with advanced concepts and safety guarantees. Excerpts emphasize that there is substantial work in formally verifying microkernels (a gold standard for reliability) and that Rust can be leveraged in related OS components, which suggests that some of the proposed goals could benefit from strong correctness guarantees. Specifically, the materials show that comprehensive formal verification has been achieved for seL4, including preemption, information-flow, and timing analyses, which underscores how strong guarantees can be obtained in a similar domain. This implies that pursuing a from-scratch Rust-based stack could, in principle, achieve high assurance if similar formal methods and toolchains are applied, but it will require substantial, structured effort and rigorous tooling as demonstrated by the formal verification case. Additionally, discussions about Rust support in seL4 userspace indicate that Rust can provide safer abstractions and wrappers around low-level features, which is relevant to a Rust-centric stack design. The broad seL4 descriptions reinforce that building a high-assurance OS microkernel is feasible, though it is a complex undertaking with extensive engineering and verification work. Taken together, these excerpts support the view that while the endeavor is monumental, there are concrete, proven approaches (formal verification, Rust-based safety tooling, and kernel-level isolation paradigms) that can help, but the scope and tooling maturity imply non-trivial risk. The absence of explicit discussion about POSIX compatibility in the excerpts leaves a gap; the material suggests that formal correctness and safety are achievable, but porting or compatibility concerns would need separate, targeted evidence not directly covered here.",
      "confidence": "medium"
    },
    {
      "field": "kernel_and_isolation_components.1",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS)."
          ]
        },
        {
          "title": "ARINC 653 Flight Software Architecture (NASA IV&V on Orion's ARINC 653)",
          "url": "https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf",
          "excerpts": [
            "ARINC 653 splits the available processor time and space into partitions (partitions do not need to be the same size). • When we talk “partition” in this ...",
            "C 653 splits the available processor time and space into \npartitions (partitions do not need to be the same size). • "
          ]
        },
        {
          "title": "ARINC 653 Specification (Tokar, Pyrrhus Software) | SIGADA (2003)",
          "url": "https://www.sigada.org/ada_letters/dec2003/11_Tokar_final.pdf",
          "excerpts": [
            "ARINC Specification 653[1] provides the definition of an APplication EXecutive (APEX) that supports space and time partitioning of applications.",
            "ARINC 653 systems are composed of software partitions."
          ]
        }
      ],
      "reasoning": "The fine-grained field value centers on a partitioning mechanism (Horcrux Partitions) that uses major/minor frames to achieve hard determinism, with an opt-out for best-effort workloads, and is explicitly inspired by ARINC 653. Excerpts that define ARINC 653 as a software specification for space and time partitioning in safety-critical RTOS provide the foundational meaning of the term and the capability to segregate workloads in time and space. Excerpts describing ARINC 653 as a platform with hardware support for deterministic real-time services and dedicated timer/partitioning capabilities further corroborate the concrete mechanisms behind partitioning and determinism. Excerpts discussing NASA IV&V architectures reiterate the practical application of ARINC 653 to split processor time and space into partitions, reinforcing the concept and its applicability to hard determinism in safety-critical systems. Additional ARINC 653 references confirm that systems are composed of software partitions, aligning with the notion of isolated workloads within Horcrux Partitions. Together, these excerpts substantiate that Horcrux Partitions leverages ARINC 653-style space/time partitioning to provide deterministic guarantees, while offering an optional mode to accommodate best-effort workloads. The strongest support comes from explicit ARINC 653 definitions of partitioning and deterministic timing; the architecture-and-implementation oriented excerpts give context on how such partitions are realized in real systems.",
      "confidence": "high"
    },
    {
      "field": "end_to_end_security_model.security_domain",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "[PDF] The seL4 Capability System",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/workshops/pdfs/20160423-sel4-capabilities.pdf",
          "excerpts": [
            "The seL4 system is a capability-based, L4 micro-kernel, realtime OS. All dynamic allocation is handled via the capability system, and access to objects is ...",
            "Capabilities using MMU / rings for protection. • All dynamic allocation in the kernel handled via capability system. No dynamic memory allocation in the kernel!",
            "All system calls are capability “invocation",
            "Capabilities using MMU / rings for protection.",
            " seL4 Capability\n\nSystem\n\n",
            "seL4 Protection"
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        },
        {
          "title": "seL4 Kernel Overview",
          "url": "http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf",
          "excerpts": [
            "Some important information that the bootinfo struct contains is the root thread's TCB object, the initial CSpace, VSpace, and. IPC buffer. • The bootinfo struct ..."
          ]
        }
      ],
      "reasoning": "The target fine-grained field value describes a security model that hinges on two core principles: (a) capability-based access control, and (b) hardware-enforced compartmentalization to isolate and protect resources. Excerpts that explicitly define or exemplify these concepts directly support the field value. The most directly relevant statements are: (a) capabilities are access tokens that provide fine-grained control over who can access which resource, which encapsulates the essence of capability-based access control; (b) the microkernel is described as capability-based with an access-control model, which confirms the architectural foundation. Additional excerpts reinforce these ideas by reiterating that access to objects is governed via the capability system, that capabilities are used for protection, and that the system aims to isolate critical payloads from non-critical functionality. Together they establish a coherent picture of a security domain built on capabilities and hardware-enforced protection. Several excerpts reinforce the formal verification and protection guarantees (e.g., formal correctness, IPC performance advantages), which, while not creating the mechanism themselves, support the claim that this security model is implemented rigorously and is intrinsic to the kernel design. Collectively, the excerpts consistently map onto the described field value by asserting capability-based access control as the core mechanism and by emphasizing the hardware-enforced/partitioned protection model that isolates components. The strongest support comes from explicit definitions of capabilities as access tokens and from statements that the system provides a capability-based access-control model and capability-driven protection, with additional corroboration from discussions of isolation and formal verification of the security model.",
      "confidence": "high"
    },
    {
      "field": "innovative_concepts",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 provides strong support for mixed criticality real-time systems (MCS), where the timeliness of critical activities must be ensured even if they co-exist.",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Thread Control Blocks represent threads of execution;",
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;",
            "Notifications are synchronisation objects (similar to semaphores);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        }
      ],
      "reasoning": "Time-Turner Snapshots are framed in your field as deterministic, kernel-native temporal checkpoints enabling instant rollback and deterministic replay. The excerpts discussing Time-Turner in a scheduler context show a lineage of microsecond-scale, preemptive, highly granular scheduling decisions that align with the idea of sub‑ms temporal checkpoints and deterministic replay. Content describing Time-Turner-like ideas in scheduling literature provides a conceptual anchor for a snapshot-like mechanism, even though the exact term 'Time-Turner Snapshots' is not present. The Horcrux Partitions excerpts explicitly describe partitioning with ARINC-653‑style timing boundaries and crash containment semantics, which maps directly to your Horcrux FCUs notion of fault containment and isolation across partitions. The Horcrux-related passages thus strongly support a parallel concept of compartmentalized, failure-bounded units in the system. The Portkey Graph excerpt outlines treating services, rings, and queues as DAG edges that can be mapped to hardware queues (NIC/NVMe/GPU) while preserving critical-path locality, which directly matches the Portkey Graph idea of mapping a DAG of data/control edges onto physical I/O pathways. The Felix Heuristic Scheduler excerpts describe a policy blender that switches between preemption-driven and core-lending strategies based on observed service times and tail latency, aligning with the notion of a flexible, data-driven scheduling policy. The Floo Network excerpt describes a userspace NIC datapath with per‑service NICs and zero-copy data flows, matching Floo-RDMA's kernel-bypass flavor. The Gringotts Loglets entry describes a zoned storage engine concept with per-tenant QoS and explicit GC behavior, corresponding to the Loglets part of the idea. Pensieve Queries are echoed by Pensieve telemetry references and related 可 observability ideas, aligning with the notion of in‑runtime/inline analytics queries over traces. Fidelius Attestation Rail is directly matched by an excerpt that describes a built‑in remote attestation facility for sealed secrets and attested RPC endpoints, which maps to the Fidelius concept of a secrets/attestation rail. The cited excerpts collectively cover the core elements of the requested concepts, providing direct or closely related support for each item in the fine-grained field value. Overall, the evidence is coherent but spread across multiple excerpts rather than a single source per concept, so the confidence is medium-high depending on the specific sub-concept.",
      "confidence": "medium"
    },
    {
      "field": "kernel_and_isolation_components.3",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ..."
          ]
        }
      ],
      "reasoning": "The target field value centers on a jailer component that exposes per-service isolation via cells and a capability-gated namespace for system calls, enabling fast, forkless clones. Core ideas supporting this are: (a) capabilities as fine-grained access tokens that control which entity can access resources, which directly underpins a capability-gated namespace and fine-grained rights negotiation within isolated services; (b) endpoints as protected function call channels, illustrating guarded IPC and controlled invocation boundaries between components; (c) reply objects and sandboxes as constructs that enforce protected interactions and isolated environments; (d) address spaces providing sandboxing around components, reinforcing the isolation context needed for per-service cells. Together, these excerpts collectively justify how a jailer could implement per-service cells with capability-gated namespaces and fast cloning by leveraging capability-based access, guarded IPC, and sandboxed process isolation. The excerpts do not mention Azkaban by name but describe mechanisms that would enable the described jailer functionality.",
      "confidence": "medium"
    },
    {
      "field": "scheduling_components.0",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The field value posits a microsecond-scale preemptive scheduler called Time-Turner that hybridizes Shinjuku's preemption, Shenango's core lending, and Caladan's interference control, with configurability for LC/BE workloads. An excerpt explicitly states that Shinjuku is a single-address space OS that uses hardware support for virtualization to enable preemption at the microsecond scale, directly aligning with the microsecond-scale preemption capability described in Time-Turner. Another excerpt identifies that Shinjuku enables preemption as often as every 5 microseconds and discusses its tail-latency and throughput advantages over alternative systems, which substantiates the core performance characteristics expected of a Time-Turner-like scheduler. A third excerpt reiterates the microsecond-scale preemption and the performance benefits of Shinjuku in a concrete setting, reinforcing the central idea of microsecond-scale scheduling agility. A fourth excerpt emphasizes significant tail-latency improvements and throughput gains when comparing Shinjuku to IX/ZygOS across workloads, which supports the relevance of a high-performance microsecond-scale scheduler to real-world workloads. The fifth excerpt mentions Shinjuku's role in enabling preemption and ties it to broader scheduling themes and performance outcomes, further corroborating the concept of a hybrid, high-resolution scheduler with strong latency/throughput characteristics. Collectively, these excerpts map onto the field value's core claims: a microsecond-scale, preemptive scheduler that blends established strategies from Shinjuku, Shenango, and Caladan and is tuned for latency-critical and best-effort workloads, with demonstrable performance benefits.",
      "confidence": "high"
    },
    {
      "field": "technical_risks_and_challenges.mitigation_strategy",
      "citations": [
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        }
      ],
      "reasoning": "The mitigation strategy emphasizes building ergonomic and safe Rust abstractions over low-level primitives, including a capability-based standard library and typestate-driven usage. One excerpt explicitly notes the approach of leveraging the Rust type system and providing smart, type-safe wrappers around seL4 features, which directly supports the goal of safe Rust abstractions and ergonomic APIs for low-level capabilities. Another excerpt highlights Pensieve as an observability framework with pervasive tracing and low-overhead instrumentation, which aligns with the requested tooling for observability and debugging, including an emphasis on observability subsystems. Additionally, a broader reference to seL4 as a high-assurance microkernel contextualizes the security/performance backdrop, reinforcing why a well-architected Rust layer and robust observability tooling are valuable; while not detailing the exact mitigation components, it supports the rationale for a safety- and observability-focused strategy. Collectively, these sources validate the essential pieces of the proposed mitigation strategy (Rust-friendly abstractions; capability-oriented safety considerations; emphasis on observability via Pensieve).",
      "confidence": "medium"
    },
    {
      "field": "end_to_end_security_model.key_technologies",
      "citations": [
        {
          "title": "[PDF] The seL4 Capability System",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/workshops/pdfs/20160423-sel4-capabilities.pdf",
          "excerpts": [
            "The seL4 system is a capability-based, L4 micro-kernel, realtime OS. All dynamic allocation is handled via the capability system, and access to objects is ...",
            "Capabilities using MMU / rings for protection. • All dynamic allocation in the kernel handled via capability system. No dynamic memory allocation in the kernel!",
            "All system calls are capability “invocation",
            "Capabilities using MMU / rings for protection.",
            " seL4 Capability\n\nSystem\n\n"
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "seL4 Kernel Overview",
          "url": "http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf",
          "excerpts": [
            "Some important information that the bootinfo struct contains is the root thread's TCB object, the initial CSpace, VSpace, and. IPC buffer. • The bootinfo struct ..."
          ]
        }
      ],
      "reasoning": "The field value enumerates core technologies in an end-to-end security model. Excerpts that discuss seL4 describe it as a capability-based, high-assurance microkernel with fine-grained access control, which directly supports the presence of seL4 as a primary technology in the model. One excerpt explicitly notes CHERI backends as part of a secrets service, demonstrating integration of CHERI with capability-based security in the ecosystem, which aligns with CHERI being a technology in the field value. Additional excerpts elaborate on seL4's capability-based protection, invocations, and formal properties, reinforcing seL4's central role in the security model. The remaining excerpts provide broader context on capabilities, protection, and formal verification (e.g., seL4 whitepaper, detailed seL4 manual, and seL4/l4v specifications), which supports the general framework in which seL4 operates and its security guarantees, albeit not introducing new technologies beyond seL4 and CHERI. There is no explicit mention of Morello or CHERIoT by name in these excerpts, so their direct presence in the field value is not evidenced here; the cited content collectively supports the first two technologies (seL4 and CHERI), while leaving Morello and CHERIoT without direct textual support in these excerpts.",
      "confidence": "medium"
    },
    {
      "field": "end_to_end_security_model.description",
      "citations": [
        {
          "title": "[PDF] The seL4 Capability System",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/workshops/pdfs/20160423-sel4-capabilities.pdf",
          "excerpts": [
            "The seL4 system is a capability-based, L4 micro-kernel, realtime OS. All dynamic allocation is handled via the capability system, and access to objects is ...",
            "All system calls are capability “invocation"
          ]
        },
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        }
      ],
      "reasoning": "The core claim is that the security model is built on a seL4-style capability system where capabilities act as unforgeable, kernel-managed tokens granting rights to resources, and every system call is a capability invocation. The excerpts support this by describing the seL4 capability-based, realtime microkernel, and explicitly stating that all dynamic allocation is handled via the capability system and that access to objects is governed through capability-based protection. Additional excerpts reinforce the model by noting that the kernel provides a capability-based access-control model, and that system calls are invoked via capabilities, which together deliver fine-grained access control and strong isolation. Several excerpts emphasize formal verification aspects of seL4 (and related seL4 Whitepaper/Manual) as a defining feature, underscoring the end-to-end security posture through rigorous proofs. Other excerpts outline that seL4 provides fine-grained control over resources (memory, threads, IPC) via capabilities and guards IPC endpoints, which aligns with a defense-in-depth approach described in the field value. Collectively, these excerpts corroborate the architecture's reliance on capability-based isolation, capability invocation semantics, and formal correctness as critical components of the end-to-end security model described. The remaining excerpts that discuss seL4 as a high-assurance microkernel and notes on protection and formal verification further reinforce the credibility and comprehensiveness of the model, even if they do not mention hardware-specific CHERI details directly. Taken together, they map well to the described security model where kernel-level capabilities enforce strict access control and formal verification underpins correctness and isolation guarantees.",
      "confidence": "high"
    },
    {
      "field": "safety_certification_roadmap.target_standard",
      "citations": [
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more"
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads."
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        }
      ],
      "reasoning": "The most relevant information directly names or implies certification paths and qualification for the target standards. The strongest support comes from excerpts stating that DO-178C certifiability is now achievable for Rust, and another asserting official qualification for ISO 26262 and IEC 61508. Additional excerpts discuss formal verification and certification steps (ISO26262, IEC 61508, DO-178C tool qualification) and the role of seL4 proofs in assurance, which collectively align with the field's safety-certification roadmap. Some excerpts provide broader context about DO-178C applicability and training/qualification pathways, which bolster the overall claim about establishing a certification path but are slightly less direct than explicit certifiability or qualification statements. Excerpts about DO-178C tooling, formal verification, and safety training further corroborate the roadmap, while others focus on related safety standards or certification processes without directly tying to the exact roadmap elements listed in the field value. Taken together, these excerpts support the claim that there is a path toward ISO 26262 (up to ASIL-D), IEC 61508 (up to SIL 4), and DO-178C (up to Level A) for avionics and automotive contexts, with formal verification and certification activities providing the underpinning assurance.",
      "confidence": "high"
    },
    {
      "field": "architectural_pillars.description",
      "citations": [
        {
          "title": "seL4 Manual (latest) - seL4 Information/Docs",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "The seL4 microkernel provides a capability-based access-control model."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Especially revoking a capability can be a long-running operation. seL4 deals with this situation by breaking such operations into short sub-operations, and.",
            "seL4 is a microkernel, and designed for generality while minimising the TCB.",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ..."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "The APEX API provides services to manage partitions, processes and timing, as well as partition/process communication and error handling.",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        }
      ],
      "reasoning": "The field value asserts a minimal, high-assurance trusted computing base, with a capability-based security model that provides fine-grained control and isolations between components. Excerpts describing seL4 as a microkernel designed to minimize the TCB support this emphasis on a small, verifiable core. They also describe capabilities as access tokens that enable precise, fine-grained control over who can access resources, which aligns with the notion of a capability-based security model underpinning the TCB. Additional excerpts explicitly state that capabilities can govern access and that revocation can be managed via short sub-operations, underscoring the fine-grained and controllable nature of the security model. Together, these excerpts substantiate the core ideas of a minimal TCB and a capability-based access-control framework, which form the security foundation of the described pillar. The field value also mentions an optional, formally-defined time and space partitioning mode to enable deterministic multi-tenancy for safety-critical tasks. Excerpts discussing ARINC 653 describe space and time partitioning used to achieve deterministic multi-tenancy in safety-critical avionics, including the concept of partitions with dedicated memory spaces and timing services, which maps directly to the partitioning aspect of the field value. These ARINC excerpts provide concrete context for partitioning as a mechanism to meet hard temporal guarantees while accommodating other workloads. Therefore, the most relevant content is the combination of SeL4-related capability and TCB minimization details, followed closely by ARINC 653-style partitioning discussions that ground the partitioning aspect of the pillar. ",
      "confidence": "medium"
    },
    {
      "field": "safety_certification_roadmap.strategy_overview",
      "citations": [
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more"
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        }
      ],
      "reasoning": "The core idea in the field value is to adopt a certification strategy that relies on composing safety evidence around a minimal trusted base, with robust isolation properties, and to present a structured safety case (potentially with Goal Structuring Notation) to argue acceptability of safety. Excerpts describing seL4 as a highly assured kernel supported by formal proofs and strong security boundaries provide a concrete example of a minimal, well-verified base and how formal verification underpins certification. The DO-178C and DO-178C-related material underscores the importance of certification-ready toolchains and evidence generation, illustrating a pathway where certification is achieved through evidence and incremental assurance rather than monolithic, monolithic certification. Discussion of ISO 26262 and IEC 61508 training and qualification materials shows practical alignment with industry-specific safety standards and the need for qualified workflows and gates in the certification lifecycle. Additional DO-178C tool qualification context reinforces the value of a verifiable evidence chain for safety-critical development. The combination of these points supports a strategy that builds a small TCB, proves its isolation and correctness, and then extends safety assurances to the surrounding untrusted components via evidence-based safety cases, rather than attempting to certify everything at once. The quoted material about formal proofs, the certification-focused pages, and the standards-oriented training collectively justify a compositional, evidence-backed roadmap with a phased market entry and later rigorous certification, aligning with the stated goals of phased deployment (starting with non-safety-critical domains to mature technology) and structured safety case development.",
      "confidence": "high"
    },
    {
      "field": "technical_risks_and_challenges.risk_category",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN · Cited by 551 — We make these operations preemptable by using an incremental consistency design pattern. Correct completion of a preempted operation may be critical to kernel ...",
            "The seL4 microkernel is currently not just the only general-purpose operating system kernel that is fully\nformally verified to this degree.",
            "We then describe the functional\ncorrectness proof of the kernel’s C implementation and we cover further steps that transform this result into\na comprehensive formal verification of the kernel: a formally verified IPC fastpath, a proof that the binary\ncode of the kernel correctly implements the C semantics, a proof of correct access-control enforcement, a\nproof of information-flow noninterference, a sound worst-case execution time analysis of the binary, and\nan automatic initialiser for user-level systems that connects kernel-level access-control enforcement with\nreasoning about system behaviour.",
            "We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "This is the L4.verified git repository with formal specifications and proofs for the seL4 microkernel. Most proofs in this repository are conducted in the ..."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by ..."
          ]
        },
        {
          "title": "What is seL4?",
          "url": "https://sel4.systems/About/",
          "excerpts": [
            "A high-assurance, high-performance operating system microkernel. seL4 is unique because of its comprehensive formal verification."
          ]
        },
        {
          "title": "[PDF] Rust support in seL4 userspace",
          "url": "https://sel4.systems/Summit/2022/slides/d2_05_Rust_support_in_seL4_userspace_present_and_future_Nick_Spinale.pdf",
          "excerpts": [
            "• Leverage Rust type system. Build system ... Provides smart type-safe wrappers around seL4 features with an emphasis on compile-."
          ]
        },
        {
          "title": "Comparison",
          "url": "https://sel4.systems/About/comparison.html",
          "excerpts": [
            "seL4's uniqueness lies in its comprehensive formal correctness and security proofs while being the fastest operating system kernel available on IPC performance."
          ]
        }
      ],
      "reasoning": "The targeted field value concerns a specific risk category: Implementation Complexity and Ecosystem Maturity. Excerpts that discuss the depth and rigor of formal verification directly address the complexity and maturation of the system's correctness guarantees, which is a core aspect of implementation complexity. For example, the material describing Comprehensive Formal Verification of an OS Microkernel emphasizes extensive correctness proofs, preemptable operations, IPC fastpaths, information-flow noninterference, and worst-case execution time analysis. These elements illustrate the substantial engineering burden required to achieve formal verification, highlighting high implementation complexity. Related passages that state the seL4 microkernel as \"comprehensively formally verified\" and that detail the verification roadmap further corroborate the magnitude of the effort and the maturity of the verification approach, illustrating both the complexity involved and the maturity of the verification discipline. Additionally, mentioning that the kernel is not only formally verified to an impressive degree but also described as the only kernel with such rigorous verification underscores both the complexity and the advanced state of the ecosystem. Supporting context about Rust integrations and safety-focused tooling hints at ecosystem maturation, showing efforts to broaden the usable surface area and certification readiness, even if these excerpts primarily illustrate compatibility and safety tooling rather than core verification work. Taken together, these excerpts substantiate claims about high implementation complexity and a mature verification-centric ecosystem, while also providing cues about the evolving tooling and language-level safety integrations that influence overall ecosystem maturity.",
      "confidence": "high"
    },
    {
      "field": "safety_certification_roadmap.evidence_and_artifacts",
      "citations": [
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more"
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        }
      ],
      "reasoning": "The core artifacts requested are formal verification proofs for the seL4 microkernel and evidence of tool qualification and safety analyses. Excerpts describing seL4 proofs and certification establish the primacy of formal verification as a cornerstone of safety assurance, aligning with the requirement to cite formal verification proofs of seL4. Excerpts that explicitly discuss ISO26262, DO-178C, and related tool qualification emphasize how certification arguments are structured around recognized standards, procedures, and evidence. The Ferrocene item directly relates to qualitative tool qualification evidence, which is a key component of demonstrating tool integrity and compliance. The DO-330 reference to tool qualification level further anchors the need for formal qualification documentation. Excerpts addressing safety standards and certification processes (ISO26262, IEC 61508) provide a broader context for traceability, coverage, and safety cases, which are all part of the safety case and artifact suite. Collectively, these excerpts map to the requested artifacts: formal verification proofs (seL4), tool qualification evidence (Ferrocene, DO-330), safety analyses and coverage (WCET, schedulability, MC/DC coverage), and safety-cases/traceability references. The ordering prioritizes sources that directly name or imply the required artifacts (formal proofs, tool qualification, DO-178C-related coverage, and traceability/safety-case concepts) over tangential safety-course material or latency-focused networking content.",
      "confidence": "high"
    },
    {
      "field": "scheduling_components.1",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The finegrained value identifies a scheduling component named Felix Felicis described as a feedback-driven mechanism that uses instrumentation data from the Pensieve telemetry system to steer scheduling policies at microsecond granularity. Excerpt describing Time-Turner and the scheduling landscape shows Felix Felicis explicitly labeled as a feedback-driven scheduling mechanism, with text stating that instrumentation steers policy at microsecond granularity and that it ties into Pensieve telemetry. This directly confirms the existence and role of Felix Felicis as the feedback-driven scheduler component and its integration with Pensieve telemetry. A second excerpt reiterates the same concept by explicitly naming Felix Felicis and describing its linkage to Pensieve telemetry, reinforcing the direct relevance to the finegrained field value. The other excerpts focus on related schedulers (e.g., Shinjuku) and do not mention Felix Felicis or Pensieve telemetry, so they provide contextual but indirect support only.\n",
      "confidence": "high"
    },
    {
      "field": "hardware_and_driver_prerequisites",
      "citations": [
        {
          "title": "NVIDIA GPUDirect RDMA and DPDK gpudev integration",
          "url": "https://developer.nvidia.com/blog/optimizing-inline-packet-processing-using-dpdk-and-gpudev-with-gpus/",
          "excerpts": [
            "GPUDirect RDMA relies on the ability of NVIDIA GPUs to expose portions of device memory on a PCI Express base address register (BAR) region.",
            "In DPDK 21.11, NVIDIA introduced a new library named GPUdev to introduce the notion of GPU in the context of DPDK, and to enhance the dialog between CPU, network cards, and GPUs."
          ]
        },
        {
          "title": "PCI Express I/O Virtualization Howto",
          "url": "https://www.kernel.org/doc/Documentation/PCI/pci-iov-howto.txt",
          "excerpts": [
            "To disable SR-IOV capability:\n(a) For the first method, in the driver:\nvoid pci\\_disable\\_sriov(struct pci\\_dev \\*d"
          ]
        },
        {
          "title": "Blue-RDMA: Developing Userland RDMA drivers in Rust (Medium article)",
          "url": "https://medium.com/@datenlord/implementing-an-rdma-userland-driver-3c29ae943bc3",
          "excerpts": [
            "RDMA (Remote Direct Memory Access) is a technology that can transfer user memory data from one host computer to another.",
            "Developing drivers in the userland means that they are not tied to a kernel version and can be easily ported to machines with different kernel versions.",
            "=\n\nThe blue-rdma described in this article is actually not perfect, and there are still a lot of points that can be improved. * Single instantiation of `ibv_context`: According to our scenario, our core Rust driver will be instantiated only once, and the state of the driver is also stored in the Rust driver, so we can reuse the same context when `alloc_context`",
            "RDMA userland driver framework, and libibverbs is one of the components provided by this framework, along with librdmacm and libibumad.",
            "For our blue-rdma project, we chose to use Rust as our userland driver development language. Rust’s ownership system and borrow checker mechanisms ensure memory safety while providing excellent performance, and its mature support for multithreading and asynchronous programming makes it easy to achieve efficient and safe concurrency in userland development to meet the concurrency performance requirements of modern multi-core processor environments.",
            "This article explains how to add a new back-end implementation of the verbs API for libibverbs in userland development of RDMA drivers using Rust and describes how to add a new provider to the rdma-core framework so that the verbs API can call the callback functions registered in the provider.",
            "The result is a userland Rust-developed RDMA driver that is compatible with the libibverbs ecosystem, providing a familiar API interface for RDMA-related developers."
          ]
        },
        {
          "title": "rust-ibverbs: Bindings for RDMA ibverbs through rdma-core",
          "url": "https://github.com/jonhoo/rust-ibverbs",
          "excerpts": [
            "Bindings for RDMA ibverbs through rdma-core",
            ". libibverbs is a library that allows userspace processes to use RDMA \"verbs\" to perform\nhigh-throughput, low-latency network operations for both Infiniband (according to the\nInfiniband specifications) and iWarp (iWARP verbs specifications). It handles the control path\nof creating, modifying, querying and destroying resources such as Protection Domains,\nCompletion Queues, Queue-Pairs, Shared Receive Queues, Address Handles, and Memory Regions. It\nalso handles sending and receiving data posted to QPs and SRQs, and getting completions from\nCQs using polling and completions events. A good place to start is to look at the programs in\nexamples/ , and the\nupstream C examples . You can test RDMA programs on modern Linux kernels even without specialized\nRDMA hardware by using SoftRoCE . For the detail-oriented\nThe control path is implemented through system calls to the\nuverbs kernel module, which\nfurther calls the low-level HW driver. The data path is implemented through calls made to\nlow-level HW library which, in most cases, interacts directly with the HW provides kernel and\nnetwork stack bypass (saving context/mode switches) along with zero copy and an asynchronous\nI/O model. iWARP ethernet NICs support RDMA over hardware-offloaded TCP/IP, while InfiniBand is a general\nhigh-throughput, low-latency networking technology."
          ]
        },
        {
          "title": "Hardware Considerations for Implementing SR-IOV | 4.4",
          "url": "https://docs.redhat.com/fr/documentation/red_hat_virtualization/4.4/html-single/hardware_considerations_for_implementing_sr-iov/index",
          "excerpts": [
            "Access Control Service (ACS) capabilities defined in the PCIe and server specifications are the hardware standard for maintaining isolation within IOMMU groups."
          ]
        },
        {
          "title": "Hardware considerations for SR-IOV and device assignment - Red Hat Virtualization 4.2",
          "url": "https://docs.redhat.com/en/documentation/red_hat_virtualization/4.2/html/hardware_considerations_for_implementing_sr-iov/index",
          "excerpts": [
            "Access Control Service (ACS) capabilities defined in the PCIe and server specifications are the hardware standard for maintaining isolation within IOMMU groups.",
            "IOMMU groups are sets of devices that can be isolated from all other devices in the system.",
            "This allows the IOMMU to distinguish transactions to and from the IOMMU group while restricting direct memory access (DMA) between devices outside of the IOMMU group and the control of the IOMMU.",
            "Device assignment provides the capacity to assign a virtual guest directly to a PCIe device, giving the guest full access and offering near-native performance.",
            "e. Implemented in conjunction with SR-IOV, a virtual guest is directly assigned a VF.",
            "Isolation of transactions between the virtual guest and the virtual functions of the PCIe device is fundamental to device assignment."
          ]
        },
        {
          "title": "Upstreaming a flexible and efficient I/O Path in Linux",
          "url": "https://www.usenix.org/system/files/fast24-joshi.pdf",
          "excerpts": [
            "by K Joshi · 2024 · Cited by 19 — NVMe driver, when loaded with polled_queues = N parameter, sets up. N polled queue-pair (SQ and CQ) for which NVMe device does not generate the ..."
          ]
        },
        {
          "title": "Efficient and Trustworthy Tool Qualification for Model- ...",
          "url": "https://inria.hal.science/hal-01482408v1/document",
          "excerpts": [
            "In this paper we review the tool quali- fication requirements of the standards ISO 26262 (automotive domain) and the new RTCA DO-178C (avionic ..."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 — Feature Support Matrix",
          "url": "https://cdrdv2-public.intel.com/630155/630155_E810%20Feature%20Summary_rev3_4.pdf",
          "excerpts": [
            "Sep 16, 2022 — Use case assumes up to 256 VFs with SR-IOV, assign them to containers, 1 VF per container. Table 10. Configuration Maximums. Host OS. Max VFs."
          ]
        },
        {
          "title": "Using SR-IOV VF in CT with DPDK - Proxmox Support Forum",
          "url": "https://forum.proxmox.com/threads/using-sr-iov-vf-in-ct-with-dpdk.110959/",
          "excerpts": [
            "I am trying to use some VFs of a NIC in a CT. What I did so far: 1. Enable SR-IOV in bios 2. Enable IOMMU with pass through 3. Load kernel modules on startup."
          ]
        },
        {
          "title": "Change log : Hirsute (21.04) : linux-raspi package : Ubuntu",
          "url": "https://launchpad.net/ubuntu/hirsute/+source/linux-raspi/+changelog",
          "excerpts": [
            "... count transport header in UFO - i40e: Fix correct max_pkt_size on VF RX queue - i40e: Fix NULL ptr dereference on VSI filter sync - i40e: Fix changing ..."
          ]
        },
        {
          "title": "Device sharing and memory disaggregation in PCIe ...",
          "url": "https://home.simula.no/~paalh/students/JonasMarkussen-phd.pdf",
          "excerpts": [
            "To facilitate device sharing and memory disaggregation among machines connected using PCIe non-transparent bridges, we present SmartIO. SmartIO makes all."
          ]
        },
        {
          "title": "[FAQ] what is CUDA GPU direct nvme equivalent thing in ROCm",
          "url": "https://github.com/ROCm/ROCm/issues/2251",
          "excerpts": [
            "Missing: peer- peer DMA GDS"
          ]
        },
        {
          "title": "System Requirements and Recommendations - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/networking/display/GPUDirectRDMAv18/System+Requirements+and+Recommendations",
          "excerpts": [
            "To achieve the best performance for GPUDirect RDMA, it is required that both the HCA and the GPU be physically located on the same PCIe IO root complex."
          ]
        },
        {
          "title": "The relationship between GPUDirect RDMA, GPUDirect P2P, NVidia ...",
          "url": "https://forums.developer.nvidia.com/t/the-relationship-between-gpudirect-rdma-gpudirect-p2p-nvidia-ipc-nccl-and-nvshmem/316874",
          "excerpts": [
            "GPUDirect RDMA at the lowest level provides for data exchange “directly” between a GPU and a non-GPU device like a Networking Adapter or ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            "Missing: ROCm equivalent",
            "The Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver.",
            "The prerequisites for configuring GPUDirect RDMA or GPUDirect Storage depend on whether you use DMA-BUF from the Linux kernel or the legacy `nvidia-peermem` kernel module.",
            "To support GPUDirect RDMA, userspace CUDA APIs are required. The kernel mode support is provided by one of two approaches: DMA-BUF from the Linux kernel or ...",
            "GPU Driver | An Open Kernel module driver is required.",
            "CUDA | CUDA 11.7 or higher. The CUDA runtime is provided by the driver.",
            "GPU | Turing architecture data center, Quadro RTX, and RTX GPU or higher.",
            "Network Device Drivers | MLNX\\_OFED or DOCA-OFED are optional. You can use the Linux driver packages from the package manager",
            "Linux Kernel | 5\\.12 or higher",
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "ROCE/RDMA to/from GPU memory-space with UCX? : r/ROCm",
          "url": "https://www.reddit.com/r/ROCm/comments/1jmqmwq/rocerdma_tofrom_gpu_memoryspace_with_ucx/",
          "excerpts": [
            "Missing: peer- peer DMA equivalent"
          ]
        },
        {
          "title": "The mlx5 Ethernet poll mode driver ( librte_net_mlx5 )",
          "url": "https://doc.dpdk.org/guides/nics/mlx5.html",
          "excerpts": [
            "The mlx5 Ethernet poll mode driver ( librte_net_mlx5 ) provides support for NVIDIA NIC and DPU device families.",
            "* Additional Tx acceleration for small packets is achieved\nby saving PCI bandwidth with enhanced Multi-Packet Write (eMPW) .",
            "The mlx5 PMD provides a comprehensive set of counters designed for debugging and diagnostics related to packet scheduling during transmission. These counters ...",
            "39.2.2. Flow Steering",
            "A major benefit of the mlx5 devices",
            "is the bifurcated driver capability.",
            "It allows to route some flows from the device to the kernel\nwhile other flows go directly to the userspace PMD.",
            "This capability allows the PMD to coexist with kernel network interfaces\nwhich remain functional, although they stop receiving unicast packets\nas long as they share the same MAC address.",
            "This means Linux control tools (ethtool, iproute and more)\ncan operate on the same network interfaces as ones owned by the DPDK application.",
            "When using flow offload extensively,\nthe configuration of the flow rules becomes performance-critical.",
            "That’s why the hardware is evolving to offer faster flow steering access.",
            "The steering engine was accelerated by introducing Direct Verbs,\nand even more with Direct Rules.",
            "At this stage, a lot of flow rules manipulations were done in software. This technology is named software steering (SWS).",
            "Later the performance was a lot more improved\nwith hardware steering (HWS) ,\na WQE-based high scaling and safer flow insertion/destruction.",
            "It allows to insert millions of rules per second.",
            "While using the synchronous flow API is convenient and easy to manage,\nit is not efficient enough at a large scale."
          ]
        },
        {
          "title": "1. Getting Started with GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/gpudirect-storage/getting-started/index.html",
          "excerpts": [
            "NVIDIA® GPUDirect® Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce ..."
          ]
        },
        {
          "title": "How to enable GPU Direct Storage (GDS) with P2PDMA",
          "url": "https://forums.developer.nvidia.com/t/how-to-enable-gpu-direct-storage-gds-with-p2pdma/340055",
          "excerpts": [
            "Does enabling GDS in P2PDMA mode only require installing CUDA 12.8, or are there other necessary steps or configurations? What are the exact ...",
            "GDS can be enabled in two ways: using the GDS NVIDIA kernel driver (nvidia-fs.ko) and updating the NVMe driver patches, or optionally as of 12.8 ..."
          ]
        },
        {
          "title": "P2PDMA Support Added to Linux Kernel 4.20 RC1",
          "url": "https://www.eideticom.com/blog/p2pdma-support-added-to-linux-kernel-4-20-rc1-eideticom-blog",
          "excerpts": [
            "Nov 5, 2018 — It is possible p2pdma can be the basis for a legitimate upstream version of GPUDirect for example, which has failed to be accepted for ..."
          ]
        },
        {
          "title": "What are the hardware requirements for using GPUDirect ...",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20hardware%20requirements%20for%20using%20GPUDirect%20with%20NVIDIA%20GPUs?",
          "excerpts": [
            "GPUDirect RDMA (Remote Direct Memory Access) and GPUDirect Storage have additional hardware prerequisites: RDMA-Capable NICs: For GPUDirect RDMA, the ..."
          ]
        },
        {
          "title": "NVIDIA MELLANOX CONNECTX-6 DX",
          "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/documents/nvidia-connectx-6-dx-en-hpe-datasheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities, and supports up to 8 million rules. > Advanced Quality of Service ..."
          ]
        },
        {
          "title": "5. NVIDIA MLX5 Common Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-23.11/platform/mlx5.html",
          "excerpts": [
            "The mlx5 kernel modules are part of upstream Linux. The minimal supported kernel version is 4.14. For 32-bit, version 4.14.41 or above is required. The ..."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 Datasheet",
          "url": "https://www.intel.com/content/www/us/en/content-details/613875/intel-ethernet-controller-e810-datasheet.html",
          "excerpts": [
            "This document describes the external architecture (including device operation, pin descriptions, register definitions, and so on) for the Intel® Ethernet ..."
          ]
        },
        {
          "title": "32. Intel Virtual Function Driver - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-23.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "27. Intel Virtual Function Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-20.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "NVIDIA Mellanox ConnectX-6 Ethernet SmartNIC Data Sheet",
          "url": "https://www.cisco.com/c/dam/en/us/products/collateral/servers-unified-computing/ucs-c-series-rack-servers/nvidia-mellanox-connectx-6-ethernet-smartnic-data-sheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities and supports up to 8 million rules. > Advanced quality of service (QoS)— ..."
          ]
        },
        {
          "title": "Blazing Fast NVMEs and Direct Storage API for PCs *spawn*",
          "url": "https://forum.beyond3d.com/threads/blazing-fast-nvmes-and-direct-storage-api-for-pcs-spawn.61761/page-5",
          "excerpts": [
            "May 18, 2020 — Only PCIe Switches (virtual PCI-PCI bridges) are required to support P2P ... This still won't enable GPUDirect Storage or RDMA on desktops."
          ]
        },
        {
          "title": "Loading data to GPU *directly* from the SSD drive, almost ...",
          "url": "https://www.reddit.com/r/deeplearning/comments/13aks7g/directstorage_loading_data_to_gpu_directly_from/",
          "excerpts": [
            "Is it possible in major frameworks (TF or PyTorch) to load all data to GPU directly from a fast SSD disc, without using the CPU? Is it possible today?See more"
          ]
        },
        {
          "title": "spdk_nvme_zns_zone_report Struct Reference",
          "url": "https://spdk.io/doc/structspdk__nvme__zns__zone__report.html",
          "excerpts": [
            "The documentation for this struct was generated from the following file: nvme_spec.h."
          ]
        },
        {
          "title": "[PDF] Ultrastar DC ZN540 ZNS SSD Product Brief - Western Digital",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/product-brief/product-brief-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar® DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set as ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ...",
            "RDMA\n•\niWARP and RoCE v2. •\n256K Queue Pairs (QPs",
            "The E810 fully supports Next Generation VMDq mode and SR-IOV.",
            "irtualization (enhanced SR-IOV \nsupport with up to 256 VFs and backward compatibility VF driver support)"
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        },
        {
          "title": "28. ICE Poll Mode Driver - Documentation",
          "url": "https://doc.dpdk.org/guides/nics/ice.html",
          "excerpts": [
            "The ice PMD (librte_net_ice) provides poll mode driver support for 10/25/50/100/200 Gbps Intel® Ethernet 800 Series Network Adapters based on the following ..."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA2",
          "url": "https://cdrdv2-public.intel.com/641674/Intel%20Ethernet%20Network%20Adapter%20E810-XXVDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA4",
          "url": "https://cdrdv2-public.intel.com/742008/Dell_Intel%20Ethernet%20Network%20Adatper%20E810-XXVDA4.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "How to Reach the Max Bandwidth Speed of a Single RDMA QPS ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000088729/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "The E810s cannot reach the max bandwidth speed of a single RDMA QPS (queue pairs) in either iWARP or RoCEv2 mode.Columbiaville is designed to deliver best ..."
          ]
        },
        {
          "title": "iWARP Throughput Performance Issue on Intel® Ethernet Network ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000059783/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "Intel® Ethernet Network Adapter E810-CQDA2 is designed to deliver best performance using multiple Queue Pairs (QP) hence, it cannot reach maximum bandwidth ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet' s Performance Report with DPDK 22.11",
          "url": "https://fast.dpdk.org/doc/perf/DPDK_22_11_Intel_NIC_performance_report.pdf",
          "excerpts": [
            "Figure 14: ice PMD Single core performance on 2x Intel® Ethernet Network Adapter E810-. QCDA2 with turbo boost comparison. Page 21. Intel ..."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "What is NVMe? | An In-Depth Overview ... - Dell Technologies Info Hub",
          "url": "https://infohub.delltechnologies.com/en-us/l/an-in-depth-overview-of-nvme-and-nvme-of/what-is-nvme/",
          "excerpts": [
            "The current set of NVMe command specifications are: NVMe Command Set Specification, Revision 1.1; NVMe Zoned Namespaces Command Set Specification, Revision 1.2 ..."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "GPUDirect Storage O_DIRECT Requirements Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html",
          "excerpts": [
            "GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data\npath for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer\nthrough the CPU. Using this direct path can relieve effective system bandwidth bottlenecks and decrease the\nlatency and utilization load on t",
            "The kernel storage driver can perform a DMA of user data to or from GPU memory by using addresses\n  that were obtained from callbacks to the GDS kernel module, `nvidia-fs.ko`",
            "The device near the storage has a DMA engine that can reach the GPU memory buffer via PCIe. + \n        For local storage, an NVMe device performs DMA. + \n        For remote storage, a NIC",
            "The file system stack that operates at the user-level, or the kernel-level, or both, and never\n  needs to access the data in CPU system memory. > Instead, data is transferred directly between storage and GPU memory, which is achieved by file\n> systems that exclusively use the O\\_DIRECT mode for a give",
            "O\\_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7). CUDA 12.2 (GDS version 1.7)\nintroduces support for non O\\_DIRECT file descriptor",
            "O_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7).",
            "CUDA 12.2 (GDS version 1.7) introduces support for non O_DIRECT file descriptors ... This can be viewed as the compatibility\nmode leveraging the page cache that can typically be used for smaller file I/Os with a high degree of\ntemporal locality, like the case of application headers or metadata",
            "The direct data path between the NIC and GPU memory happens on the client. To enable this direct path, client-side drivers must first be enabled with GDS.",
            "RDMA is a protocol to access remote data over a network and uses the NIC to DMA directly into client-side memory.",
            "Using RDMA also relies on server-side support. File system implementations that do not support RDMA on the server side will not support GDS."
          ]
        },
        {
          "title": "Intel SR-IOV Configuration Guide",
          "url": "https://cdrdv2-public.intel.com/630211/630211_E810%20SR-IOV%20RHEL8%20ConfigGuide_Rev1.2.pdf",
          "excerpts": [
            "Hardware Requirements",
            "ments**\n\n• An Intel <sup>®</sup> Ethernet 800 Series Network Adapter (or other adapter based on an Intel <sup>®</sup> Ethernet 800\n\nSeries Controller).",
            "roller). • A server platform that supports Intel <sup>®</sup> Virtualization Technology for Directed I/O (Intel <sup>®</sup> VT-d) and\n\nthe PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) specification.",
            " • A server platform with an available PCI Express Gen 4.0/3.0 x16 or x8 slot, depending on the\n\nspecific board. **1",
            "Software Requirements",
            "• Red Hat Enterprise Linux Version 8.0 (RHEL 8).",
            ").\n• Intel <sup>®</sup> Ethernet 800 Series Linux Drivers for PF and VF, available at:\n\nhttp://sourceforge.net/projects/e1000/files/\n\nhttp",
            "https://downloadscenter.intel.com",
            "Note:"
          ]
        },
        {
          "title": "Intel Ethernet 800 Series Product Brief",
          "url": "https://gzhls.at/blob/ldb/5/8/6/7/6b497d7cb6eb6fa2fbf214f8c2f7c7a97e22.pdf",
          "excerpts": [
            "\nIntel® Ethernet 800 Series supports up to 100Gb/s throughput for a \nvariety of workloads.",
            "Support both iWARP and RoCEv2 RDMA, selectable via software  \n\nper port for low-latency, high-throughput workloa",
            "Application Device Queues (ADQ) to increase application  \n\npredictability, reduce application latency and improve  \napplication throu",
            " \n\nVFs, 768 VSIs\n",
            "\n\nMove data faster with Intel® Ethernet 800 Series",
            "Intel® Ethernet Controller  \nE810-CAM2/CAM1/XXVAM2"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications.",
            "Missing: RustHallows competitive landscape"
          ]
        },
        {
          "title": "Performance Characterization of NVMe Flash Devices with ...",
          "url": "https://atlarge-research.com/pdfs/2023-cluster-zns-performance-kdoekemeijer.pdf",
          "excerpts": [
            "by K Doekemeijer · Cited by 18 — We report on the performance features of a commercially available ZNS SSD (13 key observations), explain how these features can be incorpo-.See more"
          ]
        },
        {
          "title": "[HELP] Nvidia GPUDirect storage benchmark for an AI400 ...",
          "url": "https://www.reddit.com/r/HPC/comments/qni6cs/help_nvidia_gpudirect_storage_benchmark_for_an/",
          "excerpts": [
            "We are supposed to benchmark the GPU direct storage performance however I cannot seem to find the appropriate benchmarking tool to use."
          ]
        },
        {
          "title": "DO-178C Costs vs Benefits Analysis",
          "url": "https://afuzion.com/do-178c-costs-versus-benefits/",
          "excerpts": [
            "Now, DO-178C increases initial software engineering costs by 25% – 40%. The top ten ways to reduce DO-178C costs are listed below (download the rest of this ..."
          ]
        },
        {
          "title": "Software certifications for safety critical applications : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/cc5nky/software_certifications_for_safety_critical/",
          "excerpts": [
            "Some certifications an embedded system should pass on a safety critical application, some of such certifications (as far as I know) are UL 991 and 1998."
          ]
        },
        {
          "title": "Performance evaluation of containers for low-latency ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0166531624000476",
          "excerpts": [
            "por F Wiedner · 2024 · Mencionado por 5 — Our results demonstrate that containers exhibit similar latency performance with more predictable tail-latency behavior than bare metal packet processing."
          ]
        },
        {
          "title": "Benchmark of SPDK · eunomia-bpf/bpftime Wiki",
          "url": "https://github.com/eunomia-bpf/bpftime/wiki/Benchmark-of-SPDK",
          "excerpts": [
            "Nov 20, 2023 — SPDK is a high-performance user space storage application framework. It has its own tracing capability. We have tried to use bpftrace with SPDK, but the ..."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            "This handbook takes you through the whole DO-178C journey with a focus on verification, leaving you with an understanding of the compliance process as a whole."
          ]
        },
        {
          "title": "DO-178C",
          "url": "https://en.wikipedia.org/wiki/DO-178C",
          "excerpts": [
            "The new document is called DO-178C/ED-12C and was completed in November 2011 and approved by the RTCA in December 2011. It became available for sale and use in ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification is the primary document by which the certification authorities such as FAA, ..."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds.",
            " By avoiding intermediate buffers and memory copies, this approach reduces latency by 50–100 nanoseconds per packet—a meaningful gain in HFT systems.",
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "However, zero-copy networking introduces greater development complexity, requiring careful buffer management, error handling, and integration with kernel-level APIs.",
            "The next section integrates these concepts into a practical low-latency architecture.",
            "Practical Design Example: Building a Low-Latency Pipeline",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay."
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "QNX OS for Safety 8.0",
          "url": "https://blackberry.qnx.com/en/products/safety-certified/qnx-os-for-safety",
          "excerpts": [
            "The QNX OS for Safety is a microkernel OS for embedded systems certified to IEC 61508 SIL 3, ISO 26262 ASIL D and IEC 62304 Class C."
          ]
        },
        {
          "title": "QNX Safety Certifications | ISO 26262, IEC 61508, IEC 62304",
          "url": "https://blackberry.qnx.com/en/developers/certifications",
          "excerpts": [
            "Streamline safety certifications and compliance with embedded software solutions from QNX. Learn more."
          ]
        },
        {
          "title": "Wind River Store - Buy VxWorks, Diab Compiler & More ...",
          "url": "https://www.windriver.com/store",
          "excerpts": [
            "Purchase up to three seats of the world's #1 real-time operating system (RTOS), starting at $19,500 per seat. VxWorks® is a deterministic, priority-based ..."
          ]
        },
        {
          "title": "Linux Licensing Cost - TCO Calculator",
          "url": "https://www.windriver.com/products/linux/tco-calculator",
          "excerpts": [
            "Calculate the costs of building your own embedded Linux product with our TCO Calculator. Find out how market-leading Wind River Linux can save you money!"
          ]
        },
        {
          "title": "AWS Marketplace: QNX OS for Safety 2.2.3",
          "url": "https://aws.amazon.com/marketplace/pp/prodview-26pvihq76slfa",
          "excerpts": [
            "3. Pricing is based on actual usage, with charges varying according to how much you consume."
          ]
        },
        {
          "title": "Green Hills Software: Real-Time Operating Systems (RTOS ...",
          "url": "https://www.ghs.com/",
          "excerpts": [
            "Green Hills Software is the worldwide leader in embedded safety and security. With the most safety and security certifications and the best track record."
          ]
        },
        {
          "title": "QNX Developer License Options",
          "url": "https://blackberry.qnx.com/en/products/qnx-everywhere/licensing",
          "excerpts": [
            "Missing: per unit"
          ]
        },
        {
          "title": "QNX license cost discussion on Reddit",
          "url": "https://www.reddit.com/r/embedded/comments/1e72fip/qnx_license_cost/",
          "excerpts": [
            "There are a few places that are indicating that the dev platform license is ~$15k/yr. QNX license cost? : r/embedded"
          ]
        },
        {
          "title": "What Is DO-178C? - Wind River Systems",
          "url": "https://www.windriver.com/solutions/learning/do-178c",
          "excerpts": [
            "It is the standard that directs software certification for airborne systems for the commercial segment. (Its ramifications for military aerospace will be ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification, is the principal certification document used by certification agencies ..."
          ]
        },
        {
          "title": "Your Complete DO-178C Guide to Aerospace Software Compliance",
          "url": "https://ldra.com/do-178/",
          "excerpts": [
            "DO-178C is a formal process standard that covers the complete software lifecycle – the planning process, development process, and integral processes."
          ]
        },
        {
          "title": "IEC Certification Kit (for ISO 26262 and IEC 61508)",
          "url": "https://www.mathworks.com/products/iec-61508.html",
          "excerpts": [
            "IEC Certification Kit provides tool classification and tool qualification work products, together with templates, certificates, and validation suites."
          ]
        },
        {
          "title": "Tool Qualification Support Package (TQSP)",
          "url": "https://ldra.com/products/tool-qualification-support-packs-tqsp/",
          "excerpts": [
            "A TQSP is an optional module available for the LDRA tool suite. Each TQSP module provides artefacts and guidance to simplify the process of qualifying the LDRA ..."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
          "url": "https://www.lynx.com/challenges/safety-certification",
          "excerpts": [
            "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
            "Delays in certification due to software non-compliance can be costly and de rail project timelines. Lynx empowers teams across industries with modular platforms, pre-certified components, and advanced tools to simplify compliance with DO-178C, ISO 26262, and IEC 61508. Deliver safer, certifiable systems faster and with greater confidence. Seize the Edge with Lynx to achieve 30% faster certification and reduce project complexity.",
            "pre-certified software components",
            "Backed by a track record of successful certifications, LynxSecure and LynxOS-178 deliver DO-178C and FAA RSC compliance while reducing project complexity.",
            "Safety-Critical GPU Solutions",
            "Empower your systems with our certifiable GPU solutions. Achieve high-performance graphics for avionics and automotive applications while maintaining ISO 26262 and DO-178C compliance.",
            "Advanced Vulnerability Management",
            "Ensure system integrity with Vigiles, the industry-leading tool for SBOM-based CVE triage and lifecycle vulnerability management, reducing false positives by 95%.",
            "Certification Consulting Services",
            "Leverage decades of experience in certification-compliant development with expert guidance tailored to DO-178C, ISO 26262, and IEC 61508 projects.",
            "Streamlining DO-178C Certification for Avionics",
            "Our pre-certified components and modular platforms reduce integration complexity and enable seamless compliance with DO-178C DAL A standards.",
            "Ensuring ISO 26262 Compliance in Automotive Systems",
            "ISO 26262 compliance isn’t just a checkbox—it’s the key to safe and reliable ADAS and autonomous systems. Lynx simplifies compliance with certifiable GPU compute solutions and pre-certified software components, ensuring your program stays on track and ahead of the competition.",
            "Streamlining IEC 61508 Certification for Industrial Systems",
            "From robotics to critical infrastructure, Lynx provides the tools to meet IEC 61508 certification requirements.",
            "30% faster certification",
            "Streamline processes and reduce certification timelines with modular pre-certified platforms like LynxSecure and LynxOS-178.",
            "95% Fewer False Positives",
            "Ensure accuracy in vulnerability management with Vigiles, reducing unnecessary manual triage."
          ]
        },
        {
          "title": "AMD Pensando™ DPU Technology",
          "url": "https://www.amd.com/en/products/data-processing-units/pensando.html",
          "excerpts": [
            "The AMD Pensando™ Giglio DPU builds on second-generation architecture with enhanced power and performance efficiency, delivering dual 200 Gbps line-rate offload ..."
          ]
        },
        {
          "title": "Compression Analysis for BlueField-2/-3 Data Processing ...",
          "url": "https://par.nsf.gov/servlets/purl/10538184",
          "excerpts": [
            "by Y Li · 2024 · Cited by 6 — Our study encompasses a comprehensive per- formance analysis of Nvidia BlueField DPUs, specifically focusing on one lossy (SZ34) and three."
          ]
        },
        {
          "title": "Economics And The Inevitability Of The DPU",
          "url": "https://www.nextplatform.com/2022/11/03/economics-and-the-inevitability-of-the-dpu/",
          "excerpts": [
            "Nov 3, 2022 — ... performance of the two ports on the DPU, at 49 Gb/sec. There is an obvious performance benefit, but this is more like getting the performance ..."
          ]
        },
        {
          "title": "Boosting Performance with SPDK and DPDK Solutions - Mirror Review",
          "url": "https://www.mirrorreview.com/spdk-and-dpdk-solutions/",
          "excerpts": [
            "Missing: RustHallows TCO Linux"
          ]
        },
        {
          "title": "Linux Kernel vs DPDK: HTTP Performance Showdown | talawah.io",
          "url": "https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/",
          "excerpts": [
            "Missing: RustHallows competitive"
          ]
        },
        {
          "title": "What is the Cost of a Real-time Operating System (RTOS)?",
          "url": "https://www.lynx.com/embedded-systems-learning-center/cost-of-a-real-time-operating-system-rtos",
          "excerpts": [
            "Generally speaking, purchasing a commercial RTOS will cost about $10K – $20K for the RTOS and one seat of development tools."
          ]
        },
        {
          "title": "RTOS | Wind River Studio",
          "url": "https://www.windriver.com/studio/edge-devices/real-time-os",
          "excerpts": [
            "Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat. Log in or create an account to get ..."
          ]
        },
        {
          "title": "LynxOS-178: Based on Open Standards",
          "url": "https://www.lynx.com/products/lynxos-178-do-178c-certified-posix-rtos",
          "excerpts": [
            "LynxOS-178 is a COTS RTOS supporting x86, Arm, and PowerPC platforms. It is based on open standards and is designed specifically to fulfill the stringent needs ..."
          ]
        },
        {
          "title": "Free Access to QNX SDP 8.0 for Non-Commercial Use",
          "url": "https://www.qnx.com/products/everywhere/",
          "excerpts": [
            "You are now able to get a free QNX SDP 8.0 license for your personal non-commercial use. You must first have a myQNX account which will allow you to access ..."
          ]
        },
        {
          "title": "GreenHills costs what and has Python 2.3? : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/7kw1a3/greenhills_costs_what_and_has_python_23/",
          "excerpts": [
            "GreenHills costs what and has Python 2.3? ... I've mainly used WindRiver's diab and got moved to a certified project. It's my first experience ..."
          ]
        },
        {
          "title": "Licensing Information",
          "url": "http://licensing.qnx.com/info/",
          "excerpts": [
            "This folder contains PDF copies of QNX licensing documents associated with QNX Software Development Platform versions 7.x and 8.0, and associated compatible ..."
          ]
        },
        {
          "title": "VxWorks Reviews in 2025",
          "url": "https://sourceforge.net/software/product/VxWorks/",
          "excerpts": [
            "$18,500 / seat. Pricing Details: Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat."
          ]
        },
        {
          "title": "ISO 26262 Functional Safety Training & Certification Program",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/36-34-20-0006",
          "excerpts": [
            "Course Agenda. The certified Functional Safety according to ISO 26262 is a training spanned across 4 and a half days comprising of the following: Day 1 - ..."
          ]
        },
        {
          "title": "IEC 61508: A comprehensive guide to functional safety ...",
          "url": "https://spyro-soft.com/blog/industry-4-0/iec-61508",
          "excerpts": [
            "SIL 3: High level of safety integrity, with a significantly lower probability of failure than SIL 2. SIL 4: Highest level of safety integrity, ..."
          ]
        },
        {
          "title": "VxWorks Safety Platforms - Wind River Systems",
          "url": "https://www.windriver.com/products/vxworks/safety-platforms",
          "excerpts": [
            "An RTOS platform for safety-critical applications that require DO-178C, IEC 61508, or ISO 26262 certification evidence in the avionics, transportation, ..."
          ]
        },
        {
          "title": "DO-178C Explained",
          "url": "https://consunova.com/do-178c-explained/",
          "excerpts": [
            "Mar 31, 2024 — DO-178C defines five levels (A, B, C, D, and E) to classify the criticality of software functions based on their potential impact on aircraft ..."
          ]
        },
        {
          "title": "Guidance on Using IEC 61508 SIL Certification to Support ...",
          "url": "https://www.nrc.gov/docs/ML2130/ML21305A001.pdf",
          "excerpts": [
            "The SIL certification process involves manufacturers seeking compliance with IEC 61508, a separate entity called the CB that reviews the ..."
          ]
        },
        {
          "title": "How developers can leverage RTOS functional safety certification",
          "url": "https://www.embedded.com/how-developers-can-leverage-rtos-functional-safety-certification/",
          "excerpts": [
            "RTOS functional safety certification benefits not only safety-critical devices but all embedded devices as a means to improve time-to-market ..."
          ]
        },
        {
          "title": "How to get started with iso 26262 as a firmware developer?",
          "url": "https://www.reddit.com/r/embedded/comments/14icplp/how_to_get_started_with_iso_26262_as_a_firmware/",
          "excerpts": [
            "Your first step at estimating cost is to get a static analysis tool and find out how many warnings there are in your code base, and writing up a ..."
          ]
        },
        {
          "title": "Low Latency 5G UPF Using Priority Based Packet Classification",
          "url": "https://builders.intel.com/docs/networkbuilders/low-latency-5g-upf-using-priority-based-5g-packet-classification.pdf",
          "excerpts": [
            "SA UPF, developed by Intel and SK Telecom, shows improved performance in latency and jitter for high priority traffic while still running.",
            "Foundational NICs do not \ntypically offer offloads for functions \nsuch as vSwitch acceleration, VXLAN \nTEP or inline IPS",
            "They do, however, \noffer advanced features in order to \nscale the VNF performance by \noptimizing packet steering in the \nser",
            "Dynamic Device Personalization (DDP) \nis a capability that was introduced with \nIntel® Ethernet 700 Series Network \nAdapters to load an additional package \nto enable classification and steering of \nadditional specified packet types and \nperformance of additional inline \nact",
            "DDP can be used to optimize \npacket processing performance for \ndifferent network functions, native or \nrunning in a virtual environme",
            "By \napplying a DDP profile to the network \ncontroller the following use cases can \nbe address",
            "Extended support for protocols:\n\n• 5G GTP support for 5G user plane.",
            "• 5G SDAP/PDCP support for 5G NR\nuser plane.",
            "• 5G/4G PFCP (CP-UP separation)\nsupport.",
            "• IP protocols as new flow types, for\nexample L2TPv3, ESP/AH for\nIPSec.",
            "• Legacy protocols: PPPoE,\nPPPoL2TPv2.",
            "• New protocols/standards: eCPRI/\nORAN, Radio over Ethernet (RoE).",
            "• Extensibility for custom protocol\nparsing/classification.",
            "The Intel® Ethernet 800 Series provides \nthe capability to steer packets of \ndifferent priority into specific queue \ngroups as described in Figure 5",
            "software receiving and processing \n\npackets must be aware of the receive \nqueue priority mechanism to enable the \nefficient handling of high priority \npackets",
            "The User Plane Function (UPF) \napplication used in the context of this \nwork is based on the FD.io Vector Packet \nProcessor (VPP) framewo",
            "This \nframework utilizes Data Plane \nDevelopment Kit (DPDK) functionality to \nfetch received packets from the NIC \nqueues and deliver them for further \nproces",
            "The DPDK plugin is a part of \nthe VPP project that exposes packet \nreceive functionality over the dpdk-input \nno",
            "Default implementation of the \ndpdk-input node enables handling of \nmultiple RX queues in the context of a \nsingle worker thre",
            "re 6 implements \nstrict priority logic where packets from \nhigher priority queues are always \nfetched first and next priority queues \nare not served until all packets from \nhigh priority queues are in the \nprocessing stage."
          ]
        },
        {
          "title": "DOCA Perftest RDMA benchmarking tool",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Perftest/index.html",
          "excerpts": [
            "DOCA Perftest is an RDMA benchmarking tool designed for compute clusters, enabling fine-tuned evaluation of bandwidth, message rate, and latency. [Dependencies](.DOCAPerftestv3.0.0-Dependencies)",
            "  + CUDA 12.8 or later, required for GPUDirect RDMA benchmarks"
          ]
        },
        {
          "title": "DOCA Accelerated UPF Reference Application Guide",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Accelerated+UPF+Reference+Application+Guide/index.html",
          "excerpts": [
            "The Accelerated UPF-RAP provides a reference implementation of an accelerated data path of UPF on top of the NVIDIA® BlueField-3®. Tas",
            "Tasks like GTP-U encapsulation/decapsulation, flow tagging, QoS enforcement, and packet forwarding are handled by the NIC, providing deterministic performance and scalability.",
            "Subsequent packets of that flow will be fully processed by Bluefiled-3 HW and forward to their destination without going through the host/UPF-RAP."
          ]
        },
        {
          "title": "performance | microkerneldude",
          "url": "https://microkerneldude.org/tag/performance/",
          "excerpts": [
            "And that means verified seL4 outperforms any microkernel. In almost all cases that's by about a factor of 10 in IPC latency. The closest in ..."
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "I'm Not Dead Yet!: The Role of the Operating System in a Kernel ...",
          "url": "https://dl.acm.org/doi/10.1145/3317550.3321422",
          "excerpts": [
            "This paper argues for a new high-level, device-agnostic I/O abstraction for kernel-bypass devices. We propose the Demikernel, a new library OS architecture for ..."
          ]
        },
        {
          "title": "seL4 Formal Verification Paper (SOSP 2009)",
          "url": "https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf",
          "excerpts": [
            ", is a third-generation\n\nmicrokernel, and is broadly based on L4 [46] and  \ninfluenced by EROS [58].",
            "Complete formal verification is the only known way to guarantee that a system is free of programming errors.",
            "ts. We present seL4, a member of the L4 [46] microker-\n\nnel family, designed to provide this ultimate degree  \nof assurance of functional correctness by machine-  \nassisted and machine-checked formal proof.",
            "e  \nshown the correctness of a very detailed, low-level  \ndesign of seL4 and we have formally verified its C  \nimplementation.",
            "To our knowledge, seL4 is the first-ever general-\n\npurpose OS kernel that is fully formally verified for  \nfunctional correctn"
          ]
        },
        {
          "title": "avionics application software standard interface part 0 overview of ...",
          "url": "https://www.sae.org/standards/content/arinc653p0-3/",
          "excerpts": [
            "The primary objective of ARINC 653 is to define a general-purpose APplication/EXecutive (APEX) interface (API = Application Program Interface)"
          ]
        },
        {
          "title": "[PDF] ARINC-653 Inter-partition Communications and the Ravenscar Profile",
          "url": "https://oa.upm.es/42418/1/INVE_MEM_2015_228287.pdf",
          "excerpts": [
            "The ARINC-653 standard [1] defines an inter-partition communication (IPC) mechanism that can be used to exchange messages between ARINC partitions running on ..."
          ]
        },
        {
          "title": "[PDF] ARINC 653",
          "url": "http://retis.sssup.it/~giorgio/slides/cbsd/cbsd-arinc-2p.pdf",
          "excerpts": [
            "ARINC 653 Services. ➢ Inter-partition communication. ▫ Communication between two or more partitions via messages;. ▫ Two types of communication services are ..."
          ]
        },
        {
          "title": "ARINC 653 on PikeOS - SYSGO",
          "url": "https://www.sysgo.com/arinc-653",
          "excerpts": [
            "The ARINC 653 standard specifies an operational environment for application software used in Integrated Modular Avionics (IMA) modules."
          ]
        },
        {
          "title": "avionics application software standard interface part 1 required ...",
          "url": "https://www.sae.org/standards/content/arinc653p1-5/",
          "excerpts": [
            "This standard defines a general-purpose Application/Executive (APEX) software interface between the Operating System of an avionics computer ..."
          ]
        },
        {
          "title": "[PDF] Using IOMMU for DMA Protection in UEFI Firmware - Intel",
          "url": "https://www.intel.com/content/dam/develop/external/us/en/documents/intel-whitepaper-using-iommu-for-dma-protection-in-uefi-820238.pdf",
          "excerpts": [
            "This paper proposes using IOMMU to resist DMA attacks in firmware, where bus mastering can allow malicious devices to access system memory."
          ]
        },
        {
          "title": "Single Root IO Virtualization (SR-IOV)",
          "url": "https://docs.nvidia.com/networking/display/OFED/Single+Root+IO+Virtualization+(SR-IOV)",
          "excerpts": [
            "Feb 29, 2024 — Single Root IO Virtualization (SR-IOV) is a technology that allows a physical PCIe device to present itself multiple times through the PCIe bus."
          ]
        },
        {
          "title": "IOMMU DMA Remapping - Windows drivers - Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/display/iommu-dma-remapping",
          "excerpts": [
            "IOMMU DMA remapping allows the GPU to access memory through logical addresses that are no longer mapped 1:1. Instead, Dxgkrnl is able to provide logically ..."
          ]
        },
        {
          "title": "Is it possible SR-IOV inside VM? : r/VFIO",
          "url": "https://www.reddit.com/r/VFIO/comments/1emladg/is_it_possible_sriov_inside_vm/",
          "excerpts": [
            "I have a Broadcom NIC with SR-IOV support and would like to create VFs inside the VM, i.e. pass PF to the VM with SR-IOV enabled."
          ]
        },
        {
          "title": "Kernel DMA Protection | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/kernel-dma-protection-for-thunderbolt",
          "excerpts": [
            "Learn how Kernel DMA Protection protects Windows devices against drive-by Direct Memory Access (DMA) attacks using PCI hot plug devices."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "Key Benefits of io_uring. Reduced Overhead: Batched submissions and completions cut system calls drastically.",
            "Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir )",
            "Completion Queue (CQ) : The kernel posts results as Completion Queue Entries (CQEs).",
            "scribe\nThis design minimizes system calls and context switches. Instead of invoking a syscall per operation, the kernel polls the SQ for new entries, while user space checks the CQ for completions — enabling true asynchronous processing.",
            "Key Benefits of io_uring",
            "* Reduced Overhead : Batched submissions and completions cut system calls drastically.",
            "* Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir ).",
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency.",
            "* Ease of Use : The\nliburing library simplifies setup and management."
          ]
        },
        {
          "title": "Put an io_uring on it - Exploiting the Linux Kernel",
          "url": "https://chomp.ie/Blog+Posts/Put+an+io_uring+on+it+-+Exploiting+the+Linux+Kernel",
          "excerpts": [
            "It can be particularly useful for applications that are server/backend related, where a significant proportion of the application time is spent waiting on I/O."
          ]
        },
        {
          "title": "The IOMMU Impact - I/O Memory Management Units",
          "url": "https://medium.com/@mike.anderson007/the-iommu-impact-i-o-memory-management-units-feb7ea95b819",
          "excerpts": [
            "The IOMMU serves as a hardware abstraction layer that provides device isolation, memory protection, and address translation, much like how a traditional Memory Management Unit (MMU) governs virtual memory for CPUs.",
            "IOMMUs abstract this dependency by allowing devices to use I/O virtual addresses.",
            "IOMMU enforces **isolation** between devices and memory regions, a critical security feat",
            "In systems without an IOMMU, a misbehaving or compromised device could write to arbitrary memory regions, leading to system crashes, data leaks, or privilege escalation.",
            "These faults are invaluable for debugging DMA-related issues and for building **resilient systems** that can withstand partial hardware or software failures without complete system cras",
            "SR-IOV takes this a step further by allowing a single physical device to expose multiple **Virtual Functions (VFs)** — lightweight virtual devices that can be independently assigned to different ",
            "Intel VT-d",
            "AMD-Vi (IOMMU)",
            "ARM’s equivalent is the **System Memory Management Unit (SMM",
            "M’s SMMU enables secure execution environments, supporting trusted execution, real-time processing, and virtualization on low-power hardware.",
            "While IOMMUs introduce security and flexibility, they can also add **latency** to I/O operations due to address translation overhead. To mitigate this, modern IOMMUs use **Translation Lookaside Buffers (IOTLBs)** to cache recent address mappings, much like C"
          ]
        },
        {
          "title": "Design Guidelines for High Performance RDMA Systems",
          "url": "https://www.usenix.org/system/files/login/articles/login_fall16_07_kalia.pdf",
          "excerpts": [
            "Queue pairs: RDMA hosts communicate by posting verbs to interfaces called queue pairs (QPs). On completing a verb, the requester's NIC optionally signals ..."
          ]
        },
        {
          "title": "Planning for GPUDirect Storage - IBM",
          "url": "https://www.ibm.com/docs/en/storage-scale/5.2.1?topic=considerations-planning-gpudirect-storage",
          "excerpts": [
            "Supported hardware · GDS clients: x86 with a GPU model that supports GDS. For more details, see NVIDIA GDS documentation. · Network: EDR or HDR InfiniBand, ..."
          ]
        },
        {
          "title": "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified!",
          "url": "https://www.reddit.com/r/rust/comments/17qi9v0/its_official_ferrocene_is_iso_26262_and_iec_61508/",
          "excerpts": [
            "Ferrocene is upstream rustc but with some extra targets, long term support, and qualifications so you can use them in safety critical contexts."
          ]
        },
        {
          "title": "ECDSA Attestation with Intel Software Guard Extensions ...",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/quote-verification-attestation-with-intel-sgx-dcap.html",
          "excerpts": [
            "In this article, we'll demonstrate a remote attestation using the sample code from the Intel SGX DCAP source code repository."
          ]
        },
        {
          "title": "Arrakis: The Operating System Is the Control Plane",
          "url": "https://dl.acm.org/doi/10.1145/2812806",
          "excerpts": [
            "We have designed and implemented a new operating system, Arrakis, that splits the traditional role of the kernel in two."
          ]
        },
        {
          "title": "IX: A Protected Dataplane Operating System for High ...",
          "url": "https://web.eecs.umich.edu/~sugih/courses/eecs589/f16/39-ChunYu+Xinghao.pdf",
          "excerpts": [
            "by A Belay · Cited by 629 — In this paper, the authors introduce a new approach to improve the throughput and reduce the latency with a customized dataplane operating system, called IX ..."
          ]
        },
        {
          "title": "31. Shared Virtual Addressing (SVA) with ENQCMD",
          "url": "https://www.kernel.org/doc/html/next/x86/sva.html",
          "excerpts": [
            "Use of SVA requires IOMMU support in the platform. IOMMU is also required to support the PCIe features ATS and PRI. ATS allows devices to cache translations ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/613875_E810_Datasheet_Rev2_7-3314030.pdf?srsltid=AfmBOopOVGq1VlDC61e6xt9KhgfHGjfbQA4NBSKRxAMyy195mgxFyoAu",
          "excerpts": [
            "Page 1. Revision 2.7. March 2024. 613875-009. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K ..."
          ]
        }
      ],
      "reasoning": "The finegrained_field_value describes a composite hardware prerequisite set requiring (a) NIC capabilities including SR-IOV for partitioning, IOMMU for device passthrough, and (b) RDMA-enabled networking; (c) NVMe with ZNS support and SPDK/DPDK user-space tooling; and (d) GPUs with GPUDirect Storage and GPUDirect RDMA to enable direct GPU-to-device data paths. The most directly relevant excerpts explicitly name and discuss these technologies and their deployment contexts: excerpts discussing SR-IOV, VFIO/IOMMU and PCIe passthrough (for NICs), vendor NICs (e.g., Intel E810) with SR-IOV, and SR-IOV configuration guides; excerpts detailing GPUDirect RDMA and GPUDirect Storage (GDS) usage; excerpts describing NVMe ZNS and SPDK/DPDK user-space stacks; and excerpts describing related PCIe IOMMU/VFIO setups. The order places the strongest, most specific matches first, followed by excerpts that cover related prerequisites (VFIO/IOMMU, SR-IOV usage and configuration guidance), then GPU/NVMe/GDS/NVMe-ZNS context, and finally broader safety/architecture material which supports but is less directly aligned with the exact prerequisites. The included excerpts collectively substantiate the required device classes (NIC/NVMe/GPU) and their prerequisite stacks (SR-IOV, IOMMU, RDMA, ZNS, SPDK/DPDK, GPUDirect) referenced in the fine-grained field value.",
      "confidence": "medium"
    },
    {
      "field": "safety_certification_roadmap.key_enablers",
      "citations": [
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more"
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        }
      ],
      "reasoning": "Ferrocene is explicitly described as a Rust compiler toolchain that is pre-qualified for ISO 26262 and IEC 61508, which directly supports the goal of a pre-qualified toolchain for safety certification. This exact claim aligns with the need for a certified verification and tooling backbone in a high-assurance roadmap. The seL4-related excerpts provide strong evidence of formal verification and machine-checked proofs that underpin functional correctness, integrity, and confidentiality, which are central to high-assurance software stacks and are a cornerstone for achieving DO-178C/DO-254-like confidence in safety-critical systems. The seL4 verification excerpts reinforce that such formal proofs are a credible path to certification, supporting the assertion that formal verification can meet or exceed stringent safety requirements. The excerpt stating that DO-178C requires or benefits from formal verification for high ASIL levels further substantiates the alignment between rigorous verification and certification readiness. ISO 26262-related content in conjunction with seL4 and DO-178C discussions strengthens the argument that a multi-standard certification pathway (functional safety and software quality) is convergent and practical for the stated roadmap. The DO-330 tool qualification reference, while not as richly detailed as Ferrocene or seL4 mentions, adds another dimension by pointing to tool qualification levels and the importance of tool-related substantiation in certification processes. Collectively, these excerpts support the idea that a combination of a qualified Rust toolchain, formal verification, and tool qualification practices form a coherent set of key enablers for safety certification in the RustHallows-inspired architecture.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.1.inspiration",
      "citations": [
        {
          "title": "ARINC 653 Flight Software Architecture (NASA IV&V on Orion's ARINC 653)",
          "url": "https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf",
          "excerpts": [
            "ARINC 653 splits the available processor time and space into partitions (partitions do not need to be the same size). • When we talk “partition” in this ...",
            "C 653 splits the available processor time and space into \npartitions (partitions do not need to be the same size). • "
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS)."
          ]
        },
        {
          "title": "ARINC 653 Specification (Tokar, Pyrrhus Software) | SIGADA (2003)",
          "url": "https://www.sigada.org/ada_letters/dec2003/11_Tokar_final.pdf",
          "excerpts": [
            "ARINC Specification 653[1] provides the definition of an APplication EXecutive (APEX) that supports space and time partitioning of applications.",
            "ARINC 653 systems are composed of software partitions."
          ]
        }
      ],
      "reasoning": "The fine-grained field value we are evaluating is ARINC 653, which is described as a software specification for space and time partitioning in safety-critical real-time systems. The most directly supportive information comes from excerpts that state ARINC 653 splits the available processor time and space into partitions, i.e., a partitioning mechanism for deterministic real-time behavior. This aligns with the field's context of isolation and partitioning in a kernel-like environment. Additional excerpts reinforce the concept by describing ARINC 653 as a platform specification for time/space partitioning in safety-critical RTOS, which further corroborates its role as an isolation mechanism in kernel architectures. Other excerpts reference ARINC 653 in broader descriptions and include mentions of partitions and their properties, supplementing the core definition with corroborating context. Collectively, these excerpts substantiate that ARINC 653 is a partitioning paradigm relevant to kernel isolation and safety-critical separation, matching the requested fine-grained field value.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.0.component_name",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system."
          ]
        }
      ],
      "reasoning": "The specific field value refers to the named component 'Ministry of Magic' within the kernel and isolation components. The excerpt describes the Ministry of Magic as the microkernel's organization by stating that this kernel adopts the capability-based model to keep the kernel minimal and to prove invariants, which directly supports the existence and naming of a distinct kernel component called 'Ministry of Magic'. This evidence indicates that 'Ministry of Magic' is the name attributed to the kernel component in this context, matching the requested field value. The other excerpts discuss related concepts (endpoints, reply objects, address spaces, and capabilities) but do not mention the named component, so they offer contextual support but not direct confirmation of the field value. Therefore, the most relevant excerpt is the one that explicitly contains the phrase linking 'Ministry of Magic' to the kernel, while the others provide supporting background on SeL4-style components and capabilities without naming the component.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.2.component_name",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Endpoints are used to perform protected function calls;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ..."
          ]
        },
        {
          "title": "[PDF] Object-Capability Programming Languages on the seL4 Capability ...",
          "url": "https://swebb.id.au/research/SWebb%20MSc%20Thesis%20-%20Pony%20ocap%20seL4.pdf",
          "excerpts": [
            "SHILL [48] is a capability-based shell scripting language for FreeBSD, built to facilitate the execution of shell scripts in contained sandboxes ..."
          ]
        }
      ],
      "reasoning": "The target field value denotes a capability-scoped secrets service within a capability-based isolation architecture. Excerpts that describe capabilities as tokens that grant fine-grained access control and that discuss protected endpoints and sandboxed address spaces establish the essential security model in which a secrets service like Fidelius would operate. Specifically, statements about capabilities enabling precise authority over resource access and about endpoints for protected function calls ground the architectural rationale for Fidelius as a secrets service within a capability-based kernel. Similarly, discussions of address spaces providing sandboxes around components reinforce the isolation guarantees that Fidelius would rely on to protect secrets and enforce compartmental boundaries. While none of the excerpts names Fidelius directly, they describe the critical mechanism (capabilities) and architectural primitives (endpoints, sandboxes) that Fidelius would use or rely upon. Thus, these excerpts collectively support understanding the context and rationale for Fidelius within a SeL4-like, capability-based isolation model.",
      "confidence": "medium"
    },
    {
      "field": "kernel_and_isolation_components.1.component_name",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A"
          ]
        },
        {
          "title": "ARINC 653 Flight Software Architecture (NASA IV&V on Orion's ARINC 653)",
          "url": "https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf",
          "excerpts": [
            "ARINC 653 splits the available processor time and space into partitions (partitions do not need to be the same size). • When we talk “partition” in this ...",
            "C 653 splits the available processor time and space into \npartitions (partitions do not need to be the same size). • "
          ]
        },
        {
          "title": "ARINC 653 Specification (Tokar, Pyrrhus Software) | SIGADA (2003)",
          "url": "https://www.sigada.org/ada_letters/dec2003/11_Tokar_final.pdf",
          "excerpts": [
            "ARINC 653 systems are composed of software partitions.",
            "ARINC Specification 653[1] provides the definition of an APplication EXecutive (APEX) that supports space and time partitioning of applications."
          ]
        }
      ],
      "reasoning": "The fine-grained field value denotes Horcrux Partitions, which corresponds to a partitioning concept in the kernel/isolation design. The excerpts collectively describe ARINC 653-style space and time partitioning as a method for deterministically dividing processor time and memory across safety-critical domains, which directly supports the idea of partitioned isolation akin to Horcrux Partitions. Specifically, the excerpts explain that partitioning distributes available processor time and space into partitions, enabling deterministic multi-tenant or safety-domain isolation, and that partitions can be of different sizes or configured modes. This aligns with the notion of Horcrux Partitions as a mechanism for compartmentalizing components with explicit boundaries and invariants within a capability-based microkernel design. Therefore, these excerpts provide direct contextual support for interpreting Horcrux Partitions as a partitioning construct used to enforce isolation and determinism in the system architecture. The most directly relevant statements are those that describe ARINC 653-like partitioning of time and space and its role in determinism and safety-critical contexts, followed by sources that elaborate on partitions as software constructs and their architectural implications. ",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.1.function",
      "citations": [
        {
          "title": "ARINC 653 Flight Software Architecture (NASA IV&V on Orion's ARINC 653)",
          "url": "https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf",
          "excerpts": [
            "ARINC 653 splits the available processor time and space into partitions (partitions do not need to be the same size). • When we talk “partition” in this ...",
            "C 653 splits the available processor time and space into \npartitions (partitions do not need to be the same size). • "
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 platform contains:A hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output). An implementation for the ARINC 653 services (the A"
          ]
        },
        {
          "title": "ARINC 653 Specification (Tokar, Pyrrhus Software) | SIGADA (2003)",
          "url": "https://www.sigada.org/ada_letters/dec2003/11_Tokar_final.pdf",
          "excerpts": [
            "ARINC Specification 653[1] provides the definition of an APplication EXecutive (APEX) that supports space and time partitioning of applications.",
            "ARINC 653 systems are composed of software partitions."
          ]
        }
      ],
      "reasoning": "The field value describes a partitioning mechanism (major/minor frames) used to provide hard determinism for workloads, a concept that is central to ARINC 653. Excerpts that explicitly state ARINC 653 splits the available processor time and space into partitions (partitions may differ in size) directly support this mode of operation and its determinism implications. Additional excerpts define ARINC 653 as a software specification for space and time partitioning in safety-critical RTOS, which provides the formal context for partitioning to achieve determinism. Other excerpts that discuss ARINC 653 in more general terms (e.g., partitioning of time/space) reinforce the same interpretation and help establish that this partitioning is a core mechanism described by the field value. Taken together, these sources corroborate that time/space partitioning via major/minor frames is the intended functional mechanism, and that there is an option to disable this mode for best-effort workloads.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.0.inspiration",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ..."
          ]
        }
      ],
      "reasoning": "The target field value asserts support for a capability-based model exemplified by seL4, and an invariants-based approach attributed to Theseus OS. Content describing capabilities as fine-grained access tokens, enabling access control to resources, directly supports the seL4 capability-model portion. Additional excerpts describe endpoints for protected function calls, reply objects as return paths from protected calls, and address spaces that sandbox components, all of which reinforce a capability- and isolation-centric architecture consistent with seL4's design principles. These excerpts collectively substantiate the kernel isolation and capability aspects asserted by seL4. However, there is no explicit reference to Theseus OS within the excerpts; thus the invariants or design principles attributed to Theseus OS lack direct textual support here. The evidence thus strongly supports the seL4 capability-model portion and only weakly supports the Theseus OS invariants portion, via absence rather than explicit mention. Based on this, the overall alignment with the finegrained field value is high for seL4-related content and low for Theseus OS content, yielding an overall medium confidence about the composite field value.",
      "confidence": "medium"
    },
    {
      "field": "kernel_and_isolation_components.0.function",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        }
      ],
      "reasoning": "The field value describes a capability-based microkernel core with per-object rights, guarded IPC, and deterministic hot-path system calls. The most direct support comes from passages that define capabilities as access tokens enabling very fine-grained control over which entity can access a given resource, which maps to per-object rights and strong access control in a microkernel. Additional excerpts describe endpoints that enable protected function calls and reply objects that provide a return path from protected procedures, which together illustrate guarded IPC and protected cross-component interactions. Further excerpts discuss address spaces that sandbox components, reinforcing the idea of isolation boundaries and deterministic execution contexts. Collectively, these excerpts substantiate the key elements: capability-based access control, guarded IPC, per-object rights, and isolation via sandboxed address spaces, all of which underlie a deterministic, performance-focused kernel path for syscalls. The most direct statements anchor the claim in the capability model; the IPC-related excerpts extend that to guarded inter-process communication; the sandboxing/exposure to address spaces provides the isolation framework that supports deterministic behavior on hot paths.",
      "confidence": "high"
    },
    {
      "field": "scheduling_components.0.inspiration",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency.",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value lists the three schedulers Shinjuku, Shenango, and Caladan. The provided excerpts focus on scheduling, particularly Shinjuku as a preemptive, microsecond-scale scheduler and its performance benefits. Specifically, the passages describe Shinjuku as a system that enables centralized scheduling policies with very frequent preemption (as often as 5 microseconds) and demonstrate improvements in tail latency and throughput for various workloads. These excerpts directly support the existence and characteristics of Shinjuku as a practical, high-resolution scheduler. While the excerpts extensively cover Shinjuku's design and benefits, they do not mention Shenango or Caladan by name. Therefore, the strongest-supported part of the requested field value (Shinjuku) is well-supported, while the parts referencing Shenango and Caladan lack explicit backing in the provided excerpts. The excerpts collectively establish a strong link to Shinjuku, with partial or no explicit evidence for Shenango and Caladan in this set.",
      "confidence": "medium"
    },
    {
      "field": "kernel_and_isolation_components.2.function",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        }
      ],
      "reasoning": "The target field describes a capability-scoped secrets service that operates with hardware-backed enclaves and compartments for enhanced security. The most relevant excerpt defines capabilities as access tokens that enable very fine-grained control over which entity can access a resource, which underpins a capability-based secrets service and its isolation guarantees. This aligns with the idea of using capabilities to tightly govern access to secrets and enclaves. Additionally, the mention that endpoints perform protected function calls and that address spaces provide sandboxing around components reinforces the concept of isolated, capability-governed interactions, which are essential for a secrets service operating within compartments and potentially leveraging hardware-backed security features. Together, these excerpts support the fundamental security model (capabilities, fine-grained access control, protected isolation) that would enable a hardware-backed, compartmental secrets service, even though the exact hardware enclave details aren't spelled out in the excerpts.",
      "confidence": "medium"
    },
    {
      "field": "innovative_concepts.7",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "seL4 provides strong support for mixed criticality real-time systems (MCS), where the timeliness of critical activities must be ensured even if they co-exist.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a security rail built on hardware-backed remote attestation and cryptographic trust, enabling sealed secrets and attested RPC endpoints. Excerpt emphasizing capabilities as access tokens for fine-grained control aligns with the foundational security model needed for attestation infrastructures, supporting the idea of tightly scoped trust tokens and least-privilege access. Another excerpt discusses SeL4 whitepaper material on mixed-criticality and capability-based access controls, which provides background on robust, fine-grained security mechanisms essential for a trusted communication rail. A third excerpt reinforces the role of capabilities in enforcing security boundaries and access control, further supporting the notion that a capability-based security model underpins a remote attestation rail. Collectively, these excerpts connect via the underlying security primitives (capabilities, access control, isolation) that would enable a Fidelius Attestation Rail, even though none directly describe attestation hardware like SGX/TrustZone.",
      "confidence": "medium"
    },
    {
      "field": "kernel_and_isolation_components.3.inspiration",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ..."
          ]
        }
      ],
      "reasoning": "The concept of a 'Capability-gated namespace' aligns with the fundamental notion that capabilities are access tokens enabling fine-grained control over resource access. One excerpt explicitly states that capabilities are access tokens which support very fine-grained control over which entity can access a particular resource, illustrating the core mechanism behind gating a namespace by capabilities. A closely related excerpt reinforces this by describing capabilities as support for strong security via least privilege, underscoring how capability-based controls can delimit access to resources within a namespace. Additional excerpts describe protected function calls, return paths from protected procedures, and sandboxed address spaces, which collectively illuminate how namespaces could be isolated and access-controlled in a system that employs capabilities. Taken together, these excerpts support the notion that a namespace could be guarded by capabilities, i.e., a capability-gated namespace, by providing the foundational definition of capabilities and the surrounding protected, isolated context in which such a gating mechanism would operate.",
      "confidence": "high"
    },
    {
      "field": "scheduling_components.1.component_name",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The target value represents a named scheduling component analogous to other entries in the document (e.g., Time-Turner, Shinjuku, Shenango, Caladan). The excerpts provided discuss preemptive scheduling and policy-blending ideas among several named schedulers, but they do not include the exact name corresponding to the target value. The excerpts do reference related scheduling concepts (preemption, per-core reallocation, interference control) and other named schedulers, which provides peripheral context about the scheduling domain, yet there is no direct evidence that the exact fine-grained field value 'Felix Felicis' is present or described. Therefore, the connection is weak and non-confirmatory.",
      "confidence": "low"
    },
    {
      "field": "scheduling_components.0.component_name",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The field value Time-Turner denotes a high-resolution scheduler that blends multiple scheduling approaches to optimize tail latency and throughput. The excerpts consistently describe a scheduler capable of microsecond-scale preemption and aggressive scheduling policies that improve tail latency and throughput across diverse workloads. This aligns with the notion of Time-Turner as a composite scheduler combining elements like Shinjuku (ultra-fast preemption), Shenango (core reallocation for efficiency), and Caladan (interference control). Specifically, the excerpts indicate that microsecond-scale preemption enables centralized scheduling and better handling of tail latency, which supports the idea of a time-centric, high-resolution scheduler. The discussion of significant tail-latency improvements and higher throughput when employing such scheduling strategies further corroborates that Time-Turner would embody these time-aware, preemptive capabilities. Taken together, these excerpts provide direct evidence of the core properties Time-Turner is intended to capture: ultra-fast preemption, time/space efficiency, and throughput/latency benefits from a sophisticated, multi-component scheduling framework.",
      "confidence": "medium"
    },
    {
      "field": "innovative_concepts.0",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 provides strong support for mixed criticality real-time systems (MCS), where the timeliness of critical activities must be ensured even if they co-exist.",
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The requested fine-grained field value describes a kernel-native mechanism for deterministic, sub-millisecond temporal checkpoints (Time-Turner Snapshots) that capture complete process state to enable instant rollbacks and deterministic replay for tail-latency remediation and fuzzing. The most relevant information from the excerpts centers on real-time determinism, fine-grained time/resource governance, and capability-based control that would underpin such a mechanism. Specifically:\n\n- An excerpt describing seL4's strong support for mixed criticality real-time systems highlights a foundation for deterministic timing guarantees, which aligns with the goal of precise, timing-sensitive checkpoints and rollbacks in a kernel-native context.\n- An excerpt about Scheduling Contexts representing the right to access a certain fraction of execution time on a core underscores the need for precise time budgeting and isolation at the scheduler level, which is relevant to ensuring deterministic checkpoints can capture and replay state without perturbing timing guarantees.\n- Excerpts detailing preemptive scheduling at microsecond scale illustrate the feasibility and design patterns for achieving very fine-grained temporal control within a microkernel, which is consistent with constructing sub-millisecond snapshots that freeze or capture system state cleanly.\n- Excerpts about capabilities as access tokens and fine-grained control over resources provide the architectural mechanism by which a checkpointing feature could securely and precisely access and snapshot all relevant state (registers, DMA state, I/O ring cursors) without violating isolation or security properties.\n- Additional excerpts on Shinjuku's preemptive scheduling, and on kernel/IPC concepts, offer contextual support for integrating a deterministic snapshot mechanism within a capability-based, high-precision scheduling environment; they reinforce the feasibility of coordinating timing, state capture, and rollback semantics in a kernel-first design.\n\nTaken together, these excerpts support the general feasibility and design principles for a kernel-native, time-deterministic snapshot mechanism, even though none explicitly describe Time-Turner Snapshots. They collectively map to the required capabilities (fine-grained access tokens), real-time determinism (seL4, MCS), and scheduling precision (Scheduling Contexts, microsecond preemption) that such a feature would need.",
      "confidence": "medium"
    },
    {
      "field": "scheduling_components.0.function",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The requested fine-grained field value centers on a scheduler capable of microsecond-scale preemption, drawing on the ideas from Shinjuku, Shenango, and Caladan, and it is designed to mix latency-critical and best-effort workloads. The most directly supportive content describes Shinjuku as a scheduling system that enables preemption at microsecond scales, including how it preempts frequently (often on the order of microseconds) and how it achieves tail-latency improvements and throughput benefits. This directly underpins the notion of a microsecond-scale preemptive scheduler. Additional excerpts reinforce the same theme by highlighting substantial tail-latency reductions and high throughput when comparing Shinjuku to other systems and by noting the core capability of ultra-fast preemption. Together, these excerpts substantiate the core capabilities (ultra-fast preemption, microsecond-scale scheduling, and performance improvements) that the fine-grained field value describes. The explicit mention of core ideas from Shenango and Caladan is not present in these excerpts, but the cited material provides the essential, concrete evidence about a microsecond-scale preemptive scheduler and its impact on latency and throughput, which supports the field value's claim of a hybrid, high-performance scheduling design activated for LC/BE workloads.",
      "confidence": "high"
    },
    {
      "field": "innovative_concepts.3",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;"
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The target field value describes an online, feedback-driven scheduling policy blender that learns per-flow service time distributions, detects heavy-tail behavior, and adapts scheduling strategies in real time. Excerpts that discuss the granularity and practicality of preemption, such as a scheduling system designed to preempt at microsecond scales, directly support the feasibility and design of a fine-grained, adaptive scheduler. The material describing a scheduling context as the right to access a certain fraction of core execution time further supports the notion that scheduling is governed by programmable rights and policies, which a heuristic, policy-blender would leverage to steer decisions. While explicit mention of Felix Heuristic Scheduler is not present, these excerpts together establish the foundational constructs (ultra-fine-grained preemption, per-core time ownership, and policy-driven scheduling) that a dynamic, online scheduler plausibly builds upon. The excerpts on capabilities and seL4-style isolation provide contextual assurances about secure, partitioned environments in which such a scheduler would operate, but they are less directly about the adaptive scheduling policy itself. Taken together, the most relevant excerpts paint a coherent picture of the scheduling substrate (preemption feasibility at microsecond scales and per-core execution rights) that underpins a heuristic, online blender-like scheduler; additional context from safety-oriented papers reinforces the operating environment without adding core scheduling detail.",
      "confidence": "medium"
    },
    {
      "field": "innovative_concepts.2",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "seL4 provides strong support for mixed criticality real-time systems (MCS), where the timeliness of critical activities must be ensured even if they co-exist.",
            "Thread Control Blocks represent threads of execution;",
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;"
          ]
        }
      ],
      "reasoning": "Explicit statements describe capabilities as access tokens enabling very fine-grained control over resource access, which underpins the kind of precise governance a Portkey Graph would require when mapping services and I/O rings through a DAG. The seL4 Whitepaper notes that capabilities support strong security via least-privilege access to resources, which directly aligns with the Portkey Graph's goal of controlled, graph-based resource mapping. Additional seL4 references emphasize strong isolation guarantees and real-time scheduling concepts (thread control blocks, scheduling contexts), which support the notion that a platform could rely on capability-based protection and deterministic scheduling to realize microsecond-scale execution windows along a mapped DAG of edges to hardware queues. Together, these excerpts establish a foundation for how a Portkey Graph could function in a RustHallows-like system by enabling fine-grained access control and predictable timing behavior, even though the exact Portkey Graph term is not used in the excerpts. The scheduling-focused excerpts about preemption and real-time capabilities further reinforce the practicality of DAG-driven, time-sensitive pipelines in a high-performance environment.",
      "confidence": "medium"
    },
    {
      "field": "hardware_and_driver_prerequisites.device_class",
      "citations": [
        {
          "title": "NVIDIA GPUDirect RDMA and DPDK gpudev integration",
          "url": "https://developer.nvidia.com/blog/optimizing-inline-packet-processing-using-dpdk-and-gpudev-with-gpus/",
          "excerpts": [
            "GPUDirect RDMA relies on the ability of NVIDIA GPUs to expose portions of device memory on a PCI Express base address register (BAR) region.",
            "In DPDK 21.11, NVIDIA introduced a new library named GPUdev to introduce the notion of GPU in the context of DPDK, and to enhance the dialog between CPU, network cards, and GPUs."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        },
        {
          "title": "GPUDirect Storage O_DIRECT Requirements Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html",
          "excerpts": [
            "GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data\npath for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer\nthrough the CPU. Using this direct path can relieve effective system bandwidth bottlenecks and decrease the\nlatency and utilization load on t",
            "The kernel storage driver can perform a DMA of user data to or from GPU memory by using addresses\n  that were obtained from callbacks to the GDS kernel module, `nvidia-fs.ko`",
            "The device near the storage has a DMA engine that can reach the GPU memory buffer via PCIe. + \n        For local storage, an NVMe device performs DMA. + \n        For remote storage, a NIC",
            "The file system stack that operates at the user-level, or the kernel-level, or both, and never\n  needs to access the data in CPU system memory. > Instead, data is transferred directly between storage and GPU memory, which is achieved by file\n> systems that exclusively use the O\\_DIRECT mode for a give",
            "O\\_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7). CUDA 12.2 (GDS version 1.7)\nintroduces support for non O\\_DIRECT file descriptor",
            "O_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7).",
            "CUDA 12.2 (GDS version 1.7) introduces support for non O_DIRECT file descriptors ... This can be viewed as the compatibility\nmode leveraging the page cache that can typically be used for smaller file I/Os with a high degree of\ntemporal locality, like the case of application headers or metadata",
            "The direct data path between the NIC and GPU memory happens on the client. To enable this direct path, client-side drivers must first be enabled with GDS.",
            "RDMA is a protocol to access remote data over a network and uses the NIC to DMA directly into client-side memory.",
            "Using RDMA also relies on server-side support. File system implementations that do not support RDMA on the server side will not support GDS."
          ]
        },
        {
          "title": "Intel SR-IOV Configuration Guide",
          "url": "https://cdrdv2-public.intel.com/630211/630211_E810%20SR-IOV%20RHEL8%20ConfigGuide_Rev1.2.pdf",
          "excerpts": [
            "Hardware Requirements",
            "ments**\n\n• An Intel <sup>®</sup> Ethernet 800 Series Network Adapter (or other adapter based on an Intel <sup>®</sup> Ethernet 800\n\nSeries Controller).",
            "roller). • A server platform that supports Intel <sup>®</sup> Virtualization Technology for Directed I/O (Intel <sup>®</sup> VT-d) and\n\nthe PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) specification.",
            " • A server platform with an available PCI Express Gen 4.0/3.0 x16 or x8 slot, depending on the\n\nspecific board. **1",
            "Software Requirements",
            "• Red Hat Enterprise Linux Version 8.0 (RHEL 8).",
            ").\n• Intel <sup>®</sup> Ethernet 800 Series Linux Drivers for PF and VF, available at:\n\nhttp://sourceforge.net/projects/e1000/files/\n\nhttp",
            "https://downloadscenter.intel.com",
            "Note:"
          ]
        },
        {
          "title": "Intel Ethernet 800 Series Product Brief",
          "url": "https://gzhls.at/blob/ldb/5/8/6/7/6b497d7cb6eb6fa2fbf214f8c2f7c7a97e22.pdf",
          "excerpts": [
            "\nIntel® Ethernet 800 Series supports up to 100Gb/s throughput for a \nvariety of workloads.",
            "Support both iWARP and RoCEv2 RDMA, selectable via software  \n\nper port for low-latency, high-throughput workloa",
            "Application Device Queues (ADQ) to increase application  \n\npredictability, reduce application latency and improve  \napplication throu",
            " \n\nVFs, 768 VSIs\n",
            "\n\nMove data faster with Intel® Ethernet 800 Series",
            "Intel® Ethernet Controller  \nE810-CAM2/CAM1/XXVAM2"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications.",
            "Missing: RustHallows competitive landscape"
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ...",
            "RDMA\n•\niWARP and RoCE v2. •\n256K Queue Pairs (QPs",
            "The E810 fully supports Next Generation VMDq mode and SR-IOV.",
            "irtualization (enhanced SR-IOV \nsupport with up to 256 VFs and backward compatibility VF driver support)"
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        }
      ],
      "reasoning": "The field value concerns device classes NIC, NVMe, and GPU that participate in high-performance data paths. Excerpts explicitly describing GPUDirect RDMA and GPUDirect Storage (which enable direct GPU-to-NIC/NVMe paths, or GPU-to-storage paths) directly substantiate the NIC, NVMe, and GPU classes and their roles in zero-copy, kernel-bypass, and RDMA-enabled architectures. For example, mentions of GPUDirect RDMA and GPUDirect Storage explain direct memory access between GPUs and NICs or storage, aligning with NIC and GPU as device classes and NVMe as the storage path in GDS contexts. Other excerpts describe user-space RDMA drivers, libibverbs, and RDMA ecosystems that revolve around NICs and NVMe storage interfaces, reinforcing the NIC/NVMe facets. Excerpts detailing io_uring, DPDK-like user-space stacks, and SR-IOV/IOMMU-oriented hardware isolation provide contextual framing for how NIC/NVMe/GPU data paths are isolated and accelerated, which supports the presence and interaction of these device classes in the architecture. A subset of excerpts discuss the broader hardware prerequisites (SR-IOV, IOMMU, VFs) that enable NIC/NVMe/GPU pathways, further corroborating their inclusion as core device classes in the research context, though these are slightly less direct than explicit GPUDirect/GDS references. Overall, the most compelling support comes from passages that explicitly describe GPUDirect RDMA/Storage and the associated user-space driver and kernel-bypass ecosystems, followed by direct mentions of GPUs, NICs, and NVMe in the same architectural theme.",
      "confidence": "high"
    },
    {
      "field": "kernel_and_isolation_components.3.function",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Endpoints are used to perform protected function calls;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);",
            "Reply Objects represent a return path from a protected procedure call;",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ..."
          ]
        }
      ],
      "reasoning": "The field value centers on a jailer mechanism that uses capabilities to tightly control per-service access and a namespace for system calls, enabling fast, forkless clones. Excerpt describing capabilities as fine-grained access tokens and controlling which entity can access resources directly supports the idea of a capability-gated namespace underlying such a jailer. Excerpts that discuss SeL4-style capabilities, per-object rights, and protected interfaces provide the foundational mechanism (capabilities) and architectural primitives (endpoints, protected calls, sandboxes) that a per-service jailer would leverage to implement per-service cells. Additional excerpts describing per-object rights and protected function calls reinforce the concept of isolated, capability-controlled execution contexts. While no excerpt explicitly names the jailer feature, the collection collectively corroborates the feasibility and design primitives (capabilities, isolation, protected IPC) that such a jailer would require. The strongest support comes from explicit statements about capabilities enabling fine-grained access control and protected interfaces, followed by context about endpoints and address spaces as part of the isolation model, with weaker support from broader capabilities-focused references and general isolation discussions.",
      "confidence": "medium"
    },
    {
      "field": "scheduling_components.1.function",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a feedback-driven scheduler that uses instrumentation data from a telemetry system (Pensieve) to steer scheduling at microsecond granularity. The first excerpt describes Shinjuku as capable of preempting requests as often as every 5 microseconds and enabling centralized scheduling policies, which directly corresponds to microsecond-scale scheduling and the notion of aggressive, instrumentation-driven control implied by a feedback-driven approach. The second excerpt also discusses microsecond-scale improvements in throughput and tail latency when using Shinjuku in a server context, reinforcing the idea that ultra-fine-grained scheduling decisions at microsecond resolution can yield tangible performance benefits. However, neither excerpt explicitly mentions the Pensieve telemetry system or explicitly ties Pensieve to the described scheduling mechanism. Despite that, the core elements of microsecond-scale responsive scheduling and the use of instrumentation/observability to influence scheduling are present, which makes these excerpts relevant as partial support for the described fine-grained field value. The most relevant parts are the explicit microsecond-scale preemption capability and the performance gains from such scheduling, which align with a feedback-driven scheduler that reacts to fine-grained telemetry data.\n",
      "confidence": "medium"
    },
    {
      "field": "hardware_and_driver_prerequisites.required_features",
      "citations": [
        {
          "title": "Hardware Considerations for Implementing SR-IOV | 4.4",
          "url": "https://docs.redhat.com/fr/documentation/red_hat_virtualization/4.4/html-single/hardware_considerations_for_implementing_sr-iov/index",
          "excerpts": [
            "Access Control Service (ACS) capabilities defined in the PCIe and server specifications are the hardware standard for maintaining isolation within IOMMU groups."
          ]
        },
        {
          "title": "Hardware considerations for SR-IOV and device assignment - Red Hat Virtualization 4.2",
          "url": "https://docs.redhat.com/en/documentation/red_hat_virtualization/4.2/html/hardware_considerations_for_implementing_sr-iov/index",
          "excerpts": [
            "Access Control Service (ACS) capabilities defined in the PCIe and server specifications are the hardware standard for maintaining isolation within IOMMU groups.",
            "IOMMU groups are sets of devices that can be isolated from all other devices in the system.",
            "This allows the IOMMU to distinguish transactions to and from the IOMMU group while restricting direct memory access (DMA) between devices outside of the IOMMU group and the control of the IOMMU.",
            "Device assignment provides the capacity to assign a virtual guest directly to a PCIe device, giving the guest full access and offering near-native performance.",
            "e. Implemented in conjunction with SR-IOV, a virtual guest is directly assigned a VF.",
            "Isolation of transactions between the virtual guest and the virtual functions of the PCIe device is fundamental to device assignment."
          ]
        },
        {
          "title": "Upstreaming a flexible and efficient I/O Path in Linux",
          "url": "https://www.usenix.org/system/files/fast24-joshi.pdf",
          "excerpts": [
            "by K Joshi · 2024 · Cited by 19 — NVMe driver, when loaded with polled_queues = N parameter, sets up. N polled queue-pair (SQ and CQ) for which NVMe device does not generate the ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "1. Getting Started with GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/gpudirect-storage/getting-started/index.html",
          "excerpts": [
            "NVIDIA® GPUDirect® Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce ..."
          ]
        },
        {
          "title": "What are the hardware requirements for using GPUDirect ...",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20hardware%20requirements%20for%20using%20GPUDirect%20with%20NVIDIA%20GPUs?",
          "excerpts": [
            "GPUDirect RDMA (Remote Direct Memory Access) and GPUDirect Storage have additional hardware prerequisites: RDMA-Capable NICs: For GPUDirect RDMA, the ..."
          ]
        },
        {
          "title": "28. ICE Poll Mode Driver - Documentation",
          "url": "https://doc.dpdk.org/guides/nics/ice.html",
          "excerpts": [
            "The ice PMD (librte_net_ice) provides poll mode driver support for 10/25/50/100/200 Gbps Intel® Ethernet 800 Series Network Adapters based on the following ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/613875_E810_Datasheet_Rev2_7-3314030.pdf?srsltid=AfmBOopOVGq1VlDC61e6xt9KhgfHGjfbQA4NBSKRxAMyy195mgxFyoAu",
          "excerpts": [
            "Page 1. Revision 2.7. March 2024. 613875-009. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K ..."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "What is NVMe? | An In-Depth Overview ... - Dell Technologies Info Hub",
          "url": "https://infohub.delltechnologies.com/en-us/l/an-in-depth-overview-of-nvme-and-nvme-of/what-is-nvme/",
          "excerpts": [
            "The current set of NVMe command specifications are: NVMe Command Set Specification, Revision 1.1; NVMe Zoned Namespaces Command Set Specification, Revision 1.2 ..."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "GPUDirect Storage O_DIRECT Requirements Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html",
          "excerpts": [
            "GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data\npath for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer\nthrough the CPU. Using this direct path can relieve effective system bandwidth bottlenecks and decrease the\nlatency and utilization load on t",
            "The kernel storage driver can perform a DMA of user data to or from GPU memory by using addresses\n  that were obtained from callbacks to the GDS kernel module, `nvidia-fs.ko`",
            "The device near the storage has a DMA engine that can reach the GPU memory buffer via PCIe. + \n        For local storage, an NVMe device performs DMA. + \n        For remote storage, a NIC",
            "The file system stack that operates at the user-level, or the kernel-level, or both, and never\n  needs to access the data in CPU system memory. > Instead, data is transferred directly between storage and GPU memory, which is achieved by file\n> systems that exclusively use the O\\_DIRECT mode for a give",
            "O\\_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7). CUDA 12.2 (GDS version 1.7)\nintroduces support for non O\\_DIRECT file descriptor",
            "O_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7).",
            "CUDA 12.2 (GDS version 1.7) introduces support for non O_DIRECT file descriptors ... This can be viewed as the compatibility\nmode leveraging the page cache that can typically be used for smaller file I/Os with a high degree of\ntemporal locality, like the case of application headers or metadata",
            "The direct data path between the NIC and GPU memory happens on the client. To enable this direct path, client-side drivers must first be enabled with GDS.",
            "RDMA is a protocol to access remote data over a network and uses the NIC to DMA directly into client-side memory.",
            "Using RDMA also relies on server-side support. File system implementations that do not support RDMA on the server side will not support GDS."
          ]
        }
      ],
      "reasoning": "Direct evidence for NICs shows SR-IOV as a mechanism to present multiple virtual functions from a single NIC, enabling hardware partitioning and isolation across tenants. This supports the hardware partitioning aspect of the field value. Documentation and discussion of IOMMU usage (such as VT-d) demonstrate secure DMA remapping and isolation between devices and memory regions, which aligns with secure device pass-through requirements. Pass-through and isolation concepts are reinforced by SR-IOV and IOMMU references, which underpin secure device sharing in multi-tenant environments. The excerpts also explicitly discuss RDMA capabilities for NICs (RoCEv2 and iWARP), which are essential for low-latency networking paths described in the field value. NVMe Zoned Namespaces (ZNS) command support is covered, indicating mechanisms to reduce write amplification and improve latency in NVMe devices, matching the NVMe prerequisite. GPUDirect Storage and GPUDirect RDMA passages describe direct GPU-to-storage and GPU-to-network data paths that bypass CPU involvement, which correspond to the GPUDirect requirements in the field value. Additional passages discuss user-space stacks and frameworks like SPDK/DPDK that enable high-performance, user-space data paths, reinforcing the overall architecture described in the field value. Overall, the strongest, most direct matches are SR-IOV and IOMMU for isolation, RDMA capabilities for NICs, ZNS support for NVMe, and GPUDirect pathways for GPUs; the SPDK/DPDK references provide supporting context for user-space acceleration of these pathways.",
      "confidence": "high"
    },
    {
      "field": "innovative_concepts.7.description",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "seL4 provides strong support for mixed criticality real-time systems (MCS), where the timeliness of critical activities must be ensured even if they co-exist."
          ]
        }
      ],
      "reasoning": "The target field value describes a built-in infrastructure for remote attestation using hardware features (e.g., SGX, TrustZone) to support trusted Portkeys and attested communication. The excerpts provided discuss capabilities as access tokens for fine-grained control and SeL4-style isolation, which are foundational security concepts relevant to secure architectures but do not mention remote attestation, hardware-backed trusted endpoints, or attested RPC channels. Specifically, one excerpt emphasizes that capabilities are fine-grained access tokens controlling who can access resources, which aligns with core security primitives but does not address attestation mechanisms. Another excerpt highlights SeL4's support for mixed criticality and strong security properties through capabilities, which again underpins secure isolation but stops short of attestation infrastructure. A third excerpt reiterates that capabilities support fine-grained access control, reinforcing the security-architecture angle without addressing attestation. Collectively, these excerpts partially relate to the broader theme of secure capability-based design but do not provide evidence for the remote attestation infrastructure and trusted Portkeys described in the field value. Therefore, they offer contextual support about security foundations but lack direct quotes or specifics about hardware-assisted attestation or attested RPC endpoints.",
      "confidence": "low"
    },
    {
      "field": "innovative_concepts.3.description",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;"
          ]
        }
      ],
      "reasoning": "The target fine-grained field value describes an online, feedback-driven scheduling policy blender that learns per-flow service time distributions (including heavy-tail behavior) and dynamically switches between scheduling strategies to optimize latency and throughput. The most relevant excerpts discuss advanced microsecond-scale scheduling capabilities and preemption policies: one describes a scheduler capable of preemption on microsecond scales and centralized policy control, while another notes rapid preemption coupled with \"centralized scheduling policies\" that can handle variable request service times. These excerpts directly touch on microsecond-scale responsiveness, policy control, and the capability to adapt scheduling behavior in real time, which are the core aspects of a feedback-driven policy blender. A third excerpt reinforces the notion of a fast, preemptive, configurable scheduling environment, which aligns with the idea of blending different scheduling modes to balance latency and throughput. The remaining excerpt provides context about scheduling contexts and rights-based access to core resources, which is related background but less directly tied to the feedback-driven blending mechanism. Collectively, the excerpts support the existence and importance of sophisticated, latency-aware scheduling policies and centralized policy control, which underpins the described policy blender.",
      "confidence": "medium"
    },
    {
      "field": "hardware_and_driver_prerequisites.target_hardware_examples",
      "citations": [
        {
          "title": "Intel® Ethernet Controller E810 Datasheet",
          "url": "https://www.intel.com/content/www/us/en/content-details/613875/intel-ethernet-controller-e810-datasheet.html",
          "excerpts": [
            "This document describes the external architecture (including device operation, pin descriptions, register definitions, and so on) for the Intel® Ethernet ..."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA2",
          "url": "https://cdrdv2-public.intel.com/641674/Intel%20Ethernet%20Network%20Adapter%20E810-XXVDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA4",
          "url": "https://cdrdv2-public.intel.com/742008/Dell_Intel%20Ethernet%20Network%20Adatper%20E810-XXVDA4.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "[PDF] Ultrastar DC ZN540 ZNS SSD Product Brief - Western Digital",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/product-brief/product-brief-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar® DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set as ..."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ..."
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        },
        {
          "title": "28. ICE Poll Mode Driver - Documentation",
          "url": "https://doc.dpdk.org/guides/nics/ice.html",
          "excerpts": [
            "The ice PMD (librte_net_ice) provides poll mode driver support for 10/25/50/100/200 Gbps Intel® Ethernet 800 Series Network Adapters based on the following ..."
          ]
        },
        {
          "title": "1. Getting Started with GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/gpudirect-storage/getting-started/index.html",
          "excerpts": [
            "NVIDIA® GPUDirect® Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce ..."
          ]
        },
        {
          "title": "How to enable GPU Direct Storage (GDS) with P2PDMA",
          "url": "https://forums.developer.nvidia.com/t/how-to-enable-gpu-direct-storage-gds-with-p2pdma/340055",
          "excerpts": [
            "Does enabling GDS in P2PDMA mode only require installing CUDA 12.8, or are there other necessary steps or configurations? What are the exact ...",
            "GDS can be enabled in two ways: using the GDS NVIDIA kernel driver (nvidia-fs.ko) and updating the NVMe driver patches, or optionally as of 12.8 ..."
          ]
        },
        {
          "title": "P2PDMA Support Added to Linux Kernel 4.20 RC1",
          "url": "https://www.eideticom.com/blog/p2pdma-support-added-to-linux-kernel-4-20-rc1-eideticom-blog",
          "excerpts": [
            "Nov 5, 2018 — It is possible p2pdma can be the basis for a legitimate upstream version of GPUDirect for example, which has failed to be accepted for ..."
          ]
        },
        {
          "title": "What are the hardware requirements for using GPUDirect ...",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20hardware%20requirements%20for%20using%20GPUDirect%20with%20NVIDIA%20GPUs?",
          "excerpts": [
            "GPUDirect RDMA (Remote Direct Memory Access) and GPUDirect Storage have additional hardware prerequisites: RDMA-Capable NICs: For GPUDirect RDMA, the ..."
          ]
        },
        {
          "title": "32. Intel Virtual Function Driver - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-23.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "27. Intel Virtual Function Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-20.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "NVIDIA MELLANOX CONNECTX-6 DX",
          "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/documents/nvidia-connectx-6-dx-en-hpe-datasheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities, and supports up to 8 million rules. > Advanced Quality of Service ..."
          ]
        },
        {
          "title": "5. NVIDIA MLX5 Common Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-23.11/platform/mlx5.html",
          "excerpts": [
            "The mlx5 kernel modules are part of upstream Linux. The minimal supported kernel version is 4.14. For 32-bit, version 4.14.41 or above is required. The ..."
          ]
        }
      ],
      "reasoning": "The most directly supportive excerpts explicitly name the hardware in the fine-grained value. For example, excerpts that present the Intel Ethernet Controller E810 datasheet and product brief confirm the NIC family and its SR-IOV/VF capabilities, aligning with the NICs specified in the field value. Excerpts that describe Ultrastar DC ZNS/ZN540 products confirm the ZNS NVMe storage devices, which map to the ZNS drives mentioned. Excerpts referencing Samsung PM1731a provide explicit ZNS SSD examples that match the storage devices in the field value. Excerpts discussing GPUDirect RDMA/GPUDirect Storage (and related NVIDIA documentation) directly address GPUs and the direct memory access paths between GPU memory and storage or NICs, which correspond to the GPU portion of the field value and the GPUDirect capability requirement. Where an excerpt discusses GPUDirect Storage (GDS) and related driver/user-space interfaces (e.g., RDMA, nvme/gds workflows), it aligns with the GPUs' GPUDirect/Storage ecosystem mentioned in the field value. In supporting excerpts, more general NVMe, SR-IOV, and IOMMU concepts are included because they underpin the same hardware context (PCIe devices, isolation, and high-performance I/O), though they do not name the exact models; these provide corroborating context for why the listed hardware choices are relevant in a high-performance, isolation-focused stack. The intent is to stitch together a coherent hardware picture: Intel E810 family NICs with SR-IOV, ZNS storage devices like Ultrastar ZN540 and PM1731a, and GPUs with GPUDirect/Storage capabilities, with supporting vendor docs and architecture discussions that reinforce how these components fit into a zero-copy, device-bypass, high-performance stack.",
      "confidence": "high"
    },
    {
      "field": "innovative_concepts.2.description",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 provides strong support for mixed criticality real-time systems (MCS), where the timeliness of critical activities must be ensured even if they co-exist.",
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;",
            "Capabilities  are access tokens which support very ﬁne-grained control over\nwhich entity can access a particular resource in a system.",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Thread Control Blocks represent threads of execution;"
          ]
        }
      ],
      "reasoning": "The finegrained field describes a dataflow-oriented abstraction where services, I/O rings, and message queues are organized as a Directed Acyclic Graph (DAG) to map edges to NIC/NVMe/GPU queues while preserving critical-path cache locality, and where the scheduler uses this DAG to pre-provision microsecond-scale execution windows for time-sensitive processing pipelines. Excerpts that discuss real-time guarantees and scheduling contexts align with the emphasis on timing and deterministic execution, which underpin the feasibility of scheduling as a DAG-driven orchestration. Specifically, the excerpt noting mixed criticality real-time systems highlights the importance of deterministic timing guarantees when multiple domains co-exist, which supports the need for tightly coordinated execution windows. The excerpt about scheduling contexts conveying \"the right to access a certain fraction of execution time on a core\" reinforces the concept of fine-grained, schedule-aware control that would be necessary in a DAG-based mapping and time-provisioning scheme. The excerpts focused on capabilities and isolation establish the foundational mechanisms that would support such a DAG-based orchestration (capability-based control, isolation, and per-object rights), even though they do not describe the DAG concept itself. Together, these excerpts substantiate the feasibility and architectural prerequisites (deterministic scheduling, fine-grained control) for a DAG-based runtime and time-provisioning scheduler, but they do not directly contain the explicit DAG description. Therefore, the strongest support comes from the real-time scheduling and scheduling-context-related excerpts, with capabilities/isolation excerpts providing essential backdrop, and the DAG-specific description remaining implicit in the combination of those concepts.",
      "confidence": "medium"
    },
    {
      "field": "innovative_concepts.0.concept_name",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The concept name Time-Turner is explicitly introduced as a scheduler in the material. This establishes a concrete temporal control mechanism within the system's scheduling framework. A separate fine-grained field value labeled Time-Turner Snapshots would logically extend this temporal control by introducing deterministic checkpoints to capture process state at precise moments in time, enabling rollback or replay aligned with the scheduler's governance. The excerpt describing Time-Turner as a μcs-scale scheduler and policy blender provides the strongest direct link: it establishes that time-centric control and policy-driven scheduling are core design motifs, which Time-Turner Snapshots would leverage to create reliable, low-latency temporal checkpoints. Other excerpts discuss related scheduling approaches (Shinjuku, Shenango, Caladan) and capability-based isolation, which enrich the context for a time-aware system but do not directly reference temporal checkpoints; however, they reinforce the broader architectural emphasis on precise timing, preemption, and isolation that Time-Turner Snapshots would inhabit. Taken together, these excerpts support the notion that a Time-Turner Snapshots concept would fit into the existing Time-Turner scheduling framework and the system's emphasis on sub-microsecond timing control, determinism, and policy-driven behavior.",
      "confidence": "medium"
    },
    {
      "field": "innovative_concepts.3.concept_name",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Scheduling Contexts represent the right to access a certain fraction of\nexecution time on a core;"
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The target field value represents a scheduler that blends policies online, learns per-flow service distributions, and chooses between different preemption strategies to optimize latency and throughput. Excerpt describing Shinjuku as a framework for microsecond-scale preemption directly supports the kind of fine-grained, responsive scheduling behavior that a heuristic policy blender would need to implement. Excerpts detailing SeL4-like scheduling contexts establish the broader capability-based, deterministic scheduling guarantees that such a scheduler would leverage to provide predictable performance. The general discussion of scheduling contexts and the idea of centralized scheduling policies further illustrate the kinds of mechanisms (preemption control, policy-driven decisions, multi-tenant determinism) that a heuristic scheduler would operate within. Together, these excerpts align with the concept of Felix Heuristic Scheduler by outlining the scheduling architecture, preemption capabilities, and policy-blending goals that such a scheduler would encapsulate, even though the exact name is not present in the excerpts. The alignment is indirect but coherent: the excerpts describe the enabling technologies and scheduling philosophies that the Felix Heuristic Scheduler would rely on to function effectively.",
      "confidence": "medium"
    },
    {
      "field": "hardware_and_driver_prerequisites.driver_dependencies",
      "citations": [
        {
          "title": "Hardware Considerations for Implementing SR-IOV | 4.4",
          "url": "https://docs.redhat.com/fr/documentation/red_hat_virtualization/4.4/html-single/hardware_considerations_for_implementing_sr-iov/index",
          "excerpts": [
            "Access Control Service (ACS) capabilities defined in the PCIe and server specifications are the hardware standard for maintaining isolation within IOMMU groups."
          ]
        },
        {
          "title": "Hardware considerations for SR-IOV and device assignment - Red Hat Virtualization 4.2",
          "url": "https://docs.redhat.com/en/documentation/red_hat_virtualization/4.2/html/hardware_considerations_for_implementing_sr-iov/index",
          "excerpts": [
            "Access Control Service (ACS) capabilities defined in the PCIe and server specifications are the hardware standard for maintaining isolation within IOMMU groups.",
            "IOMMU groups are sets of devices that can be isolated from all other devices in the system.",
            "This allows the IOMMU to distinguish transactions to and from the IOMMU group while restricting direct memory access (DMA) between devices outside of the IOMMU group and the control of the IOMMU.",
            "Device assignment provides the capacity to assign a virtual guest directly to a PCIe device, giving the guest full access and offering near-native performance.",
            "e. Implemented in conjunction with SR-IOV, a virtual guest is directly assigned a VF.",
            "Isolation of transactions between the virtual guest and the virtual functions of the PCIe device is fundamental to device assignment."
          ]
        },
        {
          "title": "Single Root IO Virtualization (SR-IOV)",
          "url": "https://docs.nvidia.com/networking/display/OFED/Single+Root+IO+Virtualization+(SR-IOV)",
          "excerpts": [
            "Feb 29, 2024 — Single Root IO Virtualization (SR-IOV) is a technology that allows a physical PCIe device to present itself multiple times through the PCIe bus."
          ]
        },
        {
          "title": "IOMMU DMA Remapping - Windows drivers - Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/display/iommu-dma-remapping",
          "excerpts": [
            "IOMMU DMA remapping allows the GPU to access memory through logical addresses that are no longer mapped 1:1. Instead, Dxgkrnl is able to provide logically ..."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 Datasheet",
          "url": "https://www.intel.com/content/www/us/en/content-details/613875/intel-ethernet-controller-e810-datasheet.html",
          "excerpts": [
            "This document describes the external architecture (including device operation, pin descriptions, register definitions, and so on) for the Intel® Ethernet ..."
          ]
        },
        {
          "title": "32. Intel Virtual Function Driver - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-23.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "27. Intel Virtual Function Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-20.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            "RDMA\n•\niWARP and RoCE v2. •\n256K Queue Pairs (QPs",
            "The E810 fully supports Next Generation VMDq mode and SR-IOV.",
            "irtualization (enhanced SR-IOV \nsupport with up to 256 VFs and backward compatibility VF driver support)",
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ..."
          ]
        },
        {
          "title": "Intel Ethernet 800 Series Product Brief",
          "url": "https://gzhls.at/blob/ldb/5/8/6/7/6b497d7cb6eb6fa2fbf214f8c2f7c7a97e22.pdf",
          "excerpts": [
            "\nIntel® Ethernet 800 Series supports up to 100Gb/s throughput for a \nvariety of workloads.",
            "Support both iWARP and RoCEv2 RDMA, selectable via software  \n\nper port for low-latency, high-throughput workloa",
            "Application Device Queues (ADQ) to increase application  \n\npredictability, reduce application latency and improve  \napplication throu",
            " \n\nVFs, 768 VSIs\n",
            "\n\nMove data faster with Intel® Ethernet 800 Series",
            "Intel® Ethernet Controller  \nE810-CAM2/CAM1/XXVAM2"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value lists concrete prerequisites and components for a safe, high-performance, I/O-heavy stack. Excerpts describing SR-IOV and IOMMU concepts establish the firmware/driver isolation requirements: SR-IOV as a hardware feature enabling multiple virtual functions per physical device, and IOMMU in charge of memory isolation across devices. The kernel-module and driver references (vfio-pci for IOMMU-based device assignment, i40e for Intel NICs, mlx5_core for Mellanox NICs) map directly to the kernel and device drivers part of the field value. References that discuss the NVIDIA Open GPU kernel module and GPUDirect RDMA/Storage contexts align with the GPU driver and RDMA stack components in the field value. Excerpts mentioning DPDK for networking and SPDK for storage illustrate the user-space libraries that the field value requires. Finally, excerpts about MLNX_OFED and SR-IOV VF counts on Intel E810 products corroborate the RDMA and virtualization features that the field value lists as necessary in practice.",
      "confidence": "high"
    },
    {
      "field": "core_value_proposition",
      "citations": [
        {
          "title": "CHEOPS 2023: I/O Stack (ZNS, SPDK, ZenFS, vroom, and Rust-based user-space stacks)",
          "url": "https://atlarge-research.com/pdfs/2023-cheops-iostack.pdf",
          "excerpts": [
            "Storage Performance Development Kit (SPDK) is a user space\nI/O library that provides zero-copy, high-performance, and\nefficient direct access to NVMe SSDs from the userspace\nleveraging a poll-based NVMe driver [69].",
            "The Storage Perfor-\nmance Development Kit (SPDK) is one of the most popular\nand widely used user space I/O libraries, which can deliver\nup to 10 million IOPS using a single CPU core [2",
            "SPDK initializes\nand accesses NVMe I/O queues directly in the userspace,\nthus completely skipping the kernel during I/O operations.",
            "SPDK initializes\nand accesses NVMe I/O queues directly in the userspace,\nthus completely skipping the kernel during I/O operations."
          ]
        },
        {
          "title": "SPDK v21.04: ZNS NVMe bdev, PMR, ADQ initiator, RPM",
          "url": "https://spdk.io/release/2021/04/29/21.04_release/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications. It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead."
          ]
        },
        {
          "title": "Leveraging NVMe SSDs for Building a Fast, Cost-effective, LSM-tree ...",
          "url": "https://dl.acm.org/doi/10.1145/3480963",
          "excerpts": [
            "SPDK moves drivers into user space, avoiding system calls and enabling zero-copy access. It polls hardware for completion instead of using ..."
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "What is SPDK",
          "url": "https://spdk.io/doc/about.html",
          "excerpts": [
            "Avoiding all locks in the I/O path, instead relying on message passing. The bedrock of SPDK is a user space, polled-mode, asynchronous, lockless NVMe driver."
          ]
        },
        {
          "title": "SPDK: NVMe Driver",
          "url": "https://spdk.io/doc/nvme.html",
          "excerpts": [
            "The SPDK NVMe driver provides a zero-copy data transfer path, which means that there are no data buffers for I/O commands.",
            "The NVMe driver takes no locks in the I/O path, so it scales linearly in terms of performance per thread as long as a queue pair and a CPU core are dedicated to each new thread.",
            "The NVMe driver is a C library that may be linked directly into an application that provides direct, zero-copy data transfer to and from NVMe SSDs."
          ]
        },
        {
          "title": "120 Million I/O Per Second with a Standard 2U Intel® Xeon® System",
          "url": "https://spdk.io/news/2023/02/01/nvme-120m-iops/",
          "excerpts": [
            "The SPDK NVMe driver does not take locks in the I/O path, so it scales linearly in terms of performance per thread as long as a queue pair and a ...",
            "This results in a\n[message passing architecture](https://spdk.io/doc/concurrency.html), as opposed\nto a locking architecture, and will result in superior scaling across CPU cores.",
            "NVMe queue pairs provide parallel submission path\nfor I/O. Queue pairs contain no locks or atomics, however, so a given queue pair\nmay only be used by a single thread at a time."
          ]
        },
        {
          "title": "Writing an NVMe Driver in Rust",
          "url": "https://db.in.tum.de/~ellmann/theses/finished/24/pirhonen_writing_an_nvme_driver_in_rust.pdf",
          "excerpts": [
            "To enable multithreaded I/O processing, we have defined NvmeQueuePair, so, akin\nto SPDK, each thread can have its own queue pair to handle reading and writing\nwithout needing locking access to a single instance of NvmeDevice."
          ]
        },
        {
          "title": "Accelerate Your NVMe Drives with SPDK",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/accelerating-your-nvme-drives-with-spdk.html",
          "excerpts": [
            "This tutorial will focus on the userspace NVMe driver provided by SPDK and will show you a Hello World example running on an Intel® architecture platform.",
            "Oct 2, 2017 — This tutorial will focus on the userspace NVMe driver provided by SPDK and will show you a Hello World example running on an Intel® architecture platform."
          ]
        },
        {
          "title": "libnvm: a userspace NVMe driver library",
          "url": "https://github.com/enfiskutensykkel/ssd-gpu-dma",
          "excerpts": [
            "The API is in essence similar to SPDK , in that it moves driver code to\nuserspace and relies on hardware polling rather than being interrupt driven.",
            "This library is a userspace API implemented in C for writing custom NVM Express (NVMe) drivers and high-performance storage applications.",
            "By mapping userspace memory directly,\nlibnvm eliminates the cost of context\nswitching into kernel space and enables zero-copy access from userspace.",
            "This greatly reduces the latency of IO operations compared to accessing storage\ndevices through normal file system abstractions provided by the Linux kernel.",
            "libnvm can be\nlinked with CUDA programs, enabling high-performance storage access directly\nfrom your CUDA kernels . This is achieved by placing IO queues and data\nbuffers directly in GPU memory, eliminating the need to involve the CPU in\nthe IO path entirely .",
            "With minimal driver support, it is possible to set\nup arbitrary memory mappings to device memory, enabling direct IO between NVMe\nstorage devices and other PCIe devices ( PCIe peer-to-peer )."
          ]
        },
        {
          "title": "GPUDirect Storage - NVIDIA Technical Blog",
          "url": "https://developer.nvidia.com/blog/gpudirect-storage/",
          "excerpts": [
            "A new technology called GPUDirect Storage enables a direct data path between local or remote storage, like NVMe or NVMe over Fabric (NVMe-oF), and GPU memory.",
            "GPUDirect RDMA and GPUDirect Storage avoid extra copies through a bounce buffer in the CPU’s memory and enable a direct memory access (DMA) engine near the NIC or storage to move data on a direct path into or out of GPU memory, all without burdening the CPU or GPU (Figure 1).",
            "* 2x-8x higher bandwidth with data transfers directly between storage and GPU."
          ]
        },
        {
          "title": "The NVIDIA GPUDirect Storage cuFile API Reference Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/api-reference-guide/index.html",
          "excerpts": [
            "GDS enables a direct data path for direct memory\naccess (DMA) transfers between GPU memory and storage, which avoids a bounce buffer through the CPU. This direct path increases\nsystem bandwidth and decreases the latency and utilization load on the CPU."
          ]
        },
        {
          "title": "GPUDirect Storage - NVIDIA (Getting Started / Overview)",
          "url": "https://docs.nvidia.com/gpudirect-storage/",
          "excerpts": [
            "GPUDirect Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer through the CPU. This direct path increases system bandwidth and decreases the latency and utilization load on the CPU.",
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer through the CPU."
          ]
        },
        {
          "title": "1. Getting Started with GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/gpudirect-storage/getting-started/index.html",
          "excerpts": [
            "NVIDIA® GPUDirect® Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required."
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        },
        {
          "title": "GPUDirect Storage O_DIRECT Requirements Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html",
          "excerpts": [
            "GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data\npath for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer\nthrough the CPU. Using this direct path can relieve effective system bandwidth bottlenecks and decrease the\nlatency and utilization load on t",
            "The device near the storage has a DMA engine that can reach the GPU memory buffer via PCIe. + \n        For local storage, an NVMe device performs DMA. + \n        For remote storage, a NIC",
            "The file system stack that operates at the user-level, or the kernel-level, or both, and never\n  needs to access the data in CPU system memory. > Instead, data is transferred directly between storage and GPU memory, which is achieved by file\n> systems that exclusively use the O\\_DIRECT mode for a give",
            "The direct data path between the NIC and GPU memory happens on the client. To enable this direct path, client-side drivers must first be enabled with GDS.",
            "RDMA is a protocol to access remote data over a network and uses the NIC to DMA directly into client-side memory.",
            "Using RDMA also relies on server-side support. File system implementations that do not support RDMA on the server side will not support GDS."
          ]
        },
        {
          "title": "Boosting Data Ingest Throughput with GPUDirect Storage ...",
          "url": "https://developer.nvidia.com/blog/boosting-data-ingest-throughput-with-gpudirect-storage-and-rapids-cudf/",
          "excerpts": [
            "May 27, 2022 — GPUDirect Storage provides a direct data path to the GPU, reducing latency and increasing throughput for I/O operations. RAPIDS cuDF leverages ..."
          ]
        },
        {
          "title": "Austin Labs - Zoned Namespace (ZNS) Testing Services",
          "url": "https://www.teledynelecroy.com/doc/al-testing-zns-brochure",
          "excerpts": [
            "By dividing the NVMe namespace into zones, ZNS improves latency, throughput and drive capacity, making it ideal for hyper-scale, all-flash array, and large ..."
          ]
        },
        {
          "title": "'Apples to Apples' Zoned Namespaces (ZNS) vs. FTL SSD ...",
          "url": "https://www.radianmemory.com/about/news/apples-to-apples-zoned-namespaces-zns-vs-ftl-ssd-performance-benchmark/",
          "excerpts": [
            "The ultimate performance tests for today's data center applications show tail latencies (99.99% or greater QoS) and include IOPS in the same measurement, ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Statistics Behind Latency Metrics: Understanding P90, P95, and P99",
          "url": "https://medium.com/tuanhdotnet/statistics-behind-latency-metrics-understanding-p90-p95-and-p99-dc87420d505d",
          "excerpts": [
            "Latency percentiles, such as P90, P95, and P99, are statistical measures that indicate how response times are distributed.",
            "P99 (99th Percentile): The P99 metric means that 99% of the requests have a response time less than or equal to this value. It focuses on the ..."
          ]
        },
        {
          "title": "Tail Latency: Key in Large-Scale Distributed Systems - Last9",
          "url": "https://last9.io/blog/tail-latency/",
          "excerpts": [
            "p50 (median): This indicates what the \"typical\" request looks like. p95: 95% of requests are faster than this value. p99: This is where tail ..."
          ]
        },
        {
          "title": "Long-Tail Latency Problem in Microservices",
          "url": "https://www.geeksforgeeks.org/system-design/long-tail-latency-problem-in-microservices/",
          "excerpts": [
            "In a microservices architecture, this issue can manifest when a few service calls have notably longer response times compared to the average."
          ]
        },
        {
          "title": "Learning Unified System Representations for Microservice ...",
          "url": "https://arxiv.org/html/2508.01635v1",
          "excerpts": [
            "In this paper, we presented USRFNet, a dual-stream fusion network for predicting window-level P95 tail latency in microservice systems."
          ]
        },
        {
          "title": "An Analysis of Holistic Tail Latency Behaviors of Java ...",
          "url": "https://ieeexplore.ieee.org/document/8855342",
          "excerpts": [
            "by P Tennage · 2019 · Cited by 7 — In this paper, we focus on analyzing and characterizing the behaviour of tail latency values of microservices workloads under service's peak sustainable ..."
          ]
        },
        {
          "title": "Predicting bounds on queuing delay for batch-scheduled ...",
          "url": "https://dl.acm.org/doi/10.1145/1122971.1122989",
          "excerpts": [
            "by J Brevik · 2006 · Cited by 110 — In this work, we explore a new method for providing end-users with predictions for the bounds on the queuing delay individual jobs will experience. We evaluate ..."
          ]
        },
        {
          "title": "A Small Dice Game for the Kingman Formula",
          "url": "https://inria.hal.science/hal-02164892v1/document",
          "excerpts": [
            "by C Roser · 2018 · Cited by 1 — For the general G/G/1 queue, there exist different approximations. The most com- mon one is the Kingman approximation as shown in equation (2)."
          ]
        },
        {
          "title": "Kingman's formula",
          "url": "https://en.wikipedia.org/wiki/Kingman%27s_formula",
          "excerpts": [
            "Kingman's formula, also known as the VUT equation, is an approximation for the mean waiting time in a G/G/1 queue."
          ]
        },
        {
          "title": "The Kingman Formula – Variation, Utilization, and Lead Time",
          "url": "https://www.allaboutlean.com/kingman-formula/",
          "excerpts": [
            "The Kingman equation (also known as Kingman formula or Kingman approximation) gives you an approximation of the waiting time of the parts for a single process."
          ]
        },
        {
          "title": "Lead-time variability in a homogeneous queueing model of ...",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/S0925527398000292",
          "excerpts": [
            "by R Kuik · 1999 · Cited by 32 — In addition, they state that the batching decision that minimizes the average queueing delay also tends to minimize the variance in the waiting time. In this ..."
          ]
        },
        {
          "title": "NIC の⾼速化と システムソフトウェア研究",
          "url": "https://seminar-materials.iijlab.net/iijlab-seminar/iijlab-seminar-20231017.pdf",
          "excerpts": [
            "Oct 17, 2023 — • Shinjuku (NSDI 2019). • TAS (EuroSys 2019). • Caladan (OSDI 2020) ... Tail Latency. In 16th USENIX Symposium on Networked Systems Design ..."
          ]
        },
        {
          "title": "seL4/sel4bench: sel4 benchmarking applications and support library.",
          "url": "https://github.com/seL4/sel4bench",
          "excerpts": [
            "Missing: cycles microbenchmark"
          ]
        },
        {
          "title": "L4 microkernel family - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/L4_microkernel_family",
          "excerpts": [
            "L4 is a family of second-generation microkernels, used to implement a variety of types of operating systems (OS)"
          ]
        },
        {
          "title": "r/linux on Reddit: L4 Microkernels: The Lessons from 20 Years of ...",
          "url": "https://www.reddit.com/r/linux/comments/4ef9ab/l4_microkernels_the_lessons_from_20_years_of/",
          "excerpts": [
            "I often hear the pure microkernel architecture is slow because it requires more context switches line, but according to these figures, it would ..."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". Arrakis: The Operating System is the Control\nPlane. OSDI, 2014.",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        },
        {
          "title": "Network Interface Controller Drivers - Download",
          "url": "https://fast.dpdk.org/doc/pdf-guides-20.02/nics-20.02.pdf",
          "excerpts": [
            "May 18, 2020 — The SR-IOV NIC switch forwards the packet to a specific VM according to the. MAC destination address which belongs to the destination VF on ..."
          ]
        },
        {
          "title": "Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOoroPxwW5RK38PZBdOI2YMlE1W5qR4wyNfP0NTN08UNbtRkAXUOs",
          "excerpts": [
            "May 23, 2023 — Page 1. Revision 2.6. May 2023. 613875-008. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ..."
          ]
        },
        {
          "title": "Intel® Ethernet Network Adapter E810-2CQDA2",
          "url": "https://cdrdv2-public.intel.com/639389/Intel%20Ethernet%20Network%20Adapter%20E810-2CQDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 512 SR-IOV Virtual Functions**. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized ...",
          "url": "https://semiconductor.samsung.com/news-events/news/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Samsung Electronics, today unveiled its new enterprise solid-state drive (SSD) featuring Zoned Namespace (ZNS) technology — the PM1731a.",
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ports, ensuring ..."
          ]
        },
        {
          "title": "What are the system requirements for GPUDirect RDMA?",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20system%20requirements%20for%20GPUDirect%20RDMA?",
          "excerpts": [
            "Hardware Requirements  PCIe Bus Support: The system must support PCIe Gen3 or higher for optimal performance. RDMA-Capable Network Adapter: The network interface card (NIC) must support GPUDirect RDMA (e.g., Mellanox ConnectX-6/7, NVIDIA BlueField DPU, or other compatible adapters)."
          ]
        },
        {
          "title": "31. Shared Virtual Addressing (SVA) with ENQCMD",
          "url": "https://www.kernel.org/doc/html/next/x86/sva.html",
          "excerpts": [
            "Use of SVA requires IOMMU support in the platform. IOMMU is also required to support the PCIe features ATS and PRI. ATS allows devices to cache translations ..."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 — Feature Support Matrix",
          "url": "https://cdrdv2-public.intel.com/630155/630155_E810%20Feature%20Summary_rev3_4.pdf",
          "excerpts": [
            "Sep 16, 2022 — Use case assumes up to 256 VFs with SR-IOV, assign them to containers, 1 VF per container. Table 10. Configuration Maximums. Host OS. Max VFs."
          ]
        },
        {
          "title": "Using SR-IOV VF in CT with DPDK - Proxmox Support Forum",
          "url": "https://forum.proxmox.com/threads/using-sr-iov-vf-in-ct-with-dpdk.110959/",
          "excerpts": [
            "I am trying to use some VFs of a NIC in a CT. What I did so far: 1. Enable SR-IOV in bios 2. Enable IOMMU with pass through 3. Load kernel modules on startup."
          ]
        },
        {
          "title": "NVIDIA MELLANOX CONNECTX-6 DX",
          "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/documents/nvidia-connectx-6-dx-en-hpe-datasheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities, and supports up to 8 million rules. > Advanced Quality of Service ..."
          ]
        },
        {
          "title": "5. NVIDIA MLX5 Common Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-23.11/platform/mlx5.html",
          "excerpts": [
            "The mlx5 kernel modules are part of upstream Linux. The minimal supported kernel version is 4.14. For 32-bit, version 4.14.41 or above is required. The ..."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 Datasheet",
          "url": "https://www.intel.com/content/www/us/en/content-details/613875/intel-ethernet-controller-e810-datasheet.html",
          "excerpts": [
            "This document describes the external architecture (including device operation, pin descriptions, register definitions, and so on) for the Intel® Ethernet ..."
          ]
        },
        {
          "title": "32. Intel Virtual Function Driver - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-23.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "27. Intel Virtual Function Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-20.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "NVIDIA Mellanox ConnectX-6 Ethernet SmartNIC Data Sheet",
          "url": "https://www.cisco.com/c/dam/en/us/products/collateral/servers-unified-computing/ucs-c-series-rack-servers/nvidia-mellanox-connectx-6-ethernet-smartnic-data-sheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities and supports up to 8 million rules. > Advanced quality of service (QoS)— ..."
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ...",
            "RDMA\n•\niWARP and RoCE v2. •\n256K Queue Pairs (QPs",
            "The E810 fully supports Next Generation VMDq mode and SR-IOV.",
            "irtualization (enhanced SR-IOV \nsupport with up to 256 VFs and backward compatibility VF driver support)"
          ]
        },
        {
          "title": "28. ICE Poll Mode Driver - Documentation",
          "url": "https://doc.dpdk.org/guides/nics/ice.html",
          "excerpts": [
            "The ice PMD (librte_net_ice) provides poll mode driver support for 10/25/50/100/200 Gbps Intel® Ethernet 800 Series Network Adapters based on the following ..."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA2",
          "url": "https://cdrdv2-public.intel.com/641674/Intel%20Ethernet%20Network%20Adapter%20E810-XXVDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA4",
          "url": "https://cdrdv2-public.intel.com/742008/Dell_Intel%20Ethernet%20Network%20Adatper%20E810-XXVDA4.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "How to Reach the Max Bandwidth Speed of a Single RDMA QPS ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000088729/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "The E810s cannot reach the max bandwidth speed of a single RDMA QPS (queue pairs) in either iWARP or RoCEv2 mode.Columbiaville is designed to deliver best ..."
          ]
        },
        {
          "title": "iWARP Throughput Performance Issue on Intel® Ethernet Network ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000059783/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "Intel® Ethernet Network Adapter E810-CQDA2 is designed to deliver best performance using multiple Queue Pairs (QP) hence, it cannot reach maximum bandwidth ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet' s Performance Report with DPDK 22.11",
          "url": "https://fast.dpdk.org/doc/perf/DPDK_22_11_Intel_NIC_performance_report.pdf",
          "excerpts": [
            "Figure 14: ice PMD Single core performance on 2x Intel® Ethernet Network Adapter E810-. QCDA2 with turbo boost comparison. Page 21. Intel ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/613875_E810_Datasheet_Rev2_7-3314030.pdf?srsltid=AfmBOopOVGq1VlDC61e6xt9KhgfHGjfbQA4NBSKRxAMyy195mgxFyoAu",
          "excerpts": [
            "Page 1. Revision 2.7. March 2024. 613875-009. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K ..."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "What is NVMe? | An In-Depth Overview ... - Dell Technologies Info Hub",
          "url": "https://infohub.delltechnologies.com/en-us/l/an-in-depth-overview-of-nvme-and-nvme-of/what-is-nvme/",
          "excerpts": [
            "The current set of NVMe command specifications are: NVMe Command Set Specification, Revision 1.1; NVMe Zoned Namespaces Command Set Specification, Revision 1.2 ..."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "Intel SR-IOV Configuration Guide",
          "url": "https://cdrdv2-public.intel.com/630211/630211_E810%20SR-IOV%20RHEL8%20ConfigGuide_Rev1.2.pdf",
          "excerpts": [
            "Hardware Requirements",
            "ments**\n\n• An Intel <sup>®</sup> Ethernet 800 Series Network Adapter (or other adapter based on an Intel <sup>®</sup> Ethernet 800\n\nSeries Controller).",
            "roller). • A server platform that supports Intel <sup>®</sup> Virtualization Technology for Directed I/O (Intel <sup>®</sup> VT-d) and\n\nthe PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) specification.",
            " • A server platform with an available PCI Express Gen 4.0/3.0 x16 or x8 slot, depending on the\n\nspecific board. **1",
            "Software Requirements",
            "• Red Hat Enterprise Linux Version 8.0 (RHEL 8).",
            ").\n• Intel <sup>®</sup> Ethernet 800 Series Linux Drivers for PF and VF, available at:\n\nhttp://sourceforge.net/projects/e1000/files/\n\nhttp",
            "https://downloadscenter.intel.com",
            "Note:"
          ]
        },
        {
          "title": "Intel Ethernet 800 Series Product Brief",
          "url": "https://gzhls.at/blob/ldb/5/8/6/7/6b497d7cb6eb6fa2fbf214f8c2f7c7a97e22.pdf",
          "excerpts": [
            "\nIntel® Ethernet 800 Series supports up to 100Gb/s throughput for a \nvariety of workloads.",
            "Support both iWARP and RoCEv2 RDMA, selectable via software  \n\nper port for low-latency, high-throughput workloa",
            "Application Device Queues (ADQ) to increase application  \n\npredictability, reduce application latency and improve  \napplication throu",
            " \n\nVFs, 768 VSIs\n",
            "\n\nMove data faster with Intel® Ethernet 800 Series",
            "Intel® Ethernet Controller  \nE810-CAM2/CAM1/XXVAM2"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Performance Characterization of NVMe Flash Devices with ...",
          "url": "https://atlarge-research.com/pdfs/2023-cluster-zns-performance-kdoekemeijer.pdf",
          "excerpts": [
            "by K Doekemeijer · Cited by 18 — We report on the performance features of a commercially available ZNS SSD (13 key observations), explain how these features can be incorpo-.See more"
          ]
        },
        {
          "title": "[HELP] Nvidia GPUDirect storage benchmark for an AI400 ...",
          "url": "https://www.reddit.com/r/HPC/comments/qni6cs/help_nvidia_gpudirect_storage_benchmark_for_an/",
          "excerpts": [
            "We are supposed to benchmark the GPU direct storage performance however I cannot seem to find the appropriate benchmarking tool to use."
          ]
        },
        {
          "title": "Performance evaluation of containers for low-latency ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0166531624000476",
          "excerpts": [
            "por F Wiedner · 2024 · Mencionado por 5 — Our results demonstrate that containers exhibit similar latency performance with more predictable tail-latency behavior than bare metal packet processing."
          ]
        },
        {
          "title": "Benchmark of SPDK · eunomia-bpf/bpftime Wiki",
          "url": "https://github.com/eunomia-bpf/bpftime/wiki/Benchmark-of-SPDK",
          "excerpts": [
            "Nov 20, 2023 — SPDK is a high-performance user space storage application framework. It has its own tracing capability. We have tried to use bpftrace with SPDK, but the ..."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds.",
            " By avoiding intermediate buffers and memory copies, this approach reduces latency by 50–100 nanoseconds per packet—a meaningful gain in HFT systems.",
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "However, zero-copy networking introduces greater development complexity, requiring careful buffer management, error handling, and integration with kernel-level APIs.",
            "The next section integrates these concepts into a practical low-latency architecture.",
            "Practical Design Example: Building a Low-Latency Pipeline",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay."
          ]
        },
        {
          "title": "QNX OS for Safety 8.0",
          "url": "https://blackberry.qnx.com/en/products/safety-certified/qnx-os-for-safety",
          "excerpts": [
            "The QNX OS for Safety is a microkernel OS for embedded systems certified to IEC 61508 SIL 3, ISO 26262 ASIL D and IEC 62304 Class C."
          ]
        },
        {
          "title": "QNX Safety Certifications | ISO 26262, IEC 61508, IEC 62304",
          "url": "https://blackberry.qnx.com/en/developers/certifications",
          "excerpts": [
            "Streamline safety certifications and compliance with embedded software solutions from QNX. Learn more."
          ]
        },
        {
          "title": "Wind River Store - Buy VxWorks, Diab Compiler & More ...",
          "url": "https://www.windriver.com/store",
          "excerpts": [
            "Purchase up to three seats of the world's #1 real-time operating system (RTOS), starting at $19,500 per seat. VxWorks® is a deterministic, priority-based ..."
          ]
        },
        {
          "title": "Linux Licensing Cost - TCO Calculator",
          "url": "https://www.windriver.com/products/linux/tco-calculator",
          "excerpts": [
            "Calculate the costs of building your own embedded Linux product with our TCO Calculator. Find out how market-leading Wind River Linux can save you money!"
          ]
        },
        {
          "title": "AWS Marketplace: QNX OS for Safety 2.2.3",
          "url": "https://aws.amazon.com/marketplace/pp/prodview-26pvihq76slfa",
          "excerpts": [
            "3. Pricing is based on actual usage, with charges varying according to how much you consume."
          ]
        },
        {
          "title": "Green Hills Software: Real-Time Operating Systems (RTOS ...",
          "url": "https://www.ghs.com/",
          "excerpts": [
            "Green Hills Software is the worldwide leader in embedded safety and security. With the most safety and security certifications and the best track record."
          ]
        },
        {
          "title": "QNX Developer License Options",
          "url": "https://blackberry.qnx.com/en/products/qnx-everywhere/licensing",
          "excerpts": [
            "Missing: per unit"
          ]
        },
        {
          "title": "QNX license cost discussion on Reddit",
          "url": "https://www.reddit.com/r/embedded/comments/1e72fip/qnx_license_cost/",
          "excerpts": [
            "There are a few places that are indicating that the dev platform license is ~$15k/yr. QNX license cost? : r/embedded"
          ]
        },
        {
          "title": "What Is DO-178C? - Wind River Systems",
          "url": "https://www.windriver.com/solutions/learning/do-178c",
          "excerpts": [
            "It is the standard that directs software certification for airborne systems for the commercial segment. (Its ramifications for military aerospace will be ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification, is the principal certification document used by certification agencies ..."
          ]
        },
        {
          "title": "Your Complete DO-178C Guide to Aerospace Software Compliance",
          "url": "https://ldra.com/do-178/",
          "excerpts": [
            "DO-178C is a formal process standard that covers the complete software lifecycle – the planning process, development process, and integral processes."
          ]
        },
        {
          "title": "IEC Certification Kit (for ISO 26262 and IEC 61508)",
          "url": "https://www.mathworks.com/products/iec-61508.html",
          "excerpts": [
            "IEC Certification Kit provides tool classification and tool qualification work products, together with templates, certificates, and validation suites."
          ]
        },
        {
          "title": "Tool Qualification Support Package (TQSP)",
          "url": "https://ldra.com/products/tool-qualification-support-packs-tqsp/",
          "excerpts": [
            "A TQSP is an optional module available for the LDRA tool suite. Each TQSP module provides artefacts and guidance to simplify the process of qualifying the LDRA ..."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
          "url": "https://www.lynx.com/challenges/safety-certification",
          "excerpts": [
            "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
            "Delays in certification due to software non-compliance can be costly and de rail project timelines. Lynx empowers teams across industries with modular platforms, pre-certified components, and advanced tools to simplify compliance with DO-178C, ISO 26262, and IEC 61508. Deliver safer, certifiable systems faster and with greater confidence. Seize the Edge with Lynx to achieve 30% faster certification and reduce project complexity.",
            "pre-certified software components",
            "Backed by a track record of successful certifications, LynxSecure and LynxOS-178 deliver DO-178C and FAA RSC compliance while reducing project complexity.",
            "Safety-Critical GPU Solutions",
            "Empower your systems with our certifiable GPU solutions. Achieve high-performance graphics for avionics and automotive applications while maintaining ISO 26262 and DO-178C compliance.",
            "Advanced Vulnerability Management",
            "Ensure system integrity with Vigiles, the industry-leading tool for SBOM-based CVE triage and lifecycle vulnerability management, reducing false positives by 95%.",
            "Certification Consulting Services",
            "Leverage decades of experience in certification-compliant development with expert guidance tailored to DO-178C, ISO 26262, and IEC 61508 projects.",
            "Streamlining DO-178C Certification for Avionics",
            "Our pre-certified components and modular platforms reduce integration complexity and enable seamless compliance with DO-178C DAL A standards.",
            "Ensuring ISO 26262 Compliance in Automotive Systems",
            "ISO 26262 compliance isn’t just a checkbox—it’s the key to safe and reliable ADAS and autonomous systems. Lynx simplifies compliance with certifiable GPU compute solutions and pre-certified software components, ensuring your program stays on track and ahead of the competition.",
            "Streamlining IEC 61508 Certification for Industrial Systems",
            "From robotics to critical infrastructure, Lynx provides the tools to meet IEC 61508 certification requirements.",
            "30% faster certification",
            "Streamline processes and reduce certification timelines with modular pre-certified platforms like LynxSecure and LynxOS-178.",
            "95% Fewer False Positives",
            "Ensure accuracy in vulnerability management with Vigiles, reducing unnecessary manual triage."
          ]
        },
        {
          "title": "AMD Pensando™ DPU Technology",
          "url": "https://www.amd.com/en/products/data-processing-units/pensando.html",
          "excerpts": [
            "The AMD Pensando™ Giglio DPU builds on second-generation architecture with enhanced power and performance efficiency, delivering dual 200 Gbps line-rate offload ..."
          ]
        },
        {
          "title": "Compression Analysis for BlueField-2/-3 Data Processing ...",
          "url": "https://par.nsf.gov/servlets/purl/10538184",
          "excerpts": [
            "by Y Li · 2024 · Cited by 6 — Our study encompasses a comprehensive per- formance analysis of Nvidia BlueField DPUs, specifically focusing on one lossy (SZ34) and three."
          ]
        },
        {
          "title": "Economics And The Inevitability Of The DPU",
          "url": "https://www.nextplatform.com/2022/11/03/economics-and-the-inevitability-of-the-dpu/",
          "excerpts": [
            "Nov 3, 2022 — ... performance of the two ports on the DPU, at 49 Gb/sec. There is an obvious performance benefit, but this is more like getting the performance ..."
          ]
        },
        {
          "title": "Boosting Performance with SPDK and DPDK Solutions - Mirror Review",
          "url": "https://www.mirrorreview.com/spdk-and-dpdk-solutions/",
          "excerpts": [
            "Missing: RustHallows TCO Linux"
          ]
        },
        {
          "title": "Linux Kernel vs DPDK: HTTP Performance Showdown | talawah.io",
          "url": "https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/",
          "excerpts": [
            "Missing: RustHallows competitive"
          ]
        },
        {
          "title": "What is the Cost of a Real-time Operating System (RTOS)?",
          "url": "https://www.lynx.com/embedded-systems-learning-center/cost-of-a-real-time-operating-system-rtos",
          "excerpts": [
            "Generally speaking, purchasing a commercial RTOS will cost about $10K – $20K for the RTOS and one seat of development tools."
          ]
        },
        {
          "title": "RTOS | Wind River Studio",
          "url": "https://www.windriver.com/studio/edge-devices/real-time-os",
          "excerpts": [
            "Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat. Log in or create an account to get ..."
          ]
        },
        {
          "title": "LynxOS-178: Based on Open Standards",
          "url": "https://www.lynx.com/products/lynxos-178-do-178c-certified-posix-rtos",
          "excerpts": [
            "LynxOS-178 is a COTS RTOS supporting x86, Arm, and PowerPC platforms. It is based on open standards and is designed specifically to fulfill the stringent needs ..."
          ]
        },
        {
          "title": "Free Access to QNX SDP 8.0 for Non-Commercial Use",
          "url": "https://www.qnx.com/products/everywhere/",
          "excerpts": [
            "You are now able to get a free QNX SDP 8.0 license for your personal non-commercial use. You must first have a myQNX account which will allow you to access ..."
          ]
        },
        {
          "title": "GreenHills costs what and has Python 2.3? : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/7kw1a3/greenhills_costs_what_and_has_python_23/",
          "excerpts": [
            "GreenHills costs what and has Python 2.3? ... I've mainly used WindRiver's diab and got moved to a certified project. It's my first experience ..."
          ]
        },
        {
          "title": "Licensing Information",
          "url": "http://licensing.qnx.com/info/",
          "excerpts": [
            "This folder contains PDF copies of QNX licensing documents associated with QNX Software Development Platform versions 7.x and 8.0, and associated compatible ..."
          ]
        },
        {
          "title": "VxWorks Reviews in 2025",
          "url": "https://sourceforge.net/software/product/VxWorks/",
          "excerpts": [
            "$18,500 / seat. Pricing Details: Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat."
          ]
        },
        {
          "title": "ISO 26262 Functional Safety Training & Certification Program",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/36-34-20-0006",
          "excerpts": [
            "Course Agenda. The certified Functional Safety according to ISO 26262 is a training spanned across 4 and a half days comprising of the following: Day 1 - ..."
          ]
        },
        {
          "title": "IEC 61508: A comprehensive guide to functional safety ...",
          "url": "https://spyro-soft.com/blog/industry-4-0/iec-61508",
          "excerpts": [
            "SIL 3: High level of safety integrity, with a significantly lower probability of failure than SIL 2. SIL 4: Highest level of safety integrity, ..."
          ]
        },
        {
          "title": "VxWorks Safety Platforms - Wind River Systems",
          "url": "https://www.windriver.com/products/vxworks/safety-platforms",
          "excerpts": [
            "An RTOS platform for safety-critical applications that require DO-178C, IEC 61508, or ISO 26262 certification evidence in the avionics, transportation, ..."
          ]
        },
        {
          "title": "DO-178C Explained",
          "url": "https://consunova.com/do-178c-explained/",
          "excerpts": [
            "Mar 31, 2024 — DO-178C defines five levels (A, B, C, D, and E) to classify the criticality of software functions based on their potential impact on aircraft ..."
          ]
        },
        {
          "title": "Guidance on Using IEC 61508 SIL Certification to Support ...",
          "url": "https://www.nrc.gov/docs/ML2130/ML21305A001.pdf",
          "excerpts": [
            "The SIL certification process involves manufacturers seeking compliance with IEC 61508, a separate entity called the CB that reviews the ..."
          ]
        },
        {
          "title": "How developers can leverage RTOS functional safety certification",
          "url": "https://www.embedded.com/how-developers-can-leverage-rtos-functional-safety-certification/",
          "excerpts": [
            "RTOS functional safety certification benefits not only safety-critical devices but all embedded devices as a means to improve time-to-market ..."
          ]
        },
        {
          "title": "How to get started with iso 26262 as a firmware developer?",
          "url": "https://www.reddit.com/r/embedded/comments/14icplp/how_to_get_started_with_iso_26262_as_a_firmware/",
          "excerpts": [
            "Your first step at estimating cost is to get a static analysis tool and find out how many warnings there are in your code base, and writing up a ..."
          ]
        },
        {
          "title": "Low Latency 5G UPF Using Priority Based Packet Classification",
          "url": "https://builders.intel.com/docs/networkbuilders/low-latency-5g-upf-using-priority-based-5g-packet-classification.pdf",
          "excerpts": [
            "SA UPF, developed by Intel and SK Telecom, shows improved performance in latency and jitter for high priority traffic while still running.",
            "Foundational NICs do not \ntypically offer offloads for functions \nsuch as vSwitch acceleration, VXLAN \nTEP or inline IPS",
            "They do, however, \noffer advanced features in order to \nscale the VNF performance by \noptimizing packet steering in the \nser",
            "Dynamic Device Personalization (DDP) \nis a capability that was introduced with \nIntel® Ethernet 700 Series Network \nAdapters to load an additional package \nto enable classification and steering of \nadditional specified packet types and \nperformance of additional inline \nact",
            "DDP can be used to optimize \npacket processing performance for \ndifferent network functions, native or \nrunning in a virtual environme",
            "By \napplying a DDP profile to the network \ncontroller the following use cases can \nbe address",
            "Extended support for protocols:\n\n• 5G GTP support for 5G user plane.",
            "• 5G SDAP/PDCP support for 5G NR\nuser plane.",
            "• 5G/4G PFCP (CP-UP separation)\nsupport.",
            "• IP protocols as new flow types, for\nexample L2TPv3, ESP/AH for\nIPSec.",
            "• Legacy protocols: PPPoE,\nPPPoL2TPv2.",
            "• New protocols/standards: eCPRI/\nORAN, Radio over Ethernet (RoE).",
            "• Extensibility for custom protocol\nparsing/classification.",
            "The Intel® Ethernet 800 Series provides \nthe capability to steer packets of \ndifferent priority into specific queue \ngroups as described in Figure 5",
            "software receiving and processing \n\npackets must be aware of the receive \nqueue priority mechanism to enable the \nefficient handling of high priority \npackets",
            "The User Plane Function (UPF) \napplication used in the context of this \nwork is based on the FD.io Vector Packet \nProcessor (VPP) framewo",
            "This \nframework utilizes Data Plane \nDevelopment Kit (DPDK) functionality to \nfetch received packets from the NIC \nqueues and deliver them for further \nproces",
            "The DPDK plugin is a part of \nthe VPP project that exposes packet \nreceive functionality over the dpdk-input \nno",
            "Default implementation of the \ndpdk-input node enables handling of \nmultiple RX queues in the context of a \nsingle worker thre",
            "re 6 implements \nstrict priority logic where packets from \nhigher priority queues are always \nfetched first and next priority queues \nare not served until all packets from \nhigh priority queues are in the \nprocessing stage."
          ]
        },
        {
          "title": "DOCA Perftest RDMA benchmarking tool",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Perftest/index.html",
          "excerpts": [
            "DOCA Perftest is an RDMA benchmarking tool designed for compute clusters, enabling fine-tuned evaluation of bandwidth, message rate, and latency. [Dependencies](.DOCAPerftestv3.0.0-Dependencies)",
            "  + CUDA 12.8 or later, required for GPUDirect RDMA benchmarks"
          ]
        },
        {
          "title": "DOCA Accelerated UPF Reference Application Guide",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Accelerated+UPF+Reference+Application+Guide/index.html",
          "excerpts": [
            "The Accelerated UPF-RAP provides a reference implementation of an accelerated data path of UPF on top of the NVIDIA® BlueField-3®. Tas",
            "Tasks like GTP-U encapsulation/decapsulation, flow tagging, QoS enforcement, and packet forwarding are handled by the NIC, providing deterministic performance and scalability.",
            "Subsequent packets of that flow will be fully processed by Bluefiled-3 HW and forward to their destination without going through the host/UPF-RAP."
          ]
        },
        {
          "title": "performance | microkerneldude",
          "url": "https://microkerneldude.org/tag/performance/",
          "excerpts": [
            "And that means verified seL4 outperforms any microkernel. In almost all cases that's by about a factor of 10 in IPC latency. The closest in ..."
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "I'm Not Dead Yet!: The Role of the Operating System in a Kernel ...",
          "url": "https://dl.acm.org/doi/10.1145/3317550.3321422",
          "excerpts": [
            "This paper argues for a new high-level, device-agnostic I/O abstraction for kernel-bypass devices. We propose the Demikernel, a new library OS architecture for ..."
          ]
        },
        {
          "title": "seL4 Formal Verification Paper (SOSP 2009)",
          "url": "https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf",
          "excerpts": [
            ", is a third-generation\n\nmicrokernel, and is broadly based on L4 [46] and  \ninfluenced by EROS [58].",
            "Complete formal verification is the only known way to guarantee that a system is free of programming errors.",
            "ts. We present seL4, a member of the L4 [46] microker-\n\nnel family, designed to provide this ultimate degree  \nof assurance of functional correctness by machine-  \nassisted and machine-checked formal proof.",
            "e  \nshown the correctness of a very detailed, low-level  \ndesign of seL4 and we have formally verified its C  \nimplementation.",
            "To our knowledge, seL4 is the first-ever general-\n\npurpose OS kernel that is fully formally verified for  \nfunctional correctn"
          ]
        },
        {
          "title": "avionics application software standard interface part 0 overview of ...",
          "url": "https://www.sae.org/standards/content/arinc653p0-3/",
          "excerpts": [
            "The primary objective of ARINC 653 is to define a general-purpose APplication/EXecutive (APEX) interface (API = Application Program Interface)"
          ]
        },
        {
          "title": "[PDF] ARINC-653 Inter-partition Communications and the Ravenscar Profile",
          "url": "https://oa.upm.es/42418/1/INVE_MEM_2015_228287.pdf",
          "excerpts": [
            "The ARINC-653 standard [1] defines an inter-partition communication (IPC) mechanism that can be used to exchange messages between ARINC partitions running on ..."
          ]
        },
        {
          "title": "[PDF] ARINC 653",
          "url": "http://retis.sssup.it/~giorgio/slides/cbsd/cbsd-arinc-2p.pdf",
          "excerpts": [
            "ARINC 653 Services. ➢ Inter-partition communication. ▫ Communication between two or more partitions via messages;. ▫ Two types of communication services are ..."
          ]
        },
        {
          "title": "ARINC 653 on PikeOS - SYSGO",
          "url": "https://www.sysgo.com/arinc-653",
          "excerpts": [
            "The ARINC 653 standard specifies an operational environment for application software used in Integrated Modular Avionics (IMA) modules."
          ]
        },
        {
          "title": "avionics application software standard interface part 1 required ...",
          "url": "https://www.sae.org/standards/content/arinc653p1-5/",
          "excerpts": [
            "This standard defines a general-purpose Application/Executive (APEX) software interface between the Operating System of an avionics computer ..."
          ]
        },
        {
          "title": "[PDF] Using IOMMU for DMA Protection in UEFI Firmware - Intel",
          "url": "https://www.intel.com/content/dam/develop/external/us/en/documents/intel-whitepaper-using-iommu-for-dma-protection-in-uefi-820238.pdf",
          "excerpts": [
            "This paper proposes using IOMMU to resist DMA attacks in firmware, where bus mastering can allow malicious devices to access system memory."
          ]
        },
        {
          "title": "Single Root IO Virtualization (SR-IOV)",
          "url": "https://docs.nvidia.com/networking/display/OFED/Single+Root+IO+Virtualization+(SR-IOV)",
          "excerpts": [
            "Feb 29, 2024 — Single Root IO Virtualization (SR-IOV) is a technology that allows a physical PCIe device to present itself multiple times through the PCIe bus."
          ]
        },
        {
          "title": "IOMMU DMA Remapping - Windows drivers - Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/display/iommu-dma-remapping",
          "excerpts": [
            "IOMMU DMA remapping allows the GPU to access memory through logical addresses that are no longer mapped 1:1. Instead, Dxgkrnl is able to provide logically ..."
          ]
        },
        {
          "title": "Is it possible SR-IOV inside VM? : r/VFIO",
          "url": "https://www.reddit.com/r/VFIO/comments/1emladg/is_it_possible_sriov_inside_vm/",
          "excerpts": [
            "I have a Broadcom NIC with SR-IOV support and would like to create VFs inside the VM, i.e. pass PF to the VM with SR-IOV enabled."
          ]
        },
        {
          "title": "Kernel DMA Protection | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/kernel-dma-protection-for-thunderbolt",
          "excerpts": [
            "Learn how Kernel DMA Protection protects Windows devices against drive-by Direct Memory Access (DMA) attacks using PCI hot plug devices."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "Key Benefits of io_uring. Reduced Overhead: Batched submissions and completions cut system calls drastically.",
            "Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir )",
            "Completion Queue (CQ) : The kernel posts results as Completion Queue Entries (CQEs).",
            "scribe\nThis design minimizes system calls and context switches. Instead of invoking a syscall per operation, the kernel polls the SQ for new entries, while user space checks the CQ for completions — enabling true asynchronous processing.",
            "Key Benefits of io_uring",
            "* Reduced Overhead : Batched submissions and completions cut system calls drastically.",
            "* Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir ).",
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency.",
            "* Ease of Use : The\nliburing library simplifies setup and management."
          ]
        },
        {
          "title": "Put an io_uring on it - Exploiting the Linux Kernel",
          "url": "https://chomp.ie/Blog+Posts/Put+an+io_uring+on+it+-+Exploiting+the+Linux+Kernel",
          "excerpts": [
            "It can be particularly useful for applications that are server/backend related, where a significant proportion of the application time is spent waiting on I/O."
          ]
        },
        {
          "title": "The IOMMU Impact - I/O Memory Management Units",
          "url": "https://medium.com/@mike.anderson007/the-iommu-impact-i-o-memory-management-units-feb7ea95b819",
          "excerpts": [
            "The IOMMU serves as a hardware abstraction layer that provides device isolation, memory protection, and address translation, much like how a traditional Memory Management Unit (MMU) governs virtual memory for CPUs.",
            "IOMMUs abstract this dependency by allowing devices to use I/O virtual addresses.",
            "IOMMU enforces **isolation** between devices and memory regions, a critical security feat",
            "In systems without an IOMMU, a misbehaving or compromised device could write to arbitrary memory regions, leading to system crashes, data leaks, or privilege escalation.",
            "These faults are invaluable for debugging DMA-related issues and for building **resilient systems** that can withstand partial hardware or software failures without complete system cras",
            "SR-IOV takes this a step further by allowing a single physical device to expose multiple **Virtual Functions (VFs)** — lightweight virtual devices that can be independently assigned to different ",
            "Intel VT-d",
            "AMD-Vi (IOMMU)",
            "ARM’s equivalent is the **System Memory Management Unit (SMM",
            "M’s SMMU enables secure execution environments, supporting trusted execution, real-time processing, and virtualization on low-power hardware.",
            "While IOMMUs introduce security and flexibility, they can also add **latency** to I/O operations due to address translation overhead. To mitigate this, modern IOMMUs use **Translation Lookaside Buffers (IOTLBs)** to cache recent address mappings, much like C"
          ]
        },
        {
          "title": "Design Guidelines for High Performance RDMA Systems",
          "url": "https://www.usenix.org/system/files/login/articles/login_fall16_07_kalia.pdf",
          "excerpts": [
            "Queue pairs: RDMA hosts communicate by posting verbs to interfaces called queue pairs (QPs). On completing a verb, the requester's NIC optionally signals ..."
          ]
        },
        {
          "title": "Planning for GPUDirect Storage - IBM",
          "url": "https://www.ibm.com/docs/en/storage-scale/5.2.1?topic=considerations-planning-gpudirect-storage",
          "excerpts": [
            "Supported hardware · GDS clients: x86 with a GPU model that supports GDS. For more details, see NVIDIA GDS documentation. · Network: EDR or HDR InfiniBand, ..."
          ]
        },
        {
          "title": "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified!",
          "url": "https://www.reddit.com/r/rust/comments/17qi9v0/its_official_ferrocene_is_iso_26262_and_iec_61508/",
          "excerpts": [
            "Ferrocene is upstream rustc but with some extra targets, long term support, and qualifications so you can use them in safety critical contexts."
          ]
        },
        {
          "title": "ECDSA Attestation with Intel Software Guard Extensions ...",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/quote-verification-attestation-with-intel-sgx-dcap.html",
          "excerpts": [
            "In this article, we'll demonstrate a remote attestation using the sample code from the Intel SGX DCAP source code repository."
          ]
        },
        {
          "title": "Arrakis: The Operating System Is the Control Plane",
          "url": "https://dl.acm.org/doi/10.1145/2812806",
          "excerpts": [
            "We have designed and implemented a new operating system, Arrakis, that splits the traditional role of the kernel in two."
          ]
        },
        {
          "title": "IX: A Protected Dataplane Operating System for High ...",
          "url": "https://web.eecs.umich.edu/~sugih/courses/eecs589/f16/39-ChunYu+Xinghao.pdf",
          "excerpts": [
            "by A Belay · Cited by 629 — In this paper, the authors introduce a new approach to improve the throughput and reduce the latency with a customized dataplane operating system, called IX ..."
          ]
        }
      ],
      "reasoning": "RustHallows aims to achieve 10-40x performance improvements by fundamentally re-architecting the OS. This is achieved by moving I/O-intensive fast paths for networking, storage, and GPU data loading out of the kernel and into user space. This 'kernel bypass' approach is inspired by systems like Arrakis, IX, DPDK, and SPDK. For instance, Arrakis is designed to limit or remove kernel mediation for most I/O operations, routing requests to and from the application's address space without kernel involvement, while maintaining security and isolation. IX also separates the control plane from the dataplanes, running networking stacks and applications as protected, library-based operating systems on dedicated hardware. DPDK provides a framework for fast packet processing in user space, emphasizing zero-copy and direct access to network interfaces. SPDK moves drivers into user space, avoiding system calls and enabling zero-copy access by polling hardware for completion instead of using interrupts, which eliminates kernel context switches and interrupt handling overhead. These techniques drastically reduce overhead from system calls, context switches, and data copies. For example, Arrakis/N reduces server-side overhead to 0.38 µs, 57% less than Linux, and achieves 3.9x the throughput of Linux. SPDK can achieve over 10 million IOPS using a single CPU core and scales linearly with additional cores, reaching 120 million IOPS at 25.56 microseconds average latency with 12 cores. GPUDirect Storage (GDS) enables a direct data path for DMA transfers between GPU memory and storage, avoiding a bounce buffer through the CPU, which increases system bandwidth and decreases latency and CPU utilization. This direct path is supported for NVMe devices and RDMA. The aggressive optimizations are made safe and practical through a formally verified, capability-based microkernel (Ministry of Magic) inspired by seL4. seL4 is a microkernel designed for generality while minimizing the Trusted Computing Base (TCB) and provides fine-grained access control through capabilities. It is formally verified for functional correctness, integrity, and confidentiality, and its proofs establish the absence of many common programming errors. This provides provable isolation between components, ensuring that a bug in a user-space driver cannot compromise the rest of the system. The use of Rust provides memory safety and a clear path to formal certification, as demonstrated by Ferrocene, a qualified Rust toolchain for safety-critical systems (ISO 26262 ASIL D, IEC 61508 SIL 4, and IEC 62304 Class C). This unique combination allows RustHallows to offer the raw performance of specialized hardware appliances with the flexibility of software, all while preserving memory safety and certifiability, a feat unattainable with conventional OS architectures like Linux.",
      "confidence": "high"
    },
    {
      "field": "gpu_and_accelerator_components",
      "citations": [
        {
          "title": "1. Overview — GPUDirect RDMA 13.0 documentation",
          "url": "https://docs.nvidia.com/cuda/gpudirect-rdma/",
          "excerpts": [
            "Missing: deterministic quiescence ring cursor NVMe",
            "Developing a Linux Kernel Module using GPUDirect RDMA. The API reference guide for enabling GPUDirect RDMA connections to NVIDIA GPUs."
          ]
        },
        {
          "title": "GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html",
          "excerpts": [
            " Linux has added support for PCI P2PDMA in Linux kernel version 6.2 and above kernels, enabling `ZONE_DEVICE` address pointers to GPU memory to be passed through the VFS without causing a page fault, in the case of NVMe, `nvidia-fs.ko`",
            "cuFileRead",
            "cuFileBuf(Registe",
            "Check whether the DMA target address is on the GPU ( nvfs_is_gpu_page ) and needs to be handled differently. ... nvidia-fs.ko. The cuFile APIs and their ... POSIX pread and pwrite require buffers\nin CPU system memory and an extra copy, but cuFile read and write only requires file handle registration. This code sample uses the POSIX API",
            "The cuFile library, `libcufile.so` , services those calls and makes appropriate IOCTL calls to the `nvidia-fs.ko` driver.",
            " Explicit data transfers between storage and GPU memory, which closely mimic POSIX `pread` and `pwrite` . * \n  Performing IO in a CUDA stream, so that it is both async and ordered relative to the other commands in that same stream. The direct data path that GDS provides relies on the availability of file system drivers that are enabled with\nGDS. These drivers run on the CPU and implement the control path that sets up the direct data path. ### 1\\.2.2.",
            "int fd = open(...)\nvoid *sysmem_buf, *gpumem_buf;\nsysmem_buf = malloc(buf_size);\ncudaMalloc(gpumem_buf, buf_size);\npread(fd, sysmem_buf, buf_size);\ncudaMemcpy(sysmem_buf,\n           gpumem_buf, buf_size, H2D);\ncuStreamSynchronize(0);\ndoit<<<gpumem_buf, ...>>>\n"
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "cuFile Compatibility Mode - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/cuda/archive/11.4.0/gds/api-reference-guide/topics/cufile-compatibility.html",
          "excerpts": [
            "The cuFile library provides a mechanism for cuFile reads and writes to use compatibility mode using POSIX pread and pwrite APIS respectively to system memory ..."
          ]
        },
        {
          "title": "PCI Peer-to-Peer DMA Support",
          "url": "https://docs.kernel.org/driver-api/pci/p2pdma.html",
          "excerpts": [
            "The NVMe PCI driver is both a client, provider and orchestrator in that it exposes any CMB (Controller Memory Buffer) as a P2P memory resource (provider), it ..."
          ]
        },
        {
          "title": "ROCK-Kernel-Driver/include/drm/amd_rdma.h at master - GitHub",
          "url": "https://github.com/RadeonOpenCompute/ROCK-Kernel-Driver/blob/master/include/drm/amd_rdma.h",
          "excerpts": [
            "* to specific location of GPU memory */ struct amd_rdma_interface { int (*get_pages)( ... (*put_pages)(struct amd_p2p_info **amd_p2p_data); int ..."
          ]
        },
        {
          "title": "Multi-node network configuration for AMD Instinct ...",
          "url": "https://instinct.docs.amd.com/projects/gpu-cluster-networking/en/latest/how-to/multi-node-config.html",
          "excerpts": [
            "ROCm™ Docs · Support · Instinct ... Used to define the maximum level of distance between a GPU and NIC at which GPU Direct RDMA/PeerDirect should be used."
          ]
        },
        {
          "title": "HowTo Implement PeerDirect Client using MLNX_OFED",
          "url": "https://enterprise-support.nvidia.com/s/article/howto-implement-peerdirect-client-using-mlnx-ofed",
          "excerpts": [
            "The AMD ROCnRDMA module provides PeerDirect support for AMD GPUs as part of the ROCm project. Peer Memory Registration/Deregistration. Memory Regions (MRs) are ..."
          ]
        },
        {
          "title": "GDS cuFile API",
          "url": "https://training.continuumlabs.ai/infrastructure/storage/introduction-to-nvidia-gpudirect-storage-gds/gds-cufile-api",
          "excerpts": [
            "Jun 27, 2024 — The cuFile APIs are most effective in scenarios where there is a need for high-performance data transfer between GPU memory and storage."
          ]
        },
        {
          "title": "Pinning GPU memory for RDMA failed",
          "url": "https://forums.developer.nvidia.com/t/pinning-gpu-memory-for-rdma-failed/209545",
          "excerpts": [
            "Mar 28, 2022 — I am using ibverbs API. I passed a buffer on the GPU-memory (allocated by cudaMalloc) to the function ibv_reg_mr and it failed to register the ..."
          ]
        },
        {
          "title": "Does CX6 support ATS and PRS(Page Request Service)?",
          "url": "https://forums.developer.nvidia.com/t/does-cx6-support-ats-and-prs-page-request-service/290546",
          "excerpts": [
            "Check that it worked: “sudo lspci -s -vvv | grep -I ats”. If you see ATS with +, its enabled. GPU direct with RDMA will use ATS. Thank you"
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "The cuFile configuration settings in GDS are stored in the /etc/cufile.json file. Edit the file for best performance for your application as shown below.",
            "GPU buffers need to be exposed to third-party devices to enable DMA by those devices. The set of pages that\nspan those buffers in the GPU virtual address space need to be mapped to the Base Address Register (BAR) space,\nand this mapping is an overhead. The mechanism to accomplish this mapping is called registration. Explicit GPU buffer registration with the `cuFileBufRegister` API is optional.",
            "If a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer. The following table and IO pattern descriptions provide guidance on whether registration is profitable.",
            "In compatibility mode, an additional file descriptor can be opened on the file without requiring `O_DIRECT` mode. This mode can also handle unaligned reads/writes, even when POSIX cannot.",
            "`cuFileBufRegister` API is optional.\nIf a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer.",
            "This example demonstrates the usage of `cuFileRead` / `cuFileWrite` APIs without using the `cuFileBufRegister` and `cuFileBufDeRegister` APIs.",
            "Although semantically correct, this loop might not be optimal. Internally, GDS uses GPU bounce buffers to perform IOs. Bounce buffers are GPU memory allocations that\nare internal to GDS, and these buffers are registered and managed by the GDS library.",
            "The IO-Pattern - 3 code snippet is the same as the [IO Pattern 1]() and [IO Pattern 2]() code snippets but the `cuFileBufRegister` API is not used.",
            "In the above example, the initialization of `file_offset` is on line 10. 1. After allocating 1 GB of GPU memory, `cuFileBufRegister` is immediately invoked for the entire\n   range of 1 GB as seen on line 15. 2. Fill the entire 1 GB GPU memory by reading 100 MB at a time from file as seen in the following lo",
            "This example demonstrates using `cuFileRead` / `cuFileWrite` when IO is unaligned. The `devPtr_base + devPtr_offset` that are issued to `cuFileRead` or `cuFileWrite` are not 4K aligned. If the IO is unaligned, the cuFile library will issue IO through its internal GPU bounce buffer\ncache. However, if the allocation of the internal cache fails, the IO will fail. To avoid IO failure in this\ncase, you can set `allow_compat_mode` to `true` in the `/etc/cufile.json` file.",
            "Before you install GDS, you must disable IOMMU. Refer to Installing GPUDirect Storage for more information. Note. To determine whether the IOMMU setting is ..."
          ]
        },
        {
          "title": "LWN - Peer-to-peer DMA",
          "url": "https://lwn.net/Articles/931668/",
          "excerpts": [
            "Peer-to-peer DMA",
            "The idea is to\nremove the host system's participation in a transfer of data from one\nPCIe-connected device to another.",
            "The feature was originally aimed at NVMe\nSSDs so that data could simply be copied directly to and from the storage\ndevice without needing to move it to system memory and then from\nthere to somewhere else.",
            "P2PDMA is available in the NVMe driver but only devices\nthat have a CMB can be a DMA source or destination.",
            "NVMe devices are the\nonly systems currently supported as DMA masters as well.",
            "The IOMMU can also play a safeguard\nrole to ensure that errant DMA operations are not actually performed.",
            "The amdgpu/amdkfd driver has supported PCIe P2PDMA between AMD GPUs since 6.0."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky · Cited by 417 — In this paper, we show that a general- purpose RPC library called eRPC can provide state-of-the-art performance on commodity datacenter networks without."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kalia",
          "excerpts": [
            "by A Kalia · 2019 · Cited by 417 — eRPC is a new general-purpose remote procedure call (RPC) library that offers performance comparable to specialized systems, while running on commodity CPUs."
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        },
        {
          "title": "[PDF] FaRM: Fast Remote Memory - USENIX",
          "url": "https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-dragojevic.pdf",
          "excerpts": [
            "FaRM uses one-sided RDMA reads to access data di- rectly and it uses RDMA writes to implement a fast message passing primitive. This ...",
            "by A Dragojević · 2014 · Cited by 1162 — It achieves low latency and high throughput because it bypasses the kernel, avoids the overheads of complex protocol stacks, and performs re-.See more"
          ]
        },
        {
          "title": "[PDF] FaSST: Fast, Scalable and Simple Distributed Transactions with Two ...",
          "url": "https://www.usenix.org/system/files/conference/osdi16/osdi16-kalia.pdf",
          "excerpts": [
            "RPCs involve the remote CPU in message processing and are more flexible than one-sided. RDMA, allowing data access in a single round trip [15]."
          ]
        },
        {
          "title": "picoquic with support for DPDK (work in progress) - GitHub",
          "url": "https://github.com/IPNetworkingLab/picoquic-dpdk",
          "excerpts": [
            "This is a version of PICOQUIC with support for DPDK, which provides better performance by bypassing the kernel networking stack."
          ]
        },
        {
          "title": "Towards Zero-Copy Serialization with NIC Scatter-Gather",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s10-raghavan.pdf",
          "excerpts": [
            "by D Raghavan · 2021 · Cited by 46 — We use a minimal UDP networking stack for DPDK based on LWIP [7]. We show the results in Figure 2. The “No Serialization” line removes ..."
          ]
        },
        {
          "title": "Efficient Remote Procedure Calls for Datacenters",
          "url": "https://www.pdl.cmu.edu/PDL-FTP/CloudComputing/CMU-CS-19-126.pdf",
          "excerpts": [
            "by A Kalia · 2019 — Currently, eRPC is primarily optimized for Mellanox NICs. eRPC also works with DPDK- capable NICs that support flow steering. For Mellanox Ethernet NICs, we ..."
          ]
        },
        {
          "title": "Datacenter RPCs Can Be General and Fast",
          "url": "https://www.usenix.org/system/files/login/articles/login_summer19_05_kalia.pdf",
          "excerpts": [
            "by D Andersen — eRPC is implemented in 6200 SLOC of C++, excluding tests and benchmarks. We evaluated eRPC's performance both in micro- benchmarks and real applications."
          ]
        },
        {
          "title": "Lecture 3: RPC",
          "url": "https://courses.cs.washington.edu/courses/cse452/22wi/lecture/L3/",
          "excerpts": [
            "Three options for RPC semantics: At least once (NFS, DNS, lab 1b); At most once (common, lab 1c); Exactly once. RPC Semantics.See more"
          ]
        },
        {
          "title": "at-most-once and exactly-once - rpc",
          "url": "https://stackoverflow.com/questions/13566869/at-most-once-and-exactly-once",
          "excerpts": [
            "Exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times).See more"
          ]
        },
        {
          "title": "Exploiting Commutativity For Practical Fast Replication",
          "url": "https://www.usenix.org/system/files/nsdi19-park.pdf",
          "excerpts": [
            "by SJ Park · 2019 · Cited by 61 — To avoid duplicate executions of the requests that are already replicated to backups, CURP relies on exactly-once semantics provided by RIFL [20] ..."
          ]
        },
        {
          "title": "Logical Physical Clocks and Consistent Snapshots in Globally ...",
          "url": "https://cse.buffalo.edu/tech-reports/2014-04.pdf",
          "excerpts": [
            "In this paper, we introduced the hybrid logical clocks. (HLC) that combines the benefits of logical clocks (LC) and physical time (PT) while overcoming their ..."
          ]
        },
        {
          "title": "Hybrid Logical Clock (HLC)",
          "url": "https://sergeiturukin.com/2017/06/26/hybrid-logical-clocks.html",
          "excerpts": [
            "HLC combines the benefits of logical clocks (LC) and physical time (PT) while overcoming their shortcomings."
          ]
        },
        {
          "title": "Balance Performance in MsQuic and XDP",
          "url": "https://techcommunity.microsoft.com/t5/networking-blog/balance-performance-in-msquic-and-xdp/ba-p/3627665",
          "excerpts": [
            "Sep 16, 2022 — We look at two performance metrics here: Our goal is to get as low as possible latency while maintaining the highest RPS."
          ]
        },
        {
          "title": "Open-sourcing mvfst-rl, a research platform for managing ...",
          "url": "https://ai.meta.com/blog/open-sourcing-mvfst-rl-a-research-platform-for-managing-network-congestion-with-reinforcement-learning/",
          "excerpts": [
            "Oct 14, 2019 — Mvfst-rl implements congestion control with an asynchronous RL agent, making the training environment more realistic for real-world deployment."
          ]
        },
        {
          "title": "mvfst/quic/state/StateData.h at main",
          "url": "https://github.com/facebookincubator/mvfst/blob/master/quic/state/StateData.h",
          "excerpts": [
            "An implementation of the QUIC transport protocol. Contribute to facebook/mvfst development by creating an account on GitHub."
          ]
        },
        {
          "title": "MsQuic Performance Dashboard - Microsoft Open Source",
          "url": "https://microsoft.github.io/msquic/",
          "excerpts": [
            "MsQuic performance tests have standardized on the draft-banks-quic-performance specification for all scenarios, and are implemented in the MsQuic tool ..."
          ]
        },
        {
          "title": "picoquic-dpdk/README.picoquic.md at main - GitHub",
          "url": "https://github.com/IPNetworkingLab/picoquic-dpdk/blob/main/README.picoquic.md",
          "excerpts": [
            "Picoquic is currently developed as a Visual Studio 2017 project, and simultaneously tested on Windows and on Linux. It has a dependency on the Picotls ..."
          ]
        },
        {
          "title": "Understanding QUIC's Throughput Speedbumps",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3744200.3744780",
          "excerpts": [
            "by S Mukherjee · 2025 — Moreover, kernel-bypass stacks have even higher throughput than the Linux UDP stack. • Crypto:This stage keeps track of all crypto metadata ...See more"
          ]
        },
        {
          "title": "QUIC for the kernel",
          "url": "https://news.ycombinator.com/item?id=44746948",
          "excerpts": [
            "Jul 31, 2025 — This could be achieved by encapsulating TCP in UDP and running a custom TCP stack in userspace on the client. That would allow protocol ...See more"
          ]
        },
        {
          "title": "RPCValet: NI-Driven Tail-Aware Balancing of μs-Scale RPCs",
          "url": "https://faculty.cc.gatech.edu/~adaglis3/files/papers/RPCValet_asplos19.pdf",
          "excerpts": [
            "RPCValet, an NI-driven dynamic load-balancing design\nthat outperforms existing hardware mechanisms for load\ndistribution, and approaches the theoretical maximum\nperformance predicted by queuing models.",
            "Hardware and protocol extensions to soNUMA for na-\ntive messaging support, a required feature for efficient\nRPC handlin",
            "We distinguish RPCValet from\nthese software-only systems by our focus on balancing the\nload of incoming RPCs across the CPU cores.",
            "An RPCValet implementation on soNUMA that delivers\nnear-ideal RPC throughput under strict SLOs, attaining\nwithin 3–16% of the theoretically optimal queuing model.",
            "For µs-scale RPCs, RPCValet outperforms software-based\nand RSS-like hardware-driven load distribution by 2.3–\n2.7× and 29–76%, respectively",
            "RPCValet performs within 3–15% of the ideal single-\nqueue system and significantly outperforms current RPC\nload-balancing approaches",
            "To lower communication overheads and tighten tail la-\ntency, there has been an intensive evolution effort in data-\ncenter-scale networking hardware and software, away from\ntraditional POSIX sockets and TCP/IP and towards lean user-\nlevel protocols such as InfiniBand/RDMA [21] or dataplanes\nsuch as IX a"
          ]
        },
        {
          "title": "RIFL: Reusable Infrastructure for Linearizability (Stanford paper)",
          "url": "https://web.stanford.edu/~ouster/cgi-bin/papers/rifl.pdf",
          "excerpts": [
            "In this paper we describe RIFL (Reusable Infrastruc-\nture for Linearizability), which is a mechanism for ensur-\ning “exactly-once semantics” in large-scale syst",
            "RIFL\nrecords the results of completed remote procedure calls\n(RPCs) durably; if an RPC is retried after it has completed,\nRIFL ensures that the correct result is returned without re-\nexecuting the RPC",
            "RIFL provides a\ngeneral-purpose mechanism for converting at-least-once\nRPC semantics to exactly-once semantics, thereby mak-\ning it easy to turn non-linearizable operations into lineariz-\nable ones.",
            "RAMCloud has several properties that make it an\nattractive target for RIFL. It is already designed for large\nscale and it offers low latency (small remote reads take\n4.7 µs end to end, small durable writes take 13.5 µs);",
            "[8], which have end-to-end RPC times as low as\n5 µs.\n ... \nThese systems offer latencies as\nlow as 5 µs end-to-end for remote operations; the overheads\nintroduced by RIFL must not significantly impact these la-\ntencies. For examp",
            "FaRM [8], which have end-to-end RPC times as low as\n5 µs."
          ]
        },
        {
          "title": "RIFL exactly-once semantics and deduplication mechanisms",
          "url": "https://www.cncf.io/blog/2024/01/19/xline-command-deduplication-mechanism-part-one-introduction-to-rifl/",
          "excerpts": [
            "When the system implements this deduplication mechanism, it can realize exactly-once semantics of command execution, and thus realize a higher ...",
            " The RIFL paper mentions that servers can cache the expiration time of a client\\_id lease and query the Lease Manager only as it nears expiration, reducing network communication.",
            " In the aforementioned processes, either checkDuplicate or processAck involves at least one O(n) complexity operation (either checking duplicates in sequenceNumber order or filtering unordered sequenceNumbers but needing to traverse and filter those less than first\\_incomplete for processAck).",
            "Compared to the O(1) complexity of the previous IndexSet approach, RIFL incurs some additional overhead.",
            "Performance can be optimized by making processAck a separate RPC to notify the server to recycle completion records."
          ]
        },
        {
          "title": "Kernel-bypass network stacks performance (USENIX ATC 2025, Awamoto)",
          "url": "https://www.usenix.org/system/files/atc25-awamoto.pdf",
          "excerpts": [
            "\nDemikernel, which achieves 13 µs , the lowest among all the\n\nstacks we test."
          ]
        },
        {
          "title": "arXiv:2505.14358 - Latency-Aware Networking for Ultra-Low-Latency RPCs",
          "url": "https://arxiv.org/html/2505.14358v1",
          "excerpts": [
            "Pirate accurately estimates response latencies over an encrypted transport (mvfst QUIC [31] ).",
            "Figure 9 compares the accuracy of Pirate against\nthe ground truth response latency and the\nrequest-to-triggered-request latency, for a connection\nrunning for over a minute.",
            "The Pirate algorithm runs on the switch-facing ingress\ninterface of the vantage point.",
            "g loads, the\nlatency-aware Katran is able to produce a sizable\nbenefit in tail latency, and also leads to more\npredictable tail latencies (shorter error bars).",
            "The\nlatency awareness provided by continuous and real-time\nresponse latency measurement enables reducing the 99th\npercentile tail response latency by 37% on average\nacross loads.",
            "In the future, we believe that\neither an extension to the protocol, or heuristics\nbased on payload sizes, may be applied to accurately\nidentify pure ACKs (scenario -ack ) and\npractically realize these benefits",
            "Figure 9: CDF of measured response latencies for a\nQUIC connection, in scenarios that do or do not\ngenerate pure ACK frames ( -ack and -noack ).",
            "G4. Capable of being run “online,” in\nparticular on software middleboxes. Measurement and\nmonitoring devices are frequently deployed in the form\nof virtual network functions managed through a\nsoftware-defined measurement infrastructure, e.g. [ 89 , 35 ] ."
          ]
        },
        {
          "title": "Paper review: Implementing Linearizability at Large Scale and Low ...",
          "url": "http://muratbuffalo.blogspot.com/2016/02/paper-review-implementing.html",
          "excerpts": [
            "In order to implement exactly-once semantics, RIFL must solve 4 problems: RPC identification, completion record durability, retry rendezvous, ..."
          ]
        },
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        },
        {
          "title": "[PDF] RAMCloud RPC Performance Over 10G Ethernet Fabric",
          "url": "https://www.scs.stanford.edu/14au-cs244b/labs/projects/montazeri.pdf",
          "excerpts": [
            "RAMCloud RPC system is one of the lowest latency RPC systems designed up until today. The low latency characteristics in RAMCloud's RPC has been achieved using."
          ]
        },
        {
          "title": "[PDF] RAMCloud and the Low- Latency Datacenter - SNIA.org",
          "url": "https://www.snia.org/sites/default/files/JohnOusterhout_RAMCloud.pdf",
          "excerpts": [
            "▫ Bad for latency. ▫ E.g. RAMCloud threading structure costs 200-300ns/RPC. ▫ Virtualization is potential problem. ○ Buffering. ▫ Network ..."
          ]
        },
        {
          "title": "intel-sgx-dcap-ecdsa-orientation.pdf",
          "url": "https://www.intel.com/content/dam/develop/public/us/en/documents/intel-sgx-dcap-ecdsa-orientation.pdf",
          "excerpts": [
            "This orientation guide describes various third party attestation collaterals provided by Intel that you can use to enable remote attestation of Intel® SGX ...",
            "\nThe Intel® SGX provisioning certificate service offers\n\nAPIs for retrieving provisioning certification key (PCK)\n\ncertificates, revocation lists, Trusted Computing Base\n\n(TCB) information, and the quoting enclave (QE) identity\n\nfor platforms with Intel® SGX enabled, all provided to an\n\non-premise caching service for the Intel® SGX\n\nprovisioning certificate service.",
            "The caching service for Intel® SGX provisioning certification\n\nservice allows a CSP or a datacenter to cache PCK\n\ncertificates, PCK certificate revocation lists (CRL), TCB\n\nInformation, and QE identity structures for all platforms in\n\nits cloud or data center",
            " The CSP or data center can request the attestation data\n\nstructures from Intel for each of its platforms during a\n\ndeployment phase. To request the attestation data from\n\nthe Intel® SGX provisioning certificate service, a proxy\n\nserver with controlled access to the Internet is used. During runtime, the ECDSA based Intel® SGX quote can be\n\nverified using the data cached in the caching service for\n\nthe Intel® SGX provisioning certificate service.",
            "\nThe main limitation is\n\nthat it requires run-time access to the internet to acquire\n\nthe PCK certificates from the Intel® SGX provisioning\n\ncertificate service. I.e. it does not support APIs to retrieve\n\nPCK certificates at deployment time.",
            "t**\n\nIntel has developed a quote format for Intel® SGX ECDSA\n\nbased quotes. This format is used by both the Intel SGX\n\nECDSA quote generation library and the Intel® SGX ECDSA\n\nQuote Verification Library.",
            "**\n\nThe platform quote provider library provides a set of APIs\n\nthat allow the Intel® SGX ECDSA quote generation library\n\nto get platform specific services",
            " platform quote provider library API documentation,\n\nsee https://download.01.org/intel-sgx/dcap-\n\n1\\.1/linux/docs/Intel\\_SGX\\_ECDSA\\_QuoteGenReference\\_DC\n\nAP\\_API\\_Linux",
            ". ** **ECDSA quote format**\n\nIntel has developed a quote format for Intel® SGX ECDSA\n\nbased quotes. This format is used by both the Intel SGX\n\nECDSA quote generation library and the Intel® SGX ECDSA\n\nQuote Verification Library.",
            "This orientation guide describes various third party attestation collaterals provided by Intel that you can use to enable remote attestation of Intel® SGX ..."
          ]
        },
        {
          "title": "[PDF] ReDMArk: Bypassing RDMA Security Mechanisms - USENIX",
          "url": "https://www.usenix.org/system/files/sec21-rothenberger.pdf",
          "excerpts": [
            "They raise concerns about the pre- dictability of hardware-managed memory protection key and the potential misuse of one-sided RDMA ..."
          ]
        },
        {
          "title": "intel/SGX-TDX-DCAP-QuoteVerificationService",
          "url": "https://github.com/intel/SGX-TDX-DCAP-QuoteVerificationService",
          "excerpts": [
            "Quote Verification Service is a stateless server endpoint implementation that verifies attestation evidence (quote) of ISV (Independent Software Vendor) ..."
          ]
        },
        {
          "title": "RDMA IP Core for RoCE v2 from Grovf - BittWare",
          "url": "https://www.bittware.com/partners/grovf-rdma/",
          "excerpts": [
            "MACsec + IPsec. Featuring Xiphera's IP running these popular security protocols in hardware has never been easier! MACsec @ Up to 100G · IPsec @ up to 200G · On ..."
          ]
        },
        {
          "title": "eRPC - Low latency and performance metrics",
          "url": "https://github.com/erpc-io/eRPC",
          "excerpts": [
            "Low latency: 2.3 microseconds round-trip RPC latency with UDP over Ethernet\n    * Performance for small 32-byte RPCs: ~10M RPCs/sec with one CPU core,\n60--80M RPCs/sec with one",
            "Bandwidth for large RPC: 75 Gbps on one connection (one CPU core at server\nand client) for 8 MB RPCs",
            "Scalability: 20000 RPC sessions per server",
            "End-to-end congestion control that tolerates 100-way incasts"
          ]
        },
        {
          "title": "eRPC: A high-performance RPC system for datacenter networks",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/erpc_2019.pdf",
          "excerpts": [
            "eRPC is at most 800 ns slower than RDMA reads.",
            " eRPC's median latency on CX5 is only 2.3 µs",
            "In microbenchmarks, one CPU\ncore can handle up to 10 million small RPCs per second",
            "zero-copy transmission\nin the presence of retransmissions, node failures, and\nrate limiting",
            "eRPC works well in commodity, lossy datacenter networks.",
            "eRPC uses userspace net-\nworking with polling, as in most prior high-performance\nnetworked system"
          ]
        },
        {
          "title": "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics (RAMCloud)",
          "url": "https://dl.acm.org/doi/10.1145/2815400.2815416",
          "excerpts": [
            "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics, thereby making it easy to turn non-linearizable ...",
            "RIFL is designed for large-scale systems and is lightweight enough to be used in low-latency environments.",
            "RIFL handles data migration by associating linearizability metadata with objects in the underlying store and migrating metadata with the corresponding objects.",
            "It uses a lease mechanism to implement garbage collection for metadata.",
            "We have implemented RIFL in the RAMCloud storage system and used it to make basic operations such as writes and atomic increments linearizable; RIFL adds only 530 ns to the 13.5 μs base latency for durable writes.",
            "We also used RIFL to construct a new multi-object transaction mechanism in RAMCloud; RIFL's facilities significantly simplified the transaction implementation.",
            "The transaction mechanism can commit simple distributed transactions in about 20 μs and it outperforms the H-Store main-memory database system for the TPC-C benchmark."
          ]
        },
        {
          "title": "arXiv:1801.05863 - Design and Implementation of RA-TLS for Intel SGX Enclaves",
          "url": "https://arxiv.org/pdf/1801.05863",
          "excerpts": [
            "e propose to\n\ninclude additional information into the X.509\n\ncertificate exchanged during a TLS handshake",
            "**Attestation Verification Report. ** This is the reply\n\nreceived from the Intel Attestation Service (IAS) when\n\nsubmitting a quote for verification [10]. IAS reports\n\nwhether the quote was generated on a genuine Intel\n\nSGX platform by a genuine encl",
            "**Attestation Verification Report Signature. ** The\n\nattestation verification report is signed by IAS. The\n\nsignature ensures that report is authentic and\n\nunmodifi",
            "**Attestation Report Signing Certificate. ** To verify the\n\nsignature over the attestation report, the client must\n\nknow the keys used to create the signatur",
            "**Non-standard X.509 extensions. ** We embed the SGX\n\nidentity information in custom X.509 extensions",
            "**Quoting Enclave Identity. ** The latest identity of Intel’s\n\nquoting enclave including its code measurement and\n\nsecurity versions number"
          ]
        },
        {
          "title": "Reusable Infrastructure for Linearizability(RIFL)",
          "url": "https://www.linkedin.com/pulse/reusable-infrastructure-linearizabilityrifl-hohuan-chang",
          "excerpts": [
            "RIFL aims to solve linearizability problems on large scale distributed systems by providing \"exactly once\" delivery. In fact that thing is not ..."
          ]
        },
        {
          "title": "At-most-once Algorithm for Linearizable RPC in Distributed ...",
          "url": "https://www.scs.stanford.edu/14au-cs244b/labs/projects/park.pdf",
          "excerpts": [
            "RAMCloud handles missing responses by retrying the RPC. Retrying RPCs with missing responses is appropriate for ensuring that the RPC is executed at-least-once ..."
          ]
        },
        {
          "title": "QUIC: A UDP-Based Multiplexed and Secure Transport",
          "url": "https://datatracker.ietf.org/doc/rfc9000/",
          "excerpts": [
            "Feb 19, 2022 — QUIC provides applications with flow-controlled streams for structured communication, low-latency connection establishment, and network path migration."
          ]
        },
        {
          "title": "One of either QUIC or RDMA already deliver this, ...",
          "url": "https://news.ycombinator.com/item?id=28441315",
          "excerpts": [
            "Sep 7, 2021 — QUIC achieves lower latency for connection establishment than TCP+TLS by merging the TCP and TLS handshakes and avoids additional handshakes by ..."
          ]
        },
        {
          "title": "QUIC is not quick enough over fast internet",
          "url": "https://news.ycombinator.com/item?id=41484991",
          "excerpts": [
            "A shared memory queue is a reasonable basis for improving the IO cost between applications and IO stacks such as the network or filesystem stacks."
          ]
        },
        {
          "title": "Attestation Services for Intel® Software Guard Extensions",
          "url": "https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/attestation-services.html",
          "excerpts": [
            "ECDSA-based attestation with Intel SGX DCAP allows providers to build and deliver their own attestation service. This is useful for enterprise, data center, and ..."
          ]
        },
        {
          "title": "Using RDMA Efficiently for Key-Value Services",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/herd_2014.pdf",
          "excerpts": [
            "ABSTRACT. This paper describes the design and implementation of HERD, a key- value system designed to make the best use of an RDMA network."
          ]
        },
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        },
        {
          "title": "Intel SGX",
          "url": "https://docs.ata.network/pom/attestation-module/machine-attestation/intel-sgx",
          "excerpts": [
            "Apr 19, 2024 — Intel SGX facilitates two distinct categories of attestation: Local Attestation, also known as Intra-Platform Attestation, and Remote ..."
          ]
        },
        {
          "title": "Solved: intel sgx secure channel",
          "url": "https://community.intel.com/t5/Intel-Software-Guard-Extensions/intel-sgx-secure-channel/td-p/1358583",
          "excerpts": [
            "Feb 9, 2022 — The answer remains the same. You should build a secure channel between the untrusted application on server S1 and the application on server S2."
          ]
        },
        {
          "title": "QUIC: The Secure Communication Protocol Shaping ...",
          "url": "https://www.zscaler.com/blogs/product-insights/quic-secure-communication-protocol-shaping-future-of-internet",
          "excerpts": [
            "Oct 8, 2024 — One of QUIC's main advantages is its reduced latency. Traditional TCP requires a multi-step handshake to establish a connection and additional ..."
          ]
        },
        {
          "title": "Attestation - SGX 101 - GitBook",
          "url": "https://sgx101.gitbook.io/sgx101/sgx-bootstrap/attestation",
          "excerpts": [
            "Nov 17, 2022 — Local attestation provides an authenticated assertion between two enclaves running on the same platform that they can trust each other and exchange information ..."
          ]
        },
        {
          "title": "First, the latency of RPC may vibrate... RDMA and queue pair (QP)",
          "url": "https://www.usenix.org/system/files/atc22-wei.pdf",
          "excerpts": [
            "As the latency of typical RDMA-enabled applications that\nrequire elasticity has reached to microsecond-scale (see Fig-\nure 1(a)), this high connection time may significantly decrease\nthe application efficiency, e.g., increasing latency when ex-\npanding resources to handle load spike",
            "RDMA is a high bandwidth and low latency networking fea-\nture widely adopted in modern datacenters [53, 19",
            "It has\ntwo well-known primitives: two-sided provides a message\npassing primitive while one-sided provides a remote memory\nabstraction—the RDMA-capable network card (RNIC) can\ndirectly read/write server memory in a CPU-bypassing way.",
            "he latency of RPC may vibrate to tens of mil- liseconds due to the scheduling and queuing overhead of the. CP"
          ]
        },
        {
          "title": "RDMA ICDE20 Paper",
          "url": "https://www.cs.purdue.edu/homes/csjgwang/CloudNativeDB/RDMAICDE20.pdf",
          "excerpts": [
            "UDP and protocols on top of it, like QUIC [20], also have the potential to improve performance, but currently lack hardware acceleration."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://www.usenix.org/legacy/event/sec10/tech/full_papers/Watson.pdf",
          "excerpts": [
            "by RNM Watson · Cited by 275 — Capsicum extends, rather than replaces,. UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sand- box API."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://www.cl.cam.ac.uk/research/security/capsicum/",
          "excerpts": [
            "Capsicum extends the POSIX API, providing several new OS primitives to support object-capability security on UNIX-like operating systems: capabilities - refined ..."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://research.google.com/pubs/archive/36736.pdf",
          "excerpts": [
            "by RNM Watson · 2010 · Cited by 275 — Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives. (sandboxed capability mode and capabilities) and a userspace ..."
          ]
        },
        {
          "title": "What if Rust is combined with CHERI(Capability Hardware ...",
          "url": "https://www.reddit.com/r/rust/comments/1m3w25v/what_if_rust_is_combined_with_chericapability/",
          "excerpts": [
            "CHERI revolutionize computer architecture and can let the memory error hidden in C/C++ to be precisely catched by OS."
          ]
        },
        {
          "title": "exploring CHERI capabilities for a safe language - Nicholas Sim",
          "url": "https://nw0.github.io/cheri-rust.pdf",
          "excerpts": [
            "by NWS Sim · 2020 · Cited by 7 — Both Rust, a safe programming language, and CHERI, an architecture providing hardware capabil- ities, claim to provide low-overhead memory safety to prevent ..."
          ]
        },
        {
          "title": "glommio - Rust",
          "url": "https://docs.rs/glommio/latest/glommio/",
          "excerpts": [
            "Glommio is a library providing a safe Rust interface for asynchronous, thread-local I/O, based on the linux io_uring interface and Rust's async support."
          ]
        },
        {
          "title": "DataDog/glommio",
          "url": "https://github.com/DataDog/glommio",
          "excerpts": [
            "Glommio (pronounced glo-mee-jow or |glomjəʊ|) is a Cooperative Thread-per-Core crate for Rust & Linux based on io_uring . Like other rust asynchronous crates, ...",
            "Glommio is a thread-per-core crate that makes writing highly parallel asynchronous applications in a thread-per-core architecture easier for rustaceans."
          ]
        },
        {
          "title": "tokio-rs/tokio-uring: An io_uring backed runtime for Rust",
          "url": "https://github.com/tokio-rs/tokio-uring",
          "excerpts": [
            "This crate provides io-uring for Tokio by exposing a new Runtime that is compatible with Tokio but also can drive io-uring -backed resources."
          ]
        },
        {
          "title": "Announcing tokio-uring: io-uring support for Tokio",
          "url": "https://tokio.rs/blog/2021-07-tokio-uring",
          "excerpts": [
            "Jul 19, 2021 — Tokio is a runtime for writing reliable asynchronous applications with Rust. It provides async I/O, networking, scheduling, timers, ..."
          ]
        },
        {
          "title": "Tokio vs Tokio-Uring for High-Throughput Web Servers",
          "url": "https://www.reddit.com/r/rust/comments/1hhn40b/performance_comparison_tokio_vs_tokiouring_for/",
          "excerpts": [
            "io_uring is faster. It allows zero copy APIs, allows sharing read and write buffers with the kernel, and a bunch of other goodies."
          ]
        },
        {
          "title": "Zero-copy async IO in Rust? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/zero-copy-async-io-in-rust/106996",
          "excerpts": [
            "It is fundamentally impossible to do async IO from/to &[u8] / &mut [u8] without copies in Rust. The reason is that any such operation must be able to read/ ...",
            "Feb 18, 2024 — Because io-uring differs significantly from epoll, Tokio must provide a new set of APIs to take full advantage of the reduced overhead."
          ]
        },
        {
          "title": "[PDF] LibPreemptible: Enabling Fast, Adaptive, and Hardware-Assisted ...",
          "url": "https://www.csl.cornell.edu/~zhiruz/pdfs/libpreemptible-hpca2024.pdf",
          "excerpts": [
            "Compared to the prior state-of-the-art scheduling system Shinjuku, our system achieves significant tail latency and throughput improvements for various ..."
          ]
        },
        {
          "title": "IO_uring Zero-Copy Receive Support Ready For Linux ...",
          "url": "https://www.reddit.com/r/linux/comments/1ilacgo/io_uring_zerocopy_receive_support_ready_for_linux/",
          "excerpts": [
            "My basic understanding is that DPDK will bypass the kernel network stack and provide direct access to network packets in the user application."
          ]
        },
        {
          "title": "capsule - Rust - Docs.rs",
          "url": "https://docs.rs/capsule",
          "excerpts": [
            "We've created a tool to efficiently manipulate network packets while being type-safe, memory-safe, and thread-safe. Building on DPDK and Rust, Capsule offers:."
          ]
        },
        {
          "title": "datenlord/async-dpdk: DPDK API in async Rust - GitHub",
          "url": "https://github.com/datenlord/async-dpdk",
          "excerpts": [
            "DPDK API in async Rust. Contribute to datenlord/async-dpdk development by creating an account on GitHub."
          ]
        },
        {
          "title": "Zero-Copy in Rust: Challenges and Solutions",
          "url": "https://coinsbench.com/zero-copy-in-rust-challenges-and-solutions-c0d38a6468e9",
          "excerpts": [
            "Jun 8, 2025 — The concept of zero-copy in Rust refers to a technique of working with data in memory without making unnecessary copies, which significantly improves ..."
          ]
        },
        {
          "title": "[PATCH] rust: RFC/demo of safe API for Dpdk Eal, Eth and Rxq",
          "url": "https://inbox.dpdk.org/dev/9c4a970a-576c-7b0b-7685-791c4dd2689d@nvidia.com/T/",
          "excerpts": [
            "[PATCH] rust: RFC/demo of safe API for Dpdk Eal, Eth and Rxq ... DPDK provides mbuf*s: that's a large mismatch. (Yes I'm aware of ..."
          ]
        },
        {
          "title": "Resistance to Rust abstractions for DMA mapping in Linux ...",
          "url": "https://www.reddit.com/r/linux/comments/1igrime/resistance_to_rust_abstractions_for_dma_mapping/",
          "excerpts": [
            "We wrote a single piece of Rust code that abstracts the C API for all Rust drivers, which we offer to maintain ourselves."
          ]
        },
        {
          "title": "Using Capabilities to design safer, more expressive APIs in Rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/7rmgxo/using_capabilities_to_design_safer_more/",
          "excerpts": [
            "The point here being that `Capability` is a trait, which means you can implement it on any type you want.",
            "Suppose we have a `SQLite` type that implements a bunch of methods for interacting with our database.",
            "We might want to grant the capability to a function to save new comments on a thread (just as an example), but want to always first check that the caller has permission to do so. We could achieve this by implementing a new capability for our `SQLite` type. I'm just sketching code below- don't expect this to run as is.",
            "struct SQLite(Connection);",
            "// Post will contain the `Comment` we want to save and the `User` that is trying to post the comment. struct Post<T, U>(pub T, pub U);",
            "impl Capability<Post<Comment, User>> for SQLite {",
            "  type Data = Comment;",
            "  type Error = DBError;",
            "  fn perform(&self, post_comment: Post<Comment, User>) -> Result<Comment, DBError> {",
            "    // Here is where we can check permissions and do the save operation. if self.user_can_post_comments(post_comment.1) {",
            "      self.save_comment(post_comment.0)",
            "    } else {",
            "      Err(InsufficientPermission)",
            "    }",
            "fn handle_comment_post<DB>(db: &DB, comment: Comment, user: User) -> Result<(), DBError>",
            "   where DB: Capability<Post<Comment, User>>",
            "  db.perform(Post(comment, user)).map(|_| ())",
            "This way, capabilities get passed into functions from any of the function's call sites. I could have, instead of writing the `handle_comment_post` function, also have simply made `MyRequestHandler` generic on its contained values and used the `Capability` trait to specify the capabilities that it wants to have.",
            "In this scenario, I can restrict the capabilities of my functions, request handlers, etc. in my `main` function, when I set up each handler. The point here being that `Capability` is a trait, which means you can implement it on any type you want.",
            "If you wanted to create a new type that maybe wraps `SQLite`, you could implement capabilities for that type that only grant a subset of the capabilities had by `SQLite` itself.",
            "Furthermore, since `Capability` is generic on its input, you can define any other types you want, like `Save`, `Post`, `PostButCheckPermissionsFirst`, etc. to only allow callers to use a specific implementation.",
            "e could now write a function that requests this new capability.",
            "struct HandleCommentPosts<DB> {",
            "  database: DB,",
            "impl<DB> Handler for HandleCommentPosts<DB>\n ",
            "  where DB: Capability<Post<Comment, User>>",
            "{",
            "{",
            "  fn handle(&self, req: mut Request) -> IronResult<...> {",
            "    self.database.perform(Post(comment, user))",
            "  }",
            "  }",
            "}",
            "}",
            "}",
            "}",
            "This way, capabilities get passed into functions from any of the function's call sites.",
            "t `Capability` is a trait, which means you can implement it on any type you want. If you "
          ]
        },
        {
          "title": "io_uring interface and shared ring buffers (as described in the provided document)",
          "url": "https://unixism.net/loti/low_level.html",
          "excerpts": [
            "    }",
            "    }",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Sandbox Permissions - Flatpak documentation",
          "url": "https://docs.flatpak.org/en/latest/sandbox-permissions.html",
          "excerpts": [
            "Sandbox Permissions . One of Flatpak's main goals is to increase the security of desktop systems by isolating applications from one another."
          ]
        },
        {
          "title": "Snap confinement | Snapcraft documentation",
          "url": "https://snapcraft.io/docs/snap-confinement",
          "excerpts": [
            "Snap confinement determines the amount of access an application has to system resources, such as files, the network, peripherals and services."
          ]
        },
        {
          "title": "Manifests - Flatpak documentation",
          "url": "https://docs.flatpak.org/en/latest/manifests.html",
          "excerpts": [
            "This page provides information and guidance on how to use manifests, including an explanation of the most common parameters that can be specified."
          ]
        },
        {
          "title": "Snapcraft confinement & interfaces",
          "url": "https://snapcraft.io/blog/snapcraft-confinement-interfaces",
          "excerpts": [
            "Jun 6, 2019 — In this tutorial, we are going to talk about confinement and interfaces – how to restrict what your snaps can do, and then fine-tune the ..."
          ]
        },
        {
          "title": "Flatpak documentation",
          "url": "https://docs.flatpak.org/",
          "excerpts": [
            "These docs cover everything you need to know to build and distribute applications using Flatpak. They begin with a basic introduction to Flatpak."
          ]
        },
        {
          "title": "Interfaces - Snapcraft 8.11.1 documentation",
          "url": "https://documentation.ubuntu.com/snapcraft/stable/explanation/interfaces/",
          "excerpts": [
            "A strictly-confined snap is considered untrusted and runs in a restricted environment. It's only able to access a limited set of resources outside the ..."
          ]
        },
        {
          "title": "Flatpak Command Reference",
          "url": "https://docs.flatpak.org/en/latest/flatpak-command-reference.html",
          "excerpts": [
            "Flatpak is a tool for managing applications and the runtimes they use. In the Flatpak model, applications can be built and distributed independently from the ..."
          ]
        },
        {
          "title": "Rust public abi for foreign language ffi",
          "url": "https://stackoverflow.com/questions/78285226/rust-public-abi-for-foreign-language-ffi",
          "excerpts": [
            "I'm writing a language and want it to be binary compatible with rust, c++ and some other languages. The problem is that I couldn't find information on rusts ..."
          ]
        },
        {
          "title": "Rust ❤️ C++",
          "url": "https://cxx.rs/",
          "excerpts": [
            "safe interop between Rust and C++ by David Tolnay. This library provides a safe mechanism for calling C++ code from Rust and Rust code from C++."
          ]
        },
        {
          "title": "Crate abi_stable - Rust - Docs.rs",
          "url": "https://docs.rs/abi_stable/",
          "excerpts": [
            "The `abi_stable` crate is for Rust-to-Rust FFI, creating libraries loaded at startup with load-time type-checking, and allows dynamic libraries even with ..."
          ]
        },
        {
          "title": "We Need Type Information, Not Stable ABI",
          "url": "https://blaz.is/blog/post/we-dont-need-a-stable-abi/",
          "excerpts": [
            "What it seems to boil down to is parsing a portion of Rust code, collecting types within, and then emitting a C layer, as well as other language ..."
          ]
        },
        {
          "title": "cxx - Rust",
          "url": "https://docs.rs/cxx",
          "excerpts": [
            "This library provides a safe mechanism for calling C++ code from Rust and Rust code from C++, not subject to the many ways that things can go wrong."
          ]
        },
        {
          "title": "abi_stable - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/abi_stable",
          "excerpts": [
            "To run the example crates you'll generally have to build the *_impl crate, then run the *_user crate (all *_user crates should have a help ..."
          ]
        },
        {
          "title": "Experimental Rust Feature: Safer Interoperable ABI",
          "url": "https://news.ycombinator.com/item?id=34145972",
          "excerpts": [
            "Dec 27, 2022 — This proposal seems to define how to convert C ABI to/from Rust types in a standard way. This will likely improve Rust+C use cases over time."
          ]
        },
        {
          "title": "Is #[repr(C)] necessary for Rust-to-Rust FFI - help",
          "url": "https://users.rust-lang.org/t/is-repr-c-necessary-for-rust-to-rust-ffi/50596",
          "excerpts": [
            "The trouble is that in Rust when a struct is repr(Rust) (the default) it is then free to use whatever layout it thinks is most efficient for your program."
          ]
        },
        {
          "title": "The new dynamic user space tracing feature in LTTng",
          "url": "https://lttng.org/blog/2019/10/15/new-dynamic-user-space-tracing-in-lttng/",
          "excerpts": [
            "Oct 15, 2019 — This feature allows you to instrument functions in user space apps and shared libraries at run time by adding and removing user space probes."
          ]
        },
        {
          "title": "aya_ebpf - Rust - Docs.rs",
          "url": "https://docs.rs/aya-ebpf",
          "excerpts": [
            "A library to write eBPF programs. Aya-bpf is an eBPF library built with a focus on operability and developer experience. It is the kernel-space counterpart of ...",
            "A library to write eBPF programs. Aya-bpf is an eBPF library built with a focus on operability and developer experience. It is the kernel-space counterpart of ..."
          ]
        },
        {
          "title": "provide observability on how kernel handles io_uring request #467",
          "url": "https://github.com/axboe/liburing/issues/467",
          "excerpts": [
            "FWIW, perf record can track multiple trace points. // trace all io_uring events perf record -e \"io_uring:*\" -- ./app_to_trace // two specific ..."
          ]
        },
        {
          "title": "LTTng v2.13 — LTTng Documentation",
          "url": "https://lttng.org/docs/v2.13/",
          "excerpts": [
            "Nov 28, 2023 — This is a short guide to get started quickly with LTTng kernel and user space tracing. Before you follow this guide, make sure to install LTTng."
          ]
        },
        {
          "title": "aya - Rust - Docs.rs",
          "url": "https://docs.rs/aya",
          "excerpts": [
            "Aya is an eBPF library built with a focus on operability and developer experience. It does not rely on libbpf nor bcc - it's built from the ground up purely in ..."
          ]
        },
        {
          "title": "Missing Manuals - io_uring worker pool - The Cloudflare Blog",
          "url": "https://blog.cloudflare.com/missing-manuals-io_uring-worker-pool/",
          "excerpts": [
            "We can discover the tracepoints with perf list or bpftrace -l , or by browsing the events/ directory on the tracefs filesystem , usually ..."
          ]
        },
        {
          "title": "Can I view LTTng traced Userspace events and Kernel ...",
          "url": "https://stackoverflow.com/questions/60330773/can-i-view-lttng-traced-userspace-events-and-kernel-events-together-in-trace-com",
          "excerpts": [
            "I am using LTTng to trace kernel events and userspace tracepoints. I want to visualize them together in one Trace Compass window."
          ]
        },
        {
          "title": "Android Manifest Introduction",
          "url": "https://developer.android.com/guide/topics/manifest/manifest-intro",
          "excerpts": [
            "The manifest file describes essential information about your app to the Android build tools, the Android operating system, and Google Play.",
            "| `<permission>` | Declares a security permission that can be used to limit access to specific components or features of this or other applications.",
            "| `<permission-group>` | Declares a name for a logical grouping of related permissions.",
            "| `<permission-tree>` | Declares the base name for a tree of permissions."
          ]
        },
        {
          "title": "Android Permissions Documentation",
          "url": "https://developer.android.com/training/permissions/declaring",
          "excerpts": [
            "To declare a permission that your app might request, include the appropriate <uses-permission> element in your app's manifest file.",
            "For example, an app that needs to access the camera\nhas this line in `AndroidManifest.xml`:\n\n```\n<manifest ...>\n    <uses-permission android:name=\"android.permission.CAMERA\"/>\n    <application ...>\n        ...\n    </application>\n</manifest>\n```",
            "Declare hardware as optional"
          ]
        },
        {
          "title": "The Rustonomicon: Other representations (repr(C))",
          "url": "https://doc.rust-lang.org/nomicon/other-reprs.html",
          "excerpts": [
            "This is the most important `repr` . It has fairly simple intent: do what C does. The order, size, and alignment of fields is exactly what you would expect from C",
            "The interaction of `repr(C)` with Rust's more exotic data layout features must be\nkept in mind.",
            "We strongly recommend using [rust-bindgen](https://rust-lang.github.io/rust-bindgen/) and/or [cbindgen](https://github.com/eqrion/cbindgen) to manage your FFI\nboundaries for you.",
            "The Rust team works closely with those projects to ensure\nthat they work robustly and are compatible with current and future guarantees\nabout type layouts and `repr` s."
          ]
        },
        {
          "title": "The Rustonomicon - FFI",
          "url": "https://doc.rust-lang.org/nomicon/ffi.html",
          "excerpts": [
            "Most foreign code exposes a C ABI, and Rust uses the platform's C calling convention by default when calling foreign functions.",
            "\n\nThe `extern \"C\"` makes this function adhere to the C calling convention, as discussed below in \" [Foreign Calling Conventions](ffi.html) \". The `no_mangle` attribute turns off Rust's name mangling, so that it has a well defined symbol to link to.",
            "Rust guarantees that the layout of a `struct` is compatible with the platform's\nrepresentation in C only if the `#[repr(C)]` attribute is applied to it.",
            "The list of supported ABI constraints\nare:\n\n* `stdcall`\n* `aapcs`\n* `cdecl`\n* `fastcall`\n* `thiscall`\n* `vectorcall` This is currently hidden behind the `abi_vectorcall` gate and is subject to change. * `Rust`\n* `system`\n* `C`"
          ]
        },
        {
          "title": "CantripOS: seL4 + Rust",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-01-leffler.pdf",
          "excerpts": [
            "CantripOS: 100% Rust",
            "Provides a variety of developer tools.",
            "CantripOS: sel4gdb",
            "seL4-thread-aware debugging \nsupport for gdb + Renod",
            "Rust log crate integration",
            "kmem (+ bloaty): tools for inspecting memory footprint",
            "sel4-sys",
            "Rootserver runs and sets up CAmkES \nassembly using untainted memor",
            "CantripOS: Memory Footprint Tools",
            "Memory footprint = $$$ + power."
          ]
        },
        {
          "title": "cap_std - Rust - Docs.rs",
          "url": "https://docs.rs/cap-std",
          "excerpts": [
            "Capability-based APIs represent access to external resources as values which can be passed around between different parts of a program. Two notable features ..."
          ]
        },
        {
          "title": "cap-primitives - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cap-primitives",
          "excerpts": [
            "Capability-based primitives The cap-primitives crate provides primitive sandboxing operations that cap-std and cap-async-std are built on. The ..."
          ]
        },
        {
          "title": "cap-std - Rust Package Registry - Crates.io",
          "url": "https://crates.io/crates/cap-std",
          "excerpts": [
            "This crate provides a capability-based version of std , providing sandboxed filesystem, networking, and clock APIs."
          ]
        },
        {
          "title": "The Typestate Pattern in Rust",
          "url": "https://www.reddit.com/r/rust/comments/c33u9m/the_typestate_pattern_in_rust/",
          "excerpts": [
            "Typestates are a type-system features that allow you to change the type of the object. Here, you do not change the type of anything, you return a new thing ..."
          ]
        },
        {
          "title": "tokio_uring - Rust",
          "url": "https://docs.rs/tokio-uring/latest/tokio_uring/",
          "excerpts": [
            "Tokio-uring provides a safe io-uring interface for the Tokio runtime. The library requires Linux kernel 5.10 or later."
          ]
        },
        {
          "title": "DmaFile in glommio::io - Rust",
          "url": "https://docs.rs/glommio/latest/glommio/io/struct.DmaFile.html",
          "excerpts": [
            "An asynchronously accessed Direct Memory Access (DMA) file. All access uses Direct I/O, and all operations including open and close are asynchronous."
          ]
        },
        {
          "title": "I Built a Rust Zero-Copy Network Proxy That Processes 1M ...",
          "url": "https://medium.com/@FAANG/i-built-a-rust-zero-copy-network-proxy-that-processes-1m-tps-heres-how-093446529f03",
          "excerpts": [
            "In this project I designed a proxy that hijacks OS packet buffers directly, routes them between sockets with minimal Rust abstractions, and ..."
          ]
        },
        {
          "title": "I don't understand zero copy : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/18cian3/i_dont_understand_zero_copy/",
          "excerpts": [
            "There is no single \"zerocopy\" thing, it just implies that you avoid some copying of data, probably for less resource usage."
          ]
        },
        {
          "title": "GitHub - spacejam/rio: pure rust io_uring library, built on ...",
          "url": "https://github.com/spacejam/rio",
          "excerpts": [
            "... buffers until the corresponding request has completed; but it is considered safe in Rust for an object's lifetime and borrows to end without its destructor ..."
          ]
        },
        {
          "title": "Async Rust is not safe with io_uring",
          "url": "https://news.ycombinator.com/item?id=41992975",
          "excerpts": [
            "io-uring's async cancellation mechanism is just an optimization opportunity and doesn't synchronize anything, so it can't be relied on for correctness here."
          ]
        },
        {
          "title": "Structured concurrency? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1270z03/structured_concurrency/",
          "excerpts": [
            "Does Rust have a notion of structured concurrency? The reason I ask is because I'm looking at atuff that's wrapping an Arc around a Mutex."
          ]
        },
        {
          "title": "Local Async Executors and Why They Should be the Default",
          "url": "https://www.reddit.com/r/rust/comments/v8e9fa/local_async_executors_and_why_they_should_be_the/",
          "excerpts": [
            "I prefer a multithreaded executor with the potentially avoidable Send, Sync and 'static bounds sprinkled throughout."
          ]
        },
        {
          "title": "cap-primitives - Rust Package Registry - Crates.io",
          "url": "https://crates.io/crates/cap-primitives/dependencies",
          "excerpts": [
            "The module also provides useful traits that extend `Ipv4Addr` and `Ipv6Addr` with methods for `Add`, `Sub`, `BitAnd`, and `BitOr` operations."
          ]
        },
        {
          "title": "Async Rust is not safe with io_uring",
          "url": "https://www.reddit.com/r/rust/comments/1gfi5r1/async_rust_is_not_safe_with_io_uring/",
          "excerpts": [
            "The problem isn't async Rust, its libraries exposing flawed APIs. My ringbahn, that I wrote in 2019, correctly handles this case by registering a cancellation ..."
          ]
        },
        {
          "title": "PermRust: A Token-based Permission System for Rust - arXiv",
          "url": "https://arxiv.org/html/2506.11701v1",
          "excerpts": [
            "Furthermore, we need our framework to not permit ambient authority, which is “authority that is exercised, but not [explicitly] selected by its ..."
          ]
        },
        {
          "title": "Ambient Authority: The Root of all Evil | by Rico Mariani - Medium",
          "url": "https://ricomariani.medium.com/ambient-authority-the-root-of-all-evil-c3312eebe0c0",
          "excerpts": [
            "Everyone knows (“It is known”) that global variables are “bad”. Lots of global variables makes things very confusing because when your important ..."
          ]
        },
        {
          "title": "structured_spawn - Rust - Docs.rs",
          "url": "https://docs.rs/structured-spawn",
          "excerpts": [
            "Structured async task spawn implementations for Tokio. Read “Tree-Structured Concurrency” for a complete overview of what structured concurrency is, ..."
          ]
        },
        {
          "title": "Structured Concurrency Support · Issue #1879 · tokio-rs/tokio - GitHub",
          "url": "https://github.com/tokio-rs/tokio/issues/1879",
          "excerpts": [
            "Structured concurrency describes programming paradigm. Concurrent tasks are structured in a fashion where there exist clean task hierarchies."
          ]
        },
        {
          "title": "Exploring Capability-based security in software design with Rust",
          "url": "https://bora.uib.no/bora-xmlui/bitstream/handle/11250/3001153/exploring_capability-based_security_in_software_design_with_Rust.pdf?sequence=1&isAllowed=y",
          "excerpts": [
            "Restricting the user's permissions is also known as Principle of Least Privilege (PoLP).",
            "In CBAC, capabilities are unforgeable tokens describing the authorization to\naccess a resource for a principal. Capabilities may be transferred between principals.",
            "We created a capability library 5.8 we used to implement a RESTful API, simple-api 5.9,\nconnecting it with Grant Negotiation and Authorization Protocol (GNAP) into a proof-of-\nconcept capability-based system published on GitHub [10",
            "TypeState enables structs to change behavior after running a\nfunction that changes the internal state of the struct.",
            "We created a library with three procedural macros to implement the design we used in\nCapabilityApi.",
            "ted library enables the developer to specify the available CRUD operations\nfor a data structure in the RESTful API.",
            "We will use\nthis library to build a RESTful API as part of a capability system."
          ]
        },
        {
          "title": "Taming stateful computations in Rust with typestates_.pdf",
          "url": "https://novaresearch.unl.pt/files/47111984/Taming_stateful_computations_in_Rust_with_typestates_.pdf",
          "excerpts": [
            "In typestate-oriented programming objects are modeled in terms of classes and changing states, much like our Rust-based approach. B",
            ". We propose a macro which embeds a typestate description DSL in Rust which allows developers to specify\ntypestates for their APIs; the typestate is checked at compile-time for common mistakes and to ensure the\ncorrect usage of the typestate, we leverage Rust’s type system.",
            "To enforce linear resource usage when build\nthe processes the library makes use of the type system to enforce the\nconsumption of each ‘‘state’’; enforcing protocol completion is done\nthrough a closure, which takes the initial session type and returns a\nterminal End type, a session is then required to be run until completion\notherwise the return type will not be respected and the type checker\nwill raise an error.",
            "\nPart of the typestate-oriented paradigm, the Plaid language [16] is an\n\nextension of the object paradigm. In typestate-oriented programming\nobjects are modeled in terms of classes and changing states, much like\nour Rust-based approach."
          ]
        },
        {
          "title": "Structured concurrency in Rust with Tokio Beyond Tokio Spawn",
          "url": "https://medium.com/@adamszpilewicz/structured-concurrency-in-rust-with-tokio-beyond-tokio-spawn-78eefd1febb4",
          "excerpts": [
            "tructured Concurrency? Structured concurrency is about **scoping tasks** . Instead of fire-and-forget, you treat tasks like children of a parent",
            "\nWelcome to the world of **structured concurrency** — a pattern that helps you manage task lifecycles, handle cancellation, and avoid future leaks.",
            "\n\nRust’s async story is fast, safe, and incredibly powerful.",
            "Rust’s borrow checker already enforces structured memory. Structured concurrency brings that same discipline to async code."
          ]
        },
        {
          "title": "CancellationToken (tokio-util)",
          "url": "https://docs.rs/tokio-util/latest/tokio_util/sync/struct.CancellationToken.html",
          "excerpts": [
            "A token which can be used to signal a cancellation request to one or more tasks. Tasks can call CancellationToken::cancelled() in order to obtain a Future ... [Source](../../src/tokio_util/sync/cancellation_token.rs.html)",
            "#### pub async fn [run\\_until\\_cancelled\\_owned](.run_until_cancelled_owned) <F>(self, fut: F) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <F:: [Output](https://doc.rust-lang.org/nightly/core/future/future/trait.Future.html.Output \"type core::future::future::Future::Output\") >",
            "Runs a future to completion and returns its result wrapped inside of an `Option` unless the `CancellationToken` is cancelled. In that case the function returns `None` and the future gets dropped. The function takes self by value and returns a future that owns the token."
          ]
        },
        {
          "title": "Tree-structured concurrency (Yoshua Wuyts Blog)",
          "url": "https://blog.yoshuawuyts.com/tree-structured-concurrency/",
          "excerpts": [
            "When you drop a future to cancel it, it's\n  guaranteed that all futures underneath it are also cancelle",
            "When an error is created somewhere down in the\n  call-graph, it can always be propagated up to the callers until there is a\n  caller who is ready to handle",
            "When a function returns, you know it is done doing\n  wor",
            "These properties put together lead to something called a **\"black box model of\nexecution\"**: under a structured model of computing you don't need to know\nanything about the inner workings of the functions you're calling, because their\nbehavior is guaranteed. A function will return when it's done, will cancel all\nwork when you ask it to, and you'll always receive an error if there is something\nwhich needs handling. And as a result code under this model is **compo",
            "Structured concurrency is a lens I use in almost all of my\nreasoning about async Rust, and I think it might help others too."
          ]
        },
        {
          "title": "Rust Tokio Task Cancellation Patterns",
          "url": "https://cybernetist.com/2024/04/19/rust-tokio-task-cancellation-patterns/",
          "excerpts": [
            "Rust provides support for [async programming](https://rust-lang.github.io/async-book/?ref=cybernetist.com)\nwhich lets you spawn asynchronous tasks which are then scheduled for execution across OS threads via a runtime executor.",
            "As with everything in Rust, async programming has to be memory-safe so you need to make sure the borrow checker is happy.",
            "One thing the tutorial doesn’t go into much detail is task cancellations, which is something I had a need for in\none of my projects.",
            "Specifically, I needed to spin a bunch of worker tasks and I needed a way to cancel either any or\nall of them."
          ]
        },
        {
          "title": "Forging Ergonomic Rust: The Evolution of Language ...",
          "url": "https://medium.com/the-software-frontier/forging-ergonomic-rust-the-evolution-of-language-design-with-technical-precision-f4f13ca18953",
          "excerpts": [
            "This article revisits that initiative with a deep technical lens, unpacking what ergonomics means in programming languages, how Rust tackled it, ..."
          ]
        },
        {
          "title": "Resources on writing ergonomic APIs? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/9nv60v/resources_on_writing_ergonomic_apis/",
          "excerpts": [
            "Are there any resources or guidance on what exactly makes an ergonomic API in Rust, and how to do that? Thanks in advance! (Further design ..."
          ]
        },
        {
          "title": "Making Async Rust Reliable - Tyler Mandry - GitLab",
          "url": "https://tmandry.gitlab.io/blog/posts/making-async-reliable/",
          "excerpts": [
            "A Rust future can be canceled and stop executing at any await point, in theory. In practice, cancellation semantics of Rust futures is an ..."
          ]
        },
        {
          "title": "Async Rust can be a pleasure to work with (without `Send + Sync + ...",
          "url": "https://www.reddit.com/r/rust/comments/1f920z8/async_rust_can_be_a_pleasure_to_work_with_without/",
          "excerpts": [
            "You can still do that with structured concurrency, no? Structured concurrency just eliminates 'static , not necessarily Send or Sync ."
          ]
        },
        {
          "title": "Async Rust is about concurrency, not (just) performance",
          "url": "https://kobzol.github.io/rust/2025/01/15/async-rust-is-about-concurrency.html",
          "excerpts": [
            "The primary benefit of async/await is that it lets us concisely express complex concurrency; any (potential) performance improvements are just a second-order ..."
          ]
        },
        {
          "title": "io_uring nvme example : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/z0z50w/io_uring_nvme_example/",
          "excerpts": [
            "Io_uring is a next gen async io platform, and NVMe is a super fast API to talk directly with SSDs. I hope by sharing this to avoid to others all ..."
          ]
        },
        {
          "title": "FAQ - Redox - Your Next(Gen) OS",
          "url": "https://www.redox-os.org/faq/",
          "excerpts": [
            "Redox is a microkernel-based, general-purpose OS, created in 2015, aiming to be a complete alternative to Linux and BSD, and is currently in alpha development."
          ]
        },
        {
          "title": "Capability-based security for Redox",
          "url": "https://nlnet.nl/project/Capability-based-RedoxOS/",
          "excerpts": [
            "Capability-based security for Redox ... Redox OS is a Unix-like microkernel-based operating system written in Rust, intended for both the cloud and the desktop."
          ]
        },
        {
          "title": "The Security Benefits of a Rust-Based Operating System ...",
          "url": "https://www.reddit.com/r/rust/comments/1hfvjfy/the_security_benefits_of_a_rustbased_operating/",
          "excerpts": [
            "These types of devices require robust security, and a Rust-based OS could help mitigate vulnerabilities such as buffer overflows and memory- ..."
          ]
        },
        {
          "title": "Linux perf Examples",
          "url": "https://www.brendangregg.com/perf.html",
          "excerpts": [
            "It depends on the rate of the event you are tracing: the more frequent, the higher the overhead and larger the perf.data size. To really cut down overhead ..."
          ]
        },
        {
          "title": "Linux eBPF Tracing Tools",
          "url": "https://www.brendangregg.com/ebpf.html",
          "excerpts": [
            "Dec 28, 2016 — On this page I'll describe eBPF, the front-ends, and demonstrate some of the tracing tools I've developed."
          ]
        },
        {
          "title": "BPF ring buffer - Andrii Nakryiko's Blog",
          "url": "https://nakryiko.com/posts/bpf-ringbuf/",
          "excerpts": [
            "At the same time, BPF ringbuf solves the following issues with BPF perfbuf: memory overhead;; data ordering;; wasted work and extra data copying ...",
            "Being shared across all CPUs, BPF ringbuf allows using one big common buffer to\ndeal with this. Bigger buffer can absorb bigger spikes, but also might allow\nusing less RAM overall, compared to BPF perfbuf.",
            "BPF perfbuf allocates a separate buffer for each CPU. This often means that BPF\ndevelopers have to make a trade off between allocating big enough per-CPU\nbuffers (accommodating possible spikes of emitted data) or being\nmemory-efficient (by not wasting unnecessary memory for mostly empty buffers in\na steady state, but dropping data during data spikes).",
            "BPF ringbuf provides a better performance and memory efficiency, better\nordering guarantees, and better API (both kernel-side and in user-space)."
          ]
        },
        {
          "title": "eBPF Ecosystem Progress in 2024–2025",
          "url": "https://eunomia.dev/blog/2025/02/12/ebpf-ecosystem-progress-in-20242025-a-technical-deep-dive/",
          "excerpts": [
            "Feb 12, 2025 — Verifier Enhancements: The BPF verifier — which ensures that loaded eBPF programs are safe (no out-of-bounds access, no infinite loops, etc.) — ..."
          ]
        },
        {
          "title": "Aya: your tRusty eBPF companion",
          "url": "https://www.deepfence.io/blog/aya-your-trusty-ebpf-companion",
          "excerpts": [
            "Jul 22, 2022 — Although the eBPF verifier ensures memory safety, using Rust over C is still beneficial in terms of type safety. Both Rust and macros inside Aya ..."
          ]
        },
        {
          "title": "libbpf/libbpf-rs: Minimal and opinionated eBPF tooling for ...",
          "url": "https://github.com/libbpf/libbpf-rs",
          "excerpts": [
            "Idiomatic Rust wrapper around libbpf. libbpf-cargo. Helps you build and develop BPF programs with standard Rust tooling."
          ]
        },
        {
          "title": "libbpf_rs - Rust",
          "url": "https://docs.rs/libbpf-rs",
          "excerpts": [
            "libbpf-rs, together with libbpf-cargo (libbpf cargo plugin) allow you to write Compile-Once-Run-Everywhere (CO-RE) eBPF programs. Note this document uses “eBPF” ..."
          ]
        },
        {
          "title": "A Complete Guide to eBPF with Rust: Building Modern ...",
          "url": "https://blog.devgenius.io/a-complete-guide-to-ebpf-with-rust-building-modern-observability-tools-79ea23b0999c",
          "excerpts": [
            "Apr 26, 2025 — In this guide, we'll explore how to leverage eBPF using Rust, a language known for its performance and safety guarantees."
          ]
        },
        {
          "title": "A Deep Dive into Apache Arrow Flight and Its Use Cases",
          "url": "https://celerdata.com/glossary/a-deep-dive-into-apache-arrow-flight-and-its-use-cases",
          "excerpts": [
            "Jan 21, 2025 — Built on Apache Arrow, it leverages a standardized in-memory columnar format that supports zero-copy reads and efficient data processing. This ..."
          ]
        },
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Just raw, zero-copy data movement at high speed. Temporal keeps workflows running smoothly. Arrow Flight keeps data moving without friction. ...",
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency ."
          ]
        },
        {
          "title": "Powered by | Apache Arrow",
          "url": "https://arrow.apache.org/powered_by/",
          "excerpts": [
            "Uses Arrow to efficiently store Python data structures containing large arrays of numerical data. Data can be accessed with zero-copy by multiple processes ..."
          ]
        },
        {
          "title": "Apache Arrow: Use-case Example : r/dataengineering",
          "url": "https://www.reddit.com/r/dataengineering/comments/1gx33ka/apache_arrow_usecase_example/",
          "excerpts": [
            "Arrow's table can be shared with other processes running the same machine without copying the data residing in the RAM."
          ]
        },
        {
          "title": "Safe and usable kernel extensions with Rax",
          "url": "https://arxiv.org/html/2502.18832v1",
          "excerpts": [
            "Feb 26, 2025 — Aya eventually implemented its own version for both intrinsics, using a simple loop to iterate over the data to avoid ever tripping the verifier ..."
          ]
        },
        {
          "title": "Research Update: Isolated Execution Environment for eBPF",
          "url": "https://ebpf.foundation/research-update-isolated-execution-environment-for-ebpf/",
          "excerpts": [
            "This project introduces a novel execution environment designed to isolate BPF programs, offering an alternative architectural solution to enhance the security ..."
          ]
        },
        {
          "title": "Linux perf event Features and Overhead",
          "url": "https://web.eece.maine.edu/~vweaver/projects/perf_events/overhead/weaver_perfevent_overhead.pdf",
          "excerpts": [
            "by VM Weaver · Cited by 185 — It allows sampling with arbitrary performance events (or a timer if you lack performance counters) and provides frequency graphs, profiles, and stack traces."
          ]
        },
        {
          "title": "eBPF and Performance",
          "url": "https://www.brendangregg.com/Slides/SIGCOMM2024_eBPF_Performance.pdf",
          "excerpts": [
            "5) Crosscheck measured numbers. 6) Measure tool overhead. 7) <80 chars wide by default. 8) Add CLI options: follow other tool style. 9) Concise, intuitive, self ..."
          ]
        },
        {
          "title": "Pitfalls of relying on eBPF for security monitoring (and ...",
          "url": "https://blog.trailofbits.com/2023/09/25/pitfalls-of-relying-on-ebpf-for-security-monitoring-and-some-solutions/",
          "excerpts": [
            "Sep 25, 2023 — As Brendan Gregg observed: eBPF has many uses in improving computer security, but just taking eBPF observability tools as-is and using them ..."
          ]
        },
        {
          "title": "Unraveling eBPF Ring Buffers",
          "url": "https://www.deep-kondah.com/deep-dive-into-ebpf-ring-buffers/",
          "excerpts": [
            "This post is to provide an in-depth discussion of BPF ring buffers, covering their internals, including memory allocation, user-space mapping, locking ..."
          ]
        },
        {
          "title": "Performance Overhead of Perf Event Subsystem in Linux ...",
          "url": "https://stackoverflow.com/questions/2794188/performance-overhead-of-perf-event-subsystem-in-linux-kernel",
          "excerpts": [
            "The overhead of the PMU-based hardware counters should depend on how many different events you're sampling, and how often."
          ]
        },
        {
          "title": "[PDF] A Practical, Lightweight, and Flexible Confinement Framework in eBPF",
          "url": "https://www.cisl.carleton.ca/~will/written/techreport/mcs-thesis.pdf",
          "excerpts": [
            "The goal was to implement namespace remapping and security isolation for commercial server deployments in (possibly multi-tenant) Solaris environments. The."
          ]
        },
        {
          "title": "Data at the Speed of Light. The Apache Arrow Revolution",
          "url": "https://medium.com/@tfmv/data-at-the-speed-of-light-8e32da656de8",
          "excerpts": [
            "The Apache Arrow ecosystem eliminates this tax completely: In-memory columnar format optimized for modern CPUs, Zero-copy, zero-serialization data sharing ..."
          ]
        },
        {
          "title": "Our journey at F5 with Apache Arrow (part 1)",
          "url": "https://arrow.apache.org/blog/2023/04/11/our-journey-at-f5-with-apache-arrow-part-1/",
          "excerpts": [
            "Apr 11, 2023 — Our benchmarks thus far have shown promising results, with compression ratio improvements ranging from 1.5x to 5x, depending on the data type ( ..."
          ]
        },
        {
          "title": "Tracing Methods",
          "url": "https://thume.ca/2023/12/02/tracing-methods/",
          "excerpts": [
            "eBPF subsystem allows you to attach complex programs to all sorts of different things in the kernel and efficiently shuttle data back to userspace, basically subsuming all the legacy facilities like ftrace and kprobes such that I won’t talk about them.",
            "ace. You normally write BPF programs in C but there are perhaps even nicer toolkits for using [Zig](ht",
            "I could even include fields pulled from the packet header and NIC queue information, all at 1 million packets per second with no noticeable overhead."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface.html",
          "excerpts": [
            "Make it easy for third-party projects to implement support for (including partial\n  support where sufficient), with little initial investment. * \n  Allow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process. * \n  Match the Arrow array concepts closely to avoid the development of\n  yet another marshalling layer.",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow format.",
            "Expose an ABI-stable interface.",
            "llow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process.",
            "Zero-copy by design.",
            "The Arrow C data interface is inspired by the [Python buffer protocol](https://www.python.org/dev/peps/pep-3118/) ,\nwhich has proven immensely successful in allowing various Python libraries\nexchange numerical data with no knowledge of each other and near-zero\nadaptation cost.",
            "Allow zero-copy sharing of Arrow data between independent runtimes and components running in the same process. Match the Arrow array concepts closely to ...",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow forma",
            "Memory management",
            "The release callback MUST free any data area directly owned by the structure\n(such as the buffers and children members). The release callback MUST mark the structure as released, by setting\nits `release` member to NULL."
          ]
        },
        {
          "title": "Arrow C Data Interface and Streams",
          "url": "https://arrow.apache.org/docs/format/CStreamInterface.html",
          "excerpts": [
            "An Arrow C stream exposes a streaming source of data chunks, each with the same schema. Chunks are obtained by calling a blocking pull-style iteration function. [Apache Arrow v21.0.0 - Home](../_static/arrow-dark.png)](../index.html)",
            "The C stream interface is defined by a single `struct` definition:",
            "int ( * get_schema )( struct ArrowArrayStream * , struct ArrowSchema * out );",
            "int ( * get_next )( struct ArrowArrayStream * , struct ArrowArray * out );",
            "const char * ( * get_last_error )( struct ArrowArrayStream * );",
            "void ( * release )( struct ArrowArrayStream * );",
            "The canonical guard `ARROW_C_STREAM_INTERFACE` is meant to avoid\nduplicate definitions if two projects copy the C data interface\ndefinitions in their own headers, and a third-party project\nincludes from these two projects.",
            "The `ArrowArrayStream` provides the required callbacks to interact with a\nstreaming source of Arrow arrays. It has the following field",
            "The `ArrowArrayStream` provides the required callbacks to interact with a\nstreaming source of Arrow arrays. It has the following field"
          ]
        },
        {
          "title": "Introducing the Apache Arrow C Data Interface",
          "url": "https://arrow.apache.org/blog/2020/05/03/introducing-arrow-c-data-interface/",
          "excerpts": [
            "May 3, 2020 — Apache Arrow includes a cross-language, platform-independent in-memory columnar format allowing zero-copy data sharing and transfer between heterogenous ... This post introduces the Arrow C Data Interface, a simple C-based interoperability standard to simplify interactions between independent users and implementors of the Arrow in-memory format. Introducing the Apache Arrow C Data Interface | Apache Arrow",
            "zero-copy data sharing",
            "The C Data Interface passes Arrow data buffers through memory pointers. So,\nby construction, it allows you to share data from one runtime to\nanother without copying it. Since the data is in standard\n[Arrow in-memory format](https://arrow.apache.org/docs/format/Columnar.html),\nits layout is well-defined and unambiguous. This design also restricts the C Data Interface to *in-process* data sharing. For interprocess communication, we recommend use of the Arrow\n[IPC format",
            "Separate type and data representation",
            "For applications which produce many instances of data of a single datatype\n(for example, as a stream of record batches), repeatedly reconstructing the\ndatatype from its string encoding would represent unnecessary overhead.",
            "The C Data Interface passes Arrow data buffers through memory pointers. So,\nby construction, it allows you to share data from one runtime to\nanother without copying it.",
            "Two libraries that utilize\nthe C structures defined by the C Data Interface can do zero-copy data\ntransfers at runtime without any build-time or link-time dependency\nrequirements.",
            "The C Data Interface carries no dependencies\nexcept a shared C ABI between binaries which use it.",
            "May 3, 2020 — Apache Arrow includes a cross-language, platform-independent in-memory columnar format allowing zero-copy data sharing and transfer between heterogenous ... ",
            "For interprocess communication, we recommend use of the Arrow\n[IPC format"
          ]
        },
        {
          "title": "BPF ring buffer — The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/next/bpf/ringbuf.html",
          "excerpts": [
            "This document describes BPF ring buffer design, API, and implementation details. ... BPF ringbuf provides two sets of APIs to BPF programs:.",
            "`bpf_ringbuf_output()` allows to _copy_ data from one place to a ring\n  buffer, similarly to `bpf_perf_event_output()`",
            "`bpf_ringbuf_reserve()` / `bpf_ringbuf_commit()` / `bpf_ringbuf_discard()` APIs split the whole process into two steps. First, a fixed amount of space\n  is reserved. If successful, a pointer to a data inside ring buffer data\n  area is returned, which BPF programs can use similarly to a data inside\n  array/hash maps. Once ready, this piece of memory is either committed or\n  discarded. Discard is similar to commit, but makes consumer ignore the",
            "The ring buffer itself internally is implemented as a power-of-2 sized\ncircular buffer, with two logical and ever-increasing counters (which might\nwrap around on 32-bit architectures, that’s not a problem):",
            "consumer counter shows up to which logical position consumer consumed the\n  dat",
            "producer counter denotes amount of data reserved by all producers.",
            "Together with `BPF_RB_NO_WAKEUP` / `BPF_RB_FORCE_WAKEUP` flags for output/commit/discard\nhelpers, it allows BPF program a high degree of control and, e.g., more\nefficient batched notifications.",
            "This document describes BPF ring buffer design, API, and implementation details. ... Returned values are momentarily snapshots of ring buffer state and ..."
          ]
        },
        {
          "title": "anakryiko/bpf-ringbuf-examples",
          "url": "https://github.com/anakryiko/bpf-ringbuf-examples",
          "excerpts": [
            "This is a collection of examples showing the usage of BPF ringbuf and perfbuf APIs. Each example implements a simple tracing tool, collecting all exec() ..."
          ]
        },
        {
          "title": "C Data Interface — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/java/cdata.html",
          "excerpts": [
            "Arrow supports exchanging data without copying or serialization within the same process through the The Arrow C data interface, even between different language ..."
          ]
        },
        {
          "title": "Interface to the nanoarrow C Library",
          "url": "https://arrow.apache.org/nanoarrow/latest/r/",
          "excerpts": [
            "Example. The Arrow C Data and Arrow C Stream interfaces are comprised of three structures: the ArrowSchema which represents a data type of an array, ..."
          ]
        },
        {
          "title": "Leveraging the Arrow C Data Interface",
          "url": "https://willayd.com/leveraging-the-arrow-c-data-interface.html",
          "excerpts": [
            "Feb 20, 2024 — This blog post describes how the Arrow C Data interface works, as witnessed through transformation of the pantab library."
          ]
        },
        {
          "title": "What is eBPF? An Introduction and Deep Dive into the eBPF ...",
          "url": "https://ebpf.io/what-is-ebpf/",
          "excerpts": [
            "eBPF is a revolutionary technology with origins in the Linux kernel that can run sandboxed programs in a privileged context such as the operating system kernel."
          ]
        },
        {
          "title": "ebpf_exporter/benchmark/README.md at master",
          "url": "https://github.com/cloudflare/ebpf_exporter/blob/master/benchmark/README.md",
          "excerpts": [
            "To measure the overhead of eBPF probes we measure performance in the following cases: No probes attached; Empty probe doing nothing at all; Simple probe ..."
          ]
        },
        {
          "title": "What is the performance impact added to eBPF via kprobe ...",
          "url": "https://stackoverflow.com/questions/78572661/what-is-the-performance-impact-added-to-ebpf-via-kprobe-and-uprobe",
          "excerpts": [
            "All I can tell you is that uprobe overhead will be much higher because it has to cross to kernel space to execute the BPF program."
          ]
        },
        {
          "title": "Head Based Sampling using the OTEL Collector",
          "url": "https://squaredup.com/blog/head-based-sampling-using-the-otel-collector/",
          "excerpts": [
            "Oct 25, 2023 — Head based VS tail based sampling ... Head based sampling means that we decide whether to keep or discard each trace as early as possible (before ..."
          ]
        },
        {
          "title": "The Tail at Scale",
          "url": "https://research.google/pubs/the-tail-at-scale/",
          "excerpts": [
            "by J Dean · 2013 · Cited by 2294 — This article outlines some of the common causes of high latency episodes in large online services and describes techniques that reduce their severity."
          ]
        },
        {
          "title": "The tail at scale - Luiz André Barroso",
          "url": "https://www.barroso.org/publications/TheTailAtScale.pdf",
          "excerpts": [
            "by JR Dean · 2013 · Cited by 2294 — The 'tail' refers to high-latency episodes that can dominate performance in large-scale systems, even though rare, and are difficult to keep short.",
            "tail-tolerant software techniques form a predictable whole out of less-predictable parts.",
            "dividual components is mag-\nnified at the service level; for example, \nconsider a system where each server \ntypically responds in 10ms but with a \n99th-percentile latency of one second.",
            "Hedged requests. A simple way to \ncurb latency variability is to issue the \nsame request to multiple replicas and \nuse the results from whichever replica \nresponds fi",
            " The hedged-requests \ntechnique also has a window of vulner-\n\nability in which multiple servers can \nexecute the same request unnecessar",
            "Within Request Short-Term  \nadaptatio",
            "cross-Request  \nLong-Term adaptatio",
            "In large information-retrieval (IR) sys-\ntems, speed is more than a performance \nmetric; it is a key quality metric, as re-\nturning good results quickly is better \nthan returning the best results s"
          ]
        },
        {
          "title": "Reservoir sampling - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Reservoir_sampling",
          "excerpts": [
            "Reservoir sampling is a family of randomized algorithms for choosing a simple random sample, without replacement, of k items from a population of unknown size n"
          ]
        },
        {
          "title": "[PDF] Random Sampling with a Reservoir - UMD Computer Science",
          "url": "https://www.cs.umd.edu/~samir/498/vitter.pdf",
          "excerpts": [
            "We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown ..."
          ]
        },
        {
          "title": "The tail at scale | Communications of the ACM",
          "url": "https://dl.acm.org/doi/10.1145/2408776.2408794",
          "excerpts": [
            "Software techniques that tolerate latency variability are vital to building responsive large-scale Web services.",
            "Barroso, L.A. and Höelzle, U. The Datacenter as a Computer: An Introduction to the Design of Warehouse-scale Machines. Synthesis Series on Computer Architecture ..."
          ]
        },
        {
          "title": "Reservoir Sampling | Richard Startin's Blog",
          "url": "https://richardstartin.github.io/posts/reservoir-sampling",
          "excerpts": [
            "It's worth taking a look at the derivations of Algorithm A and Algorithm D in Vitter's paper on Faster Methods for Random Sampling first."
          ]
        },
        {
          "title": "Falco blog: Tracing Syscalls Using eBPF (Part 1)",
          "url": "https://falco.org/blog/tracing-syscalls-using-ebpf-part-1/",
          "excerpts": [
            "eBPF instrumentation will always cause a greater overhead in the system ...",
            "Ring buffers\n------------\n\neBPF ring buffer, also known as `bpf_ringbuf`, is a mechanism provided by the Linux kernel for efficient communication between eBPF programs and user-space programs"
          ]
        },
        {
          "title": "Performance of perfbuf – Patchwork patch (May 29, 2020)",
          "url": "https://patchwork.ozlabs.org/project/netdev/patch/20200529075424.3139988-5-andriin@fb.com/",
          "excerpts": [
            "May 29, 2020 — Performance of perfbuf suffers from default \"no sampling\" policy and huge overhead that causes. In sampled mode, rb-custom is winning very ... 4 benchmarks were implemented: 2 variations for each of BPF ringbuf\nand perfbuf:,\n  ",
            "  - rb-libbpf utilizes stock libbpf ring_buffer manager for reading data;",
            "  - rb-custom implements custom ring buffer setup and reading code, to\n    eliminate overheads inherent in generic libbpf code due to callback\n    functions and the need to update consumer position after each consumed\n    record, instead of batching updates (due to pessimistic assumption that\n    user callback might take long time and thus could unnecessarily hold ring\n    buffer space for too long);",
            "  - pb-libbpf uses stock libbpf perf_buffer code with all the default\n    settings, though uses higher-performance raw event callback to minimize\n    unnecessary overhead;",
            "  - pb-custom implements its own custom consumer code to minimize any possible\n    overhead of generic libbpf implementation and indirect function calls. All of the test support default, no data notification skipped, mode, as well\nas sampled mode (with --rb-sampled flag), which allows to trigger epoll\nnotification less frequently and reduce overhead. As will be shown, this mode\nis especially critical for perf buffer, which suffers from high overhead of\nwakeups in kernel. Otherwise, all benchamrks implement similar way to generate a batch of records\nby using fentry/sys_getpgid BPF program, which pushes a bunch of records in\na tight loop and records number of successful and dropped samples."
          ]
        },
        {
          "title": "Eliminating eBPF Tracing Overhead on Untraced Processes (eBPF 924, 2024)",
          "url": "https://people.cs.vt.edu/djwillia/papers/ebpf24-mookernel.pdf",
          "excerpts": [
            "Eliminating eBPF Tracing Overhead\non Untraced Processes",
            "Executing eBPF\nprograms associated with other processes not only makes tracing\nslower, but could impact the correctness of tracing by executing\neBPF programs intended for one process, on another.",
            "Copying\ntracing hookpoint state also allows for the optimization for tracing\nhookpoint text described above. After the necessary pages have been copied, the kernel view\nmanager must update the kernel page tables for each traced process.",
            "he most efficient\nper-process approach, pre-eBPF, slows down the read and sendmsg\nsystem call by 54 and 112 nanoseconds respectively, which corre-\nspond to 15% and 6% slowdown"
          ]
        },
        {
          "title": "Arrow Columnar Format",
          "url": "https://arrow.apache.org/docs/format/Columnar.html",
          "excerpts": [
            "The **Arrow columnar format** includes a language-agnostic in-memory\ndata structure specification, metadata serialization, and a protocol\nfor serialization and generic data transp",
            "Data adjacency for sequential access (scans)",
            "The Arrow columnar format provides analytical performance and data\nlocality guarantees in exchange for comparatively more expensive\nmutation operations."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html",
          "excerpts": [
            "This interface allows any library to export Arrow data structures to other libraries that understand the same protocol.",
            "The Arrow C data interface",
            " Export the object as an ArrowSchema. Returns :\n        A PyCapsule containing a C ArrowSchema representation of the\n        object. The capsule must have a name of `\"arrow_schema\"` .",
            "owSchema and ArrowArray structures. Parameters :\n        **requested\\_schema** ( _PyCapsule_ _or_ _None_ ) – A PyCapsule containing a C ArrowSchema representation\n        of a requested schema. Conversion to this schema is best-effort. See [Schema Requests]() . Returns :\n        A pair of PyCapsules containing a C ArrowSchema and ArrowArray,\n        respectively."
          ]
        },
        {
          "title": "The Apache Arrow Revolution for Data Solutions",
          "url": "https://medium.com/israeli-tech-radar/the-apache-arrow-revolution-for-data-solutions-e59bb496c60c",
          "excerpts": [
            "Apache Arrow enables composable data systems to share the same columnar data in memory or through the wire.",
            "Arrow Interop with Zero-Copy Memory Reads",
            "The Apache Arrow Revolution for Data Solutions",
            "Zero-Copy Reads. Our task is to read a bunch of XML files, process them, and write them back to disk in an ORC format. That's a given ..."
          ]
        },
        {
          "title": "OpenTelemetry Sampling",
          "url": "https://opentelemetry.io/docs/concepts/sampling/",
          "excerpts": [
            "Tail sampling is where the decision to sample a trace takes place by considering\nall or most of the spans within the trace. Tail Sampling gives you the option to\nsample your traces based on specific criteria derived from different parts of a\ntrace, which isn’t an option with Head Sampling.",
            "The OpenTelemetry Collector includes the following sampling processors:",
            "* [Probabilistic Sampling Processo",
            "* [Tail Sampling Processo",
            "Tail sampling is where the decision to sample a trace takes place by considering all or most of the spans within the trace."
          ]
        },
        {
          "title": "Tail Sampling with OpenTelemetry",
          "url": "https://opentelemetry.io/blog/2022/tail-sampling/",
          "excerpts": [
            "Tail-based sampling is where the decision to sample a trace happens *after* all\nthe spans in a request have been complete",
            "To use tail sampling in OpenTelemetry, you need to implement a component called the tail sampling processor.",
            "This component samples traces based on a set of policies that you can choose\nfrom and define.",
            "Tail sampling lets you see only the traces that are of interest to you. You also\nlower data ingest and storage costs because you’re only exporting a\npredetermined subset of your traces.",
            "There are also some limitations to consider that are related to OpenTelemetry. Note that some of these limitations also apply more broadly to any client-hosted\ntail-based sampling solution, not just OpenTelemetry.",
            "Establishing a wait period for tail sampling**: Another challenge with tail\n  sampling is that it’s hard to predict when a trace will actually be finis"
          ]
        },
        {
          "title": "eBPF Tutorial by Example 8: Monitoring Process Exit ...",
          "url": "https://medium.com/@yunwei356/ebpf-tutorial-by-example-8-monitoring-process-exit-events-print-output-with-ring-buffer-73291d5e3a50",
          "excerpts": [
            "There is now a new BPF data structure available called the eBPF ring buffer. It solves the memory efficiency and event reordering issues of the ...See more"
          ]
        },
        {
          "title": "Helper Function 'bpf_ringbuf_reserve' - eBPF Docs",
          "url": "https://docs.ebpf.io/linux/helper-function/bpf_ringbuf_reserve/",
          "excerpts": [
            "This page documents the 'bpf_ringbuf_reserve' eBPF helper function, including its definition, usage, program types that can use it, and examples."
          ]
        },
        {
          "title": "eBPF verifier",
          "url": "https://docs.kernel.org/bpf/verifier.html",
          "excerpts": [
            "eBPF verifier¶. The safety of the eBPF program is determined in two steps. First step does DAG check to disallow loops and other CFG validation."
          ]
        },
        {
          "title": "eBPF verifier — The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/v5.17/bpf/verifier.html",
          "excerpts": [
            "In order to determine the safety of an eBPF program, the verifier must track the range of possible values in each register and also in each stack slot. This is ..."
          ]
        },
        {
          "title": "Aya is an eBPF library for the Rust programming language ...",
          "url": "https://github.com/aya-rs/aya",
          "excerpts": [
            "eBPF is a technology that allows running user-supplied programs inside the Linux kernel. For more info see What is eBPF. Aya is an eBPF library built with a ..."
          ]
        },
        {
          "title": "Getting Started - Aya",
          "url": "https://aya-rs.dev/book/",
          "excerpts": [
            "This getting started guide will help you use the Rust Programming Language and Aya library to build extended Berkley Packet Filter (eBPF) programs."
          ]
        },
        {
          "title": "Classic BPF vs eBPF",
          "url": "https://www.kernel.org/doc/html/v5.17/bpf/classic_vs_extended.html",
          "excerpts": [
            "After the call the registers R1-R5 contain junk values and cannot be read. An in-kernel eBPF verifier is used to validate eBPF programs. Also in the new design, ..."
          ]
        },
        {
          "title": "Formally verifying the BPF verifier",
          "url": "https://lwn.net/Articles/1020664/",
          "excerpts": [
            "May 23, 2025 — The Linux kernel's BPF verifier is probably the first real instance of formal verification in production, Nagarakatte said."
          ]
        },
        {
          "title": "Working with Schema",
          "url": "https://arrow.apache.org/cookbook/py/schema.html",
          "excerpts": [
            "This chapter includes recipes for dealing with schemas. Contents. Working with Schema. Setting the data type of an Arrow Array. Setting the schema of a Table."
          ]
        },
        {
          "title": "C Interfaces — Apache Arrow v5.0.0",
          "url": "https://arrow.apache.org/docs/5.0/cpp/api/c_abi.html",
          "excerpts": [
            "This is documentation for an old release of Apache Arrow (version 5.0). ... The Arrow C stream interface · Other Data Structures. Libraries. Implementation ..."
          ]
        },
        {
          "title": "pyarrow.Schema — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/python/generated/pyarrow.Schema.html",
          "excerpts": [
            "A schema defines the column names and types in a record batch or table data structure. They also contain metadata about the columns."
          ]
        },
        {
          "title": "[Python] Support C stream interface of single arrays #31194 - GitHub",
          "url": "https://github.com/apache/arrow/issues/31194",
          "excerpts": [
            "It seems that the C stream interface in pyarrow currently requires the array to be a StructArray. I do not see this constraint in the spec ..."
          ]
        },
        {
          "title": "[PDF] Better algorithms for BPF - The Linux Kernel Archives",
          "url": "http://oldvger.kernel.org/bpfconf2022_material/lsfmmbpf2022-algs.pdf",
          "excerpts": [
            "- BPF_RINGBUF_SUBMIT command runs BPF prog on each sample? - Kthread to run each BPF program? - bpf_dynptr is an interface to a memory. - Need to work through ..."
          ]
        },
        {
          "title": "eBPF Verifier Code Review",
          "url": "https://www.linuxfoundation.org/hubfs/eBPF/eBPF%20Verifier%20Security%20Audit.pdf?__hstc=137369199.8da91b5f8b42a5531651a132262dd89d.1751068800153.1751068800154.1751068800155.1&__hssc=137369199.1.1751068800156&__hsfp=150561067",
          "excerpts": [
            "Nov 11, 2024 — The eBPF verifier gates eBPF programs into the kernel, verifying their safety. The review found a vulnerability to read/write kernel memory and ..."
          ]
        },
        {
          "title": "The Arrow C Device data interface",
          "url": "https://arrow.apache.org/docs/format/CDeviceDataInterface.html",
          "excerpts": [
            "The Arrow C Device data interface builds on the existing C data interface by adding a very small, stable set of C definitions",
            "Section Navigation",
            "The Arrow C Device data interface",
            "An Arrow C device stream exposes a streaming source of data chunks, each with\nthe same schema. Chunks are obtained by calling a blocking pull-style iteration\nfunction.",
            "It is expected that all chunks should be providing data on the same\ndevice type (but not necessarily the same device id).",
            "face](CStreamInterface.html) , the C Device data\ninterface also specifies a higher-level structure for easing communication\nof streaming data within a single process.",
            "Lifetime of the C stream is managed using a release callback with similar usage as in C data interface. Thread safety#. The stream source is not assumed to ..."
          ]
        },
        {
          "title": "The eBPF verifier and observability",
          "url": "https://www.groundcover.com/ebpf/ebpf-verifier",
          "excerpts": [
            "Mar 13, 2025 — The eBPF verifier is a part of the eBPF framework that checks eBPF bytecode for safety risks before they run in the Linux kernel.",
            "Directly modifying kernel source code presented the same risk, with the added drawback of requiring a tremendous amount of work.",
            "eat. Thanks to the verifier, admins can run observability code directly in kernel space without worrying about breaking their system.",
            "he verifier is not an optional component of eBPF. eBPF code _must_ pass the verifier because the kernel will execute it",
            "Thus, if you want to leverage eBPF as an observability solution – which we strongly think you should, given that [eBPF tracing](/ebpf/ebpf-tracing) offers a hyper-efficient way of monitoring and observing any process, application, or network traffic flow running on a Linux kernel – you need to use the verifier as ",
            " process, it is a key component for executing eBPF programs, which are themselves a way of collecting observability data.",
            "he eBPF verifier is not itself a tool for collecting telemetry data or otherwise assisting in the observability process, it is a key component for executing eBPF pro",
            "eBPF verifier works via a process known as static code analysis. This means it analyzes eBPF bytecode while the code is not running, looking for issues that could cause problems when the code executes",
            "Importantly, the scope of the verifier’s functionality is limited to checking for safety issues that could destabilize a system or violate kernel-level access control restrictions. It’s not a general-purpose static code analyzer.",
            "Although the verifier supports a limited range of functionality, it offers a wide range of benefits for enhancing the observability process.",
            "The design of the verifier keeps monitoring overhead low. This is because, by using the verifier to check code prior to execution, eBPF avoids having to perform checks or impose restrictions at runtime, which would be more costly in terms of CPU and memory usage.",
            "The verifier plays an important role in protecting against situations where code inside an eBPF program could access data that shouldn’t be available to it."
          ]
        },
        {
          "title": "Jan 19, 2023 — Verifying eBPF",
          "url": "https://blog.trailofbits.com/2023/01/19/ebpf-verifier-harness/",
          "excerpts": [
            "The key to eBPF safety is the eBPF verifier, which limits the set of valid eBPF programs to those that it can guarantee will not harm the kernel or cause other issues.",
            " This means that eBPF is, by design, not [Turing-complete]",
            "The verifier performs two main passes over the code. The first pass is handled by the `check_cfg()` function, which ensures that the program is guaranteed to terminate by performing an iterative depth-first search of all possible execution paths.",
            "The second pass (done in the `do_check()` function) involves static analysis of the bytecode; this pass ensures that all memory accesses are valid, that types are used consistently (e.g., scalar values are never used as pointers), and that the number of branches and total instructions is within certain complexity limits.",
            "As mentioned earlier in the post, the constraints that the verifier enforces have changed over time.",
            "One of the key benefits of eBPF is the guarantee it provides: that the loaded code will not crash the kernel, will terminate within a time limit, and will not leak information to unprivileged user processes.",
            " The harness is not the first tool that aims to improve the verifier’s testability. The IO Visor Project’s [BPF fuzzer](https://github.com/iovisor/bpf-fuzzer) has a very similar goal of running the verifier in user space and enabling efficient fuzzing—and the tool has found [at least one bug]",
            "the harness is intended to support all kernel versions, making it easy to compare the same eBPF program across kernel versions."
          ]
        },
        {
          "title": "Include build data in your program: date, rustc version, git ...",
          "url": "https://www.reddit.com/r/rust/comments/mqnbvw/builddata_include_build_data_in_your_program_date/",
          "excerpts": [
            "SOURCE_DATE_EPOCH is a standardised environment variable that distributions can set centrally and have build tools consume this in order to ...",
            "How do you calculate SOURCE_DATE_EPOCH from a git repo? I looked through the docs and didn't find a command, script, or procedure for doing it."
          ]
        },
        {
          "title": "Rust PGO and Reproducible Build Strategies (from the provided PDF)",
          "url": "https://www.datocms-assets.com/98516/1734435430-zaitsau_2024.pdf",
          "excerpts": [
            "PGO-optimized build reproducibility - save somewhere a PGO profile and use it for all builds.",
            " PGO profile reproducibility - ... Compile the program with Instrumentation:\nrustc -Cprofile-generate=/tmp/pgo-data main.rs",
            "2. Run the instrumented program with a training workload",
            "load 3. Convert the .profraw file into a .profdata file using LLVM's \nllvm-profdata  tool:",
            "llvm-profdata merge -output=merged.profdata default.profraw",
            "\n4. Compile the program again with the profiling data:\nrustc -Cprofile-use=merged.profdata main.rs",
            "29",
            "cargo-pgo - the best PGO friend",
            "Written by Jakub “ Kobzol ” Beranek ● GitHub:  https://github.com/Kobzol/cargo-pgo",
            "Supports Instrumentation PGO and LLVM BOLT",
            "Current PGO states across Rust applications",
            "PGO integration state for Rust apps",
            "\nRule of thumb: if you want PGO for something - you need to \nrebuild it",
            "Continuous Profile-Guided Optimization",
            "AFAIK, the only thing right now is \nGoogle Wide Profiler  (GWP) based  solution, \nclosed-source",
            "There is no ready-to-use open-source solution yet",
            "There is an idea about making such a platform as a part of \nGrafana  Pyroscope  or \nElasticsearch Universal Profi",
            "Can be implemented on proprietary profiling platforms like  Yandex.Perforator, Ozon.Vision, etc",
            "PGO issues in Rustc",
            "Documentation ● Toolin",
            "cargo-pgo is not ideal ○ AutoFDO migration proce",
            "Missing most advanced PGO modes",
            "Bugs",
            "[no_std] is not supported by default*\n○ But can be achieved with  mini"
          ]
        },
        {
          "title": "vadimcn/cargo-pgo: Supercharge you Rust programs!",
          "url": "https://github.com/vadimcn/cargo-pgo",
          "excerpts": [
            "Merge profiles. Before using generated profiles, they must be first merged into an 'indexed' format: cargo pgo merge."
          ]
        },
        {
          "title": "Audit trail & MIR - compiler",
          "url": "https://internals.rust-lang.org/t/audit-trail-mir/7839",
          "excerpts": [
            "Jun 30, 2018 — An auditing tool could scan for #[safe] blocks, generate their MIR, and attach it in the note as audit data. If the audited code is changed, the ..."
          ]
        },
        {
          "title": "rust-fuzz/afl.rs: 🐇 Fuzzing Rust code with American Fuzzy Lop",
          "url": "https://github.com/rust-fuzz/afl.rs",
          "excerpts": [
            "A popular, effective, and modern fuzz testing tool based on AFL. This library, afl.rs, allows one to run AFLplusplus on code written in the Rust programming ...See more"
          ]
        },
        {
          "title": "BurntSushi/quickcheck: Automated property based testing ...",
          "url": "https://github.com/BurntSushi/quickcheck",
          "excerpts": [
            "QuickCheck is a way to do property based testing using randomly generated input. This crate comes with the ability to randomly generate and shrink integers, ..."
          ]
        },
        {
          "title": "cargo-auditable - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-auditable",
          "excerpts": [
            "The embedded dependency list uses under 4kB even on large dependency trees with 400+ entries. This typically translates to between 1/1000 ..."
          ]
        },
        {
          "title": "Performing Audits - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/performing-audits.html",
          "excerpts": [
            "Cargo vet suggest can estimate the lowest-effort audits you can perform to reduce the number of entries in exemptions, and consequently, your attack surface."
          ]
        },
        {
          "title": "Reproducible Builds in June 2022",
          "url": "https://reproducible-builds.org/reports/2022-06/",
          "excerpts": [
            "Luckily, as one of the responses mentions: “the --remap-path-prefix solves this problem and has been used to great effect in build systems that rely on ..."
          ]
        },
        {
          "title": "Setting codegen-units to 1 gives even better code quality ...",
          "url": "https://news.ycombinator.com/item?id=36681703",
          "excerpts": [
            "Setting codegen-units to 1 gives even better code quality than thin local LTO, but takes longer. Some authors of binary rust crates always use that setting ..."
          ]
        },
        {
          "title": "rust-secure-code/cargo-auditable: Make production Rust binaries ...",
          "url": "https://github.com/rust-secure-code/cargo-auditable",
          "excerpts": [
            "Audit binaries for known bugs or security vulnerabilities in production, at scale, with zero bookkeeping."
          ]
        },
        {
          "title": "cargo-sbom - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-sbom",
          "excerpts": [
            "Jun 16, 2025 — This crate provides a command line tool to create software bill of materials (SBOM) for Cargo / Rust workspaces. It supports both SPDX and CycloneDX outputs."
          ]
        },
        {
          "title": "Commands - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/commands.html",
          "excerpts": [
            "This section documents the command-line interface of cargo vet. The documentation is automatically generated from the implementation, and so it may be ..."
          ]
        },
        {
          "title": "cargo-auditable - Crates.io",
          "url": "https://crates.io/crates/cargo-auditable/versions",
          "excerpts": [
            "Make production Rust binaries auditable. 20 of 20 cargo-auditable versions since July 31st, 2022. Sort by Date Date SemVer"
          ]
        },
        {
          "title": "When reproducible builds? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/jct0y4/when_reproducible_builds/",
          "excerpts": [
            "In some domains, it is very important to be able to reproducibly rebuild a binary from the sources. This is cargo/rustc pretty bad at."
          ]
        },
        {
          "title": "Caller-side inline directives - language design",
          "url": "https://internals.rust-lang.org/t/caller-side-inline-directives/19078",
          "excerpts": [
            "It would be nice if I could use a caller-side inline directive, as recently introduced by clang, instead of having to go codegen-units = 1 or fat LTO."
          ]
        },
        {
          "title": "CycloneDX/cyclonedx-rust-cargo",
          "url": "https://github.com/CycloneDX/cyclonedx-rust-cargo",
          "excerpts": [
            "The CycloneDX module for Rust (Cargo) creates a valid CycloneDX Software Bill of Materials (SBOM) containing an aggregate of all project dependencies."
          ]
        },
        {
          "title": "cargo-vet 0.10.1",
          "url": "https://docs.rs/crate/cargo-vet/latest",
          "excerpts": [
            "The cargo vet subcommand is a tool to help projects ensure that third-party Rust dependencies have been audited by a trusted entity. It strives to be ..."
          ]
        },
        {
          "title": "Rust Cargo PGO and BOLT – Kobzol blog",
          "url": "https://kobzol.github.io/rust/cargo/2023/07/28/rust-cargo-pgo.html",
          "excerpts": [
            "Jul 28, 2023 — cargo pgo has your back! With cargo pgo test or cargo pgo bench , you can generate profiles by running instrumented tests or benchmarks, and ... I created a simple example of a GitHub Actions workflow that shows how this could be done. Going beyond PGO",
            "The (LLVM-based) PGO implementation offered by the Rust compiler is just one of many existing so-called\nFeedback-directed optimization (FDO) tools, which leverage some sort of runtime profiles to better\noptimize programs.",
            "rams. Another such tool is a post-link optimizer called BOLT . “Post-link” means that it takes a fully compiled and linked program binary as an input, and then uses\nprofiles to optimize the binary, even without access to its source code. This differs from “classic”\nPGO, which optimizes the program during compilation, and thus has access to its source code. Its main\ngoal is to better reorganize instructions within the binary, in particular to improve instruction cache\nutilization. BOLT is a part of LLVM, and can provide additional performance improvements even on top of an already\nPGO-optimized binary.",
            "Last year, I have enabled BOLT for LLVM 3 used by the Rust compiler, which resulted in ~2-5% cycle improvements across the board."
          ]
        },
        {
          "title": "Hacker News discussion thread excerpt on Rust PGO and determinism",
          "url": "https://news.ycombinator.com/item?id=25060762",
          "excerpts": [
            "Does PGO mean the build products are non-deterministic? ie if you build the Rust compiler twice you get different bits.",
            "It would be deterministic for a given set of input profile data, but would likely change every time you instrumented a new profile",
            "BOLT just permutes link order? The object permutation from a BOLT run should be good for months until the underlying objects have substantially drifted?"
          ]
        },
        {
          "title": "Securing the Software Supply Chain: Recommended Practices for Developers",
          "url": "https://www.cisa.gov/sites/default/files/publications/ESF_SECURING_THE_SOFTWARE_SUPPLY_CHAIN_DEVELOPERS.PDF",
          "excerpts": [
            "The production build environment is where reproducible deliverables are built.",
            "The artifacts for builds should include, at a minimum, the source repository, the third-party \ndependencies, the build script, and the output of the build",
            "For reproducible builds, the artifact should be the \noutput of the script that compares the builds",
            "The third party's SBOM can be compared with the SBOM produced by the SCA tools."
          ]
        },
        {
          "title": "How can I include the build date in an executable - help",
          "url": "https://users.rust-lang.org/t/how-can-i-include-the-build-date-in-an-executable/102024",
          "excerpts": [
            "Nov 3, 2023 — The recommendation is to use the SOURCE_DATE_EPOCH env var if it is set: SOURCE_DATE_EPOCH — reproducible-builds.org. 6 Likes. mark November 3 ..."
          ]
        },
        {
          "title": "refix: fast, debuggable, reproducible builds",
          "url": "https://yosefk.com/blog/refix-fast-debuggable-reproducible-builds.html",
          "excerpts": [
            "There's a simple way to make your builds all of the following: Reproducible/deterministic - same binaries always built from the same source, ..."
          ]
        },
        {
          "title": "Profiles - The Cargo Book",
          "url": "https://doc.rust-lang.org/cargo/reference/profiles.html",
          "excerpts": [
            "codegen-units. The codegen-units setting controls the -C codegen-units flag which controls how many “code generation units” a crate will be split into. More ..."
          ]
        },
        {
          "title": "Codegen Options - The rustc book",
          "url": "https://doc.rust-lang.org/rustc/codegen-options/index.html",
          "excerpts": [
            "When -C lto is not specified, LTO is disabled if codegen units is 1 or optimizations are disabled ( -C opt-level=0 ). That is: When -C lto is not specified:."
          ]
        },
        {
          "title": "An Introduction To Property-Based Testing In Rust",
          "url": "https://lpalmieri.com/posts/an-introduction-to-property-based-testing-in-rust/",
          "excerpts": [
            "Jan 3, 2021 — There are two mainstream options for property-based testing in the Rust ecosystem: quickcheck and proptest . Their domains overlap, although ..."
          ]
        },
        {
          "title": "How to Sign an SBOM with Cosign",
          "url": "https://edu.chainguard.dev/open-source/sigstore/cosign/how-to-sign-an-sbom-with-cosign/",
          "excerpts": [
            "Note the warnings — a record of the attestation will be recorded to an immutable log maintained by the Sigstore project. When you're ready, ..."
          ]
        },
        {
          "title": "Introduction - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/",
          "excerpts": [
            "The cargo vet subcommand is a tool to help projects ensure that third-party Rust dependencies have been audited by a trusted entity."
          ]
        },
        {
          "title": "`cargo audit` can now scan compiled binaries : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/yk7l3w/cargo_audit_can_now_scan_compiled_binaries/",
          "excerpts": [
            "I've been working to bring vulnerability scanning to Rust binaries by creating cargo auditable, which embeds the list of dependencies and their versions into ..."
          ]
        },
        {
          "title": "Sigstore Bundle Format",
          "url": "https://docs.sigstore.dev/about/bundle/",
          "excerpts": [
            "A Sigstore bundle is everything required to verify a signature on an artifact. This is satisfied by the Verification Material and signature Content."
          ]
        },
        {
          "title": "cargo-auditable(1) - Arch Linux manual pages",
          "url": "https://man.archlinux.org/man/cargo-auditable.1.en",
          "excerpts": [
            "The embedded dependency list uses under 4kB even on large dependency trees with 400+ entries. This typically translates to between 1/1000 and 1/10,000 of the ..."
          ]
        },
        {
          "title": "Rust Internals: rustdoc binary is not reproducible",
          "url": "https://internals.rust-lang.org/t/rustdoc-binary-is-not-reproducible/20027",
          "excerpts": [
            "Hello,\n\nWe've observed that 'rustdoc' is not reproducible in our Yocto build environment. The below differences are observed between multiple builds (The rust sources are not changed between builds). The diff in shown in _\".strtab\" & \".shstrtab\"_ sections of the binary. [<img src='https://us1.discourse-cdn.com/flex002/uploads/rustlang/original/2X/9/977de908e21d44b771b12d13b0c18a3011a52891.png' alt='image-1' width='690' height='333' /",
            "PGO for something like rustdoc seems like overkill, no? <img src='https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12' alt=':slight_smile:' width='20' height='20' />",
            "`.llvm.<hash>` suffixes are added by LLVM's thinLTO to prevent symbol collisions when making a symbol marked as internal external to enable inlining across the LLVM modules that participate in thinLTO. As for why it would differ, I have no clue. (You are not using PGO, right? PGO profile generation is not deterministic due to among other things threading.)",
            "PGO `profiler = true` in our rust build environment. Setting `profiler = false` alone not fixed the issue, there is dependent option `tools = [\"rust-demangler\",]` , when these both are set the issue is fixed.",
            "`.llvm.<hash>` suffixes are added by LLVM's thinLTO to prevent symbol collisions when making a symbol marked as internal external to enable inlining across the LLVM modules that participate in thinLTO",
            "This topic was automatically closed 90 days after the last reply. New replies are no longer allowed."
          ]
        },
        {
          "title": "Timesys — SBOM Generation and Vulnerability Monitoring for the Crates.io/Rust Ecosystem",
          "url": "https://www.timesys.com/security/sbom-generation-and-vulnerability-monitoring-for-the-crates-io-rust-ecosystem/",
          "excerpts": [
            "Jun 5, 2024 — Syft is our preferred tool for generating SBOMs due to its compliance with SPDX/CycloneDX specs and compatibility with Vigiles.",
            "Jun 5, 2024 — In this post, we'll explore the Rust ecosystem, specifically Cargo/Crates.io, and discuss the significance of SBOMs and Software Composition ...",
            "An SBOM is a comprehensive inventory of software components",
            "In the Rust ecosystem, maintaining an accurate SBOM is crucial due to the rapidly evolving landscape of libraries and dependencies available on Crates.io.",
            "Streamlining SBOM and Vulnerability Management with Syft and Vigiles",
            "Vigiles pulls from multiple security advisories, including but not limited to the National Vulnerability Database (NVD) and OSV (GitHub Security Advisory, PyPI Advisory, Go Vulnerability Database, Rust Advisory, Haskell Security Advisories, OSS-Fuzz, Debian Security Advisories, RConsortium Advisory).",
            "Using Syft to generate your SBOMs allows you to maintain a detailed inventory of your software components and dependencies."
          ]
        },
        {
          "title": "debug_info_for_profiling - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/debug_info_for_profiling.html",
          "excerpts": [
            "Unlike PGO (controlled by the rustc flags -Cprofile-generate and -Cprofile-use ), a binary being profiled does not perform significantly worse, and thus it's ..."
          ]
        },
        {
          "title": "Kobzol/cargo-pgo: Cargo subcommand for optimizing Rust ...",
          "url": "https://github.com/Kobzol/cargo-pgo",
          "excerpts": [
            "Cargo subcommand that makes it easier to use PGO and BOLT to optimize Rust binaries. For an example on how to use cargo-pgo to optimize a binary on GitHub ..."
          ]
        },
        {
          "title": "Reproducible builds: Automatically remap $CARGO_HOME and ...",
          "url": "https://github.com/rust-lang/cargo/issues/5505",
          "excerpts": [
            "I tried adding --remap-path-prefix flag but still the binaries are not reproducible. But, I suspect my change is effective or not, can anyone ..."
          ]
        },
        {
          "title": "cargo_pgo - Rust",
          "url": "https://docs.rs/cargo-pgo",
          "excerpts": [
            "This crate contains a Cargo subcommand designed for simplifying the usage of feedback-directed optimizations for Rust crates."
          ]
        },
        {
          "title": "[PDF] MirChecker: Detecting Bugs in Rust Programs via Static Analysis",
          "url": "https://www.cse.cuhk.edu.hk/~cslui/PUBLICATION/CCS2021.pdf",
          "excerpts": [
            "The design of MirChecker is presented in Section 4, and we illustrate how Abstract Interpretation is performed on our language model in Section ..."
          ]
        },
        {
          "title": "MIRAI/documentation/Overview.md at main",
          "url": "https://github.com/facebookexperimental/MIRAI/blob/main/documentation/Overview.md",
          "excerpts": [
            "Aug 22, 2024 — A decision was made to use Rust, but the analysis concluded that support for static analysis tools for Rust was one of the few areas where Rust ..."
          ]
        },
        {
          "title": "Detecting Bugs in Rust Programs via Static Analysis",
          "url": "https://dl.acm.org/doi/10.1145/3460120.3484541",
          "excerpts": [
            "Nov 13, 2021 — In this paper, we present and evaluate MirChecker, a fully automated bug detection framework for Rust programs by performing static analysis on Rust's Mid- ..."
          ]
        },
        {
          "title": "facebookexperimental/MIRAI: Rust mid-level IR Abstract ...",
          "url": "https://github.com/facebookexperimental/MIRAI",
          "excerpts": [
            "Aug 22, 2024 — MIRAI is an abstract interpreter for the Rust compiler's mid-level intermediate representation (MIR). It started out as a Facebook project, but became orphaned."
          ]
        },
        {
          "title": "lizhuohua/rust-mir-checker - GitHub",
          "url": "https://github.com/lizhuohua/rust-mir-checker",
          "excerpts": [
            "This tool tries to analyze the MIR generated by the Rust compiler and emit diagnostic messages. It is based on the theory of Abstract Interpretation."
          ]
        },
        {
          "title": "Static Assurance (1/2)",
          "url": "https://highassurance.rs/chp2/static_assurance_1.html",
          "excerpts": [
            "Static analysis tools often use a layer of indirection that simplifies answering a particular question. They map the constructs of P to an analysis-specific ..."
          ]
        },
        {
          "title": "rustc_middle::mir::interpret",
          "url": "https://doc.rust-lang.org/beta/nightly-rustc/rustc_middle/mir/interpret/index.html",
          "excerpts": [
            "An interpreter for MIR used in CTFE and by miri. Modules§. allocation: The virtual memory representation of the MIR interpreter. error; pointer ..."
          ]
        },
        {
          "title": "SBOM support in Rust",
          "url": "https://ferrous-systems.com/blog/stackable-client/",
          "excerpts": [
            "Jul 30, 2024 — A project proposal to improve the generation of Software Bill of Materials (SBOM) in the Rust eco-system."
          ]
        },
        {
          "title": "CycloneDX Tool Center",
          "url": "https://cyclonedx.org/tool-center/",
          "excerpts": [
            "Beniva SBOM allows you to consume CycloneDX SBOM and Vulnerability Exploitability eXchange (VEX) within the ServiceNow platform which increases visibility of ..."
          ]
        },
        {
          "title": "Choosing an SBOM Generation Tool",
          "url": "https://openssf.org/blog/2025/06/05/choosing-an-sbom-generation-tool/",
          "excerpts": [
            "Jun 5, 2025 — Many tools exist to generate SBOMs, and we've spent some time with the different options to help you decide."
          ]
        },
        {
          "title": "Surface Rust dependency relationships #2353 - anchore/syft",
          "url": "https://github.com/anchore/syft/issues/2353",
          "excerpts": [
            "Nov 24, 2023 — What happened: Syft not created \"dependencies\" in cyclonedx report for Go, Rust, Java and etc. Cargo.lock had \"dependencies\"."
          ]
        },
        {
          "title": "Pre-RFC: Cargo SBOM",
          "url": "https://internals.rust-lang.org/t/pre-rfc-cargo-sbom/19842",
          "excerpts": [
            "Nov 8, 2023 — A SBOM (software bill of materials) is a list of all components and dependencies used to build a piece of software. The two leading SBOM formats ..."
          ]
        },
        {
          "title": "cargo::core::compiler::output_sbom",
          "url": "https://doc.rust-lang.org/nightly/nightly-rustc/cargo/core/compiler/output_sbom/index.html",
          "excerpts": [
            "Build an Sbom for the given Unit . build_sbom_graph: List all dependencies, including transitive ones. A dependency can also appear multiple times if it's ..."
          ]
        },
        {
          "title": "Rust reproducibility and PGO discussion (GitHub issue discussion)",
          "url": "https://github.com/rust-lang/rust/issues/79442",
          "excerpts": [
            "The blog post contains a step by step description of how to obtain a PGOed compiler -- but it is rather time consuming to actually do that. In order to make things easier I could provide a branch of the compiler that has all the changes already applied and, more importantly, a pre-recorded, checked-in `.profdata` file for both LLVM and rustc. Alternatively, I could just put up the final toolchain for download somewhere. Even better would be to make it available via rustup somehow.",
            "* This makes `rustc` builds non-reproducible -- something which I don't think is true. With a fixed `.profdata` file, both rustc and Clang should always generate the same output. That is `-Cprofile-use` and `-fprofile-use` do not introduce any source of randomness, as far as I can tell. So if the `.profdata` file being used is tracked by version control, we should be fine.",
            "You get the same profile data if (and only if) the workload is deterministic. If there is some source of randomness, like if pointers are being ... ](/rust-lang/rust/security)",
            "t the build into three separate tasks: the instrumented build, the profile collection, the optimized build.",
            ". For Firefox builds, we settled on being comfortable with publishing the profile data and making sure that the optimized build step was deterministic given that same input.",
            ". This also helped us enable PGO for cross-compiled builds like the macOS build on Linux.",
            "Please post any feedback that you might have below!"
          ]
        },
        {
          "title": "High Assurance Rust: Developing Secure and Robust Software",
          "url": "https://highassurance.rs/",
          "excerpts": [
            "The State-of-the-Art in Practical Software Assurance",
            "### [_Developing Secure and Robust Software_]()",
            "ou'll learn Rust - a modern, multi-paradigm language that emphasizes speed and correctness. Most programming books teach a new language by presenting a dozen small, unrealistic programs. Not this one. We'll design, write, and validate a fully-featured alternative to the ordered map and set implementations in Rust's standard library. You'll gain a deep understanding of the Rust language by re-implementing one of its major dynamic collections, one idiomatic API at a time. Unlike the standard version, our implementation will be:\n\n* \n  **Maximally Safe. ** Upholds Rust's strongest memory safety guarantees, for all possible executions. + To test properties the compiler can't prove, we'll learn advanced program analysis techniques, including _differential fuzzing_ and _deductive verification_ \\*. * \n  **Extremely Portable. ** Capable of running on every operating system, or even without one (e.g. \"bare metal\").\n+ Our library is a _hardened component_ . To integrate it within larger codebases, we'll add _CFFI bindings_ to make the Rust functions callable from other languages - including C and Python. * \n  **Highly Available. ** Offers _fallible_ APIs for handling cases that could otherwise result in a crash. + E.g. _Out-of-Memory (OOM) error_ \\- when all pre-allocated memory has been exhausted.",
            "## [The State-of-the-Art in Practical Software Assurance]()",
            "We'll use cutting-edge, open-source software assurance tools to validate the code we write in this book. Some of these tools are mature and used in commercial industry:\n\n* `rustc` (modern compiler)\n* `libFuzzer` (fuzz testing framework)\n* `rr` (\"time-travel\" debugger)\n* `qemu` (whole-system emulator)\n\nOther tools are experimental and under active research. A full inventory is available in [the appendix](../chp16_appendix/tools.html) . Visually, this book covers the below topics (contrasted roughly on tradeoff of **development speed** and **formal rigor** ). Don't worry, we'll provide clear explanations and context for each. Notice the bias toward development speed. We're interested in **lightweight processes** that, in the long run, enable us to **ship quality code faster** and spend **less time patching** security and reliability failures. Techniques you can apply to real-world code. Today.",
            "We'll use cutting-edge, open-source software assurance tools to validate the code we write in this book. Some of these tools are mature and used in commercial industry:\n\n* `rustc` (modern compiler)\n* `libFuzzer` (fuzz testing framework)\n* `rr` (\"time-travel\" debugger)\n* `qemu` (whole-system emulator)\n\nOther tools are experimental and under active research. A full inventory is available in [the appendix](../chp16_appendix/tools.html) . Visually, this book covers the below topics (contrasted roughly on tradeoff of **development speed** and **formal rigor** ). Don't worry, we'll provide clear explanations and context for each. Notice the bias toward development speed. We're interested in **lightweight processes** that, in the long run, enable us to **ship quality code faster** and spend **less time patching** security and reliability failures. Techniques you can apply to real-world code. Today."
          ]
        },
        {
          "title": "How to properly use --remap-path-prefix?",
          "url": "https://users.rust-lang.org/t/how-to-properly-use-remap-path-prefix/104406",
          "excerpts": [
            "I want to strip references to the build directory and the general setup on the computer that build the binary. As I understand it, I'm supposed to use --remap- ..."
          ]
        },
        {
          "title": "remap-path-prefix",
          "url": "https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/unstable-book/compiler-flags/remap-path-prefix.html",
          "excerpts": [
            "This is useful for bringing debuginfo paths into a well-known form and for achieving reproducible builds independent of the directory the compiler was executed ..."
          ]
        },
        {
          "title": "remap_cwd_prefix - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/remap-cwd-prefix.html",
          "excerpts": [
            "This flag will rewrite absolute paths under the current working directory, replacing the current working directory prefix with a specified value. The given ..."
          ]
        },
        {
          "title": "SOURCE_DATE_EPOCH — reproducible-builds.org",
          "url": "https://reproducible-builds.org/docs/source-date-epoch/",
          "excerpts": [
            "SOURCE_DATE_EPOCH specifies the last modification of something, usually the source code, measured in the number seconds since the Unix epoch."
          ]
        },
        {
          "title": "Deterministic build systems",
          "url": "https://reproducible-builds.org/docs/deterministic-build-systems/",
          "excerpts": [
            "A software cannot easily be built reproducibly if the source varies depending on factors that are hard or impossible to control like the ordering of files."
          ]
        },
        {
          "title": "Certifiable Rust - Electronic Design",
          "url": "https://www.electronicdesign.com/technologies/embedded/software/video/55273394/electronic-design-rust-can-be-certified-for-safe-and-secure-applications",
          "excerpts": [
            "This Rust toolset meets ISO 26262 (ASIL D), IEC 61508 (SIL 4), and IEC 62304 certifications. It's open source and available on Linux, QNX Neutrino, and various ..."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "Installing and Using Ferrocene",
          "url": "https://rust-training.ferrous-systems.com/latest/book/ferrocene-installing",
          "excerpts": [
            "Qualified, or not; Host or Cross-compiled. Qualified Targets. Production Ready; Passes the Rust Test Suite; Support is available; Signed qualification material."
          ]
        },
        {
          "title": "Software Tool Qualification in ISO 26262 Development - Embitel",
          "url": "https://www.embitel.com/blog/embedded-blog/why-is-software-tool-qualification-indispensable-in-iso-26262-based-software-development",
          "excerpts": [
            "Nov 2, 2020 — Clause 11 of Part-8 of the ISO 26262 standard comprises the ISO 26262 tool qualification methods. As per the standard, ISO 26262 tool ...",
            "a TCL is assigned, which reflects the level of confidence that can be placed in the tool to perform its intended functions without introducing unacceptable risks.",
            "The tables will make it clearer.",
            "rd**\n\nThe tool qualification methods prescribed in the standard for TCL 2 and TCL 3 are almost similar, with a slight difference based on [ASIL",
            "rd**\n\nThe tool qualification methods prescribed in the standard for TCL 2 and TCL 3 are almost similar, with a slight difference based on [ASIL"
          ]
        },
        {
          "title": "IEC 61508 – Why Tool Qualification",
          "url": "https://61508.org/wp-content/uploads/2024/11/09B-IEC-61508-Why-tool-qualification_V2_cut.pdf",
          "excerpts": [
            "... T1, T2 and T3 support tools shall be justified, for each tool in class T3, evidence shall be available that the tool conforms to its specification or ...",
            "T1 tool is selected as part of the requirement of software configuration management tool. • Deficiency of IEC 61508: tool qualification requirements for T2 & T3 ..."
          ]
        },
        {
          "title": "ISO 26262-6:2018 - Product development at the software level - GitLab",
          "url": "https://about.gitlab.com/solutions/iso-26262/",
          "excerpts": [
            "ISO 26262-6:2018 prescribes ways to identify and mitigate safety risks for automotive applications. These methods depend on so-called Automotive Safety ..."
          ]
        },
        {
          "title": "Ferrocene Update",
          "url": "https://ferrous-systems.com/blog/sealed-rust-the-plan/",
          "excerpts": [
            "Feb 13, 2020 — Ferrocene is the effort led by Ferrous Systems GmbH to qualify the Rust language and compiler for use in mission and safety-critical domains."
          ]
        },
        {
          "title": "Ferrocene - ISO 26262 and IEC 61508 qualified rust compiler",
          "url": "https://lobste.rs/s/qhohlx/ferrocene_iso_26262_iec_61508_qualified",
          "excerpts": [
            "The aim is to ensure there's a formal chain of traceability that goes from everything an end user compiled to the features you tested and found ..."
          ]
        },
        {
          "title": "Software Tools: It's as Easy as T1, T2, T3 - EngineerZone",
          "url": "https://ez.analog.com/ez-blogs/b/engineerzone-spotlight/posts/software-tools",
          "excerpts": [
            "Nov 28, 2018 — This blog discusses requirements related to offline software tools found in standards such as IEC 61508, ISO 26262 and D0-178C/D0-330."
          ]
        },
        {
          "title": "Efficient and Trustworthy Tool Qualification for Model- ...",
          "url": "https://inria.hal.science/hal-01482408v1/document",
          "excerpts": [
            "In this paper we review the tool quali- fication requirements of the standards ISO 26262 (automotive domain) and the new RTCA DO-178C (avionic ..."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "One of the primary partitioning strategies in ARINC 653 is time and space partitioning. Time partitioning involves dividing the system's ...",
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Incremental Assurance of Multicore Integrated Modular Avionics (IMA)",
          "url": "https://ieeexplore.ieee.org/document/9594404/",
          "excerpts": [
            "DO-297/ED-124 defines incremental acceptance as a \"process for obtaining credit toward approval and certification by accepting or finding that an IMA module ..."
          ]
        },
        {
          "title": "Parasoft ISO 26262 Software Compliance Technical Whitepaper",
          "url": "https://alm.parasoft.com/hubfs/New_Pages/Whitepaper%20ISO%2026262%20Software%20Compliance%20With%20Parasoft.pdf",
          "excerpts": [
            "ISO 26262 is a functional safety standard covering the entire automotive product development process, with Part 6 addressing software development. Wh",
            "Part 8, section 11, describes the software   tool qualification proces",
            "Tools that automate  software development activities and tasks can  significantly help organizations meet ISO 26262  requiremen",
            "The information presented  here is intended to serve as an introduction to  ISO 26262 software verification and validation  processes with Paraso"
          ]
        },
        {
          "title": "Ferrocene: Qualified Rust toolchain for safety-critical systems",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles. It’s qualified at ASIL-D, the highest risk class, for peace of mind.",
            "ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or your choice of RTOS.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels.",
            "Qualified for automotive, industrial and medical development. ... ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or ...See more",
            "ull qualification\ndocuments. [Read\nDocumentation](https://public-docs.ferrocene.dev/main/index.html)",
            "TÜV SÜD conducted the audit and Ferrous Systems – leading Rust experts – supports the signed installers as well as the nightly builds.",
            "The source code of Ferrocene is\nfully open source under the MIT OR Apache-2.0 license, including the full qualification\ndocuments."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "We’ve qualified\nFerrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database. ",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "This standard provides automakers\nwith guidelines that make the software being used to develop, produce, operate\nand service the automotive sectors safe to use.",
            "Beyond the automotive, Ferrocene can also be used in electronic programmable\nsystems in the industrial sector. Here the focus is on developing products or\napplications that carry out safety functions.",
            "This means we achieved qualification for the open source Ferrocene toolchain.",
            "With these qualifications, Rust can now be used to develop software for\nelectronic systems in series production road vehicles.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "This is\nthe first qualification of a Rust compiler.",
            "This is\nthe first qualification of a Rust compiler.",
            "Ferrocene is ISO 26262 and IEC 61508 qualified!"
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "formal verification in general is stronger than other\n   traditional ways of gaining trust in software such as testing in that\n   it can prove the _absence_ of bugs, not just their\n ",
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft"
          ]
        },
        {
          "title": "Implications of the seL4 Verification",
          "url": "https://sel4.systems/Verification/implications.html",
          "excerpts": [
            "The proofs not only establish functional correctness, integrity, and confidentiality, but they also imply the absence of many common programming errors. They give you the reasons why and how\n data structures work, why it is safe to optimise and leave out certain checks\n (because you know they will always be true), and why the code always\n executes in a defined and safe mann"
          ]
        },
        {
          "title": "Ferrocene Achieves IEC 62304 Qualification",
          "url": "https://ferrous-systems.com/blog/ferrocene-achieves-iec-62304-qualification/",
          "excerpts": [
            "It is qualified to automotive (ISO 26262, ASIL-D), industrial development (IEC 61508, SIL4) and medical (IEC 62304, Class C) standards, with ..."
          ]
        },
        {
          "title": "IEC 61508 Ensuring Software Compliance",
          "url": "https://www.qa-systems.com/solutions/iec-61508/",
          "excerpts": [
            "Part 3 of IEC 61508 addresses the software requirements of a safety-related system mandating the use of better development processes, including the use of ..."
          ]
        },
        {
          "title": "ISO 26262-8:2011(en), Road vehicles — Functional safety",
          "url": "https://www.iso.org/obp/ui/#iso:std:iso:26262:-8:ed-1:en",
          "excerpts": [
            "ISO 26262 includes guidance to avoid these risks by providing appropriate requirements and processes. System safety is achieved through a number of safety ..."
          ]
        },
        {
          "title": "DO-330 Introduction – Tool Qualification",
          "url": "https://afuzion.com/do-330-introduction-tool-qualification/",
          "excerpts": [
            "This DO-330 whitepaper describes the five tool categories versus criticality levels (DALs) and how to truly qualify avionics software tools."
          ]
        },
        {
          "title": "r/rust - Ferrous Systems Donates Ferrocene Language ...",
          "url": "https://www.reddit.com/r/rust/comments/1jkfovo/ferrous_systems_donates_ferrocene_language/",
          "excerpts": [
            "... DO-178C is, in my understanding, the big requirement here. ... Now that we are here: what's the progress on DO-178 (DO-330) certification?"
          ]
        },
        {
          "title": "Ferrous Systems First to Run Rust on Cortex-R52 Under ...",
          "url": "https://www.businesswire.com/news/home/20250311274388/en/Ferrous-Systems-First-to-Run-Rust-on-Cortex-R52-Under-Open-Source-License",
          "excerpts": [
            "Ferrocene is the first open-source ... certified versions of libcore and guidance on instruction tracing for software certification."
          ]
        },
        {
          "title": "Ferrocene 25.05.0 now available! - Ferrous Systems",
          "url": "https://ferrous-systems.com/blog/ferrocene-25-05-0/",
          "excerpts": [
            "ferrocene.dev) is the first Rust compiler toolchain qualified for safety- and mission-critical systems. It is qualified to ISO 26262 (TCL 3/ASIL D), IEC 61508 (T3/SIL 4) and IEC 62304 (Class C) with TÜV SÜD.",
            "In addition, we have elevated two of our experimental targets to qualified status:\n\n* Armv7E-M bare-metal (soft-float) (`thumbv7em-none-eabi`)\n* Armv7E-M bare-metal (hard-float) (`thumbv7em-none-eabi"
          ]
        },
        {
          "title": "DO-330 Software tool qualification considerations",
          "url": "https://ldra.com/do-330/",
          "excerpts": [
            "DO-330 “Software Tool Qualification Considerations” states that “Software tools are widely used in multiple domains, to assist in developing, verifying, and ..."
          ]
        },
        {
          "title": "Leveraging ISO 26262 tool certification in IEC 61508",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2020/12/17/leveraging-iso-26262-tool-certification-in-iec-61508/",
          "excerpts": [
            "Dec 17, 2020 — Tools are assessed as T1, T2 or T3. T1 tools are tools which have no impact on safety or where there is a high degree of confidence that tool ..."
          ]
        },
        {
          "title": "Industry Standards | MOSA DO-178C FAA FACE EASA ...",
          "url": "https://www.ddci.com/resources/industry-standards/",
          "excerpts": [
            "Nov 15, 2024 — ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning ... DO-178C DAL A for this ...",
            "ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning in safety-critical avionics that ..."
          ]
        },
        {
          "title": "Shenango: achieving high CPU efficiency for latency-sensitive ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323265",
          "excerpts": [
            "Shenango achieves comparable latencies but at far greater CPU efficiency. It reallocates cores across applications at very fine granularity--every 5 μs."
          ]
        },
        {
          "title": "Clearing the Fog of ISO 26262 Tool Qualification",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2022/04/13/clearing-the-fog-of-iso-26262-tool-qualification/",
          "excerpts": [
            "The setting of TI and TD ultimately determines the TCL for the tool based on the table below, found in ISO 26262-8:2018 Clause 11.4.5.",
            "ISO 26262 dictates that tools used in the development of safety-critical electronics be assessed, and it guides this analysis by defining three terms:",
            "Tool Impact (TI): | This is an evaluation of the potential of a tool to introduce or fail to detect error",
            " Tool Detection (TD) | This is an evaluation of the confidence that the tool will prevent the malfunctioning of a software tool, and the standard defines:  **TD1**:  High confidence that a malfunction will be prevented or detected. **TD2**: Medium confidence that a malfunction will be prevented or detected. **TD3**:",
            "Tool Confidence Level (TCL) | An establishment of tool confidence based on TI and TD and the standard defines:  **TCL1**:  High level of confidence. No further qualification methods are required. **TCL2**:  Medium level of confidence. Further qualification methods are required. **TCL3**: Low level of confidence. Further qualification metho",
            " provides four methods for performing tool qualification (ISO 26262-8:2018 Clause 11.4.6)."
          ]
        },
        {
          "title": "MathWorks/Avionics Certification – A complete guide to DO-178 (tool qualification overview for ISO 26262, IEC 61508, and DO-178C)",
          "url": "https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/m/61793_CMR10-16.pdf",
          "excerpts": [
            " \nSoftware Tool Documentation",
            " \nSoftware Tool Classification Analysis",
            " \nSoftware Tool Qualification Report",
            " Tool qualification can be carried out for individual tools as well as for \ntool chains or sets of tools.",
            "The ISO/DIS 26262 tool qualification process requires the creation of the following tool \nqualification work products (ISO/DIS 26262-8, 11.5; see the appendix for a summary):",
            " \nSoftware Tool Qualification Plan",
            " \nSoftware Tool Qualification Plan",
            "• Software Tool Documentation",
            "• Software Tool Classification Analysis",
            "\n• Software Tool Qualification Report",
            ". 2.4 Software Tool Documentation (STD)",
            ". 2.6 Software Tool Qualification Report (STQR)"
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage.",
            "Proofs and Certification\n\nThe traditional way to achieve high levels of assurance are schemes\nsuch as Common Criteria, ISO-26262, and DO-178C. The seL4 proofs go\nbeyond what these certification schemes require for software\ndevelopment at their most stringent levels.",
            "The traditional way to achieve high levels of assurance are schemes such as Common Criteria, ISO-26262, and DO-178C."
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Remote attestation Implementation - BlindAI - Mithril Security",
          "url": "https://blindai.mithrilsecurity.io/en/latest/docs/security/remote_attestation/",
          "excerpts": [
            "The first one, is EPID attestation which relies on using Intel services to attest that an enclave on specific platforms is verified. The second one is DCAP ( ..."
          ]
        },
        {
          "title": "GlobalPlatform Entity Attestation Protocol Specification",
          "url": "https://globalplatform.org/wp-content/uploads/2024/07/GPP_EntityAttestationProtocolSpec_v0.0.0.26_PublicRvw2.pdf",
          "excerpts": [
            "Remote Attestation \nThe process by which attestation information is assembled by an Entity \nAttestation Service, transferred to a Relying Party, and processe",
            "The IETF NNNN specification ([draft-ietf-rats-eat]) introduces the concept of Attestation, which is a mechanism \n45 \nby which an Entity can provide information about itself with some level of assurance to a Relying Par",
            "During Attestation, an Entity \n47 \nAttestation Service builds a set of Claims, each of which consists of a piece of evidence provided by a Clai"
          ]
        },
        {
          "title": "seL4: formal verification of an OS kernel",
          "url": "https://cseweb.ucsd.edu/~dstefan/cse227-spring20/papers/sel4.pdf",
          "excerpts": [
            "by G Klein · 2009 · Cited by 3032 — ABSTRACT. Complete formal verification is the only known way to guar- antee that a system is free of programming errors."
          ]
        },
        {
          "title": "The seL4 Microkernel An Introduction",
          "url": "https://cdn.hackaday.io/files/1713937332878112/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 1 — This white paper gives an overview of seL4. ... In a capability-based system, such as seL4, invoking a capability is the one and only way."
          ]
        },
        {
          "title": "Introduction to SGX - Gramine documentation - Read the Docs",
          "url": "https://gramine.readthedocs.io/en/stable/sgx-intro.html",
          "excerpts": [
            "The Provisioning Certification Enclave is used in DCAP based remote attestation. This enclave communicates with the Intel Provisioning Certification Service ( ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.11/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM ... Refresh expired {TCB info, PCK CRLs, QE Identity, QvE Identity,. Root CA CRL} ..."
          ]
        },
        {
          "title": "[PDF] Intel® Software Guard Extensions (Intel® SGX) Data Center ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.7/linux/docs/Intel_SGX_ECDSA_QuoteLibReference_DCAP_API.pdf",
          "excerpts": [
            "Deployment Tool for PCK Certificate Chain Retrieval for Intel® SGX DCAP ... the PCK Certificate that the quote verifier uses to certify the attestation key."
          ]
        },
        {
          "title": "in-toto and SLSA",
          "url": "https://slsa.dev/blog/2023/05/in-toto-and-slsa",
          "excerpts": [
            "May 2, 2023 — It defines the Provenance predicate to record the build characteristics of the produced artifacts. The specification describes how to verify ..."
          ]
        },
        {
          "title": "Overview",
          "url": "https://docs.sigstore.dev/cosign/signing/overview/",
          "excerpts": [
            "This document explains how identity-based, or “keyless” signing works in Sigstore. To learn more about OIDC, please review OIDC Usage in Fulcio."
          ]
        },
        {
          "title": "Provenance",
          "url": "https://slsa.dev/spec/v0.1/provenance",
          "excerpts": [
            "Description of SLSA provenance specification for verifying where, when, and how something was produced."
          ]
        },
        {
          "title": "Secure Software Updates via TUF — Part 2",
          "url": "https://medium.com/@mulgundmath/secure-software-updates-via-tuf-part-2-412c6a2b10ab",
          "excerpts": [
            "Next in the file is the assignment of keys to roles such as root, targets, snapshot, and timestamp; all four need to be mandatorily listed ( ..."
          ]
        },
        {
          "title": "Use Sigstore for keyless signing and verification",
          "url": "https://docs.gitlab.com/ci/yaml/signing_examples/",
          "excerpts": [
            "The Sigstore project provides a CLI called Cosign which can be used for keyless signing of container images built with GitLab CI/CD."
          ]
        },
        {
          "title": "Securing the Software Supply Chain: How in-toto and TUF ...",
          "url": "https://www.infoq.com/presentations/software-supply-chain-security/",
          "excerpts": [
            "Nov 28, 2023 — Marina Moore covers the fundamentals of both in-toto and TUF, and discusses how to combine them with a real world case study where Datadog has been using two ..."
          ]
        },
        {
          "title": "Securing the Software Supply Chain: How in-toto and TUF ...",
          "url": "https://qconnewyork.com/presentation/jun2023/securing-software-supply-chain-how-toto-and-tuf-work-together-combat-supply",
          "excerpts": [
            "Jun 13, 2023 — The framework connects security efforts such as SLSA, Sigstore, and SBOMs, where signed and verifiable in-toto attestations are used to express ..."
          ]
        },
        {
          "title": "Signing Containers",
          "url": "https://docs.sigstore.dev/cosign/signing/signing_with_containers/",
          "excerpts": [
            "You can use Cosign to sign containers with ephemeral keys by authenticating with an OIDC (OpenID Connect) protocol supported by Sigstore."
          ]
        },
        {
          "title": "SigstoreCon 2024: Advancing Software Supply Chain ...",
          "url": "https://openssf.org/blog/2024/12/16/sigstorecon-2024-advancing-software-supply-chain-security/",
          "excerpts": [
            "Dec 16, 2024 — The one-day conference brought together developers, maintainers, and security experts to explore how Sigstore is transforming software supply chain security."
          ]
        },
        {
          "title": "Intel SGX DCAP Orientation Guide",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.9/linux/docs/Intel_SGX_DCAP_ECDSA_Orientation.pdf",
          "excerpts": [
            "Attestation is the process of demonstrating that a software executable is properly instantiated on a platform.",
            "The Intel® SGX Provisioning Certification \nService offers APIs for retrieving \nprovisioning certification key (PCK) \ncertificates, certificate revocation lists, \nTrusted Computing Base \n(TCB) information, the Intel quoting enclave (QE) \nidentity, and the Intel quote verification enclave \n(QVE) id",
            "The caching service for the Intel® SGX provisioning certification \nservice allows a CSP or a datacenter to cache PCK certificates, \nPCK certificate revocation lists (CRL), TCB Information, QE \nidentity and QVE Identity structures for all platforms in its data \ncen",
            "The current release of the reference can be \nconfigured to fill its cache in a few ways. i. Fill the cache using a push mechanism. The caching service will queue the PCK Certificate IDs \nuploaded by the PCK Certificate ID Retrieval Too",
            "The platform quote provider library provides a set of APIs \nthat abstract platform implementation specific functions",
            "e platform quote provider library \nthat works in conjunction with the reference caching \nservice (see ‘Caching Service for the Intel® SGX \nprovisioning certification service’ below) to provide this \ninformation to the quote lib",
            "The quote verification library can run on both platforms \nwith SGX and without SGX. When the platform supports \nSGX, the library can return an SGX REPORT authenticating \nthe verification result was produced by the Intel® SGX \nQuote Verification Enclave (Q"
          ]
        },
        {
          "title": "Remote Attestation on Arm TrustZone OP-TEE with ...",
          "url": "https://fosdem.org/2025/schedule/event/fosdem-2025-4952-remote-attestation-on-arm-trustzone-op-tee-with-veraison-verifier-current-status-and-future-plan-/",
          "excerpts": [
            "We report on the attestation mechanism implemented in OP-TEE, a trusted OS running on the Arm Cortex-A TrustZone. This mechanism generates attestation evidence ..."
          ]
        },
        {
          "title": "OP-TEE Remote Attestation with VERAISON Verification",
          "url": "https://github.com/OP-TEE/optee_os/issues/6921",
          "excerpts": [
            "Jun 27, 2024 — The PTA provides a general mechanism to make a RA evidence. It measures the hash of the TA and signs the hash. The RA evidence is verified by Veraison verifier.",
            "Jun 27, 2024 — We have customized OP-TEE (a Secure OS for Arm Cortex-A TrustZone) to enable Remote Attestation with VERAISON Verification."
          ]
        },
        {
          "title": "RFC 9783 - Arm's Platform Security Architecture (PSA) Attestation ...",
          "url": "https://datatracker.ietf.org/doc/rfc9783/",
          "excerpts": [
            "This document specifies the structure and semantics of the PSA attestation token. The PSA attestation token is a profile of the Entity Attestation Token (EAT)."
          ]
        },
        {
          "title": "RFC 9711 - The Entity Attestation Token (EAT) - IETF Datatracker",
          "url": "https://datatracker.ietf.org/doc/rfc9711/",
          "excerpts": [
            "An Entity Attestation Token (EAT) is a message made up of claims about an entity. An entity may be a device, some hardware, or some software."
          ]
        },
        {
          "title": "Attestation & Entity Attestation Tokens Explained - PSA Certified",
          "url": "https://www.psacertified.org/blog/what-is-an-entity-attestation-token/",
          "excerpts": [
            "An EAT token is encoded in either one of two standardized data formats: a compact binary format (CBOR) or in the text-based format JSON. A ..."
          ]
        },
        {
          "title": "draft-ietf-rats-eat-21 - The Entity Attestation Token (EAT)",
          "url": "https://datatracker.ietf.org/doc/draft-ietf-rats-eat/21/",
          "excerpts": [
            "The Entity Attestation Token (EAT) draft-ietf-rats-eat-21 · Authors, Laurence Lundblade , Giridhar Mandyam , Jeremy O'Donoghue , Carl Wallace · Last updated ..."
          ]
        },
        {
          "title": "Threat modeling for drivers (Windows hardware drivers threat model)",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/driversecurity/threat-modeling-for-drivers",
          "excerpts": [
            "Aug 31, 2023 — This section applies the principles of threat modeling to driver design and provides examples of threats to which a driver might be susceptible. ](images/sampledataflowdiagramkernelmodedriver.gif)\n\n",
            "Kernel-mode drivers must validate data that originates in user mode.",
            "The driver in the figure receives data from a user process in the following types of requests:\n\n* Create, read, and write requests (IRP\\_MJ\\_CREATE, IRP\\_MJ\\_READ, or IRP\\_MJ\\_WRITE)\n* Public device I/O control requests (IRP\\_MJ\\_DEVICE\\_ CON",
            "In response to these requests, output data and status information flow from the driver back to the user process.",
            "ess. Finally, the driver receives data from the device because of device I/O operations or user actions (such as opening the tray on a CD drive) that change device status.",
            "The previous figure shows driver data flow at a broad conceptual level. Each circle represents a relatively large task and lacks detail.",
            "Information enters the driver because of requests from the operating system, requests from a user process, or requests (typically interrupts) from the device.",
            "Information enters the driver because of requests from the operating system, requests from a user process, or requests (typically interrupts) from the device. The driver in the previous figure receives data from the operating system in several types of req",
            "the circle labeled “Handle I/O Requests” might be expanded into a separate diagram, similar to the following figure. ! [Expanded data flow diagram for I/O requests, showing separate tasks for each type of I/O request. ](images/expandeddataflowdiagramiorequests.gif)",
            "The second diagram shows separate tasks for each type of I/O request in the first diagram. (For simplicity, data paths to the device have been omitted.)",
            "...",
            "The resulting images could be corrupted, but system administrators would have no way to determine which user caused the problem.",
            "Information disclosure** threats are exactly as the name implies: the disclosure of information to a user who does not have permission to see it. Any driver that passes information to or from a user buffer is susceptible to information disclosure threat",
            "Denial-of-service** attacks threaten the ability of valid users to access resource"
          ]
        },
        {
          "title": "The CHERI capability model: Revisiting RISC in an age of ...",
          "url": "https://ieeexplore.ieee.org/document/6853201",
          "excerpts": [
            "by J Woodruff · 2014 · Cited by 475 — We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection."
          ]
        },
        {
          "title": "CHERI OS-feature matrix",
          "url": "https://www.morello-project.org/cheri-feature-matrix/",
          "excerpts": [
            "Operating systems can implement CHERI software features along several axes. This table captures key axes, and describes the maturity of those features for ..."
          ]
        },
        {
          "title": "Arm Morello Program",
          "url": "https://www.arm.com/architecture/cpu/morello",
          "excerpts": [
            "Morello is a research program with the potential to radically change the way we design and program processors in the future to improve built-in security."
          ]
        },
        {
          "title": "Morello Prototype Architecture - Arm Developer",
          "url": "https://developer.arm.com/Architectures/Morello",
          "excerpts": [
            "The Morello architecture is a prototype CPU architecture that introduces a new approach to security and is part of the wider Morello program."
          ]
        },
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        },
        {
          "title": "Review the TPM measured boot log",
          "url": "https://developer.arm.com/documentation/107981/latest/SystemReady-compliance-testing---BBSR-and-Security-Interface-Testing-FAQ/How-do-I-test-for-Base-Boot-Security-Requirements--BBSR--compliance-/Review-the-ACS-test-result-logs/Review-the-TPM-measured-boot-log",
          "excerpts": [
            "Verify that the cumulative SHA256 measurements from the event log match the TPM PCRs 0-7. The events logged in the TPM event log must match the actual ..."
          ]
        },
        {
          "title": "IMA and EVM Concepts — IMA 1.0 documentation",
          "url": "https://ima-doc.readthedocs.io/en/latest/ima-concepts.html",
          "excerpts": [
            "The IMA-Appraisal feature is local, and requires neither a TPM nor a separate verifier. IMA-Audit augments the system's audit log with the file hash. This can ..."
          ]
        },
        {
          "title": "Forward Secure Sealing (FSS) in Systemd-Journal - Learn Netdata",
          "url": "https://learn.netdata.cloud/docs/logs/systemd-journal-logs/forward-secure-sealing-fss-in-systemd-journal",
          "excerpts": [
            "Forward Secure Sealing (FSS) is a feature in the systemd journal designed to detect log file tampering . Given that attackers often try to hide their actions by modifying or deleting log file entries, FSS provides administrators with a mechanism to identify any such unauthorized alterations."
          ]
        },
        {
          "title": "[PDF] Security Threats and Opportunities in One-Sided Network ...",
          "url": "https://cseweb.ucsd.edu/~yiying/one-sided-security.pdf",
          "excerpts": [
            "One-sided network communication technologies such as. RDMA and NVMe-over-Fabrics are quickly gaining adoption in production software and in datacenters."
          ]
        },
        {
          "title": "[PDF] Changes in NVM Express® Specifications",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM-Express-Revision-Changes-2025.08.01.pdf",
          "excerpts": [
            "This technical proposal enables sanitize operations to be performed on individual namespaces, as opposed to the entire. NVM subsystem. 2.1.1.1."
          ]
        },
        {
          "title": "A journey to optimize GDRDMA in cloud scenario",
          "url": "https://lpc.events/event/18/contributions/1685/attachments/1424/3047/ATS%20vs%20IOMMU-lyan.pdf",
          "excerpts": [
            "The journey involves optimizing GDRDMA in cloud, using GPU Direct RDMA, ACS/ATS, IOMMU, and enabling ATS from both RC and EP."
          ]
        },
        {
          "title": "[PDF] Securing RDMA for High-Performance Datacenter Storage Systems",
          "url": "https://www.usenix.org/system/files/hotcloud20_paper_simpson.pdf",
          "excerpts": [
            "In general, systems leverage one-sided RDMA operations when possible, as these operations are faster and reduce remote. CPU usage. This section analyzes the ..."
          ]
        },
        {
          "title": "7 Incident Response Metrics and How to Use Them",
          "url": "https://securityscorecard.com/blog/how-to-use-incident-response-metrics/",
          "excerpts": [
            "These seven incident response metrics and how to use them can provide you with a way to reduce risk and respond to incidents more efficiently."
          ]
        },
        {
          "title": "Security Analysis of Forward Secure Log Sealing in Journald",
          "url": "https://eprint.iacr.org/2023/867",
          "excerpts": [
            "Forward-secure log sealing is a cryptographic technique used to ensure the integrity of past log entries even in the event of a full system ..."
          ]
        },
        {
          "title": "Trusted Platform Module (TPM) event logs",
          "url": "https://docs.trustauthority.intel.com/main/articles/articles/ita/tpm-log.html",
          "excerpts": [
            "Oct 25, 2024 — By replaying the event log and comparing the result with the PCR value, you can verify the integrity of the log itself. Once the log integrity ..."
          ]
        },
        {
          "title": "Integrity Measurement Architecture (IMA) / Wiki / Home",
          "url": "https://sourceforge.net/p/linux-ima/wiki/Home/",
          "excerpts": [
            "Before EVM is activated, any requested integrity appraisals are unknown, so the EVM startup should be done early in the boot process, preferably entirely within ..."
          ]
        },
        {
          "title": "What is Security Logging and Monitoring?",
          "url": "https://www.bitlyft.com/resources/what-is-security-logging-and-monitoring",
          "excerpts": [
            "System logs are designed to provide relevant information that allows you to understand and identify issues that become threats to your network."
          ]
        },
        {
          "title": "An Introduction to CHERI",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/",
          "excerpts": [
            "CHERI is a\nhybrid capability architecture in that it is able to blend\narchitectural capabilities with conventional MMU-based\narchitectures and microarchitectures,\nand with conventional software stacks based on virtual memory and C/C++. This approach allows incremental deployment within existing software\necosystems, which we have demonstrated through extensive hardware and software\nprototyping.",
            "We formalise key intended security properties of the ISA specifications, and establish that these hold with mechanised proof."
          ]
        },
        {
          "title": "CHERI/Morello Security and End-to-End Model",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-morello.html",
          "excerpts": [
            "Morello is an industrial demonstrator of a capability architecture: a prototype System-on-Chip (SoC) and development board, developed by Arm."
          ]
        },
        {
          "title": "CHERIoT: a study in CHERI (RISCV.org blog)",
          "url": "https://riscv.org/blog/2024/08/cheriot-a-study-in-cheri/",
          "excerpts": [
            "CHERIoT provides a layered security model. At the core, CHERIoT provides object-granularity (spatial and temporal) memory safety.",
            "The hardware provides low-level guarantees, such as unforgeable pointers, the ability to ensure that pointers to marked memory regions cannot be used, and a lightweight way of making pointers into opaque tamper-proof tokens.",
            "Sealing a CHERI capability turns it into an opaque token. You can pass it around as you would any other pointer, but you cannot dereference or modify it.",
            "The seal operation takes another capability with a permit-seal permission and embeds the value of that capability in the *object type* of the sealed capabilit",
            "A CHERI capability can be stored in memory or in registers and is protected by *guarded manipulation*: Operations may reduce the rights that a capability conveys, but not increase the",
            "The tag bit is a simple attestation from the hardware that says that this capability was created by following these rules, starting with one of the all-powerful capabilities provided at boot and then constrained by layers of software in the system.",
            "CHERI capability, that can be used to represent pointers. These carry bounds and permissions, in addition to an address. A CHERI capability ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 9.0.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-9.0.1.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree ... By calling seL4 CNode Revoke() on the original capability to an ...",
            "The tree structure so generated is termed the capability derivation tree (CDT). ... The seL4 CNode Revoke() method will seL4 CNode Delete ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/latest/dcap-latest/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "TCB Info,. QE Identity. QVE Identity. PCK Certificate. IDs. +. Cached PCK, CRLs ... DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM. DCAP ..."
          ]
        },
        {
          "title": "[PDF] PSA Certified Attestation API 1.0 - GitHub Pages",
          "url": "https://arm-software.github.io/psa-api/attestation/1.0/IHI0085-PSA_Certified_Attestation_API-1.0.3.pdf",
          "excerpts": [
            "IETF Entity Attestation Token (EAT), Draft. ... defined in Arm's Platform Security Architecture (PSA) Attestation Token [PSATOKEN]."
          ]
        },
        {
          "title": "ietf-rats-wg/eat: Entity Attestation Token IETF Draft Standard - GitHub",
          "url": "https://github.com/ietf-rats-wg/eat",
          "excerpts": [
            "This is the working area for the IETF RATS Working Group Internet-Draft, \"The Entity Attestation Token (EAT)\". Editor's Copy · Working Group Draft ..."
          ]
        },
        {
          "title": "Sealing and unsealing data in TPM",
          "url": "https://community.infineon.com/t5/Blogs/Sealing-and-unsealing-data-in-TPM/ba-p/465547",
          "excerpts": [
            "Aug 9, 2023 — Sealing is essentially encrypting data based on certain conditions. TPM allows decryption only if the conditions defined during encryption are satisfied."
          ]
        },
        {
          "title": "Part 4: Under the Hood — DMA, IOMMU, BARs, and VFIO | ...",
          "url": "https://medium.com/gpu-kernel-hacking-for-engineers/part-4-under-the-hood-dma-iommu-bars-and-vfio-45b4f13e545c",
          "excerpts": [
            "VFIO (Virtual Function I/O) allows safe, isolated access to PCI devices from user space, making it critical for: Containerized GPU apps ..."
          ]
        },
        {
          "title": "Understand PCR banks on TPM 2.0 devices",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/tpm/switch-pcr-banks-on-tpm-2-0-devices",
          "excerpts": [
            "To bind the use of a TPM based key to a certain state of the device, the key can be sealed to an expected set of PCR values. For instance, PCRs 0 through 7 ..."
          ]
        },
        {
          "title": "[PDF] Trusted Platform Module 2.0 Library Part 1: Architecture",
          "url": "https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-1-Architecture-Version-184-rc2_20Dec24.pdf",
          "excerpts": [
            "An NV Index is space that is defined by a user of the TPM. The ... For a Counter NV Index with the TPMA_NV_ORDERLY attribute, Index ..."
          ]
        },
        {
          "title": "[PDF] TPM 2.0 Part 1 - Architecture - Trusted Computing Group",
          "url": "https://trustedcomputinggroup.org/wp-content/uploads/TPM-Rev-2.0-Part-1-Architecture-01.07-2014-03-13.pdf",
          "excerpts": [
            "15.3 NV Index Handles (MSO=0116). An NV Index is associated with a persistent TPM resource created by TPM2_NV_DefineSpace(). 15.4 Session ..."
          ]
        },
        {
          "title": "10. Security Support - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides/howto/security.html",
          "excerpts": [
            "This document describes the security features of interest for DPDK. This guide will provides information on each protocol, including supported algorithms."
          ]
        },
        {
          "title": "Unlocking Secure High-Performance Networking with ...",
          "url": "https://www.dpdk.org/high-performance-networking-with-dpdk-security-framework/",
          "excerpts": [
            "This document outlines the security protocols and implementations supported within DPDK, serving as a guide for both users and contributors."
          ]
        },
        {
          "title": "wolfTPM support for sealing/unsealing based on externally ...",
          "url": "https://www.wolfssl.com/wolftpm-support-for-sealing-unsealing-based-on-externally-signed-pcr/",
          "excerpts": [
            "Dec 14, 2023 — With the TPM 2.0 specification, it's possible to seal/unseal secrets via cryptographic signatures of the PCR's, removing the requirement to ..."
          ]
        },
        {
          "title": "Leveraging Trusted Platform Modules (TPM) for Cryptographic ...",
          "url": "https://www.researchgate.net/publication/392693928_Leveraging_Trusted_Platform_Modules_TPM_for_Cryptographic_Anchoring_and_Remote_Attestation_of_UEFI_Capsule_Updates_in_Secure_Boot_Environments",
          "excerpts": [
            "A TPM monotonic counter is a non-volatile register that ... ○ PCR extension and monotonic counter simulation to verify rollback protection."
          ]
        },
        {
          "title": "Verify Boot | Android Open Source Project",
          "url": "https://source.android.com/docs/security/features/verifiedboot/verified-boot",
          "excerpts": [
            "Rollback protection is typically implemented by using tamper-evident storage to record the most recent version of the Android and refusing to ..."
          ]
        },
        {
          "title": "2. Features Overview - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-18.05/nics/features.html",
          "excerpts": [
            "Supports starting/stopping a specific Rx/Tx queue of a port. [implements] eth_dev_ops: rx_queue_start , rx_queue_stop , tx_queue_start , tx_queue_stop ..."
          ]
        },
        {
          "title": "[PATCH v3 24/25] net/spnic: support Tx/Rx queue start/stop ...",
          "url": "http://inbox.dpdk.org/dev/1bc4636e940682b02279711ae1714b22c958086a.1640332922.git.songyl@ramaxel.com/",
          "excerpts": [
            "... packets can be received to host. when stopping rx queue, the PMD driver will poll the rx queue until it is empty and release the mbuf, then the PMD driver ..."
          ]
        },
        {
          "title": "lib/librte_ether/rte_ethdev.h File Reference - DPDK",
          "url": "https://doc.dpdk.org/api-1.6/rte__ethdev_8h.html",
          "excerpts": [
            "Check if the DD bit of the specific RX descriptor in the queue has been set. Parameters. port_id, The port identifier of the Ethernet device. queue_id, The ..."
          ]
        },
        {
          "title": "rte_eth_dev_owner_delete(3) — dpdk-doc — Debian testing",
          "url": "https://manpages.debian.org/testing/dpdk-doc/rte_eth_dev_owner_delete.3",
          "excerpts": [
            "Check the status of a Rx descriptor in the queue. It should be called in a similar context than the Rx function: on a dataplane core; not ..."
          ]
        },
        {
          "title": "[RFE] Quiesce filesystem during VM snapshots · Issue #1795 - GitHub",
          "url": "https://github.com/flatcar/Flatcar/issues/1795",
          "excerpts": [
            "Missing: DMA NIC NVMe GPU rings checkpoint"
          ]
        },
        {
          "title": "Best practice for Snapshots? : r/vmware - Reddit",
          "url": "https://www.reddit.com/r/vmware/comments/bh80jx/best_practice_for_snapshots/",
          "excerpts": [
            "Missing: DMA NVMe GPU rings checkpoint"
          ]
        },
        {
          "title": "ccNVMe: Crash-Consistent NVMe over PCIe (RDMA and PCIe integration) – ACM/DL basis",
          "url": "https://dl.acm.org/doi/full/10.1145/3568428",
          "excerpts": [
            "The key idea of ccNVMe is to couple the crash consistency to the data dissemination; a transaction (a set of requests that must be executed atomically) is guaranteed to be crash consistent when it is about to be dispatched over PCIe.",
            "ccNVMe makes the submission queues durable in case of a sudden crash, and rings the doorbells in the unit of a transaction rather than a request, to let the requests of a transaction reach the same state (e.g., all or nothing), thereby achieving atomicity.",
            "ccNVMe rings the doorbell when all requests within a transaction arrive or when the number of work requests exceeds a pre-defined threshold (half of the queue depth by default), whichever happens earlier; this reduces the number of CPU-initiated doorbells and resolves issue 1 from Section 3.2 .",
            "The transaction-aware doorbell can also improve the performance of NIC-initiated DMAs.",
            "During crash recovery, ccNVMe finds the unfinished transactions and leaves the specific recovery algorithms (e.g., rollback) to upper layer systems.",
            "The data dissemination mechanism of the original NVMe already tracks the lifecycle (e.g., submitted or completed) of each request in the hardware queues and doorbells.",
            "ccNVMe leverages this feature to submit and complete the transaction in an ordered and atomic fashion, and makes the tracked lifecycles persistent for recovery, thereby letting the software ensure crash consistency by taking the free rides of the data dissemination MMIOs."
          ]
        },
        {
          "title": "XRSTOR — Restore Processor Extended States",
          "url": "https://www.felixcloutier.com/x86/xrstor",
          "excerpts": [
            "Performs a full or partial restore of processor state components from the XSAVE area located at the memory address specified by the source operand."
          ]
        },
        {
          "title": "How Debuggers Work: Getting and Setting x86 Registers, Part 2",
          "url": "https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/",
          "excerpts": [
            "The XSAVE and XRSTOR family of instructions can be used to save and restore the registers introduced by newer instruction sets, eg the YMM registers introduced ..."
          ]
        },
        {
          "title": "Intel x86-64 XSAVE/XRSTOR",
          "url": "https://stackoverflow.com/questions/22105247/intel-x86-64-xsave-xrstor",
          "excerpts": [
            "I'm a CS student writing in Intel x86-64 assembly, compiling with nasm , and running on an Core i7 processor with Ubuntu 12.04 as the guest OS."
          ]
        },
        {
          "title": "managing state using the xsave feature set",
          "url": "https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol1/o_7281d5ea06a5b67a-307.html",
          "excerpts": [
            "CHAPTER 13. MANAGING STATE USING THE XSAVE FEATURE SET. The XSAVE feature set extends the functionality of the FXSAVE and FXRSTOR instructions (see Section ..."
          ]
        },
        {
          "title": "setcontext - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Setcontext",
          "excerpts": [
            "setcontext is one of a family of C library functions (the others being getcontext, makecontext and swapcontext) used for context control."
          ]
        },
        {
          "title": "getcontext or setcontext Subroutine - IBM",
          "url": "https://www.ibm.com/docs/en/aix/7.3.0?topic=g-getcontext-setcontext-subroutine",
          "excerpts": [
            "The getcontext subroutine initalizes the structure pointed to by ucp to the current user context of the calling process."
          ]
        },
        {
          "title": "Can you explain the concept of CUDA context switching and its ...",
          "url": "https://massedcompute.com/faq-answers/?question=Can%20you%20explain%20the%20concept%20of%20CUDA%20context%20switching%20and%20its%20impact%20on%20application%20performance?",
          "excerpts": [
            "Latency Overhead: Each context switch requires time to save and restore GPU states, leading to delays in execution. Reduced GPU Utilization: Frequent ..."
          ]
        },
        {
          "title": "What is the context switching mechanism in GPU? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/6605581/what-is-the-context-switching-mechanism-in-gpu",
          "excerpts": [
            "As I know, GPUs switch between warps to hide the memory latency. ... context switch requires saving registers to memory and restoring them."
          ]
        },
        {
          "title": "CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads",
          "url": "https://arxiv.org/html/2502.16631v1",
          "excerpts": [
            "Feb 23, 2025 — The AMD GPU plugin enables transparent checkpoint/restore using input/output control (ioctl) operations with the Kernel Fusion Driver (KFD)."
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage: 4 Key Features, Ecosystem & ...",
          "url": "https://cloudian.com/guides/data-security/nvidia-gpudirect-storage-4-key-features-ecosystem-use-cases/",
          "excerpts": [
            "By ensuring data coherence, GPUDirect Storage minimizes synchronization issues and supports real-time processing requirements. This feature is crucial for ..."
          ]
        },
        {
          "title": "Jetson tk1 took long latency for image transfer to device through ...",
          "url": "https://forums.developer.nvidia.com/t/jetson-tk1-took-long-latency-for-image-transfer-to-device-through-opencv-gpu/43229",
          "excerpts": [
            "The overall process takes long latency ( gpuImage.upload → debayer → gpuImage.download ) It's about 1.8ms for average, and sometimes it swift to 10ms!"
          ]
        },
        {
          "title": "ASRock hidden Memory Context Restore overrides AMD's option ...",
          "url": "https://www.reddit.com/r/overclocking/comments/18avhx1/psa_asrock_hidden_memory_context_restore/",
          "excerpts": [
            "The Asrock memory context restore option only appears when you set the memory clock to something other than \"Auto.\" And apparently, this option overrides AMD's ..."
          ]
        },
        {
          "title": "How to re-init the context after cudaResetDevice, now ERROR",
          "url": "https://forums.developer.nvidia.com/t/how-to-re-init-the-context-after-cudaresetdevice-now-error-cudaerrorcontextisdestroyed/263505",
          "excerpts": [
            "There is no cudaResetDevice, but there is a cudaDeviceReset(). The only recovery method when using the runtime API is to terminate the owning host process."
          ]
        },
        {
          "title": "SPDK NVMe Driver I/O Path - My Blog",
          "url": "https://jingliu.me/posts/2021-01-20-spdkio.html",
          "excerpts": [
            "Jan 20, 2021 — The NVMe completion queue is an array of completion queue entries. Inside those entries is a CID value that SPDK provided on command submission."
          ]
        },
        {
          "title": "PyNVMe3 Script Development Guide",
          "url": "https://pynv.me/ssd/dev-guide/",
          "excerpts": [
            "Feb 19, 2025 — PyNVMe3 supports different policies for updating admin SQ Doorbell when initializing the Admin queue. By default, PyNVMe3's NVMe driver updates ..."
          ]
        },
        {
          "title": "Dataflow function offload to reconfigurable processors",
          "url": "https://patents.google.com/patent/US11392740B2/en",
          "excerpts": [
            "... RDMA, VXLAN overlays and NVMe-oF functionality. A SmartNIC may include host kernel-bypass logic for sending and receiving packets to/from nodes and ..."
          ]
        },
        {
          "title": "IBM z17 (9175) Technical Guide",
          "url": "https://www.redbooks.ibm.com/redbooks/pdfs/sg248579.pdf",
          "excerpts": [
            "... restore steady-state operations quickly. z/OS SVC memory dump processing and ... (RDMA) over Converged Ethernet. (RoCE) is a network protocol that ..."
          ]
        },
        {
          "title": "DPDK MLX5 PMD RX queue deferred start",
          "url": "https://forums.developer.nvidia.com/t/dpdk-mlx5-pmd-rx-queue-deferred-start/250805",
          "excerpts": [
            "Hi, I'm using DPDK with the MLX5 PMD to receive UDP packets. In order to receive UDP packets only, I use DPDK's Flow API, which requires ..."
          ]
        },
        {
          "title": "X86-64 Context Saving Practices",
          "url": "https://stackoverflow.com/questions/75680863/which-contexts-need-to-be-saved-in-x86-64-with-a-c-function-return",
          "excerpts": [
            "For x86-64 System V, that's only RSP, RBP, RBX, and R12-R15. Everything else is call clobbered, like RFLAGS, all the vector regs, AVX-512 mask regs, and x87",
            "The status bits in MXCSR are also basically call-clobbered, but if you want different threads to have different FP environments (e.g. rounding mode and FTZ/DAZ), then you *do* need to save/restore that. Same for the x87 control register, maybe not the status register. MPX is deprecated now so you probably don't need to worry about `bnd0-3`. If you want to have per-task performance-counter stuff, you could save/restore the PMU performance counters like Linux does of PAPI / perf.",
            "Thread-local storage using `fsbase` or `gsbase` should be saved/restored if your OS or user-space uses it. There are MSRs for the segment bases (so you can leave the actual segment register values as 0, the null selector). Or if you enable it (for use in user-space or kernel) on a CPU that supports it, [`rdfsbase` / `wrfsbase`](https://www.felixcloutier.com/x86/rdfsbase:rdgsbase) can copy the segment base to/from an integer register even more easily and efficiently than `rdmsr` / `wrmsr`. (x86-64 SysV uses FS for thread-local storage.) ---",
            "An asm caller should treat `call thrd_yield` exactly like a call to a compiler-generated function, assuming it clobbers all call-clobbered registers, leaving others unmodified.",
            "\nThe way Linux manages it is roughly:\n\n* Entering the kernel in the first place saves state of integer registers, on a per-thread kernel stack. This will be restored later when returning to user-space for this task, potentially between any two instructions so it's safe for async interrupts. * The vector regs aren't used by kernel code (unless it calls `kernel_fpu_begin()` first). So the interrupt and system call entry points don't have to run `xsave`; that can be deferred until switching to a new user-space task. At which point you do `xsave` (or `xsaveopt` or whatever) for the old context, then `xrstor` to load the new after switching to the new task's kernel stack. * Calling `switch_to` (see *[How does schedule()+switch\\_to() functions from linux kernel actually work? ](https://stackoverflow.com/questions/6525905/how-does-scheduleswitch-to-functions-from-linux-kernel-actually-work)*) just switches call-preserved integer registers (of the kernel state of the caller), and saves/restores the user-space FP/SIMD state from the vector regs. (Older kernels used to try to defer this, but modern user-space uses `movaps` all the time for memcpy and stuff.) * When that new kernel state eventually returns back to the syscall or interrupt entry point that got that task into the kernel, the user-space state will be restored.\nThe call-preserved registers will already have been restored by the kernel C functions, but Linux saves/restores all the registers anyway so debuggers (the `ptrace` system call) can modify that state all in one place. [Share](/a/75681072 \"Short permalink to this answer\")"
          ]
        },
        {
          "title": "RDMA GPU Direct Slow - CUDA - NVIDIA Developer Forums",
          "url": "https://forums.developer.nvidia.com/t/rdma-gpu-direct-slow/69946",
          "excerpts": [
            "Missing: deterministic sub- millisecond checkpoints DMA quiescence ring cursor NVMe"
          ]
        },
        {
          "title": "userfaultfd(2) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man2/userfaultfd.2.html",
          "excerpts": [
            "It can also be used to implement lazy restore for checkpoint/restore mechanisms, as well as post-copy migration to allow (nearly) uninterrupted execution ..."
          ]
        },
        {
          "title": "io_uring_enter2(2) - Linux manual page - man7.org",
          "url": "https://man7.org/linux/man-pages/man2/io_uring_enter2.2.html",
          "excerpts": [
            "IORING_ENTER_SQ_WAKEUP If the ring has been created with IORING_SETUP_SQPOLL, then this flag asks the kernel to wakeup the SQ kernel thread to submit IO.",
            "The CQE flags field will have IORING_CQE_F_MORE set on completion if the application should expect further CQE entries from the original request. If this flag ..."
          ]
        },
        {
          "title": "QP state machine",
          "url": "https://www.rdmamojo.com/2012/05/05/qp-state-machine/",
          "excerpts": [
            "May 5, 2012 — A QP is being created in the Reset state. Any QP can be transitioned to Reset or Error state by calling ibv_modify_qp() from any state."
          ]
        },
        {
          "title": "[dpdk-dev] [RFC 0/9] get Rx and Tx used descriptors",
          "url": "http://mails.dpdk.org/archives/dev/2016-November/050679.html",
          "excerpts": [
            "Missing: rx_queue_stop tx_queue_stop drain"
          ]
        },
        {
          "title": "Events",
          "url": "https://docs.nvidia.com/networking/display/RDMAAwareProgrammingv17/Events",
          "excerpts": [
            "May 23, 2023 — These errors usually occur because of bugs in the user code. When this happens, the QP is automatically transitioned to the IBV_QPS_ERR state by ..."
          ]
        },
        {
          "title": "Problem with NVMe driver : r/osdev",
          "url": "https://www.reddit.com/r/osdev/comments/1f2qc4q/problem_with_nvme_driver/",
          "excerpts": [
            "The reset deletes all I/O Submission Queues and I/O Completion Queues, resets the Admin Submission Queue and Completion Queue, and brings the ..."
          ]
        },
        {
          "title": "firecracker/docs/snapshotting/snapshot-support.md at main",
          "url": "https://github.com/firecracker-microvm/firecracker/blob/main/docs/snapshotting/snapshot-support.md?plain=1",
          "excerpts": [
            "Firecracker exposes the following APIs for manipulating snapshots: `Pause`,. `Resume` and `CreateSnapshot` can be called only after booting the microVM,. while ..."
          ]
        },
        {
          "title": "A Hot Distributed Snapshot System For Virtual Machine Cluster",
          "url": "https://www.usenix.org/conference/lisa13/technical-sessions/presentation/cui",
          "excerpts": [
            "This paper proposes HotSnap, a VMC snapshot approach designed to enable taking hot distributed snapshot with milliseconds system downtime and TCP backoff ..."
          ]
        },
        {
          "title": "io_uring_setup_buf_ring(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_setup_buf_ring.3.html",
          "excerpts": [
            "The io_uring_setup_buf_ring(3) function registers a shared buffer ring to be used with provided buffers. For the request types that support it, provided buffers ..."
          ]
        },
        {
          "title": "Can the --lazy-page feature be adapted for restoring process over ...",
          "url": "https://github.com/checkpoint-restore/criu/issues/1502",
          "excerpts": [
            "Missing: latency microseconds milliseconds"
          ]
        },
        {
          "title": "Userfaultfd",
          "url": "https://docs.kernel.org/admin-guide/mm/userfaultfd.html",
          "excerpts": [
            "In async mode, there will be no message generated when a write operation happens, meanwhile the write-protection will be resolved automatically by the kernel."
          ]
        },
        {
          "title": "userfaultfd(2) — Arch manual pages",
          "url": "https://man.archlinux.org/man/userfaultfd.2.en",
          "excerpts": [
            "Since Linux 5.7, userfaultfd supports write-protect mode for anonymous memory. The user needs to first check availability of this feature using UFFDIO_API ioctl ..."
          ]
        },
        {
          "title": "Articles - CRIU",
          "url": "https://criu.org/index.php?title=Articles&mobileaction=toggle_view_desktop",
          "excerpts": [
            "This is a collection of external articles regarding the CRIU project, sorted by date. 2025-08-13, Software Availability Protection in ..."
          ]
        },
        {
          "title": "[PDF] A Hot Distributed Snapshot System For Virtual Machine Cluster",
          "url": "https://www.usenix.org/system/files/conference/lisa13/lisa13-cui.pdf",
          "excerpts": [
            "This paper proposes HotSnap, a VMC snapshot approach designed to enable taking hot distributed snapshot with millisec- onds system downtime and ..."
          ]
        },
        {
          "title": "how AWS Lambda SnapStart optimizes function startup ...",
          "url": "https://aws.amazon.com/blogs/compute/under-the-hood-how-aws-lambda-snapstart-optimizes-function-startup-latency/",
          "excerpts": [
            "Lambda runs your function code in an isolated, secure execution environment that uses Firecracker microVM technology. ... snapshot restore latency ..."
          ]
        },
        {
          "title": "Derecho: RDMA-based state machine replication (Cornell dissertation)",
          "url": "https://www.cs.cornell.edu/projects/Quicksilver/public_pdfs/dissertation.pdf",
          "excerpts": [
            "Rather than rely on an explicitly co-\n\nordinated global checkpoint, as in [62] and [42], or attempt to record a dependency graph\n\nbetween locally-recorded checkpoints, as in [15], our system incorporates the dependency\n\ninformation already recorded in SMR updates to derive a globally consistent system snap-\n\nshot from loc",
            "RDMA (remote direct memory access) is a zero-copy communication standard. It has\n\nbeen used for many years on Infiniband, but is now also working robustly on standard\n\ndatacenter Ethernet [73,104",
            "To achieve the lowest possible latency, RDMA requires continuously polling for com-\n\npletion events, but this creates excessive CPU usage if no RDMA transfers are taking\n\npl",
            "The updates that happen asynchronously through one-sided RDMA writes must be dis-\n\ncovered very rapidly to take maximum advantage of high RDMA spee",
            " \nRDMA-enabled NICs additionally can write in-\n\ncoming network data to application memory through a DMA write and send data stored in\n\napplication memory over the network with a DMA read, therefore avoiding any memory",
            "One-sided RDMA writes do the\n\nopposite: the initiator node writes data directly to a remote node’s memory from its own\n\nmemory. Obviously, quite a bit of information is required for these to work, and in partic-\n\nular, the applications running on the two nodes need to be aware of the relevant memory\n\naddresses required for data tra",
            "This happens in the connection phase: When form-\n\ning a connection (binding), the applications exchange maps of one-other’s virtual memory\n\naddresses. Later, they reference these maps when exchanging d"
          ]
        },
        {
          "title": "NVM Express Revision 1.3",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM_Express_Revision_1.3.pdf",
          "excerpts": [
            "May 1, 2017 — Submission Queue 0 Tail Doorbell (Admin). 1000h + (1 *. (4 << CAP ... Completion Queue 0 Head Doorbell (Admin). 1000h + (2 *. (4 << CAP ..."
          ]
        },
        {
          "title": "Base Specification, Revision 2.3",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM-Express-Base-Specification-Revision-2.3-2025.08.01-Ratified.pdf",
          "excerpts": [
            "Jul 31, 2025 — 1.1 Overview. The NVM Express® (NVMe®) interface allows a host to communicate with a non-volatile memory subsystem. (NVM subsystem)."
          ]
        },
        {
          "title": "ibv_poll_cq()",
          "url": "https://www.rdmamojo.com/2013/02/15/ibv_poll_cq/",
          "excerpts": [
            "Feb 15, 2013 — When a Work Requests end, a Work Completion is being added to the tail of the CQ that this Work Queue is associated with. ibv_poll_cq() check if ..."
          ]
        },
        {
          "title": "RDMA Aware Networks Programming User Manual",
          "url": "https://docs.nvidia.com/rdma-aware-networks-programming-user-manual-1-7.pdf",
          "excerpts": [
            "Mar 3, 2011 — action will result in any posted work requests being flushed to the completion queue. rdma_disconnect may be called by both the client and ..."
          ]
        },
        {
          "title": "ibv_req_notify_cq()",
          "url": "https://www.rdmamojo.com/2013/02/22/ibv_req_notify_cq/",
          "excerpts": [
            "Feb 22, 2013 — ibv_req_notify_cq() requests a notification when the next Work Completion of a requested type is added to the CQ. Any Work Completions that ..."
          ]
        },
        {
          "title": "ibv_modify_qp() - RDMAmojo",
          "url": "https://www.rdmamojo.com/2013/01/12/ibv_modify_qp/",
          "excerpts": [
            "ibv_modify_qp() modifies the attributes of a Queue Pair. The changed attributes describe the send and receive attributes of the QP."
          ]
        },
        {
          "title": "ibv_modify_qp - man pages section 3: Library Interfaces and Headers",
          "url": "https://docs.oracle.com/cd/E88353_01/html/E37842/ibv-modify-qp-3.html",
          "excerpts": [
            "Missing: IBV_QPS_ERR IBV_QPS_RESET"
          ]
        },
        {
          "title": "lib/ring/rte_ring_peek_zc.h File Reference - Documentation - DPDK",
          "url": "https://doc.dpdk.org/api/rte__ring__peek__zc_8h.html",
          "excerpts": [
            "Note that currently these APIs are available only for two sync modes: 1) Single Producer/Single Consumer (RTE_RING_SYNC_ST) 2) Serialized Producer/Serialized ..."
          ]
        },
        {
          "title": "[PDF] Operational and Declarative Models of RDMA on TSO Architectures",
          "url": "https://www.soundandcomplete.org/papers/OOPSLA2024/RDMA/rdma-extended.pdf",
          "excerpts": [
            "Our focus here is on the IB Verbs model defined by IBTA [2022], using PCIe as the internal fabric. It was designed for InfiniBand and reused for RoCE, the two ..."
          ]
        },
        {
          "title": "[CRIU] Looking into checkpoint/restore of ROCm applications",
          "url": "http://lists.openvz.org/pipermail/criu/2020-June/045032.html",
          "excerpts": [
            "Jun 18, 2020 — ... [CRIU] Looking into checkpoint/restore of ROCm ... kfd with a cr_plugin_dump_file >> callback in a plugin. I've spent some time reading ..."
          ]
        },
        {
          "title": "Changelog - ROCm Documentation - AMD",
          "url": "https://rocm.docs.amd.com/en/docs-6.0.0/about/CHANGELOG.html",
          "excerpts": [
            "CRIU lacked the support for checkpoint restore applications that used device files such as a GPU. With this ROCm release, CRIU is enhanced with a new plugin ..."
          ]
        },
        {
          "title": "Checkpointing Tensorflow-rocm with CRIU · Issue #1763 - GitHub",
          "url": "https://github.com/RadeonOpenCompute/ROCm/issues/1763",
          "excerpts": [
            "So I'm trying to checkpoint and restore a tensorflow-rocm (2.9.1) application running on my GPU (Raedeon RX 6950 XT), however, have been so far ..."
          ]
        },
        {
          "title": "Using CUDA's checkpoint/restore API to reduce cold boot time by 12x",
          "url": "https://www.reddit.com/r/CUDA/comments/1mebckd/using_cudas_checkpointrestore_api_to_reduce_cold/",
          "excerpts": [
            "The API allows us to checkpoint and restore CUDA state, including: Device memory contents (GPU vRAM), such as model weights. CUDA kernels. CUDA ..."
          ]
        },
        {
          "title": "Checkpointing Preemptible Training Workloads",
          "url": "https://run-ai-docs.nvidia.com/self-hosted/workloads-in-nvidia-run-ai/using-training/checkpointing-preemptible-workloads",
          "excerpts": [
            "Aug 10, 2025 — NVIDIA Run:ai allows you to define whether a workload is preemptible, meaning the NVIDIA Run:ai Scheduler may pause a running workload and ..."
          ]
        },
        {
          "title": "PhoenixOS: Concurrent OS-level GPU Checkpoint and Restore with ...",
          "url": "https://arxiv.org/html/2405.12079v2",
          "excerpts": [
            "PhoenixOS (PhOS) is the first OS service that can concurrently checkpoint and restore (C/R) GPU processes—a fundamental capability for critical ..."
          ]
        },
        {
          "title": "ROCm-SMI Fails to Restore Full Power After Setting Low Profile #4257",
          "url": "https://github.com/ROCm/ROCm/issues/4257",
          "excerpts": [
            "Problem begins when I revert the performance level using: rocm-smi --setperflevel auto The power does not reach the peak as it used to..it reaches 143W max."
          ]
        },
        {
          "title": "CUDA Checkpoint/Restore Documentation",
          "url": "https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CHECKPOINT.html",
          "excerpts": [
            "CUDA API versioning support\n\nThis sections describes the checkpoint and restore functions of the low-level CUDA driver application programming interface. The CUDA checkpoint and restore API's provide a way to save and restore GPU state for full process checkpoints when used with\n CPU side process checkpointing solutions.",
            "cuCheckpointProcessCheckpoint ( int pid , [CUcheckpointCheckpointArgs](structCUcheckpointCheckpointArgs.html) \\* args )\n    Checkpoint a CUDA process's GPU memory contents."
          ]
        },
        {
          "title": "Checkpointing CUDA Applications with CRIU (NVIDIA Technical Blog)",
          "url": "https://developer.nvidia.com/blog/checkpointing-cuda-applications-with-criu/",
          "excerpts": [
            "This utility can be used to transparently checkpoint and restore CUDA state within a running Linux process.",
            "`cuda-checkpoint` checkpoints and restores the CUDA state of a single Linux process.",
            "%2F)\n\nCheckpoint and restore functionality for CUDA is exposed through a command-line utility called [cuda-checkpoint]",
            "CRIU exposes its functionality through a command line program called `criu` and operates by checkpointing and restoring every kernel mode resource associated with a process.",
            "The `cuda-checkpoint` binary can toggle the CUDA state of a process, specified by PID, between suspended and running.",
            "A running-to-suspended transition is called a *suspend* and the opposite transition is called a *resu"
          ]
        },
        {
          "title": "Morello for A-profile Architecture",
          "url": "https://developer.arm.com/documentation/ddi0606/latest/",
          "excerpts": [
            "Arm Architecture Reference Manual Supplement - Morello for A-profile Architecture. This document is only available in a PDF version. Click Download to view."
          ]
        },
        {
          "title": "Sentries for control-flow integrity",
          "url": "https://cheriot.org/isa/ibex/2024/06/26/sentries-cfi.html",
          "excerpts": [
            "Jun 26, 2024 — For a long time, CHERI platforms have had a notion of a sealed entry (sentry) capability. These use the sealing mechanism (that makes a ..."
          ]
        },
        {
          "title": "RISC-V Specification for CHERI Extensions - GitHub Pages",
          "url": "https://riscv.github.io/riscv-cheri/",
          "excerpts": [
            "If the capability tag is set, the capability is valid and can be dereferenced (contingent on checks such as permissions or bounds). All registers or memory ..."
          ]
        },
        {
          "title": "Morello Platform Model Reference Guide Version 2.0",
          "url": "https://developer.arm.com/documentation/102225/latest/Reference-information",
          "excerpts": [
            "This chapter provides reference information for the Morello Platform Model including differences between the model implementation and the Morello specification, ..."
          ]
        },
        {
          "title": "What are the purposes of sealed capabilities?",
          "url": "https://capabilitiesforcoders.com/faq/purposes_of_sealed_capabilities.html",
          "excerpts": [
            "CHERI can prevent ROP attacks by sealing automatically sealing function pointers (i.e., creating a sentry) and the return address (link register). Memory Safety."
          ]
        },
        {
          "title": "seL4 Debugging Guide",
          "url": "https://www.cse.unsw.edu.au/~cs9242/18/project/debugging.shtml",
          "excerpts": [
            "Jul 19, 2018 — The kernel exports fault handling policies to user level by sending an IPC to the appropriate IPC endpoint (see Chapter 5 of the seL4 manual)."
          ]
        },
        {
          "title": "LLP08-seL4-6up.pdf",
          "url": "https://web.cecs.pdx.edu/~mpj/llp/slides/LLP08-seL4-6up.pdf",
          "excerpts": [
            "• Kernel tracks use via the “capability derivation tree” (CDT). • Cannot retype an untyped memory area if it is already in use. (i.e., if it has children in ...",
            "• seL4 tackles this problem by introducing a special \"Reply\" capability type: • The Call system call combines a Send and a Wait. • The kernel gives a new ..."
          ]
        },
        {
          "title": "model-driven development of arinc 653 configuration tables",
          "url": "https://www.gmv.com/sites/default/files/content/file/2020/06/03/1/dasc_paper.pdf",
          "excerpts": [
            "by Á Horváth · Cited by 44 — The group consists of steps to define the Health. Monitoring tables for module, partition and application level along with the different error."
          ]
        },
        {
          "title": "Towards a Real-time Component Framework for Software ... - C3",
          "url": "https://c3.ndc.nasa.gov/dashlink/static/media/other/ISIS-TR-09-111.pdf",
          "excerpts": [
            "by A Dubey · Cited by 12 — ARINC-653 supports a health monitoring service at each layer (Partition/Module/System) which is configured by the user with the appropriate response (functions) ..."
          ]
        },
        {
          "title": "Model-driven development of ARINC 653 configuration ...",
          "url": "https://www.researchgate.net/publication/224202064_Model-driven_development_of_ARINC_653_configuration_tables",
          "excerpts": [
            "In the scope of the project, a tool chain was implemented that generates ARINC 653 configuration tables from high-level architecture models. The tool chain was ..."
          ]
        },
        {
          "title": "CHERI Software Compartmentalization",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-compartmentalization.html",
          "excerpts": [
            "The CHERI protection model provides a set of low-level primitives that enable scalable, fine-grained software compartmentalization.",
            "[CHERI-seL4](cheri-sel4.html)"
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI's capability system is blended with a conventional RISC\nusermode architecture without disrupting the majority of key design\ndecisions.",
            "CHERI is a hybrid capability system in several senses:",
            "CHERI capabilities are a low-level primitive usable for many purposes.",
            "The advent of the open RISC-V ISA provides us with a richer spectrum of\nbaseline processor designs, and as the architecture matures over time, we\nhope also a similarly rich software ecosystem."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "\nCHERI represents a new system design that blocks exploits. Architectural changes to the CPU and memory systems add integrity checks to pointers that prevent reading, writing, or executing from memory that is out of bounds or using corrupted pointers, the most common classes of severe vulnerabilities. CHERI is supported by a complete compiler toolchain, multiple operating systems, is open source, and already implemented for several different RISC CPUs including Arm’s recently released Morello prototype.",
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "Capabilities are created at boot time, and capabilities derived from these initial ones are more restrictive. The new instructions for manipulating capabilities also mean changing the instruction set architecture, or ISA.",
            " of CHERI architectures for MIPS, RISC-V, and Arm began with the Sail instruction set definition language. Sail generates sequential emulators, in C and OCaml, and theorem-prover definitions, in Coq, HOL4, and Isabelle, and SMT. These versions allow for both a means of testing in emulation and creating formal proofs of the correctness of the design.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Fault Management (MDPI)",
          "url": "https://www.mdpi.com/2076-3417/12/4/2014",
          "excerpts": [
            "ARINC 653 provides a health monitor configuration table and error handler process for managing errors. In the health monitor configuration table, the level of error is defined as a process, partition and module and the recovery method for each error is specified to enable action appropriate to the situation.",
            "In the health monitor configuration table, the level of error is defined as a process, partition and module and the recovery method for each error is specified to enable action appropriate to the situation.",
            "— ARINC 653 provides health monitoring to detect and recover hardware and software errors at the process, partition and module levels. It isolates errors and ...",
            " ARINC 653 is an integrated modular avionic (IMA)-based real-time operating system (RTOS). It is an avionic system that integrates and operates an environment where multiple computer systems are operated in a distributed manner.",
            "The FACE consists of five local segments, such as operating system segment (OSS), input/out services segment (IOSS), platform-specific services segment (PSSS), transport services segment (TSS), portable components segment (PCS). The FACE provides OS-level health monitoring and fault management (HMFM) and system-level HMFM for HMSs."
          ]
        },
        {
          "title": "[PDF] CHERIoT Architecture specification Version 0.6 (draft)",
          "url": "https://cheriot.org/cheriot-sail/cheriot-architecture.pdf",
          "excerpts": [
            "To mitigate the availability concerns this could create, the. CHERIoT RTOS provides a mechanism for recovering from faults in a controlled way. Compartments can ...",
            "by S Amar · 2024 — The first is a sealed capability to a structure describing the entry point in the callee. The second is a sentry capability to the compartment switcher. The ..."
          ]
        },
        {
          "title": "CHERIoT Architecture specification Version 0.6 (draft)",
          "url": "https://lists.riscv.org/g/tech-tg-cheri/attachment/14/0/cheriot-architecture.pdf",
          "excerpts": [
            "by S Amar · 2024 — The sealed capability is passed in a register when the sentry capability is called. A CHERI sentry is a capability that can be jumped to but ..."
          ]
        },
        {
          "title": "Secure Scripting with CHERIoT MicroPython - ACM Digital Library",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3708493.3712694",
          "excerpts": [
            "However, this register is zeroed by CHERIoT-RTOS on return from any cross-compartment call. Correct usage of this register would require its contents to be ..."
          ]
        },
        {
          "title": "Efficient and Provable Local Capability Revocation using ...",
          "url": "https://iris-project.org/pdfs/2021-popl-ucaps-final.pdf",
          "excerpts": [
            "by AL GEORGES · 2021 · Cited by 44 — On many capability machines, including CHERI, memory capabilities are designed to directly replace pointers, thus adding native bounds and permission checks ..."
          ]
        },
        {
          "title": "Building Safety by Design: CHERI in Critical…",
          "url": "https://blog.adacore.com/building-safety-by-design-cheri-in-critical-systems-development",
          "excerpts": [
            "Dec 17, 2024 — Our paper discusses examples of how cyber-attack detection, resilience, recovery, and new failure mode strategies like \"fail secure but degraded ..."
          ]
        },
        {
          "title": "ARINC Specification 653-2",
          "url": "https://mail.kia.prz.edu.pl/~ssamolej/vxworks/ARINC_653P1-2.pdf",
          "excerpts": [
            "The Health Monitor (HM) is the function of the O/S responsible for monitoring and reporting\n\nhardware, application and O/S software faults and failures. The HM helps to isolate faults and to\n\nprevent failures from propagatin",
            "Fault responses to process level errors are determined by the application programmer using a\n\nspecial (highest priority) process of the partition, the error handler process. The error handler\n\nprocess is active in NORMAL mode only. The programmer can identify the error and the faulty\n\nprocess via a HM service and then takes the recovery action at the process level (e.g., stop, start\n\nprocess) or at the partition level (e.g., set partition mode: IDLE, COLD\\_START, WARM\\_S",
            "Fault responses to partition level errors are handled in the following way:",
            "The O/S Kernel looks up the reference to the HM Callback in the HM\n\nConfiguration tables and calls the procedure if one has been identified for the\n\npartitio",
            "On completion of the HM Callback the O/S Kernel looks up the error code\n\nresponse action in the HM configuration tables",
            "The O/S Kernel performs the response identified in the configuration table.",
            "The recovery actions for process level errors are defined by the application programmer\n\nin a special error handler process"
          ]
        },
        {
          "title": "sima Command Line Tools Application Development and ...",
          "url": "https://www.gmv.com/sites/default/files/content/file/2020/06/03/1/user_manual.pdf",
          "excerpts": [
            "Jun 3, 2020 — The partition scheduling is defined in the arinc 653 configuration file in three hier- ... Figure 16 shows the structure of the arinc 653 system ..."
          ]
        },
        {
          "title": "Configuration Tool for ARINC 653 Operating Systems",
          "url": "https://gvpress.com/journals/IJMUE/vol9_no4/8.pdf",
          "excerpts": [
            "by ET Choi · 2014 · Cited by 5 — From the figure, An ARINC 653 Module consist of seven major elements, one or more Partitions, a System HM table, a Module. HM table, a Connection table, one or ..."
          ]
        },
        {
          "title": "CHERI Instruction-Set Architecture (Version 8)",
          "url": "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-951.pdf",
          "excerpts": [
            "by RNM Watson · 2020 · Cited by 158 — This hybrid approach, inspired by the Capsicum security model, addresses the performance and robustness issues that arise when trying to express more secure.",
            "by RNM Watson · 2020 · Cited by 158 — CHERI's hybrid approach allows incremental adoption of capability-oriented design: crit- ical components can be ported and recompiled to use capabilities ..."
          ]
        },
        {
          "title": "CHERI Instruction-Set Architecture (Version 9)",
          "url": "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-987.pdf",
          "excerpts": [
            "by RNM Watson · 2023 · Cited by 158 — ... Failure modes and exception delivery (Section 2.3.15). • Capability revocation (Section 2.3.16). These features allow capabilities to be architectural ..."
          ]
        },
        {
          "title": "(PDF) Configuration tool for ARINC 653 operating systems",
          "url": "https://www.researchgate.net/publication/262418287_Configuration_tool_for_ARINC_653_operating_systems",
          "excerpts": [
            "Aug 10, 2025 — This paper presents a configuration tool for ARINC 653 OS that consist of Wizard module which generates the basic configuration data for IMA based on XML ..."
          ]
        },
        {
          "title": "Behind the last line of defense: Surviving SoC faults and ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0167404822003121",
          "excerpts": [
            "by IP Gouveia · 2022 · Cited by 16 — In particular, faulty replicas may fail a subordinate vote, but agree to reset the voter, which erases the error information about the failed vote from the ..."
          ]
        },
        {
          "title": "nevill-master-capabilities.pdf - The Barrelfish OS",
          "url": "https://barrelfish.org/publications/nevill-master-capabilities.pdf",
          "excerpts": [
            "by M Nevill — Given a generic memory capability (referred to as “untyped memory”, or UM), seL4 allows this to be retyped to a mappable “virtual mem- ory” (VM) ..."
          ]
        },
        {
          "title": "CHERI Hardware and CHERIoT Overview",
          "url": "https://cheriot.org/cheri/2024/08/06/how-to-talk-about-CHERI.html",
          "excerpts": [
            "In CHERIoT, we use sealed objects for almost anything where one compartment wants to provide a handle that lets other compartments ask it to do something. This includes allocating memory, reading or writing message queues, connecting to network servers, and so on.",
            "The software model defines what valid paths exist between the initial boot state and normal execution with you holding a pointer to a heap object, the hardware guarantees that some such path must have existed for you to hold that pointer.",
            "CHERI capabilities were designed to allow everything that correct C does with pointers, which is a superset of what most safer languages permit.",
            "CHERIoT provides a trusted stack for cross-compartment calls and a switcher that enforces a lot of properties on both the call and return path."
          ]
        },
        {
          "title": "Improving Security with Hardware Support: CHERI and Arm's Morello",
          "url": "https://www.govinfo.gov/content/pkg/GPO-TNW-24-1-2023/pdf/GPO-TNW-24-1-2023-3.pdf",
          "excerpts": [
            "Three kinds of specialized sentry (sealed \nentry) capabilities may be used transparently by \ndirect branch instructions, memory-indirect branch \ninstructions, and memory-indirect branch-to-pair \ninstruction",
            "sealing capabilities, they can be labeled with an object \ntype, if the authorizing capability has that object \ntype in its bounds. The “branch to sealed capabili-\nty pair” instruction invokes a given code capability \nand also an argument data capability, checking their \nobject types match, providing object-style encap-\nsulati",
            "Three kinds of specialized sentry (sealed \nentry) capabilities may be used transparently by \ndirect branch instructions, memory-indirect branch \ninstructions, and memory-indirect branch-to-pair \ninstructions, respectiv",
            "and exception handling is also extended. Exception handling preserves extended capability \nregister state, and there are new exception cause \ncodes associated with CHERI failures such as bounds \nviolations or untagged memory accesses.",
            "CHERI capabilities are an architectural primitive \nthat can be used for a variety of software purposes \nup and down the software stack, with potential uses \nin firmware and boot loaders, OSs, language run-\ntimes, CHERI-specific compartmentalization librar-\nies, and compiler-generated code for the C and C++ \napplication p"
          ]
        },
        {
          "title": "seL4 discussion on page faults and revocation in seL4 ecosystem",
          "url": "https://sel4.com/hyperkitty/list/devel@sel4.systems/thread/QAYR2OHU7GPWTAFKJH4O3RF7TWQIKBQK/",
          "excerpts": [
            "The page-fault handler finds that the fault is due to a page shared with the client and takes appropriate action.",
            "Effectively, in seL4, if my understanding above is correct, one\nstructures the system in such a manner that revocation is eliminated,\ni.e., the client cannot revoke its pages.",
            "the client\ntrusts the driver to release the pages back via the TCB when connection\nis teared down.",
            "In other words, what is the killer use-case for fine-grained revocation\nin your opinion? I.e., what kind of system is impossible without it? Or\neven: did you see scenarios on top of seL4 when people rely on\nfine-grained revocation (i.e., revoke pages, memory regions, access to\ndevices) instead of a rather coarse-grained termination of the entire\nprocesses?"
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            " Recovery actions at the partition level are triggered when the error is a partition level error and the error handler has not been created in that partition",
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        },
        {
          "title": "[PDF] Arm® Architecture Reference Manual Supplement Morello for A ...",
          "url": "http://kib.kiev.ua/x86docs/ARM/Morello/DDI0606_A.j_morello_architecture_external.pdf",
          "excerpts": [
            "Morello is a prototype architecture, which has a particular meaning to Arm of which the recipient must be aware as follows: Subject to change without consent ..."
          ]
        },
        {
          "title": "Capability Hardware Enhanced RISC Instructions",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/20240116-cheri-web-compressed.pdf",
          "excerpts": [
            "Jan 16, 2024 — Sealed capabilities, CCall/CReturn. 2015. ISAv4. MMU-CHERI integration (TLB permissions). ISA support for compressed 128-bit capabilities. HW ..."
          ]
        },
        {
          "title": "SECURITY ANALYSIS OF CHERI ISA - GitHub",
          "url": "https://raw.githubusercontent.com/microsoft/MSRC-Security-Research/master/papers/2020/Security%20analysis%20of%20CHERI%20ISA.pdf",
          "excerpts": [
            "Exceptions where the architectural provenance chain is broken to support abstract capabilities in a real system include implementations for program startup, ..."
          ]
        },
        {
          "title": "2. The RTOS Core",
          "url": "https://cheriot.org/book/core_rtos.html",
          "excerpts": [
            "A trusted stack is a region of memory containing the register save area for context switches and a small frame for every cross-compartment call that allows a ..."
          ]
        },
        {
          "title": "The RTOS components for the CHERIoT research platform",
          "url": "https://github.com/CHERIoT-Platform/cheriot-rtos",
          "excerpts": [
            "trusted_stack_frames specifies the number of trusted stack frames (the maximum depth of cross-compartment calls possible on this thread). Note that any call ..."
          ]
        },
        {
          "title": "5. Compartments and libraries",
          "url": "https://cheriot.org/book/compartments.html",
          "excerpts": [
            "In the core of the RTOS, the scheduler is written as a safebox. It does not trust anything on the outside and assumes that everything else is trying to make it ..."
          ]
        },
        {
          "title": "seL4 Libraries: IPC",
          "url": "https://docs.sel4.systems/Tutorials/libraries-2.html",
          "excerpts": [
            "seL4 Libraries: IPC. The tutorial is designed to teach the basics of seL4 IPC using Endpoint objects, and userspace paging management."
          ]
        },
        {
          "title": "Genode on seL4 - IPC and virtual memory",
          "url": "https://genode.org/documentation/articles/sel4_part_2",
          "excerpts": [
            "In the L4 universe, the term IPC (inter-process communication) usually stands for synchronous communication between two threads. In seL4, IPC has two uses."
          ]
        },
        {
          "title": "FAILSAFE Health Management for Embedded Systems",
          "url": "https://www.techbriefs.com/component/content/article/8430-npo-46981",
          "excerpts": [
            "Under ARINC 653, the health monitoring (HM) service is invoked by an application calling the application error service, or by the operating ..."
          ]
        },
        {
          "title": "Modeling and Validation of ARINC653 architectures",
          "url": "https://hal.science/hal-02269428v1/document",
          "excerpts": [
            "by J Delange · 2010 · Cited by 12 — The Health Monitoring service detects faults at different levels (module, partition, process) and executes a recovering procedure for each one."
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "Constant bandwidth servers with constrained deadlines",
          "url": "https://dl.acm.org/doi/10.1145/3139258.3139285",
          "excerpts": [
            "The Hard Constant Bandwidth Server (H-CBS) is a reservation-based scheduling algorithm often used to mix hard and soft real-time tasks on the same system."
          ]
        },
        {
          "title": "Constant bandwidth server revisited | ACM SIGBED Review",
          "url": "https://dl.acm.org/doi/10.1145/2724942.2724945",
          "excerpts": [
            "The Constant Bandwidth Server (CBS) is an algorithm for providing temporal protection and real-time guarantees to real-time sporadic tasks."
          ]
        },
        {
          "title": "io_uring and networking in 2023 · axboe/liburing Wiki",
          "url": "https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023",
          "excerpts": [
            "Feb 15, 2023 — The simplest way to use ring messages is to just transfer 8 bytes of data between them. io_uring treats the data as a cookie and doesn't ..."
          ]
        },
        {
          "title": "NUMA, Multi-Queue NICs and CPU Affinity - Networking Notes",
          "url": "https://null.53bits.co.uk/page/numa-and-queue-affinity",
          "excerpts": [
            "Apr 17, 2016 — RPS has some advantages over RSS: 1) it can be used with any NIC, 2) software filters can easily be added to hash over new protocols, 3) it does ..."
          ]
        },
        {
          "title": "Scaling in the Linux Networking Stack",
          "url": "https://docs.kernel.org/networking/scaling.html",
          "excerpts": [
            "Each receive queue has a separate IRQ associated with it. The NIC triggers this to notify a CPU when new packets arrive on the given queue. The signaling path ..."
          ]
        },
        {
          "title": "RSS, IRQ affinity and RPS on Linux - Andreas Karis Blog",
          "url": "https://andreaskaris.github.io/blog/networking/rss-irq-affinity-and-rps/",
          "excerpts": [
            "Aug 12, 2024 — RSS, short for Receive Side Scaling, is an in-hardware feature that allows a NIC to \"send different packets to different queues to distribute ...",
            "In this blog post, we are going to have a look at the tuning of Linux receive queues and their interrupt requests. We are going to learn a bit ..."
          ]
        },
        {
          "title": "The RPS/RSS seems not take effect in platform Xavier/Orin",
          "url": "https://forums.developer.nvidia.com/t/the-rps-rss-seems-not-take-effect-in-platform-xavier-orin/218593",
          "excerpts": [
            "Jun 23, 2022 — I tried to dispatch udp packet to multi-CPU over RPS/RSS, but it seems not available. The steps are as follow: list all net rx queues:"
          ]
        },
        {
          "title": "Is it a good practice to set interrupt affinity and io handling ...",
          "url": "https://stackoverflow.com/questions/48659720/is-it-a-good-practice-to-set-interrupt-affinity-and-io-handling-thread-affinity",
          "excerpts": [
            "IRQ affinity is a double edged sword. In my experience it can improve performance but only in a very specific configuration with a pre-defined workload."
          ]
        },
        {
          "title": "Efficient Distributed Memory Management with RDMA and ...",
          "url": "https://www.vldb.org/pvldb/vol11/p1604-cai.pdf",
          "excerpts": [
            "by Q Cai · 2018 · Cited by 145 — Due to the limited size of the on-NIC cache, it is important to keep, as small as possible, the data needed by RDMA NIC, which typically include the page table, ..."
          ]
        },
        {
          "title": "Understanding CPU Interrupts in Linux",
          "url": "https://www.alibabacloud.com/blog/597128",
          "excerpts": [
            "The SMP IRQ affinity requires NICs to support multiple queues. A NIC supporting multiple queues has multiple interrupt numbers, which can be ..."
          ]
        },
        {
          "title": "[PDF] The IX Operating System: Combining Low Latency, High Throughput ...",
          "url": "https://anakli.inf.ethz.ch/papers/IX_TOCS.pdf",
          "excerpts": [
            "We present IX, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ...",
            "by G PREKAS · Cited by 96 — The IX dataplane allows for networking stacks that optimize for both bandwidth and latency. It is designed around a native, zero-copy API that supports ...",
            "by G PREKAS · Cited by 96 — Our evaluation with mem- cached, a widely deployed key-value store, shows that IX improves upon Linux by up to 6.4× in terms of throughput at a given 99th ..."
          ]
        },
        {
          "title": "Constant Bandwidth Server Revisited",
          "url": "https://ceur-ws.org/Vol-1291/ewili14_5.pdf",
          "excerpts": [
            "by L Abeni · Cited by 31 — The Constant Bandwidth Server (CBS) [1] is a reservation- based scheduling algorithm originally introduced in 1998 to handle tasks characterised by variable ...",
            "by L Abeni · Cited by 31 — ABSTRACT. The Constant Bandwidth Server (CBS) is an algorithm for providing temporal protection and real-time guarantees to real-time sporadic tasks."
          ]
        },
        {
          "title": "DPDK buffers received from the RX ring and freeded on ...",
          "url": "https://stackoverflow.com/questions/59581822/dpdk-buffers-received-from-the-rx-ring-and-freeded-on-the-tx-path",
          "excerpts": [
            "The buffers successfully put in the Tx queue will be freed by the PMD. That's the only option, so yes it's a good practice."
          ]
        },
        {
          "title": "SPDK: Changelog",
          "url": "https://spdk.io/doc/changelog.html",
          "excerpts": [
            "spdk_thread_create() now takes an optional CPU affinity mask that is passed to the scheduler. ... Users should use the -m or –cpumask command line option to ...",
            "This mode is currently supported at PCIe layer, which tracks the qpair creation with state machine and returns to the user immediately. Default mode is set to ...",
            "Added support for ZNS zone append command with new API spdk_nvme_zns_zone_append and spdk_nvme_zns_zone_append_with_md . nvmf. nvmf_fc_lld_fini now takes ..."
          ]
        },
        {
          "title": "Sharing an NVMe SSD with Multiple Processes · Issue #566",
          "url": "https://github.com/spdk/spdk/issues/566",
          "excerpts": [
            "Jan 9, 2019 — I also create a pthread and set its core affinity as 1 (called thread 1). ... The submission qpair is created on main process through master core."
          ]
        },
        {
          "title": "[PDF] Zero Copy Rx with io_uring - LPC 2023",
          "url": "https://lpc.events/event/17/contributions/1596/attachments/1346/2694/Zero%20Copy%20Rx%20with%20io_uring%20-%20LPC%202023.pdf",
          "excerpts": [
            "Hybrid solution. ○ Standard control plane using kernel networking stack. ○ Fast ZC Rx data plane using io_uring. ○ Two parts:."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet 800 Series — Linux Performance Tuning Guide",
          "url": "https://cdrdv2-public.intel.com/636781/636781_Intel%C2%AE%20Ethernet%20800%20Series_Tuning%20Guide_rev1.3.pdf",
          "excerpts": [
            "IRQ Affinity. Configuring IRQ affinity to ensure interrupts for the hardware Tx/Rx queues are affinitized to proper CPU cores can have a huge ..."
          ]
        },
        {
          "title": "DPDK SORING (Staged Ordered Ring) API Documentation",
          "url": "https://doc.dpdk.org/api/rte__soring_8h.html",
          "excerpts": [
            "This file contains definition of DPDK soring (Staged Ordered Ring) public API. Brief description: enqueue/dequeue works the same as for conventional [rte\\_ring](structrte__ring.html) : any [rte\\_ring](structrte__ring.html) sync types can be used, etc. Plus there could be multiple 'stages'. For each stage there is an acquire (start) and release (finish) operation. after some elems are 'acquired' - user can safely assume having exclusive possession of these elems till 'release' for them is done. Note that right now user has to release exactly the same number of elems acquired before. After 'release', elems can be 'acquired'",
            "he number of bytes needed for a soring, given the expected parameters for it. This value is the sum of the size of the internal metadata and the size of the memory needed by the actual soring elements and their metadata. The value is aligned to a cache line si"
          ]
        },
        {
          "title": "DPDK rte_ring - Struct Reference",
          "url": "https://doc.dpdk.org/api/structrte__ring.html",
          "excerpts": [
            "An RTE ring structure. The producer and the consumer have a head and a tail index.",
            "The particularity of these index is that they are not between 0 and size(ring)-1. These indexes are between 0 and 2^32 -1, and we mask their value when we access the ring[] field. Thanks to this assumption, we can do subtractions between 2 index values in a modulo-32bit base: that's why the overflow of the indexes is not a problem.",
            "Name of the ring.",
            "Size of ring.",
            "Mask (size-1) of ring.",
            "Usable size of ring"
          ]
        },
        {
          "title": "USENIX OSDSI 2014 Arrakis/IX paper",
          "url": "https://www.usenix.org/sites/default/files/osdi14_full_proceedings.pdf",
          "excerpts": [
            "The Arrakis operating system is based upon a fork of the\n\nBarrelfish [10] multicore OS code base",
            "The interface between an application and the Arrakis\n\ncontrol plane is used to request resources from the system\n\nand direct I/O flows to and from user program",
            "Doorbells are exposed to\n\nArrakis programs via regular event delivery mechanisms\n\n(e.g., a file descriptor event) and are fully integrated\n\nwith existing I/O multiplexing interfaces (e.g., selec",
            "We extended Barrelfish with support for SR-IOV, which\n\nrequired modifying the existing PCI device manager to rec-\n\nognize and handle SR-IOV extended PCI capabilit",
            "Who Put the Kernel in My OS Conference? Arrakis: The Operating System is the Control Plane . . . . . . . . . . . . . . . . ."
          ]
        },
        {
          "title": "[dpdk-dev] [RFC PATCH 00/11] generalise rte_ring to allow different ...",
          "url": "https://dev.dpdk.narkive.com/9Yt1Dnxo/dpdk-rfc-patch-00-11-generalise-rte-ring-to-allow-different-datatypes",
          "excerpts": [
            "The rte_ring library in DPDK provides an excellent high-performance mechanism which can be used for passing pointers between cores and"
          ]
        },
        {
          "title": "Constant Bandwidth Servers with Constrained Deadlines",
          "url": "https://retis.sssup.it/~a.biondi/papers/CBS_CD_RTNS17.pdf",
          "excerpts": [
            "by D Casini · 2017 · Cited by 14 — ABSTRACT. The Hard Constant Bandwidth Server (H-CBS) is a reservation-based scheduling algorithm often used to mix hard and soft real-time tasks."
          ]
        },
        {
          "title": "Tips and tricks to optimize your RDMA code",
          "url": "https://www.rdmamojo.com/2013/06/08/tips-and-tricks-to-optimize-your-rdma-code/",
          "excerpts": [
            "Jun 8, 2013 — Configure the Queue Pair to allow several RDMA Reads and Atomic in parallel. If one uses RDMA Read or Atomic operations, it is advised to ..."
          ]
        },
        {
          "title": "io_uring_setup — Lord of the io_uring documentation",
          "url": "https://unixism.net/loti/ref-iouring/io_uring_setup.html",
          "excerpts": [
            "The io_uring_setup() system call sets up a submission queue (SQ) and completion queue (CQ) with at least entries entries, and returns a file descriptor."
          ]
        },
        {
          "title": "In DPDK, how should the memory pool and ring be ...",
          "url": "https://stackoverflow.com/questions/79334801/in-dpdk-how-should-the-memory-pool-and-ring-be-configured-to-minimize-cache-mis",
          "excerpts": [
            "When using rte_mempool_create, set the cache_size and element_size to multiples of the cache line. 1.2: Local Cache: Enable the local cache of ..."
          ]
        },
        {
          "title": "[dpdk-dev] [PATCH v2 2/5] ring: add a non-blocking implementation",
          "url": "https://mails.dpdk.org/archives/dev/2019-January/123477.html",
          "excerpts": [
            "[dpdk-dev] [PATCH v2 2/5] ring: add a non-blocking implementation. Gage Eads gage.eads at intel.com. Wed Jan 16 00:52:24 CET 2019."
          ]
        },
        {
          "title": "[dpdk-dev] [PATCH] doc: announce ring ABI and API changes",
          "url": "https://inbox.dpdk.org/dev/20190513114632.hT__qIK2lJyTbr2YXfpKiEth8O5Q0b3wF2nJcf9X0tA@z/T/",
          "excerpts": [
            "... ring structure. * @@ -97,11 +106,19 @@ struct rte_ring { char pad0 __rte_cache_aligned; /**< empty cache line */ /** Ring producer status. */ - struct ..."
          ]
        },
        {
          "title": "Active Queue Pair Operations",
          "url": "https://docs.nvidia.com/networking/display/rdmaawareprogrammingv17/active+queue+pair+operations",
          "excerpts": [
            "May 23, 2023 — A QP can be queried staring at the point it was created and once a queue pair is completely operational, you may query it, be notified of events and conduct ..."
          ]
        },
        {
          "title": "spdk_nvmf_qpair Struct Reference - SPDK",
          "url": "https://spdk.io/doc/structspdk__nvmf__qpair.html",
          "excerpts": [
            "spdk_nvmf_qpair Struct Reference ; uint8_t, rsvd ; uint16_t, qid ; uint16_t, sq_head."
          ]
        },
        {
          "title": "RTE Ring Core Header Reference",
          "url": "https://doc.dpdk.org/api/rte__ring__core_8h.html",
          "excerpts": [
            "The maximum length of a ring name. Examples"
          ]
        },
        {
          "title": "Compute Functions — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/compute.html",
          "excerpts": [
            "Functions represent compute operations over inputs of possibly varying types. Internally, a function is implemented by one or several “kernels”, depending on ..."
          ]
        },
        {
          "title": "Compute Functions — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/api/compute.html",
          "excerpts": [
            "Apache Arrow compute functions are implementations of the `Function` class, with kernels for specific types, and are registered in a central registry."
          ]
        },
        {
          "title": "arrow/cpp/src/arrow/compute/kernel.h at main · apache/arrow - GitHub",
          "url": "https://github.com/apache/arrow/blob/master/cpp/src/arrow/compute/kernel.h",
          "excerpts": [
            "Apache Arrow is the universal columnar format and multi-language toolbox for fast data interchange and in-memory analytics ..."
          ]
        },
        {
          "title": "facebookincubator/velox: A composable and fully extensible C++ ...",
          "url": "https://github.com/facebookincubator/velox",
          "excerpts": [
            "Velox is a composable execution engine distributed as an open source C++\nlibrary. It provides reusable, extensible, and high-performance data processing\ncomponents that can be (re-)used to build data management systems focused on\ndifferent analytical workloads, including batch, interactive, stream\nprocessing, and AI/ML.",
            "Velox provides the following high-level components:",
            "* **Type** : a generic typing system that supports scalar, complex, and nested\n  types, such as structs, maps, arrays, et",
            "* **Vector** : an [Arrow-compatible columnar memory layout\n  module](https://facebookincubator.github.io/velox/develop/vectors.html) ,\n  providing encodings such as Flat, Dictionary, Constant, and Sequence/RLE, in\n  addition to a lazy materialization pattern and support for out-of-order\n ",
            "* **Expression Eval** : a [fully vectorized expression evaluation\n  engine](https://facebookincubator.github.io/velox/develop/expression-evaluation.html) that allows expressions to be efficiently executed on top of Vector/Arrow\n  encoded d",
            "* **Functions** : sets of vectorized scalar, aggregates, and window functions\n  implementations following the Presto and Spark semanti",
            "* **Operators** : implementation of relational operators such as scans, writes,\n  projections, filtering, grouping, ordering, shuffle/exchange, [hash, merge,\n  and nested loop joins](https://facebookincubator.github.io/velox/develop/joins.html) ,\n  unnest, and",
            "* **I/O** : a connector interface for extensible data sources and sinks,\n  supporting different file formats (ORC/DWRF, Parquet, Nimble), and storage\n  adapters (S3, HDFS, GCS, ABFS, local files) to be u",
            "* **Network Serializers** : an interface where different wire protocols can be\n  implemented, used for network communication, supporting [PrestoPage](https://prestodb.io/docs/current/develop/serialized-page.html) and Spark's UnsafeRo",
            "* **Resource Management** : a collection of primitives for handling\n  computational resources, such as [memory\n  arenas](https://facebookincubator.github.io/velox/develop/arena.html) and\n  buffer management, tasks, drivers, and thread pools for CPU and thread\n  execution, spilling, and "
          ]
        },
        {
          "title": "Velox | Open-Source Composable Execution Engine",
          "url": "https://velox-lib.io/",
          "excerpts": [
            "Velox is a high-performance, open-source execution engine designed for flexibility and reuse. Distributed as a C++ library, it offers modular, composable ..."
          ]
        },
        {
          "title": "io_uring_prep_timeout(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_prep_timeout.3.html",
          "excerpts": [
            "The io_uring_prep_timeout(3) function prepares a timeout request. The submission queue entry sqe is setup to arm a timeout specified by ts and with a timeout ..."
          ]
        },
        {
          "title": "Configuration Settings — Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/user-guide/configs.html",
          "excerpts": [
            "datafusion.execution.batch_size. 8192. Default batch size while creating new batches, it's especially useful for buffer-in-memory batches since creating tiny ...",
            "Setting this to true ensures that newlines in values are parsed successfully, which may reduce performance. datafusion.execution.batch_size. 8192. Default batch ..."
          ]
        },
        {
          "title": "chore: Investigate impact of small batches on performance · ...",
          "url": "https://github.com/apache/datafusion-comet/issues/495",
          "excerpts": [
            "When running TPC-H q16 with DataFusion, there is a significant difference in performance between runs with coalesce batches enabled vs disabled."
          ]
        },
        {
          "title": "jorgecarleitao/arrow2: Transmute-free Rust library to work ...",
          "url": "https://github.com/jorgecarleitao/arrow2",
          "excerpts": [
            "Feb 18, 2024 — A Rust crate to work with Apache Arrow. The most feature-complete implementation of the Arrow format after the C++ implementation.See more"
          ]
        },
        {
          "title": "Can reference a part of a slice via Rc to achieve zero copy?",
          "url": "https://users.rust-lang.org/t/can-reference-a-part-of-a-slice-via-rc-to-achieve-zero-copy/73719",
          "excerpts": [
            "Apr 1, 2022 — I'm trying to achieve zero-copy parsing of a file by saving the borrow of &'a [u8] , but soon &'a messes up the lifecycle.See more"
          ]
        },
        {
          "title": "Monitor the columnar engine | AlloyDB Omni 16.8.0 - Google Cloud",
          "url": "https://cloud.google.com/alloydb/omni/16.8.0/docs/columnar-engine/monitor",
          "excerpts": [
            "This page describes how to monitor utilization of the columnar engine. Verify usage of the columnar engine using EXPLAIN."
          ]
        },
        {
          "title": "Data Cloud - Zero Copy Connectivity | Salesforce US",
          "url": "https://www.salesforce.com/data/connectivity/zero-copy/",
          "excerpts": [
            "Zero copy is a data federation technology that enables enterprises to access and query data without copying it."
          ]
        },
        {
          "title": "OceanBase Database V4.3 Feature Breakdown: In-depth Analysis of ...",
          "url": "https://medium.com/@wpleonardo0537/oceanbase-database-v4-3-feature-breakdown-in-depth-analysis-of-columnar-storage-af31254daf6c",
          "excerpts": [
            "In row-based storage mode, OceanBase Database realizes seamless integration with the vectorized storage engine to support vectorized execution ..."
          ]
        },
        {
          "title": "Zero-copy convert slice of integers to slice of bytes",
          "url": "https://stackoverflow.com/questions/74503746/zero-copy-convert-slice-of-integers-to-slice-of-bytes",
          "excerpts": [
            "Reinterpret a slice of T as a slice of bytes without copying. Only use with simple copy types like integers, floats, bools, etc. Don't use with structs or ...See more"
          ]
        },
        {
          "title": "Zero-Copy Cloning & Time Travel: Boosting Development ... - Medium",
          "url": "https://medium.com/@pascalpfffle/zero-copy-cloning-time-travel-boosting-development-and-testing-efficiency-in-snowflake-d44078daee5c",
          "excerpts": [
            "Missing: ingestion buffers"
          ]
        },
        {
          "title": "Research for Practice: OS Scheduling - Communications of the ACM",
          "url": "https://cacm.acm.org/practice/research-for-practice-os-scheduling/",
          "excerpts": [
            "The key to achieving microsecond-scale core reallocation in the Shenango operating system is the use of a dedicated scheduling core that ..."
          ]
        },
        {
          "title": "Why does io_uring_wait_cqe_timeout always have a ...",
          "url": "https://github.com/axboe/liburing/issues/531",
          "excerpts": [
            "No, it only relates to the timespec being passed in for waiting on events. IORING_OP_TIMEOUT should be sane already in this regard. ... io_uring: ..."
          ]
        },
        {
          "title": "Zero-Copy Sharing using Apache Arrow and Golang",
          "url": "https://voltrondata.com/blog/zero-copy-sharing-using-apache-arrow-and-golang",
          "excerpts": [
            "Jul 20, 2023 — In this post, we're covering a different situation: sending data within the same process by sharing the memory directly without copying.",
            "Zero-Copy Sharing using Apache Arrow and Golang",
            "sending data within the same process by sharing the memory directly without copying. Let’s hop down this rabbit hole!",
            "What if we could hand the utility a pointer to the data and then use it “as-is” without any copying? With the Arrow C data interface, _you c",
            "the Go package provides utilities to both import and export data via this interface.",
            "Central to this vision is the Apache Arrow project.",
            "This series will help users get started with Arrow and Go and see how you can use both to build effective data science workflows.",
            "It’s time for the final post in our series to get you started with Apache Arrow and Golang."
          ]
        },
        {
          "title": "Insights from paper: Apache Arrow DataFusion",
          "url": "https://www.hemantkgupta.com/p/insights-from-paper-apache-arrow",
          "excerpts": [
            "Aug 11, 2024 — Apache Arrow DataFusion is a fast, embeddable, and extensible query engine. It is written in Rust programming language and uses Apache Arrow as its memory ..."
          ]
        },
        {
          "title": "Execution Format",
          "url": "https://duckdb.org/docs/stable/internals/vector.html",
          "excerpts": [
            "The default STANDARD_VECTOR_SIZE is 2048 tuples. Vector Format. Vectors logically represent arrays that contain data of a single type. DuckDB supports different ..."
          ]
        },
        {
          "title": "relationship / unification of arrow-rs and arrow2 going forward · Issue ...",
          "url": "https://github.com/apache/arrow-rs/issues/1176",
          "excerpts": [
            "Zero-copy Vec conversion (#3516) (#1176) #3756 adds zero-copy conversion between Vec and Buffer. Together these work towards allowing us to ..."
          ]
        },
        {
          "title": "Acero: A C++ streaming execution engine",
          "url": "https://arrow.apache.org/docs/12.0/cpp/streaming_execution.html",
          "excerpts": [
            "Push versus pull-based loop fusion in query engines. Journal of Functional ... Substrait defines a broad set of operators and functions for many different ..."
          ]
        },
        {
          "title": "Checkpointing | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/checkpointing/",
          "excerpts": [
            "Exactly-once is preferable for most applications. At-least-once may be relevant for certain super-low-latency (consistently few milliseconds) applications."
          ]
        },
        {
          "title": "Aligned checkpoints",
          "url": "https://aws.amazon.com/blogs/big-data/optimize-checkpointing-in-your-amazon-managed-service-for-apache-flink-applications-with-buffer-debloating-and-unaligned-checkpoints-part-2/",
          "excerpts": [
            "Sep 14, 2023 — The alignment of checkpoint barriers is crucial for achieving exactly-once consistency in Apache Flink applications during checkpoint runs."
          ]
        },
        {
          "title": "A Deep-Dive into Flink's Network Stack - Apache Flink",
          "url": "https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/",
          "excerpts": [
            "Jun 5, 2019 — Flink's network stack is one of the core components that make up the flink-runtime module and sit at the heart of every Flink job."
          ]
        },
        {
          "title": "Monitoring Checkpointing | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/ops/monitoring/checkpoint_monitoring/",
          "excerpts": [
            "Flink's web interface provides a tab to monitor the checkpoints of jobs. These stats are also available after the job has terminated."
          ]
        },
        {
          "title": "Flink Network Stack Vol. 2: Monitoring, Metrics, and that ...",
          "url": "https://flink.apache.org/2019/07/23/flink-network-stack-vol.-2-monitoring-metrics-and-that-backpressure-thing/",
          "excerpts": [
            "Jul 23, 2019 — Flink offers two mechanisms for identifying where the bottleneck is: directly via Flink's web UI and its backpressure monitor, or; indirectly ..."
          ]
        },
        {
          "title": "Backpressure mechanism in Spring Web-Flux - java - Stack Overflow",
          "url": "https://stackoverflow.com/questions/52244808/backpressure-mechanism-in-spring-web-flux",
          "excerpts": [
            "The backpressure is a mechanism that regulates the demand through the transmission (notification) of how many elements recipient can consume."
          ]
        },
        {
          "title": "Streaming Batch Model and Heterogeneous Execution (arXiv:2501.12407)",
          "url": "https://arxiv.org/html/2501.12407v1",
          "excerpts": [
            "We introduce the streaming batch model, a hybrid of the two models that enables efficient and fault-tolerant heterogeneous execution.",
            " materialize and send the batch to a downstream executor. If the downstream executor ",
            "backpressure is applied to limit memory.",
            "There is a common tradeoff among stream processing systems between run-time overheads vs. reconfigurability and recovery overhead",
            "Many systems use asynchronous global checkpointing   [ 28 , 9 ] . This typically imposes low execution overheads, but any failure causes a global rollback to the la",
            "irst, for heterogeneous operators, fusion is often impractical. For example, Figure   2(b) does not fuse A and C because B requires a GPU."
          ]
        },
        {
          "title": "arrow-rs/arrow/examples/zero_copy_ipc.rs at main",
          "url": "https://github.com/apache/arrow-rs/blob/main/arrow/examples/zero_copy_ipc.rs",
          "excerpts": [
            "Zero copy in this case means the Arrow arrays refer directly to a user //! ... Arrow `Buffer` to back the arrow arrays. We // do this by first creating a ..."
          ]
        },
        {
          "title": "arrow2 - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/arrow2/0.4.0",
          "excerpts": [
            "fbs. MUST lay out memory according to the arrow specification; MUST support reading from and writing to the C data interface at zero-copy."
          ]
        },
        {
          "title": "arrow::buffer - Rust",
          "url": "https://docs.rs/arrow/latest/arrow/buffer/index.html",
          "excerpts": [
            "A MutableBuffer is Arrow's interface to build a Buffer out of items or slices of items. NullBuffer: A BooleanBuffer used to encode validity for Arrow arrays ..."
          ]
        },
        {
          "title": "A Case for Informed Request Scheduling at the NIC",
          "url": "https://www.scs.stanford.edu/~dm/home/papers/humphries:gap.pdf",
          "excerpts": [
            "by JT Humphries · 2019 · Cited by 42 — Shinjuku's use of low-overhead interrupts for preemptive scheduling allows it to co-schedule workloads ranging from the microsecond to the ...See more"
          ]
        },
        {
          "title": "Don't Worry About Reactive Backpressure | by Matthew Casperson",
          "url": "https://medium.com/@matthewcasperson/dont-worry-about-reactive-backpressure-f813880fdf05",
          "excerpts": [
            "Backpressure is a complex sounding concept found in reactive systems, but the general idea is very simple."
          ]
        },
        {
          "title": "Integration Testing — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/format/Integration.html",
          "excerpts": [
            "The Arrow project includes cross-language integration tests which are regularly run as Continuous Integration tasks.See more"
          ]
        },
        {
          "title": "Event-driven Applications | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/learn-flink/event_driven/",
          "excerpts": [
            "A ProcessFunction combines event processing with timers and state, making it a powerful building block for stream processing applications."
          ]
        },
        {
          "title": "Mutiny - Flow control and Back-pressure - Quarkus",
          "url": "https://quarkus.io/blog/mutiny-back-pressure/",
          "excerpts": [
            "This post described the different approaches offered by Mutiny to handle back-pressure. The Reactive Streams protocol works well when you can control the pace ..."
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        },
        {
          "title": "The IX Operating System: Combining Low Latency, High ...",
          "url": "https://dl.acm.org/doi/10.1145/2997641",
          "excerpts": [
            "We present ix, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ..."
          ]
        },
        {
          "title": "Benchmarking Tools",
          "url": "https://docs.sel4.systems/projects/sel4-tutorials/benchmarking-guide.html",
          "excerpts": [
            "During each context switch, the kernel adds how long the current thread has run before being switched, and resets the start time for the next thread. The in ...",
            "Benchmarking Tools. The sel4bench-manifest repository collection provides a set of tools which can be used to analyse kernel and workload performance."
          ]
        },
        {
          "title": "Understanding overhead cost of context switching",
          "url": "https://unix.stackexchange.com/questions/681096/understanding-overhead-cost-of-context-switching",
          "excerpts": [
            "Dec 11, 2021 — The cost of context switching is the cost of saving all of the cpu state relating to the process context, and then loading in the context of a new process."
          ]
        },
        {
          "title": "Context Switching & Performance: What Every Developer ...",
          "url": "https://blog.codingconfessions.com/p/context-switching-and-performance",
          "excerpts": [
            "Dec 12, 2024 — For instance, the following infographic puts its cost into a really large bracket of 10,000 to 1 million CPU cycles."
          ]
        },
        {
          "title": "What is P99 latency? [closed]",
          "url": "https://stackoverflow.com/questions/12808934/what-is-p99-latency",
          "excerpts": [
            "It's 99th percentile. It means that 99% of the requests should be faster than given latency. In other words only 1% of the requests are expected to be slower.See more"
          ]
        },
        {
          "title": "Context Switching Overhead ELI5 : r/RISCV",
          "url": "https://www.reddit.com/r/RISCV/comments/ve71m5/context_switching_overhead_eli5/",
          "excerpts": [
            "An seL4 benchmark shows that an Itanium could perform a context switch in 36 cycles ... FAR lower than any other chip (a RISC-V core requires 500)."
          ]
        },
        {
          "title": "What? 80 Million I/O Per Second with a Standard 2U Intel® ...",
          "url": "https://spdk.io/news/2021/05/06/nvme-80m-iops/",
          "excerpts": [
            "80 MILLION IOPS at an amazing average latency of just 25.54 microseconds ... Additionally, the SPDK NVMe driver achieves linear IOPS scalability ..."
          ]
        },
        {
          "title": "Boosting Data Ingest Throughput with GPUDirect Storage ...",
          "url": "https://developer.nvidia.com/blog/boosting-data-ingest-throughput-with-gpudirect-storage-and-rapids-cudf/",
          "excerpts": [
            "To increase the end-to-end read throughput, cuDF uses the cuFile APIs in its data ingest interfaces, like read_parquet and read_orc . As cuDF ...",
            "May 27, 2022 — GPUDirect Storage provides a direct data path to the GPU, reducing latency and increasing throughput for I/O operations. RAPIDS cuDF leverages ..."
          ]
        },
        {
          "title": "Performance Characterization of NVMe Flash Devices with ...",
          "url": "https://arxiv.org/pdf/2310.19094",
          "excerpts": [
            "by K Doekemeijer · 2023 · Cited by 18 — In this paper, we characterize the performance and interfer- ence properties of the Western Digital Ultrastar DC ZN540. SSD, a large-zone ZNS SSD, using a ...",
            "by K Doekemeijer · 2023 · Cited by 18 — We report on the performance features of a commercially available ZNS SSD (13 key observations), explain how these features can be incorpo- rated into publicly ...See more"
          ]
        },
        {
          "title": "Austin Labs - Zoned Namespace (ZNS) Testing Services",
          "url": "https://www.teledynelecroy.com/doc/al-testing-zns-brochure",
          "excerpts": [
            "By dividing the NVMe namespace into zones, ZNS improves latency, throughput and drive capacity, making it ideal for hyper-scale, all-flash array, and large ..."
          ]
        },
        {
          "title": "'Apples to Apples' Zoned Namespaces (ZNS) vs. FTL SSD ...",
          "url": "https://www.radianmemory.com/about/news/apples-to-apples-zoned-namespaces-zns-vs-ftl-ssd-performance-benchmark/",
          "excerpts": [
            "The ultimate performance tests for today's data center applications show tail latencies (99.99% or greater QoS) and include IOPS in the same measurement, ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage ...",
          "url": "https://blogs.oracle.com/cloud-infrastructure/post/accelerate-ai-ml-workloads-oci-nvidia-ibm",
          "excerpts": [
            "Sep 14, 2023 — RAPIDS cuDF Parquet reader benchmark: Uses an open source suite of GPU-accelerated Python libraries to improve data science and analytics ..."
          ]
        },
        {
          "title": "Statistics Behind Latency Metrics: Understanding P90, P95, and P99",
          "url": "https://medium.com/tuanhdotnet/statistics-behind-latency-metrics-understanding-p90-p95-and-p99-dc87420d505d",
          "excerpts": [
            "Latency percentiles, such as P90, P95, and P99, are statistical measures that indicate how response times are distributed.",
            "P99 (99th Percentile): The P99 metric means that 99% of the requests have a response time less than or equal to this value. It focuses on the ..."
          ]
        },
        {
          "title": "On the Costs of Syscalls (2021) - Hacker News",
          "url": "https://news.ycombinator.com/item?id=39174674",
          "excerpts": [
            "This micro benchmark measures the direct cost of system calls. But flushing the TLB and trashing the caches carries an indirect cost too."
          ]
        },
        {
          "title": "Which one affects IPC performance more? context switch ...",
          "url": "https://stackoverflow.com/questions/28856089/which-one-affects-ipc-performance-more-context-switch-or-number-of-processes",
          "excerpts": [
            "In my impression, when talking about improving IPC performance or lower the latency involved, context switch seems to be the most important factor."
          ]
        },
        {
          "title": "Performance characteristics of GDS",
          "url": "https://hps.vi4io.org/_media/events/2024/mst3.pdf",
          "excerpts": [
            "GPUDirect Storage (GDS) or Nvidia Magnum IO provides a direct DMA path\nbetween GPU and PCIe attached storage via the cuFile API in a Nvidia ConnectX-4+\nbased fabric",
            "Summary\n\nI/O based on cuFile API provides large performance gains for reading compared\nto traditional CUDA I/",
            "Results 1\n\nlocal NVME\nCPU POSIX\nCUDA\ncuFile (GDS)\n\n4k rand read IOPS\n934.276\n349.722\n828.3",
            "Results 2\n\nLustre 1 node\nCPU POSIX\nCUDA\ncuFile (GDS)\n\n4k rand read IOPS\n1.124.942\n263.014\n1.054.3",
            "Results 3\n\nLustre 2 nodes\nCPU POSIX\nCUDA\ncuFile (GDS)\n\n4k rand read IOPS\n2.190.572\n497.150\n2.215.7",
            "age limited to systems with Nvidia interconnect and installed MOFED"
          ]
        },
        {
          "title": "Investigation of context switches and asynchronous I/O (B Ingimarsson, 2024)",
          "url": "https://atlarge-research.com/pdfs/2024-bingimarsson-msc_thesis.pdf",
          "excerpts": [
            "by B Ingimarsson · 2024 — 1 shows the IOPS, average and p99 latency, and context switches per second. We do not observe any difference in performance with or without",
            "2.2.2\nContext Switches",
            "On Linux, every process has its own context, which includes a private virtual memory space, and the values of registers. When an application makes a system call, most of the context remains, but execution switches into kernel mode, a special per-process kernel stack is used, and the kernel’s address space becomes accessible."
          ]
        },
        {
          "title": "On the Costs of Syscalls",
          "url": "https://gms.tf/on-the-costs-of-syscalls.html",
          "excerpts": [
            "The costs of a context switch match what others are measuring (modulo division by two).",
            "The fastest host is\nxg6256 which manages to switch modes in\nless than 100 ns.",
            "The user-kernel mode-switch micro-benchmark uses Google's benchmark library for the measurements and is available in\na git repository .",
            "For the benchmark a bunch of syscalls is called that are expected\nto be very cheap, such as getting the user id (UID), the program id\n(PID), closing an invalid file descriptor, calling an\nnon-existent syscall etc.",
            "Thus, the other nanosleep cases set a minimal timer slack of 1\nns which reduces the runtime, as expected. However, it's still\nmuch more expensive than the other syscalls.",
            "the median value of 100 repetitions is reported (real time in\nnanoseconds).",
            "In the following sections\nthe median value of 100 repetitions is reported (real time in\nnanoseconds).",
            "So looking at the real syscalls, the user-kernel mode switches\ncost in the order of a few hundred nanoseconds, on all hosts.",
            "the\nbenchmark process is running under the standard scheduling policy\nand on Linux",
            ". The table shows that on RHEL 7 querying\nCLOCK_MONOTIC_RAW and\nCLOCK_TAI invokes a real syscall while\non Fedora 33 kernels (5.12/5.13) these clock readings are also\nimplemented as vDSO."
          ]
        },
        {
          "title": "Tail Latency: Key in Large-Scale Distributed Systems - Last9",
          "url": "https://last9.io/blog/tail-latency/",
          "excerpts": [
            "p50 (median): This indicates what the \"typical\" request looks like. p95: 95% of requests are faster than this value. p99: This is where tail ..."
          ]
        },
        {
          "title": "In microkernel, do messages between applications/servers goes ...",
          "url": "https://www.quora.com/In-microkernel-do-messages-between-applications-servers-goes-through-the-kernel-or-it-is-possible-to-context-switch-directly",
          "excerpts": [
            "A context switch is the mechanism to store and restore the state or context of a CPU in Process Control block (PCB) so that a process execution ..."
          ]
        },
        {
          "title": "linux - What is the overhead of a context-switch?",
          "url": "https://stackoverflow.com/questions/21887797/what-is-the-overhead-of-a-context-switch",
          "excerpts": [
            "A context switch will not result in the flushing of the TLB – but just changing the tag of the current address space to the tag of the address space of the new ..."
          ]
        },
        {
          "title": "NSDI '19 Technical Sessions",
          "url": "https://www.usenix.org/conference/nsdi19/technical-sessions",
          "excerpts": [
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency. ... 6.6x ..."
          ]
        },
        {
          "title": "The Kingman Formula – Variation, Utilization, and Lead Time",
          "url": "https://www.allaboutlean.com/kingman-formula/",
          "excerpts": [
            "The Kingman equation (also known as Kingman formula or Kingman approximation) gives you an approximation of the waiting time of the parts for a single process."
          ]
        },
        {
          "title": "Long-Tail Latency Problem in Microservices",
          "url": "https://www.geeksforgeeks.org/system-design/long-tail-latency-problem-in-microservices/",
          "excerpts": [
            "In a microservices architecture, this issue can manifest when a few service calls have notably longer response times compared to the average."
          ]
        },
        {
          "title": "Lead-time variability in a homogeneous queueing model of ...",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/S0925527398000292",
          "excerpts": [
            "by R Kuik · 1999 · Cited by 32 — In addition, they state that the batching decision that minimizes the average queueing delay also tends to minimize the variance in the waiting time. In this ..."
          ]
        },
        {
          "title": "NIC の⾼速化と システムソフトウェア研究",
          "url": "https://seminar-materials.iijlab.net/iijlab-seminar/iijlab-seminar-20231017.pdf",
          "excerpts": [
            "Oct 17, 2023 — • Shinjuku (NSDI 2019). • TAS (EuroSys 2019). • Caladan (OSDI 2020) ... Tail Latency. In 16th USENIX Symposium on Networked Systems Design ..."
          ]
        },
        {
          "title": "seL4/sel4bench: sel4 benchmarking applications and support library.",
          "url": "https://github.com/seL4/sel4bench",
          "excerpts": [
            "Missing: cycles microbenchmark"
          ]
        },
        {
          "title": "L4 microkernel family - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/L4_microkernel_family",
          "excerpts": [
            "L4 is a family of second-generation microkernels, used to implement a variety of types of operating systems (OS)"
          ]
        },
        {
          "title": "r/linux on Reddit: L4 Microkernels: The Lessons from 20 Years of ...",
          "url": "https://www.reddit.com/r/linux/comments/4ef9ab/l4_microkernels_the_lessons_from_20_years_of/",
          "excerpts": [
            "I often hear the pure microkernel architecture is slow because it requires more context switches line, but according to these figures, it would ..."
          ]
        },
        {
          "title": "Learning Unified System Representations for Microservice ...",
          "url": "https://arxiv.org/html/2508.01635v1",
          "excerpts": [
            "In this paper, we presented USRFNet, a dual-stream fusion network for predicting window-level P95 tail latency in microservice systems."
          ]
        },
        {
          "title": "An Analysis of Holistic Tail Latency Behaviors of Java ...",
          "url": "https://ieeexplore.ieee.org/document/8855342",
          "excerpts": [
            "by P Tennage · 2019 · Cited by 7 — In this paper, we focus on analyzing and characterizing the behaviour of tail latency values of microservices workloads under service's peak sustainable ..."
          ]
        },
        {
          "title": "Predicting bounds on queuing delay for batch-scheduled ...",
          "url": "https://dl.acm.org/doi/10.1145/1122971.1122989",
          "excerpts": [
            "by J Brevik · 2006 · Cited by 110 — In this work, we explore a new method for providing end-users with predictions for the bounds on the queuing delay individual jobs will experience. We evaluate ..."
          ]
        },
        {
          "title": "A Small Dice Game for the Kingman Formula",
          "url": "https://inria.hal.science/hal-02164892v1/document",
          "excerpts": [
            "by C Roser · 2018 · Cited by 1 — For the general G/G/1 queue, there exist different approximations. The most com- mon one is the Kingman approximation as shown in equation (2)."
          ]
        },
        {
          "title": "Kingman's formula",
          "url": "https://en.wikipedia.org/wiki/Kingman%27s_formula",
          "excerpts": [
            "Kingman's formula, also known as the VUT equation, is an approximation for the mean waiting time in a G/G/1 queue."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". Arrakis: The Operating System is the Control\nPlane. OSDI, 2014.",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        },
        {
          "title": "Network Interface Controller Drivers - Download",
          "url": "https://fast.dpdk.org/doc/pdf-guides-20.02/nics-20.02.pdf",
          "excerpts": [
            "May 18, 2020 — The SR-IOV NIC switch forwards the packet to a specific VM according to the. MAC destination address which belongs to the destination VF on ..."
          ]
        },
        {
          "title": "Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOoroPxwW5RK38PZBdOI2YMlE1W5qR4wyNfP0NTN08UNbtRkAXUOs",
          "excerpts": [
            "May 23, 2023 — Page 1. Revision 2.6. May 2023. 613875-008. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ..."
          ]
        },
        {
          "title": "Intel® Ethernet Network Adapter E810-2CQDA2",
          "url": "https://cdrdv2-public.intel.com/639389/Intel%20Ethernet%20Network%20Adapter%20E810-2CQDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 512 SR-IOV Virtual Functions**. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized ...",
          "url": "https://semiconductor.samsung.com/news-events/news/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Samsung Electronics, today unveiled its new enterprise solid-state drive (SSD) featuring Zoned Namespace (ZNS) technology — the PM1731a.",
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ports, ensuring ..."
          ]
        },
        {
          "title": "What are the system requirements for GPUDirect RDMA?",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20system%20requirements%20for%20GPUDirect%20RDMA?",
          "excerpts": [
            "Hardware Requirements  PCIe Bus Support: The system must support PCIe Gen3 or higher for optimal performance. RDMA-Capable Network Adapter: The network interface card (NIC) must support GPUDirect RDMA (e.g., Mellanox ConnectX-6/7, NVIDIA BlueField DPU, or other compatible adapters)."
          ]
        },
        {
          "title": "31. Shared Virtual Addressing (SVA) with ENQCMD",
          "url": "https://www.kernel.org/doc/html/next/x86/sva.html",
          "excerpts": [
            "Use of SVA requires IOMMU support in the platform. IOMMU is also required to support the PCIe features ATS and PRI. ATS allows devices to cache translations ..."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 — Feature Support Matrix",
          "url": "https://cdrdv2-public.intel.com/630155/630155_E810%20Feature%20Summary_rev3_4.pdf",
          "excerpts": [
            "Sep 16, 2022 — Use case assumes up to 256 VFs with SR-IOV, assign them to containers, 1 VF per container. Table 10. Configuration Maximums. Host OS. Max VFs."
          ]
        },
        {
          "title": "Using SR-IOV VF in CT with DPDK - Proxmox Support Forum",
          "url": "https://forum.proxmox.com/threads/using-sr-iov-vf-in-ct-with-dpdk.110959/",
          "excerpts": [
            "I am trying to use some VFs of a NIC in a CT. What I did so far: 1. Enable SR-IOV in bios 2. Enable IOMMU with pass through 3. Load kernel modules on startup."
          ]
        },
        {
          "title": "Change log : Hirsute (21.04) : linux-raspi package : Ubuntu",
          "url": "https://launchpad.net/ubuntu/hirsute/+source/linux-raspi/+changelog",
          "excerpts": [
            "... count transport header in UFO - i40e: Fix correct max_pkt_size on VF RX queue - i40e: Fix NULL ptr dereference on VSI filter sync - i40e: Fix changing ..."
          ]
        },
        {
          "title": "Device sharing and memory disaggregation in PCIe ...",
          "url": "https://home.simula.no/~paalh/students/JonasMarkussen-phd.pdf",
          "excerpts": [
            "To facilitate device sharing and memory disaggregation among machines connected using PCIe non-transparent bridges, we present SmartIO. SmartIO makes all."
          ]
        },
        {
          "title": "[FAQ] what is CUDA GPU direct nvme equivalent thing in ROCm",
          "url": "https://github.com/ROCm/ROCm/issues/2251",
          "excerpts": [
            "Missing: peer- peer DMA GDS"
          ]
        },
        {
          "title": "System Requirements and Recommendations - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/networking/display/GPUDirectRDMAv18/System+Requirements+and+Recommendations",
          "excerpts": [
            "To achieve the best performance for GPUDirect RDMA, it is required that both the HCA and the GPU be physically located on the same PCIe IO root complex."
          ]
        },
        {
          "title": "The relationship between GPUDirect RDMA, GPUDirect P2P, NVidia ...",
          "url": "https://forums.developer.nvidia.com/t/the-relationship-between-gpudirect-rdma-gpudirect-p2p-nvidia-ipc-nccl-and-nvshmem/316874",
          "excerpts": [
            "GPUDirect RDMA at the lowest level provides for data exchange “directly” between a GPU and a non-GPU device like a Networking Adapter or ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            "Missing: ROCm equivalent",
            "The Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver.",
            "The prerequisites for configuring GPUDirect RDMA or GPUDirect Storage depend on whether you use DMA-BUF from the Linux kernel or the legacy `nvidia-peermem` kernel module.",
            "To support GPUDirect RDMA, userspace CUDA APIs are required. The kernel mode support is provided by one of two approaches: DMA-BUF from the Linux kernel or ...",
            "GPU Driver | An Open Kernel module driver is required.",
            "CUDA | CUDA 11.7 or higher. The CUDA runtime is provided by the driver.",
            "GPU | Turing architecture data center, Quadro RTX, and RTX GPU or higher.",
            "Network Device Drivers | MLNX\\_OFED or DOCA-OFED are optional. You can use the Linux driver packages from the package manager",
            "Linux Kernel | 5\\.12 or higher",
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "ROCE/RDMA to/from GPU memory-space with UCX? : r/ROCm",
          "url": "https://www.reddit.com/r/ROCm/comments/1jmqmwq/rocerdma_tofrom_gpu_memoryspace_with_ucx/",
          "excerpts": [
            "Missing: peer- peer DMA equivalent"
          ]
        },
        {
          "title": "The mlx5 Ethernet poll mode driver ( librte_net_mlx5 )",
          "url": "https://doc.dpdk.org/guides/nics/mlx5.html",
          "excerpts": [
            "The mlx5 Ethernet poll mode driver ( librte_net_mlx5 ) provides support for NVIDIA NIC and DPU device families.",
            "* Additional Tx acceleration for small packets is achieved\nby saving PCI bandwidth with enhanced Multi-Packet Write (eMPW) .",
            "The mlx5 PMD provides a comprehensive set of counters designed for debugging and diagnostics related to packet scheduling during transmission. These counters ...",
            "39.2.2. Flow Steering",
            "A major benefit of the mlx5 devices",
            "is the bifurcated driver capability.",
            "It allows to route some flows from the device to the kernel\nwhile other flows go directly to the userspace PMD.",
            "This capability allows the PMD to coexist with kernel network interfaces\nwhich remain functional, although they stop receiving unicast packets\nas long as they share the same MAC address.",
            "This means Linux control tools (ethtool, iproute and more)\ncan operate on the same network interfaces as ones owned by the DPDK application.",
            "When using flow offload extensively,\nthe configuration of the flow rules becomes performance-critical.",
            "That’s why the hardware is evolving to offer faster flow steering access.",
            "The steering engine was accelerated by introducing Direct Verbs,\nand even more with Direct Rules.",
            "At this stage, a lot of flow rules manipulations were done in software. This technology is named software steering (SWS).",
            "Later the performance was a lot more improved\nwith hardware steering (HWS) ,\na WQE-based high scaling and safer flow insertion/destruction.",
            "It allows to insert millions of rules per second.",
            "While using the synchronous flow API is convenient and easy to manage,\nit is not efficient enough at a large scale."
          ]
        },
        {
          "title": "1. Getting Started with GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/gpudirect-storage/getting-started/index.html",
          "excerpts": [
            "NVIDIA® GPUDirect® Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce ..."
          ]
        },
        {
          "title": "How to enable GPU Direct Storage (GDS) with P2PDMA",
          "url": "https://forums.developer.nvidia.com/t/how-to-enable-gpu-direct-storage-gds-with-p2pdma/340055",
          "excerpts": [
            "Does enabling GDS in P2PDMA mode only require installing CUDA 12.8, or are there other necessary steps or configurations? What are the exact ...",
            "GDS can be enabled in two ways: using the GDS NVIDIA kernel driver (nvidia-fs.ko) and updating the NVMe driver patches, or optionally as of 12.8 ..."
          ]
        },
        {
          "title": "P2PDMA Support Added to Linux Kernel 4.20 RC1",
          "url": "https://www.eideticom.com/blog/p2pdma-support-added-to-linux-kernel-4-20-rc1-eideticom-blog",
          "excerpts": [
            "Nov 5, 2018 — It is possible p2pdma can be the basis for a legitimate upstream version of GPUDirect for example, which has failed to be accepted for ..."
          ]
        },
        {
          "title": "What are the hardware requirements for using GPUDirect ...",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20hardware%20requirements%20for%20using%20GPUDirect%20with%20NVIDIA%20GPUs?",
          "excerpts": [
            "GPUDirect RDMA (Remote Direct Memory Access) and GPUDirect Storage have additional hardware prerequisites: RDMA-Capable NICs: For GPUDirect RDMA, the ..."
          ]
        },
        {
          "title": "NVIDIA MELLANOX CONNECTX-6 DX",
          "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/documents/nvidia-connectx-6-dx-en-hpe-datasheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities, and supports up to 8 million rules. > Advanced Quality of Service ..."
          ]
        },
        {
          "title": "5. NVIDIA MLX5 Common Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-23.11/platform/mlx5.html",
          "excerpts": [
            "The mlx5 kernel modules are part of upstream Linux. The minimal supported kernel version is 4.14. For 32-bit, version 4.14.41 or above is required. The ..."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 Datasheet",
          "url": "https://www.intel.com/content/www/us/en/content-details/613875/intel-ethernet-controller-e810-datasheet.html",
          "excerpts": [
            "This document describes the external architecture (including device operation, pin descriptions, register definitions, and so on) for the Intel® Ethernet ..."
          ]
        },
        {
          "title": "32. Intel Virtual Function Driver - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-23.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "27. Intel Virtual Function Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-20.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "NVIDIA Mellanox ConnectX-6 Ethernet SmartNIC Data Sheet",
          "url": "https://www.cisco.com/c/dam/en/us/products/collateral/servers-unified-computing/ucs-c-series-rack-servers/nvidia-mellanox-connectx-6-ethernet-smartnic-data-sheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities and supports up to 8 million rules. > Advanced quality of service (QoS)— ..."
          ]
        },
        {
          "title": "Blazing Fast NVMEs and Direct Storage API for PCs *spawn*",
          "url": "https://forum.beyond3d.com/threads/blazing-fast-nvmes-and-direct-storage-api-for-pcs-spawn.61761/page-5",
          "excerpts": [
            "May 18, 2020 — Only PCIe Switches (virtual PCI-PCI bridges) are required to support P2P ... This still won't enable GPUDirect Storage or RDMA on desktops."
          ]
        },
        {
          "title": "Loading data to GPU *directly* from the SSD drive, almost ...",
          "url": "https://www.reddit.com/r/deeplearning/comments/13aks7g/directstorage_loading_data_to_gpu_directly_from/",
          "excerpts": [
            "Is it possible in major frameworks (TF or PyTorch) to load all data to GPU directly from a fast SSD disc, without using the CPU? Is it possible today?See more"
          ]
        },
        {
          "title": "spdk_nvme_zns_zone_report Struct Reference",
          "url": "https://spdk.io/doc/structspdk__nvme__zns__zone__report.html",
          "excerpts": [
            "The documentation for this struct was generated from the following file: nvme_spec.h."
          ]
        },
        {
          "title": "[PDF] Ultrastar DC ZN540 ZNS SSD Product Brief - Western Digital",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/product-brief/product-brief-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar® DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set as ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ...",
            "RDMA\n•\niWARP and RoCE v2. •\n256K Queue Pairs (QPs",
            "The E810 fully supports Next Generation VMDq mode and SR-IOV.",
            "irtualization (enhanced SR-IOV \nsupport with up to 256 VFs and backward compatibility VF driver support)"
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        },
        {
          "title": "28. ICE Poll Mode Driver - Documentation",
          "url": "https://doc.dpdk.org/guides/nics/ice.html",
          "excerpts": [
            "The ice PMD (librte_net_ice) provides poll mode driver support for 10/25/50/100/200 Gbps Intel® Ethernet 800 Series Network Adapters based on the following ..."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA2",
          "url": "https://cdrdv2-public.intel.com/641674/Intel%20Ethernet%20Network%20Adapter%20E810-XXVDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA4",
          "url": "https://cdrdv2-public.intel.com/742008/Dell_Intel%20Ethernet%20Network%20Adatper%20E810-XXVDA4.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "How to Reach the Max Bandwidth Speed of a Single RDMA QPS ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000088729/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "The E810s cannot reach the max bandwidth speed of a single RDMA QPS (queue pairs) in either iWARP or RoCEv2 mode.Columbiaville is designed to deliver best ..."
          ]
        },
        {
          "title": "iWARP Throughput Performance Issue on Intel® Ethernet Network ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000059783/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "Intel® Ethernet Network Adapter E810-CQDA2 is designed to deliver best performance using multiple Queue Pairs (QP) hence, it cannot reach maximum bandwidth ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet' s Performance Report with DPDK 22.11",
          "url": "https://fast.dpdk.org/doc/perf/DPDK_22_11_Intel_NIC_performance_report.pdf",
          "excerpts": [
            "Figure 14: ice PMD Single core performance on 2x Intel® Ethernet Network Adapter E810-. QCDA2 with turbo boost comparison. Page 21. Intel ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/613875_E810_Datasheet_Rev2_7-3314030.pdf?srsltid=AfmBOopOVGq1VlDC61e6xt9KhgfHGjfbQA4NBSKRxAMyy195mgxFyoAu",
          "excerpts": [
            "Page 1. Revision 2.7. March 2024. 613875-009. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K ..."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "What is NVMe? | An In-Depth Overview ... - Dell Technologies Info Hub",
          "url": "https://infohub.delltechnologies.com/en-us/l/an-in-depth-overview-of-nvme-and-nvme-of/what-is-nvme/",
          "excerpts": [
            "The current set of NVMe command specifications are: NVMe Command Set Specification, Revision 1.1; NVMe Zoned Namespaces Command Set Specification, Revision 1.2 ..."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "GPUDirect Storage O_DIRECT Requirements Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html",
          "excerpts": [
            "GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data\npath for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer\nthrough the CPU. Using this direct path can relieve effective system bandwidth bottlenecks and decrease the\nlatency and utilization load on t",
            "The kernel storage driver can perform a DMA of user data to or from GPU memory by using addresses\n  that were obtained from callbacks to the GDS kernel module, `nvidia-fs.ko`",
            "The device near the storage has a DMA engine that can reach the GPU memory buffer via PCIe. + \n        For local storage, an NVMe device performs DMA. + \n        For remote storage, a NIC",
            "The file system stack that operates at the user-level, or the kernel-level, or both, and never\n  needs to access the data in CPU system memory. > Instead, data is transferred directly between storage and GPU memory, which is achieved by file\n> systems that exclusively use the O\\_DIRECT mode for a give",
            "O\\_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7). CUDA 12.2 (GDS version 1.7)\nintroduces support for non O\\_DIRECT file descriptor",
            "O_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7).",
            "CUDA 12.2 (GDS version 1.7) introduces support for non O_DIRECT file descriptors ... This can be viewed as the compatibility\nmode leveraging the page cache that can typically be used for smaller file I/Os with a high degree of\ntemporal locality, like the case of application headers or metadata",
            "The direct data path between the NIC and GPU memory happens on the client. To enable this direct path, client-side drivers must first be enabled with GDS.",
            "RDMA is a protocol to access remote data over a network and uses the NIC to DMA directly into client-side memory.",
            "Using RDMA also relies on server-side support. File system implementations that do not support RDMA on the server side will not support GDS."
          ]
        },
        {
          "title": "Intel SR-IOV Configuration Guide",
          "url": "https://cdrdv2-public.intel.com/630211/630211_E810%20SR-IOV%20RHEL8%20ConfigGuide_Rev1.2.pdf",
          "excerpts": [
            "Hardware Requirements",
            "ments**\n\n• An Intel <sup>®</sup> Ethernet 800 Series Network Adapter (or other adapter based on an Intel <sup>®</sup> Ethernet 800\n\nSeries Controller).",
            "roller). • A server platform that supports Intel <sup>®</sup> Virtualization Technology for Directed I/O (Intel <sup>®</sup> VT-d) and\n\nthe PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) specification.",
            " • A server platform with an available PCI Express Gen 4.0/3.0 x16 or x8 slot, depending on the\n\nspecific board. **1",
            "Software Requirements",
            "• Red Hat Enterprise Linux Version 8.0 (RHEL 8).",
            ").\n• Intel <sup>®</sup> Ethernet 800 Series Linux Drivers for PF and VF, available at:\n\nhttp://sourceforge.net/projects/e1000/files/\n\nhttp",
            "https://downloadscenter.intel.com",
            "Note:"
          ]
        },
        {
          "title": "Intel Ethernet 800 Series Product Brief",
          "url": "https://gzhls.at/blob/ldb/5/8/6/7/6b497d7cb6eb6fa2fbf214f8c2f7c7a97e22.pdf",
          "excerpts": [
            "\nIntel® Ethernet 800 Series supports up to 100Gb/s throughput for a \nvariety of workloads.",
            "Support both iWARP and RoCEv2 RDMA, selectable via software  \n\nper port for low-latency, high-throughput workloa",
            "Application Device Queues (ADQ) to increase application  \n\npredictability, reduce application latency and improve  \napplication throu",
            " \n\nVFs, 768 VSIs\n",
            "\n\nMove data faster with Intel® Ethernet 800 Series",
            "Intel® Ethernet Controller  \nE810-CAM2/CAM1/XXVAM2"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications.",
            "Missing: RustHallows competitive landscape"
          ]
        },
        {
          "title": "Performance Characterization of NVMe Flash Devices with ...",
          "url": "https://atlarge-research.com/pdfs/2023-cluster-zns-performance-kdoekemeijer.pdf",
          "excerpts": [
            "by K Doekemeijer · Cited by 18 — We report on the performance features of a commercially available ZNS SSD (13 key observations), explain how these features can be incorpo-.See more"
          ]
        },
        {
          "title": "[HELP] Nvidia GPUDirect storage benchmark for an AI400 ...",
          "url": "https://www.reddit.com/r/HPC/comments/qni6cs/help_nvidia_gpudirect_storage_benchmark_for_an/",
          "excerpts": [
            "We are supposed to benchmark the GPU direct storage performance however I cannot seem to find the appropriate benchmarking tool to use."
          ]
        },
        {
          "title": "DO-178C Costs vs Benefits Analysis",
          "url": "https://afuzion.com/do-178c-costs-versus-benefits/",
          "excerpts": [
            "Now, DO-178C increases initial software engineering costs by 25% – 40%. The top ten ways to reduce DO-178C costs are listed below (download the rest of this ..."
          ]
        },
        {
          "title": "Software certifications for safety critical applications : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/cc5nky/software_certifications_for_safety_critical/",
          "excerpts": [
            "Some certifications an embedded system should pass on a safety critical application, some of such certifications (as far as I know) are UL 991 and 1998."
          ]
        },
        {
          "title": "Performance evaluation of containers for low-latency ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0166531624000476",
          "excerpts": [
            "por F Wiedner · 2024 · Mencionado por 5 — Our results demonstrate that containers exhibit similar latency performance with more predictable tail-latency behavior than bare metal packet processing."
          ]
        },
        {
          "title": "Benchmark of SPDK · eunomia-bpf/bpftime Wiki",
          "url": "https://github.com/eunomia-bpf/bpftime/wiki/Benchmark-of-SPDK",
          "excerpts": [
            "Nov 20, 2023 — SPDK is a high-performance user space storage application framework. It has its own tracing capability. We have tried to use bpftrace with SPDK, but the ..."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            "This handbook takes you through the whole DO-178C journey with a focus on verification, leaving you with an understanding of the compliance process as a whole."
          ]
        },
        {
          "title": "DO-178C",
          "url": "https://en.wikipedia.org/wiki/DO-178C",
          "excerpts": [
            "The new document is called DO-178C/ED-12C and was completed in November 2011 and approved by the RTCA in December 2011. It became available for sale and use in ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification is the primary document by which the certification authorities such as FAA, ..."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds.",
            " By avoiding intermediate buffers and memory copies, this approach reduces latency by 50–100 nanoseconds per packet—a meaningful gain in HFT systems.",
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "However, zero-copy networking introduces greater development complexity, requiring careful buffer management, error handling, and integration with kernel-level APIs.",
            "The next section integrates these concepts into a practical low-latency architecture.",
            "Practical Design Example: Building a Low-Latency Pipeline",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay."
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "QNX OS for Safety 8.0",
          "url": "https://blackberry.qnx.com/en/products/safety-certified/qnx-os-for-safety",
          "excerpts": [
            "The QNX OS for Safety is a microkernel OS for embedded systems certified to IEC 61508 SIL 3, ISO 26262 ASIL D and IEC 62304 Class C."
          ]
        },
        {
          "title": "QNX Safety Certifications | ISO 26262, IEC 61508, IEC 62304",
          "url": "https://blackberry.qnx.com/en/developers/certifications",
          "excerpts": [
            "Streamline safety certifications and compliance with embedded software solutions from QNX. Learn more."
          ]
        },
        {
          "title": "Wind River Store - Buy VxWorks, Diab Compiler & More ...",
          "url": "https://www.windriver.com/store",
          "excerpts": [
            "Purchase up to three seats of the world's #1 real-time operating system (RTOS), starting at $19,500 per seat. VxWorks® is a deterministic, priority-based ..."
          ]
        },
        {
          "title": "Linux Licensing Cost - TCO Calculator",
          "url": "https://www.windriver.com/products/linux/tco-calculator",
          "excerpts": [
            "Calculate the costs of building your own embedded Linux product with our TCO Calculator. Find out how market-leading Wind River Linux can save you money!"
          ]
        },
        {
          "title": "AWS Marketplace: QNX OS for Safety 2.2.3",
          "url": "https://aws.amazon.com/marketplace/pp/prodview-26pvihq76slfa",
          "excerpts": [
            "3. Pricing is based on actual usage, with charges varying according to how much you consume."
          ]
        },
        {
          "title": "Green Hills Software: Real-Time Operating Systems (RTOS ...",
          "url": "https://www.ghs.com/",
          "excerpts": [
            "Green Hills Software is the worldwide leader in embedded safety and security. With the most safety and security certifications and the best track record."
          ]
        },
        {
          "title": "QNX Developer License Options",
          "url": "https://blackberry.qnx.com/en/products/qnx-everywhere/licensing",
          "excerpts": [
            "Missing: per unit"
          ]
        },
        {
          "title": "QNX license cost discussion on Reddit",
          "url": "https://www.reddit.com/r/embedded/comments/1e72fip/qnx_license_cost/",
          "excerpts": [
            "There are a few places that are indicating that the dev platform license is ~$15k/yr. QNX license cost? : r/embedded"
          ]
        },
        {
          "title": "What Is DO-178C? - Wind River Systems",
          "url": "https://www.windriver.com/solutions/learning/do-178c",
          "excerpts": [
            "It is the standard that directs software certification for airborne systems for the commercial segment. (Its ramifications for military aerospace will be ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification, is the principal certification document used by certification agencies ..."
          ]
        },
        {
          "title": "Your Complete DO-178C Guide to Aerospace Software Compliance",
          "url": "https://ldra.com/do-178/",
          "excerpts": [
            "DO-178C is a formal process standard that covers the complete software lifecycle – the planning process, development process, and integral processes."
          ]
        },
        {
          "title": "IEC Certification Kit (for ISO 26262 and IEC 61508)",
          "url": "https://www.mathworks.com/products/iec-61508.html",
          "excerpts": [
            "IEC Certification Kit provides tool classification and tool qualification work products, together with templates, certificates, and validation suites."
          ]
        },
        {
          "title": "Tool Qualification Support Package (TQSP)",
          "url": "https://ldra.com/products/tool-qualification-support-packs-tqsp/",
          "excerpts": [
            "A TQSP is an optional module available for the LDRA tool suite. Each TQSP module provides artefacts and guidance to simplify the process of qualifying the LDRA ..."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
          "url": "https://www.lynx.com/challenges/safety-certification",
          "excerpts": [
            "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
            "Delays in certification due to software non-compliance can be costly and de rail project timelines. Lynx empowers teams across industries with modular platforms, pre-certified components, and advanced tools to simplify compliance with DO-178C, ISO 26262, and IEC 61508. Deliver safer, certifiable systems faster and with greater confidence. Seize the Edge with Lynx to achieve 30% faster certification and reduce project complexity.",
            "pre-certified software components",
            "Backed by a track record of successful certifications, LynxSecure and LynxOS-178 deliver DO-178C and FAA RSC compliance while reducing project complexity.",
            "Safety-Critical GPU Solutions",
            "Empower your systems with our certifiable GPU solutions. Achieve high-performance graphics for avionics and automotive applications while maintaining ISO 26262 and DO-178C compliance.",
            "Advanced Vulnerability Management",
            "Ensure system integrity with Vigiles, the industry-leading tool for SBOM-based CVE triage and lifecycle vulnerability management, reducing false positives by 95%.",
            "Certification Consulting Services",
            "Leverage decades of experience in certification-compliant development with expert guidance tailored to DO-178C, ISO 26262, and IEC 61508 projects.",
            "Streamlining DO-178C Certification for Avionics",
            "Our pre-certified components and modular platforms reduce integration complexity and enable seamless compliance with DO-178C DAL A standards.",
            "Ensuring ISO 26262 Compliance in Automotive Systems",
            "ISO 26262 compliance isn’t just a checkbox—it’s the key to safe and reliable ADAS and autonomous systems. Lynx simplifies compliance with certifiable GPU compute solutions and pre-certified software components, ensuring your program stays on track and ahead of the competition.",
            "Streamlining IEC 61508 Certification for Industrial Systems",
            "From robotics to critical infrastructure, Lynx provides the tools to meet IEC 61508 certification requirements.",
            "30% faster certification",
            "Streamline processes and reduce certification timelines with modular pre-certified platforms like LynxSecure and LynxOS-178.",
            "95% Fewer False Positives",
            "Ensure accuracy in vulnerability management with Vigiles, reducing unnecessary manual triage."
          ]
        },
        {
          "title": "AMD Pensando™ DPU Technology",
          "url": "https://www.amd.com/en/products/data-processing-units/pensando.html",
          "excerpts": [
            "The AMD Pensando™ Giglio DPU builds on second-generation architecture with enhanced power and performance efficiency, delivering dual 200 Gbps line-rate offload ..."
          ]
        },
        {
          "title": "Compression Analysis for BlueField-2/-3 Data Processing ...",
          "url": "https://par.nsf.gov/servlets/purl/10538184",
          "excerpts": [
            "by Y Li · 2024 · Cited by 6 — Our study encompasses a comprehensive per- formance analysis of Nvidia BlueField DPUs, specifically focusing on one lossy (SZ34) and three."
          ]
        },
        {
          "title": "Economics And The Inevitability Of The DPU",
          "url": "https://www.nextplatform.com/2022/11/03/economics-and-the-inevitability-of-the-dpu/",
          "excerpts": [
            "Nov 3, 2022 — ... performance of the two ports on the DPU, at 49 Gb/sec. There is an obvious performance benefit, but this is more like getting the performance ..."
          ]
        },
        {
          "title": "Boosting Performance with SPDK and DPDK Solutions - Mirror Review",
          "url": "https://www.mirrorreview.com/spdk-and-dpdk-solutions/",
          "excerpts": [
            "Missing: RustHallows TCO Linux"
          ]
        },
        {
          "title": "Linux Kernel vs DPDK: HTTP Performance Showdown | talawah.io",
          "url": "https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/",
          "excerpts": [
            "Missing: RustHallows competitive"
          ]
        },
        {
          "title": "What is the Cost of a Real-time Operating System (RTOS)?",
          "url": "https://www.lynx.com/embedded-systems-learning-center/cost-of-a-real-time-operating-system-rtos",
          "excerpts": [
            "Generally speaking, purchasing a commercial RTOS will cost about $10K – $20K for the RTOS and one seat of development tools."
          ]
        },
        {
          "title": "RTOS | Wind River Studio",
          "url": "https://www.windriver.com/studio/edge-devices/real-time-os",
          "excerpts": [
            "Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat. Log in or create an account to get ..."
          ]
        },
        {
          "title": "LynxOS-178: Based on Open Standards",
          "url": "https://www.lynx.com/products/lynxos-178-do-178c-certified-posix-rtos",
          "excerpts": [
            "LynxOS-178 is a COTS RTOS supporting x86, Arm, and PowerPC platforms. It is based on open standards and is designed specifically to fulfill the stringent needs ..."
          ]
        },
        {
          "title": "Free Access to QNX SDP 8.0 for Non-Commercial Use",
          "url": "https://www.qnx.com/products/everywhere/",
          "excerpts": [
            "You are now able to get a free QNX SDP 8.0 license for your personal non-commercial use. You must first have a myQNX account which will allow you to access ..."
          ]
        },
        {
          "title": "GreenHills costs what and has Python 2.3? : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/7kw1a3/greenhills_costs_what_and_has_python_23/",
          "excerpts": [
            "GreenHills costs what and has Python 2.3? ... I've mainly used WindRiver's diab and got moved to a certified project. It's my first experience ..."
          ]
        },
        {
          "title": "Licensing Information",
          "url": "http://licensing.qnx.com/info/",
          "excerpts": [
            "This folder contains PDF copies of QNX licensing documents associated with QNX Software Development Platform versions 7.x and 8.0, and associated compatible ..."
          ]
        },
        {
          "title": "VxWorks Reviews in 2025",
          "url": "https://sourceforge.net/software/product/VxWorks/",
          "excerpts": [
            "$18,500 / seat. Pricing Details: Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat."
          ]
        },
        {
          "title": "ISO 26262 Functional Safety Training & Certification Program",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/36-34-20-0006",
          "excerpts": [
            "Course Agenda. The certified Functional Safety according to ISO 26262 is a training spanned across 4 and a half days comprising of the following: Day 1 - ..."
          ]
        },
        {
          "title": "IEC 61508: A comprehensive guide to functional safety ...",
          "url": "https://spyro-soft.com/blog/industry-4-0/iec-61508",
          "excerpts": [
            "SIL 3: High level of safety integrity, with a significantly lower probability of failure than SIL 2. SIL 4: Highest level of safety integrity, ..."
          ]
        },
        {
          "title": "VxWorks Safety Platforms - Wind River Systems",
          "url": "https://www.windriver.com/products/vxworks/safety-platforms",
          "excerpts": [
            "An RTOS platform for safety-critical applications that require DO-178C, IEC 61508, or ISO 26262 certification evidence in the avionics, transportation, ..."
          ]
        },
        {
          "title": "DO-178C Explained",
          "url": "https://consunova.com/do-178c-explained/",
          "excerpts": [
            "Mar 31, 2024 — DO-178C defines five levels (A, B, C, D, and E) to classify the criticality of software functions based on their potential impact on aircraft ..."
          ]
        },
        {
          "title": "Guidance on Using IEC 61508 SIL Certification to Support ...",
          "url": "https://www.nrc.gov/docs/ML2130/ML21305A001.pdf",
          "excerpts": [
            "The SIL certification process involves manufacturers seeking compliance with IEC 61508, a separate entity called the CB that reviews the ..."
          ]
        },
        {
          "title": "How developers can leverage RTOS functional safety certification",
          "url": "https://www.embedded.com/how-developers-can-leverage-rtos-functional-safety-certification/",
          "excerpts": [
            "RTOS functional safety certification benefits not only safety-critical devices but all embedded devices as a means to improve time-to-market ..."
          ]
        },
        {
          "title": "How to get started with iso 26262 as a firmware developer?",
          "url": "https://www.reddit.com/r/embedded/comments/14icplp/how_to_get_started_with_iso_26262_as_a_firmware/",
          "excerpts": [
            "Your first step at estimating cost is to get a static analysis tool and find out how many warnings there are in your code base, and writing up a ..."
          ]
        },
        {
          "title": "Low Latency 5G UPF Using Priority Based Packet Classification",
          "url": "https://builders.intel.com/docs/networkbuilders/low-latency-5g-upf-using-priority-based-5g-packet-classification.pdf",
          "excerpts": [
            "SA UPF, developed by Intel and SK Telecom, shows improved performance in latency and jitter for high priority traffic while still running.",
            "Foundational NICs do not \ntypically offer offloads for functions \nsuch as vSwitch acceleration, VXLAN \nTEP or inline IPS",
            "They do, however, \noffer advanced features in order to \nscale the VNF performance by \noptimizing packet steering in the \nser",
            "Dynamic Device Personalization (DDP) \nis a capability that was introduced with \nIntel® Ethernet 700 Series Network \nAdapters to load an additional package \nto enable classification and steering of \nadditional specified packet types and \nperformance of additional inline \nact",
            "DDP can be used to optimize \npacket processing performance for \ndifferent network functions, native or \nrunning in a virtual environme",
            "By \napplying a DDP profile to the network \ncontroller the following use cases can \nbe address",
            "Extended support for protocols:\n\n• 5G GTP support for 5G user plane.",
            "• 5G SDAP/PDCP support for 5G NR\nuser plane.",
            "• 5G/4G PFCP (CP-UP separation)\nsupport.",
            "• IP protocols as new flow types, for\nexample L2TPv3, ESP/AH for\nIPSec.",
            "• Legacy protocols: PPPoE,\nPPPoL2TPv2.",
            "• New protocols/standards: eCPRI/\nORAN, Radio over Ethernet (RoE).",
            "• Extensibility for custom protocol\nparsing/classification.",
            "The Intel® Ethernet 800 Series provides \nthe capability to steer packets of \ndifferent priority into specific queue \ngroups as described in Figure 5",
            "software receiving and processing \n\npackets must be aware of the receive \nqueue priority mechanism to enable the \nefficient handling of high priority \npackets",
            "The User Plane Function (UPF) \napplication used in the context of this \nwork is based on the FD.io Vector Packet \nProcessor (VPP) framewo",
            "This \nframework utilizes Data Plane \nDevelopment Kit (DPDK) functionality to \nfetch received packets from the NIC \nqueues and deliver them for further \nproces",
            "The DPDK plugin is a part of \nthe VPP project that exposes packet \nreceive functionality over the dpdk-input \nno",
            "Default implementation of the \ndpdk-input node enables handling of \nmultiple RX queues in the context of a \nsingle worker thre",
            "re 6 implements \nstrict priority logic where packets from \nhigher priority queues are always \nfetched first and next priority queues \nare not served until all packets from \nhigh priority queues are in the \nprocessing stage."
          ]
        },
        {
          "title": "DOCA Perftest RDMA benchmarking tool",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Perftest/index.html",
          "excerpts": [
            "DOCA Perftest is an RDMA benchmarking tool designed for compute clusters, enabling fine-tuned evaluation of bandwidth, message rate, and latency. [Dependencies](.DOCAPerftestv3.0.0-Dependencies)",
            "  + CUDA 12.8 or later, required for GPUDirect RDMA benchmarks"
          ]
        },
        {
          "title": "DOCA Accelerated UPF Reference Application Guide",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Accelerated+UPF+Reference+Application+Guide/index.html",
          "excerpts": [
            "The Accelerated UPF-RAP provides a reference implementation of an accelerated data path of UPF on top of the NVIDIA® BlueField-3®. Tas",
            "Tasks like GTP-U encapsulation/decapsulation, flow tagging, QoS enforcement, and packet forwarding are handled by the NIC, providing deterministic performance and scalability.",
            "Subsequent packets of that flow will be fully processed by Bluefiled-3 HW and forward to their destination without going through the host/UPF-RAP."
          ]
        },
        {
          "title": "performance | microkerneldude",
          "url": "https://microkerneldude.org/tag/performance/",
          "excerpts": [
            "And that means verified seL4 outperforms any microkernel. In almost all cases that's by about a factor of 10 in IPC latency. The closest in ..."
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "I'm Not Dead Yet!: The Role of the Operating System in a Kernel ...",
          "url": "https://dl.acm.org/doi/10.1145/3317550.3321422",
          "excerpts": [
            "This paper argues for a new high-level, device-agnostic I/O abstraction for kernel-bypass devices. We propose the Demikernel, a new library OS architecture for ..."
          ]
        },
        {
          "title": "seL4 Formal Verification Paper (SOSP 2009)",
          "url": "https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf",
          "excerpts": [
            ", is a third-generation\n\nmicrokernel, and is broadly based on L4 [46] and  \ninfluenced by EROS [58].",
            "Complete formal verification is the only known way to guarantee that a system is free of programming errors.",
            "ts. We present seL4, a member of the L4 [46] microker-\n\nnel family, designed to provide this ultimate degree  \nof assurance of functional correctness by machine-  \nassisted and machine-checked formal proof.",
            "e  \nshown the correctness of a very detailed, low-level  \ndesign of seL4 and we have formally verified its C  \nimplementation.",
            "To our knowledge, seL4 is the first-ever general-\n\npurpose OS kernel that is fully formally verified for  \nfunctional correctn"
          ]
        },
        {
          "title": "avionics application software standard interface part 0 overview of ...",
          "url": "https://www.sae.org/standards/content/arinc653p0-3/",
          "excerpts": [
            "The primary objective of ARINC 653 is to define a general-purpose APplication/EXecutive (APEX) interface (API = Application Program Interface)"
          ]
        },
        {
          "title": "[PDF] ARINC-653 Inter-partition Communications and the Ravenscar Profile",
          "url": "https://oa.upm.es/42418/1/INVE_MEM_2015_228287.pdf",
          "excerpts": [
            "The ARINC-653 standard [1] defines an inter-partition communication (IPC) mechanism that can be used to exchange messages between ARINC partitions running on ..."
          ]
        },
        {
          "title": "[PDF] ARINC 653",
          "url": "http://retis.sssup.it/~giorgio/slides/cbsd/cbsd-arinc-2p.pdf",
          "excerpts": [
            "ARINC 653 Services. ➢ Inter-partition communication. ▫ Communication between two or more partitions via messages;. ▫ Two types of communication services are ..."
          ]
        },
        {
          "title": "ARINC 653 on PikeOS - SYSGO",
          "url": "https://www.sysgo.com/arinc-653",
          "excerpts": [
            "The ARINC 653 standard specifies an operational environment for application software used in Integrated Modular Avionics (IMA) modules."
          ]
        },
        {
          "title": "avionics application software standard interface part 1 required ...",
          "url": "https://www.sae.org/standards/content/arinc653p1-5/",
          "excerpts": [
            "This standard defines a general-purpose Application/Executive (APEX) software interface between the Operating System of an avionics computer ..."
          ]
        },
        {
          "title": "[PDF] Using IOMMU for DMA Protection in UEFI Firmware - Intel",
          "url": "https://www.intel.com/content/dam/develop/external/us/en/documents/intel-whitepaper-using-iommu-for-dma-protection-in-uefi-820238.pdf",
          "excerpts": [
            "This paper proposes using IOMMU to resist DMA attacks in firmware, where bus mastering can allow malicious devices to access system memory."
          ]
        },
        {
          "title": "Single Root IO Virtualization (SR-IOV)",
          "url": "https://docs.nvidia.com/networking/display/OFED/Single+Root+IO+Virtualization+(SR-IOV)",
          "excerpts": [
            "Feb 29, 2024 — Single Root IO Virtualization (SR-IOV) is a technology that allows a physical PCIe device to present itself multiple times through the PCIe bus."
          ]
        },
        {
          "title": "IOMMU DMA Remapping - Windows drivers - Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/display/iommu-dma-remapping",
          "excerpts": [
            "IOMMU DMA remapping allows the GPU to access memory through logical addresses that are no longer mapped 1:1. Instead, Dxgkrnl is able to provide logically ..."
          ]
        },
        {
          "title": "Is it possible SR-IOV inside VM? : r/VFIO",
          "url": "https://www.reddit.com/r/VFIO/comments/1emladg/is_it_possible_sriov_inside_vm/",
          "excerpts": [
            "I have a Broadcom NIC with SR-IOV support and would like to create VFs inside the VM, i.e. pass PF to the VM with SR-IOV enabled."
          ]
        },
        {
          "title": "Kernel DMA Protection | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/kernel-dma-protection-for-thunderbolt",
          "excerpts": [
            "Learn how Kernel DMA Protection protects Windows devices against drive-by Direct Memory Access (DMA) attacks using PCI hot plug devices."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "Key Benefits of io_uring. Reduced Overhead: Batched submissions and completions cut system calls drastically.",
            "Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir )",
            "Completion Queue (CQ) : The kernel posts results as Completion Queue Entries (CQEs).",
            "scribe\nThis design minimizes system calls and context switches. Instead of invoking a syscall per operation, the kernel polls the SQ for new entries, while user space checks the CQ for completions — enabling true asynchronous processing.",
            "Key Benefits of io_uring",
            "* Reduced Overhead : Batched submissions and completions cut system calls drastically.",
            "* Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir ).",
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency.",
            "* Ease of Use : The\nliburing library simplifies setup and management."
          ]
        },
        {
          "title": "Put an io_uring on it - Exploiting the Linux Kernel",
          "url": "https://chomp.ie/Blog+Posts/Put+an+io_uring+on+it+-+Exploiting+the+Linux+Kernel",
          "excerpts": [
            "It can be particularly useful for applications that are server/backend related, where a significant proportion of the application time is spent waiting on I/O."
          ]
        },
        {
          "title": "The IOMMU Impact - I/O Memory Management Units",
          "url": "https://medium.com/@mike.anderson007/the-iommu-impact-i-o-memory-management-units-feb7ea95b819",
          "excerpts": [
            "The IOMMU serves as a hardware abstraction layer that provides device isolation, memory protection, and address translation, much like how a traditional Memory Management Unit (MMU) governs virtual memory for CPUs.",
            "IOMMUs abstract this dependency by allowing devices to use I/O virtual addresses.",
            "IOMMU enforces **isolation** between devices and memory regions, a critical security feat",
            "In systems without an IOMMU, a misbehaving or compromised device could write to arbitrary memory regions, leading to system crashes, data leaks, or privilege escalation.",
            "These faults are invaluable for debugging DMA-related issues and for building **resilient systems** that can withstand partial hardware or software failures without complete system cras",
            "SR-IOV takes this a step further by allowing a single physical device to expose multiple **Virtual Functions (VFs)** — lightweight virtual devices that can be independently assigned to different ",
            "Intel VT-d",
            "AMD-Vi (IOMMU)",
            "ARM’s equivalent is the **System Memory Management Unit (SMM",
            "M’s SMMU enables secure execution environments, supporting trusted execution, real-time processing, and virtualization on low-power hardware.",
            "While IOMMUs introduce security and flexibility, they can also add **latency** to I/O operations due to address translation overhead. To mitigate this, modern IOMMUs use **Translation Lookaside Buffers (IOTLBs)** to cache recent address mappings, much like C"
          ]
        },
        {
          "title": "Design Guidelines for High Performance RDMA Systems",
          "url": "https://www.usenix.org/system/files/login/articles/login_fall16_07_kalia.pdf",
          "excerpts": [
            "Queue pairs: RDMA hosts communicate by posting verbs to interfaces called queue pairs (QPs). On completing a verb, the requester's NIC optionally signals ..."
          ]
        },
        {
          "title": "Planning for GPUDirect Storage - IBM",
          "url": "https://www.ibm.com/docs/en/storage-scale/5.2.1?topic=considerations-planning-gpudirect-storage",
          "excerpts": [
            "Supported hardware · GDS clients: x86 with a GPU model that supports GDS. For more details, see NVIDIA GDS documentation. · Network: EDR or HDR InfiniBand, ..."
          ]
        },
        {
          "title": "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified!",
          "url": "https://www.reddit.com/r/rust/comments/17qi9v0/its_official_ferrocene_is_iso_26262_and_iec_61508/",
          "excerpts": [
            "Ferrocene is upstream rustc but with some extra targets, long term support, and qualifications so you can use them in safety critical contexts."
          ]
        },
        {
          "title": "ECDSA Attestation with Intel Software Guard Extensions ...",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/quote-verification-attestation-with-intel-sgx-dcap.html",
          "excerpts": [
            "In this article, we'll demonstrate a remote attestation using the sample code from the Intel SGX DCAP source code repository."
          ]
        },
        {
          "title": "Arrakis: The Operating System Is the Control Plane",
          "url": "https://dl.acm.org/doi/10.1145/2812806",
          "excerpts": [
            "We have designed and implemented a new operating system, Arrakis, that splits the traditional role of the kernel in two."
          ]
        },
        {
          "title": "IX: A Protected Dataplane Operating System for High ...",
          "url": "https://web.eecs.umich.edu/~sugih/courses/eecs589/f16/39-ChunYu+Xinghao.pdf",
          "excerpts": [
            "by A Belay · Cited by 629 — In this paper, the authors introduce a new approach to improve the throughput and reduce the latency with a customized dataplane operating system, called IX ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a hypothetical module Nimbus 2000 that enables a direct-path I/O between NVMe storage, NICs, and GPUs with zero-copy DMA and a Rust-based, queue-rings API mirroring CPU data-path semantics. The most relevant sources are those that explicitly discuss GPUDirect Storage (GDS) and related peer DMA paths, including direct GPU-to-storage or GPU-to-NIC data paths and zero-copy interfaces. Excerpts outlining GPUDirect Storage fundamentals, cuFile APIs, and GPU-accelerated or peer-direct DMA provide direct support for the described Nimbus 2000 concept. Specifically, materials that define GPUDirect Storage as a direct path between storage and GPUs (bypassing CPU) and that describe using CUDA/NVMe memory mappings and zero-copy semantics map directly to the Nimbus 2000's key claims about NVMe-to-GPU DMA, NIC-to-GPU RDMA, and Rust-based queue APIs mirroring CPU rings. Additionally, references to ROCmRDMA/PeerDirect and PCIe P2PDMA infrastructures reinforce the feasibility and architectural pattern of direct device-to-device DMA paths that Nimbus 2000 intends to exploit. The strongest alignment comes from sources that explicitly describe a direct path between storage and GPUs (GDS) and the associated CUDA/Rust-facing interfaces for zero-copy, as well as citations detailing GPU-side DMA registrations and peer-DMA mechanisms. The other excerpts that discuss related I/O bypass stacks (Arrakis, IX, DPDK, SPDK, GPUDirect RDMA) help establish the broader design space Nimbus 2000 claims to inhabit, but are slightly less direct than explicit GDS-based descriptions. Overall, the set of excerpts shows substantial, but not perfectly identical, coverage for Nimbus 2000's claimed capabilities; the alignment is strong where GDS and GPU DMA concepts are discussed, and somewhat weaker where the exact Nimbus-named stack and Rust queue mirrors are described less directly.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations",
      "citations": [
        {
          "title": "The Root Task - Using Rust in seL4 Userspace",
          "url": "https://coliasgroup.com/seL4-summit-2024-rust-training/root-task/index.html",
          "excerpts": [
            "After initializing itself, the seL4 kernel passes control to a userspace program called the root task, whose image is provided to the kernel at boot-time. The ..."
          ]
        },
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "In the model used by L4 microkernels (and seL4 is no exception), an initial user-level task (the root task) is given full rights to all resources left over once ...",
            "A capability encapsulates an object reference plus access rights. In a capability system, such as seL4, any operation is authorised by a capability.",
            "s themselves are stored in kernel memory (in\nCNodes), user mode references them via references to locations CSpace references.",
            "IPC is via Endpoint objects.",
            "In addition, the MCS configuration of seL4 has a scheduling model that supports the kind of temporal isolation that is required for supporting mixed-criticality ..."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "by G Heiser · 2020 · Cited by 43 — We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);"
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores.",
            "t preempt requests as often as every 5µsec",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            "\nFor the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores. For the many real-world scenarios where request service times follow distributions with high dispersion or a heavy tail, they allow short requests to be blocked behind long requests, which leads to poor tail latency.",
            "This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions",
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ...",
            "A Key Distinction: Unlike full kernel bypass solutions like DPDK, io_uring ZC Rx still processes packet headers through the kernel's TCP stack."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "cuFile Compatibility Mode - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/cuda/archive/11.4.0/gds/api-reference-guide/topics/cufile-compatibility.html",
          "excerpts": [
            "The cuFile library provides a mechanism for cuFile reads and writes to use compatibility mode using POSIX pread and pwrite APIS respectively to system memory ..."
          ]
        },
        {
          "title": "PCI Peer-to-Peer DMA Support",
          "url": "https://docs.kernel.org/driver-api/pci/p2pdma.html",
          "excerpts": [
            "The NVMe PCI driver is both a client, provider and orchestrator in that it exposes any CMB (Controller Memory Buffer) as a P2P memory resource (provider), it ..."
          ]
        },
        {
          "title": "ROCK-Kernel-Driver/include/drm/amd_rdma.h at master - GitHub",
          "url": "https://github.com/RadeonOpenCompute/ROCK-Kernel-Driver/blob/master/include/drm/amd_rdma.h",
          "excerpts": [
            "* to specific location of GPU memory */ struct amd_rdma_interface { int (*get_pages)( ... (*put_pages)(struct amd_p2p_info **amd_p2p_data); int ..."
          ]
        },
        {
          "title": "Multi-node network configuration for AMD Instinct ...",
          "url": "https://instinct.docs.amd.com/projects/gpu-cluster-networking/en/latest/how-to/multi-node-config.html",
          "excerpts": [
            "ROCm™ Docs · Support · Instinct ... Used to define the maximum level of distance between a GPU and NIC at which GPU Direct RDMA/PeerDirect should be used."
          ]
        },
        {
          "title": "HowTo Implement PeerDirect Client using MLNX_OFED",
          "url": "https://enterprise-support.nvidia.com/s/article/howto-implement-peerdirect-client-using-mlnx-ofed",
          "excerpts": [
            "The AMD ROCnRDMA module provides PeerDirect support for AMD GPUs as part of the ROCm project. Peer Memory Registration/Deregistration. Memory Regions (MRs) are ..."
          ]
        },
        {
          "title": "GDS cuFile API",
          "url": "https://training.continuumlabs.ai/infrastructure/storage/introduction-to-nvidia-gpudirect-storage-gds/gds-cufile-api",
          "excerpts": [
            "Jun 27, 2024 — The cuFile APIs are most effective in scenarios where there is a need for high-performance data transfer between GPU memory and storage."
          ]
        },
        {
          "title": "Pinning GPU memory for RDMA failed",
          "url": "https://forums.developer.nvidia.com/t/pinning-gpu-memory-for-rdma-failed/209545",
          "excerpts": [
            "Mar 28, 2022 — I am using ibverbs API. I passed a buffer on the GPU-memory (allocated by cudaMalloc) to the function ibv_reg_mr and it failed to register the ..."
          ]
        },
        {
          "title": "Does CX6 support ATS and PRS(Page Request Service)?",
          "url": "https://forums.developer.nvidia.com/t/does-cx6-support-ats-and-prs-page-request-service/290546",
          "excerpts": [
            "Check that it worked: “sudo lspci -s -vvv | grep -I ats”. If you see ATS with +, its enabled. GPU direct with RDMA will use ATS. Thank you"
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "The cuFile configuration settings in GDS are stored in the /etc/cufile.json file. Edit the file for best performance for your application as shown below.",
            "GPU buffers need to be exposed to third-party devices to enable DMA by those devices. The set of pages that\nspan those buffers in the GPU virtual address space need to be mapped to the Base Address Register (BAR) space,\nand this mapping is an overhead. The mechanism to accomplish this mapping is called registration. Explicit GPU buffer registration with the `cuFileBufRegister` API is optional.",
            "If a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer. The following table and IO pattern descriptions provide guidance on whether registration is profitable.",
            "In compatibility mode, an additional file descriptor can be opened on the file without requiring `O_DIRECT` mode. This mode can also handle unaligned reads/writes, even when POSIX cannot.",
            "`cuFileBufRegister` API is optional.\nIf a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer.",
            "This example demonstrates the usage of `cuFileRead` / `cuFileWrite` APIs without using the `cuFileBufRegister` and `cuFileBufDeRegister` APIs.",
            "Although semantically correct, this loop might not be optimal. Internally, GDS uses GPU bounce buffers to perform IOs. Bounce buffers are GPU memory allocations that\nare internal to GDS, and these buffers are registered and managed by the GDS library.",
            "The IO-Pattern - 3 code snippet is the same as the [IO Pattern 1]() and [IO Pattern 2]() code snippets but the `cuFileBufRegister` API is not used.",
            "In the above example, the initialization of `file_offset` is on line 10. 1. After allocating 1 GB of GPU memory, `cuFileBufRegister` is immediately invoked for the entire\n   range of 1 GB as seen on line 15. 2. Fill the entire 1 GB GPU memory by reading 100 MB at a time from file as seen in the following lo",
            "This example demonstrates using `cuFileRead` / `cuFileWrite` when IO is unaligned. The `devPtr_base + devPtr_offset` that are issued to `cuFileRead` or `cuFileWrite` are not 4K aligned. If the IO is unaligned, the cuFile library will issue IO through its internal GPU bounce buffer\ncache. However, if the allocation of the internal cache fails, the IO will fail. To avoid IO failure in this\ncase, you can set `allow_compat_mode` to `true` in the `/etc/cufile.json` file.",
            "Before you install GDS, you must disable IOMMU. Refer to Installing GPUDirect Storage for more information. Note. To determine whether the IOMMU setting is ..."
          ]
        },
        {
          "title": "LWN - Peer-to-peer DMA",
          "url": "https://lwn.net/Articles/931668/",
          "excerpts": [
            "Peer-to-peer DMA",
            "The idea is to\nremove the host system's participation in a transfer of data from one\nPCIe-connected device to another.",
            "The feature was originally aimed at NVMe\nSSDs so that data could simply be copied directly to and from the storage\ndevice without needing to move it to system memory and then from\nthere to somewhere else.",
            "P2PDMA is available in the NVMe driver but only devices\nthat have a CMB can be a DMA source or destination.",
            "NVMe devices are the\nonly systems currently supported as DMA masters as well.",
            "The IOMMU can also play a safeguard\nrole to ensure that errant DMA operations are not actually performed.",
            "The amdgpu/amdkfd driver has supported PCIe P2PDMA between AMD GPUs since 6.0."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky · Cited by 417 — In this paper, we show that a general- purpose RPC library called eRPC can provide state-of-the-art performance on commodity datacenter networks without."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kalia",
          "excerpts": [
            "by A Kalia · 2019 · Cited by 417 — eRPC is a new general-purpose remote procedure call (RPC) library that offers performance comparable to specialized systems, while running on commodity CPUs."
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        },
        {
          "title": "[PDF] FaRM: Fast Remote Memory - USENIX",
          "url": "https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-dragojevic.pdf",
          "excerpts": [
            "FaRM uses one-sided RDMA reads to access data di- rectly and it uses RDMA writes to implement a fast message passing primitive. This ...",
            "by A Dragojević · 2014 · Cited by 1162 — It achieves low latency and high throughput because it bypasses the kernel, avoids the overheads of complex protocol stacks, and performs re-.See more"
          ]
        },
        {
          "title": "[PDF] FaSST: Fast, Scalable and Simple Distributed Transactions with Two ...",
          "url": "https://www.usenix.org/system/files/conference/osdi16/osdi16-kalia.pdf",
          "excerpts": [
            "RPCs involve the remote CPU in message processing and are more flexible than one-sided. RDMA, allowing data access in a single round trip [15]."
          ]
        },
        {
          "title": "picoquic with support for DPDK (work in progress) - GitHub",
          "url": "https://github.com/IPNetworkingLab/picoquic-dpdk",
          "excerpts": [
            "This is a version of PICOQUIC with support for DPDK, which provides better performance by bypassing the kernel networking stack."
          ]
        },
        {
          "title": "Towards Zero-Copy Serialization with NIC Scatter-Gather",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s10-raghavan.pdf",
          "excerpts": [
            "by D Raghavan · 2021 · Cited by 46 — We use a minimal UDP networking stack for DPDK based on LWIP [7]. We show the results in Figure 2. The “No Serialization” line removes ..."
          ]
        },
        {
          "title": "Efficient Remote Procedure Calls for Datacenters",
          "url": "https://www.pdl.cmu.edu/PDL-FTP/CloudComputing/CMU-CS-19-126.pdf",
          "excerpts": [
            "by A Kalia · 2019 — Currently, eRPC is primarily optimized for Mellanox NICs. eRPC also works with DPDK- capable NICs that support flow steering. For Mellanox Ethernet NICs, we ..."
          ]
        },
        {
          "title": "Datacenter RPCs Can Be General and Fast",
          "url": "https://www.usenix.org/system/files/login/articles/login_summer19_05_kalia.pdf",
          "excerpts": [
            "by D Andersen — eRPC is implemented in 6200 SLOC of C++, excluding tests and benchmarks. We evaluated eRPC's performance both in micro- benchmarks and real applications."
          ]
        },
        {
          "title": "Lecture 3: RPC",
          "url": "https://courses.cs.washington.edu/courses/cse452/22wi/lecture/L3/",
          "excerpts": [
            "Three options for RPC semantics: At least once (NFS, DNS, lab 1b); At most once (common, lab 1c); Exactly once. RPC Semantics.See more"
          ]
        },
        {
          "title": "at-most-once and exactly-once - rpc",
          "url": "https://stackoverflow.com/questions/13566869/at-most-once-and-exactly-once",
          "excerpts": [
            "Exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times).See more"
          ]
        },
        {
          "title": "Exploiting Commutativity For Practical Fast Replication",
          "url": "https://www.usenix.org/system/files/nsdi19-park.pdf",
          "excerpts": [
            "by SJ Park · 2019 · Cited by 61 — To avoid duplicate executions of the requests that are already replicated to backups, CURP relies on exactly-once semantics provided by RIFL [20] ..."
          ]
        },
        {
          "title": "Logical Physical Clocks and Consistent Snapshots in Globally ...",
          "url": "https://cse.buffalo.edu/tech-reports/2014-04.pdf",
          "excerpts": [
            "In this paper, we introduced the hybrid logical clocks. (HLC) that combines the benefits of logical clocks (LC) and physical time (PT) while overcoming their ..."
          ]
        },
        {
          "title": "Hybrid Logical Clock (HLC)",
          "url": "https://sergeiturukin.com/2017/06/26/hybrid-logical-clocks.html",
          "excerpts": [
            "HLC combines the benefits of logical clocks (LC) and physical time (PT) while overcoming their shortcomings."
          ]
        },
        {
          "title": "Balance Performance in MsQuic and XDP",
          "url": "https://techcommunity.microsoft.com/t5/networking-blog/balance-performance-in-msquic-and-xdp/ba-p/3627665",
          "excerpts": [
            "Sep 16, 2022 — We look at two performance metrics here: Our goal is to get as low as possible latency while maintaining the highest RPS."
          ]
        },
        {
          "title": "Open-sourcing mvfst-rl, a research platform for managing ...",
          "url": "https://ai.meta.com/blog/open-sourcing-mvfst-rl-a-research-platform-for-managing-network-congestion-with-reinforcement-learning/",
          "excerpts": [
            "Oct 14, 2019 — Mvfst-rl implements congestion control with an asynchronous RL agent, making the training environment more realistic for real-world deployment."
          ]
        },
        {
          "title": "mvfst/quic/state/StateData.h at main",
          "url": "https://github.com/facebookincubator/mvfst/blob/master/quic/state/StateData.h",
          "excerpts": [
            "An implementation of the QUIC transport protocol. Contribute to facebook/mvfst development by creating an account on GitHub."
          ]
        },
        {
          "title": "MsQuic Performance Dashboard - Microsoft Open Source",
          "url": "https://microsoft.github.io/msquic/",
          "excerpts": [
            "MsQuic performance tests have standardized on the draft-banks-quic-performance specification for all scenarios, and are implemented in the MsQuic tool ..."
          ]
        },
        {
          "title": "picoquic-dpdk/README.picoquic.md at main - GitHub",
          "url": "https://github.com/IPNetworkingLab/picoquic-dpdk/blob/main/README.picoquic.md",
          "excerpts": [
            "Picoquic is currently developed as a Visual Studio 2017 project, and simultaneously tested on Windows and on Linux. It has a dependency on the Picotls ..."
          ]
        },
        {
          "title": "Understanding QUIC's Throughput Speedbumps",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3744200.3744780",
          "excerpts": [
            "by S Mukherjee · 2025 — Moreover, kernel-bypass stacks have even higher throughput than the Linux UDP stack. • Crypto:This stage keeps track of all crypto metadata ...See more"
          ]
        },
        {
          "title": "QUIC for the kernel",
          "url": "https://news.ycombinator.com/item?id=44746948",
          "excerpts": [
            "Jul 31, 2025 — This could be achieved by encapsulating TCP in UDP and running a custom TCP stack in userspace on the client. That would allow protocol ...See more"
          ]
        },
        {
          "title": "RPCValet: NI-Driven Tail-Aware Balancing of μs-Scale RPCs",
          "url": "https://faculty.cc.gatech.edu/~adaglis3/files/papers/RPCValet_asplos19.pdf",
          "excerpts": [
            "RPCValet, an NI-driven dynamic load-balancing design\nthat outperforms existing hardware mechanisms for load\ndistribution, and approaches the theoretical maximum\nperformance predicted by queuing models.",
            "Hardware and protocol extensions to soNUMA for na-\ntive messaging support, a required feature for efficient\nRPC handlin",
            "We distinguish RPCValet from\nthese software-only systems by our focus on balancing the\nload of incoming RPCs across the CPU cores.",
            "An RPCValet implementation on soNUMA that delivers\nnear-ideal RPC throughput under strict SLOs, attaining\nwithin 3–16% of the theoretically optimal queuing model.",
            "For µs-scale RPCs, RPCValet outperforms software-based\nand RSS-like hardware-driven load distribution by 2.3–\n2.7× and 29–76%, respectively",
            "RPCValet performs within 3–15% of the ideal single-\nqueue system and significantly outperforms current RPC\nload-balancing approaches",
            "To lower communication overheads and tighten tail la-\ntency, there has been an intensive evolution effort in data-\ncenter-scale networking hardware and software, away from\ntraditional POSIX sockets and TCP/IP and towards lean user-\nlevel protocols such as InfiniBand/RDMA [21] or dataplanes\nsuch as IX a"
          ]
        },
        {
          "title": "RIFL: Reusable Infrastructure for Linearizability (Stanford paper)",
          "url": "https://web.stanford.edu/~ouster/cgi-bin/papers/rifl.pdf",
          "excerpts": [
            "In this paper we describe RIFL (Reusable Infrastruc-\nture for Linearizability), which is a mechanism for ensur-\ning “exactly-once semantics” in large-scale syst",
            "RIFL\nrecords the results of completed remote procedure calls\n(RPCs) durably; if an RPC is retried after it has completed,\nRIFL ensures that the correct result is returned without re-\nexecuting the RPC",
            "RIFL provides a\ngeneral-purpose mechanism for converting at-least-once\nRPC semantics to exactly-once semantics, thereby mak-\ning it easy to turn non-linearizable operations into lineariz-\nable ones.",
            "RAMCloud has several properties that make it an\nattractive target for RIFL. It is already designed for large\nscale and it offers low latency (small remote reads take\n4.7 µs end to end, small durable writes take 13.5 µs);",
            "[8], which have end-to-end RPC times as low as\n5 µs.\n ... \nThese systems offer latencies as\nlow as 5 µs end-to-end for remote operations; the overheads\nintroduced by RIFL must not significantly impact these la-\ntencies. For examp",
            "FaRM [8], which have end-to-end RPC times as low as\n5 µs."
          ]
        },
        {
          "title": "RIFL exactly-once semantics and deduplication mechanisms",
          "url": "https://www.cncf.io/blog/2024/01/19/xline-command-deduplication-mechanism-part-one-introduction-to-rifl/",
          "excerpts": [
            "When the system implements this deduplication mechanism, it can realize exactly-once semantics of command execution, and thus realize a higher ...",
            " The RIFL paper mentions that servers can cache the expiration time of a client\\_id lease and query the Lease Manager only as it nears expiration, reducing network communication.",
            " In the aforementioned processes, either checkDuplicate or processAck involves at least one O(n) complexity operation (either checking duplicates in sequenceNumber order or filtering unordered sequenceNumbers but needing to traverse and filter those less than first\\_incomplete for processAck).",
            "Compared to the O(1) complexity of the previous IndexSet approach, RIFL incurs some additional overhead.",
            "Performance can be optimized by making processAck a separate RPC to notify the server to recycle completion records.",
            " Finally, since the first mechanism for recycling only checks first\\_incomplete, it may encounter a long-running RPC that blocks the recycling of subsequent RPC completion records, potentially leading to excessive memory usage on the server.",
            "The RIFL paper suggests setting a maximum number of inflight RPCs for a client, refusing excess RPCs, and considering early recycling of subsequent RPC completion records, which could make RIFL more complex.",
            "mary**\n\nThe above describes the mechanism by which RIFL maintains exactly-once semantics for unary RPCs. Section 6 of the RIFL paper, titled “Implementing Transactions with RIFL,” details the mechanism for maintaining exactly-once semantics for transactions involving multiple objects."
          ]
        },
        {
          "title": "Kernel-bypass network stacks performance (USENIX ATC 2025, Awamoto)",
          "url": "https://www.usenix.org/system/files/atc25-awamoto.pdf",
          "excerpts": [
            "by S Awamoto — We have seen a surge of kernel-bypass network stacks with different design decisions for higher throughput and lower latency than the kernel ...See more Major criticisms are\n\n",
            "Latency of small messages has been crucial in datacenters,\n\nbecause servers handle many RPCs, such as in-memory key-\n\nvalue cache access for small items and API calls.",
            "In this\n\nsection, we discuss _unloaded_ latency, where the message or\n\npacket is never queued in the network, host interconnect or\n\nthe host software stack, to directly highlight basic software\n\noverheads of the stack; we discuss latency in the presence of\n\nconcurrent requests and connections in the next sectio",
            "For the Linux stack, the application busy-\n\npolls the event descriptor (i.e., on epoll\\_wait ) to avoid the\n\nwake-up procedure of the application that is blocking",
            "However, it is still higher than\n\nDemikernel, which achieves 13 µs , the lowest among all the\n\nstacks we test.",
            ". Warpcore [ 20 ] is a kernel-bypass UDP/IP stack designed for\n\nQUIC, which could also be used to implement kernel-bypass\n\nTCP on top of it. LKL [ 76 ] ",
            "iip [ 78 ] is a portable TCP/IP im-\n\nplementation, potentially replaces lwip and thus improves IX. Warpcore [ 20 ] is a kernel-bypass UDP/IP stack designed for\n\nQUIC, which could also be used to implement kernel-bypass\n\nTCP on top of i",
            "\nDemikernel, which achieves 13 µs , the lowest among all the\n\nstacks we test."
          ]
        },
        {
          "title": "arXiv:2505.14358 - Latency-Aware Networking for Ultra-Low-Latency RPCs",
          "url": "https://arxiv.org/html/2505.14358v1",
          "excerpts": [
            "Pirate accurately estimates response latencies over an encrypted transport (mvfst QUIC [31] ).",
            "Figure 9 compares the accuracy of Pirate against\nthe ground truth response latency and the\nrequest-to-triggered-request latency, for a connection\nrunning for over a minute.",
            "The Pirate algorithm runs on the switch-facing ingress\ninterface of the vantage point.",
            "g loads, the\nlatency-aware Katran is able to produce a sizable\nbenefit in tail latency, and also leads to more\npredictable tail latencies (shorter error bars).",
            "The\nlatency awareness provided by continuous and real-time\nresponse latency measurement enables reducing the 99th\npercentile tail response latency by 37% on average\nacross loads.",
            "In the future, we believe that\neither an extension to the protocol, or heuristics\nbased on payload sizes, may be applied to accurately\nidentify pure ACKs (scenario -ack ) and\npractically realize these benefits",
            "Figure 9: CDF of measured response latencies for a\nQUIC connection, in scenarios that do or do not\ngenerate pure ACK frames ( -ack and -noack ).",
            "G4. Capable of being run “online,” in\nparticular on software middleboxes. Measurement and\nmonitoring devices are frequently deployed in the form\nof virtual network functions managed through a\nsoftware-defined measurement infrastructure, e.g. [ 89 , 35 ] ."
          ]
        },
        {
          "title": "Paper review: Implementing Linearizability at Large Scale and Low ...",
          "url": "http://muratbuffalo.blogspot.com/2016/02/paper-review-implementing.html",
          "excerpts": [
            "In order to implement exactly-once semantics, RIFL must solve 4 problems: RPC identification, completion record durability, retry rendezvous, ..."
          ]
        },
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        },
        {
          "title": "[PDF] RAMCloud RPC Performance Over 10G Ethernet Fabric",
          "url": "https://www.scs.stanford.edu/14au-cs244b/labs/projects/montazeri.pdf",
          "excerpts": [
            "RAMCloud RPC system is one of the lowest latency RPC systems designed up until today. The low latency characteristics in RAMCloud's RPC has been achieved using."
          ]
        },
        {
          "title": "[PDF] RAMCloud and the Low- Latency Datacenter - SNIA.org",
          "url": "https://www.snia.org/sites/default/files/JohnOusterhout_RAMCloud.pdf",
          "excerpts": [
            "▫ Bad for latency. ▫ E.g. RAMCloud threading structure costs 200-300ns/RPC. ▫ Virtualization is potential problem. ○ Buffering. ▫ Network ..."
          ]
        },
        {
          "title": "intel-sgx-dcap-ecdsa-orientation.pdf",
          "url": "https://www.intel.com/content/dam/develop/public/us/en/documents/intel-sgx-dcap-ecdsa-orientation.pdf",
          "excerpts": [
            "This orientation guide describes various third party attestation collaterals provided by Intel that you can use to enable remote attestation of Intel® SGX ...",
            "\nThe Intel® SGX provisioning certificate service offers\n\nAPIs for retrieving provisioning certification key (PCK)\n\ncertificates, revocation lists, Trusted Computing Base\n\n(TCB) information, and the quoting enclave (QE) identity\n\nfor platforms with Intel® SGX enabled, all provided to an\n\non-premise caching service for the Intel® SGX\n\nprovisioning certificate service.",
            "The caching service for Intel® SGX provisioning certification\n\nservice allows a CSP or a datacenter to cache PCK\n\ncertificates, PCK certificate revocation lists (CRL), TCB\n\nInformation, and QE identity structures for all platforms in\n\nits cloud or data center",
            " The CSP or data center can request the attestation data\n\nstructures from Intel for each of its platforms during a\n\ndeployment phase. To request the attestation data from\n\nthe Intel® SGX provisioning certificate service, a proxy\n\nserver with controlled access to the Internet is used. During runtime, the ECDSA based Intel® SGX quote can be\n\nverified using the data cached in the caching service for\n\nthe Intel® SGX provisioning certificate service.",
            "\nThe main limitation is\n\nthat it requires run-time access to the internet to acquire\n\nthe PCK certificates from the Intel® SGX provisioning\n\ncertificate service. I.e. it does not support APIs to retrieve\n\nPCK certificates at deployment time.",
            "t**\n\nIntel has developed a quote format for Intel® SGX ECDSA\n\nbased quotes. This format is used by both the Intel SGX\n\nECDSA quote generation library and the Intel® SGX ECDSA\n\nQuote Verification Library.",
            "**\n\nThe platform quote provider library provides a set of APIs\n\nthat allow the Intel® SGX ECDSA quote generation library\n\nto get platform specific services",
            " platform quote provider library API documentation,\n\nsee https://download.01.org/intel-sgx/dcap-\n\n1\\.1/linux/docs/Intel\\_SGX\\_ECDSA\\_QuoteGenReference\\_DC\n\nAP\\_API\\_Linux",
            ". ** **ECDSA quote format**\n\nIntel has developed a quote format for Intel® SGX ECDSA\n\nbased quotes. This format is used by both the Intel SGX\n\nECDSA quote generation library and the Intel® SGX ECDSA\n\nQuote Verification Library.",
            "This orientation guide describes various third party attestation collaterals provided by Intel that you can use to enable remote attestation of Intel® SGX ..."
          ]
        },
        {
          "title": "[PDF] ReDMArk: Bypassing RDMA Security Mechanisms - USENIX",
          "url": "https://www.usenix.org/system/files/sec21-rothenberger.pdf",
          "excerpts": [
            "They raise concerns about the pre- dictability of hardware-managed memory protection key and the potential misuse of one-sided RDMA ..."
          ]
        },
        {
          "title": "intel/SGX-TDX-DCAP-QuoteVerificationService",
          "url": "https://github.com/intel/SGX-TDX-DCAP-QuoteVerificationService",
          "excerpts": [
            "Quote Verification Service is a stateless server endpoint implementation that verifies attestation evidence (quote) of ISV (Independent Software Vendor) ..."
          ]
        },
        {
          "title": "RDMA IP Core for RoCE v2 from Grovf - BittWare",
          "url": "https://www.bittware.com/partners/grovf-rdma/",
          "excerpts": [
            "MACsec + IPsec. Featuring Xiphera's IP running these popular security protocols in hardware has never been easier! MACsec @ Up to 100G · IPsec @ up to 200G · On ..."
          ]
        },
        {
          "title": "eRPC - Low latency and performance metrics",
          "url": "https://github.com/erpc-io/eRPC",
          "excerpts": [
            "Low latency: 2.3 microseconds round-trip RPC latency with UDP over Ethernet\n    * Performance for small 32-byte RPCs: ~10M RPCs/sec with one CPU core,\n60--80M RPCs/sec with one",
            "Bandwidth for large RPC: 75 Gbps on one connection (one CPU core at server\nand client) for 8 MB RPCs",
            "Scalability: 20000 RPC sessions per server",
            "End-to-end congestion control that tolerates 100-way incasts"
          ]
        },
        {
          "title": "eRPC: A high-performance RPC system for datacenter networks",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/erpc_2019.pdf",
          "excerpts": [
            "eRPC is at most 800 ns slower than RDMA reads.",
            " eRPC's median latency on CX5 is only 2.3 µs",
            "In microbenchmarks, one CPU\ncore can handle up to 10 million small RPCs per second",
            "zero-copy transmission\nin the presence of retransmissions, node failures, and\nrate limiting",
            "eRPC works well in commodity, lossy datacenter networks.",
            "eRPC uses userspace net-\nworking with polling, as in most prior high-performance\nnetworked system"
          ]
        },
        {
          "title": "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics (RAMCloud)",
          "url": "https://dl.acm.org/doi/10.1145/2815400.2815416",
          "excerpts": [
            "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics, thereby making it easy to turn non-linearizable ...",
            "RIFL is designed for large-scale systems and is lightweight enough to be used in low-latency environments.",
            "RIFL handles data migration by associating linearizability metadata with objects in the underlying store and migrating metadata with the corresponding objects.",
            "It uses a lease mechanism to implement garbage collection for metadata.",
            "We have implemented RIFL in the RAMCloud storage system and used it to make basic operations such as writes and atomic increments linearizable; RIFL adds only 530 ns to the 13.5 μs base latency for durable writes.",
            "We also used RIFL to construct a new multi-object transaction mechanism in RAMCloud; RIFL's facilities significantly simplified the transaction implementation.",
            "The transaction mechanism can commit simple distributed transactions in about 20 μs and it outperforms the H-Store main-memory database system for the TPC-C benchmark."
          ]
        },
        {
          "title": "arXiv:1801.05863 - Design and Implementation of RA-TLS for Intel SGX Enclaves",
          "url": "https://arxiv.org/pdf/1801.05863",
          "excerpts": [
            "e propose to\n\ninclude additional information into the X.509\n\ncertificate exchanged during a TLS handshake",
            "**Attestation Verification Report. ** This is the reply\n\nreceived from the Intel Attestation Service (IAS) when\n\nsubmitting a quote for verification [10]. IAS reports\n\nwhether the quote was generated on a genuine Intel\n\nSGX platform by a genuine encl",
            "**Attestation Verification Report Signature. ** The\n\nattestation verification report is signed by IAS. The\n\nsignature ensures that report is authentic and\n\nunmodifi",
            "**Attestation Report Signing Certificate. ** To verify the\n\nsignature over the attestation report, the client must\n\nknow the keys used to create the signatur",
            "**Non-standard X.509 extensions. ** We embed the SGX\n\nidentity information in custom X.509 extensions",
            "**Quoting Enclave Identity. ** The latest identity of Intel’s\n\nquoting enclave including its code measurement and\n\nsecurity versions number"
          ]
        },
        {
          "title": "Reusable Infrastructure for Linearizability(RIFL)",
          "url": "https://www.linkedin.com/pulse/reusable-infrastructure-linearizabilityrifl-hohuan-chang",
          "excerpts": [
            "RIFL aims to solve linearizability problems on large scale distributed systems by providing \"exactly once\" delivery. In fact that thing is not ..."
          ]
        },
        {
          "title": "At-most-once Algorithm for Linearizable RPC in Distributed ...",
          "url": "https://www.scs.stanford.edu/14au-cs244b/labs/projects/park.pdf",
          "excerpts": [
            "RAMCloud handles missing responses by retrying the RPC. Retrying RPCs with missing responses is appropriate for ensuring that the RPC is executed at-least-once ..."
          ]
        },
        {
          "title": "QUIC: A UDP-Based Multiplexed and Secure Transport",
          "url": "https://datatracker.ietf.org/doc/rfc9000/",
          "excerpts": [
            "Feb 19, 2022 — QUIC provides applications with flow-controlled streams for structured communication, low-latency connection establishment, and network path migration."
          ]
        },
        {
          "title": "One of either QUIC or RDMA already deliver this, ...",
          "url": "https://news.ycombinator.com/item?id=28441315",
          "excerpts": [
            "Sep 7, 2021 — QUIC achieves lower latency for connection establishment than TCP+TLS by merging the TCP and TLS handshakes and avoids additional handshakes by ..."
          ]
        },
        {
          "title": "QUIC is not quick enough over fast internet",
          "url": "https://news.ycombinator.com/item?id=41484991",
          "excerpts": [
            "A shared memory queue is a reasonable basis for improving the IO cost between applications and IO stacks such as the network or filesystem stacks."
          ]
        },
        {
          "title": "Attestation Services for Intel® Software Guard Extensions",
          "url": "https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/attestation-services.html",
          "excerpts": [
            "ECDSA-based attestation with Intel SGX DCAP allows providers to build and deliver their own attestation service. This is useful for enterprise, data center, and ..."
          ]
        },
        {
          "title": "Using RDMA Efficiently for Key-Value Services",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/herd_2014.pdf",
          "excerpts": [
            "ABSTRACT. This paper describes the design and implementation of HERD, a key- value system designed to make the best use of an RDMA network."
          ]
        },
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        },
        {
          "title": "Intel SGX",
          "url": "https://docs.ata.network/pom/attestation-module/machine-attestation/intel-sgx",
          "excerpts": [
            "Apr 19, 2024 — Intel SGX facilitates two distinct categories of attestation: Local Attestation, also known as Intra-Platform Attestation, and Remote ..."
          ]
        },
        {
          "title": "Solved: intel sgx secure channel",
          "url": "https://community.intel.com/t5/Intel-Software-Guard-Extensions/intel-sgx-secure-channel/td-p/1358583",
          "excerpts": [
            "Feb 9, 2022 — The answer remains the same. You should build a secure channel between the untrusted application on server S1 and the application on server S2."
          ]
        },
        {
          "title": "QUIC: The Secure Communication Protocol Shaping ...",
          "url": "https://www.zscaler.com/blogs/product-insights/quic-secure-communication-protocol-shaping-future-of-internet",
          "excerpts": [
            "Oct 8, 2024 — One of QUIC's main advantages is its reduced latency. Traditional TCP requires a multi-step handshake to establish a connection and additional ..."
          ]
        },
        {
          "title": "Attestation - SGX 101 - GitBook",
          "url": "https://sgx101.gitbook.io/sgx101/sgx-bootstrap/attestation",
          "excerpts": [
            "Nov 17, 2022 — Local attestation provides an authenticated assertion between two enclaves running on the same platform that they can trust each other and exchange information ..."
          ]
        },
        {
          "title": "First, the latency of RPC may vibrate... RDMA and queue pair (QP)",
          "url": "https://www.usenix.org/system/files/atc22-wei.pdf",
          "excerpts": [
            "As the latency of typical RDMA-enabled applications that\nrequire elasticity has reached to microsecond-scale (see Fig-\nure 1(a)), this high connection time may significantly decrease\nthe application efficiency, e.g., increasing latency when ex-\npanding resources to handle load spike",
            "RDMA is a high bandwidth and low latency networking fea-\nture widely adopted in modern datacenters [53, 19",
            "It has\ntwo well-known primitives: two-sided provides a message\npassing primitive while one-sided provides a remote memory\nabstraction—the RDMA-capable network card (RNIC) can\ndirectly read/write server memory in a CPU-bypassing way.",
            "he latency of RPC may vibrate to tens of mil- liseconds due to the scheduling and queuing overhead of the. CP"
          ]
        },
        {
          "title": "RDMA ICDE20 Paper",
          "url": "https://www.cs.purdue.edu/homes/csjgwang/CloudNativeDB/RDMAICDE20.pdf",
          "excerpts": [
            "UDP and protocols on top of it, like QUIC [20], also have the potential to improve performance, but currently lack hardware acceleration."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://www.usenix.org/legacy/event/sec10/tech/full_papers/Watson.pdf",
          "excerpts": [
            "by RNM Watson · Cited by 275 — Capsicum extends, rather than replaces,. UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sand- box API."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://www.cl.cam.ac.uk/research/security/capsicum/",
          "excerpts": [
            "Capsicum extends the POSIX API, providing several new OS primitives to support object-capability security on UNIX-like operating systems: capabilities - refined ..."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://research.google.com/pubs/archive/36736.pdf",
          "excerpts": [
            "by RNM Watson · 2010 · Cited by 275 — Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives. (sandboxed capability mode and capabilities) and a userspace ..."
          ]
        },
        {
          "title": "What if Rust is combined with CHERI(Capability Hardware ...",
          "url": "https://www.reddit.com/r/rust/comments/1m3w25v/what_if_rust_is_combined_with_chericapability/",
          "excerpts": [
            "CHERI revolutionize computer architecture and can let the memory error hidden in C/C++ to be precisely catched by OS."
          ]
        },
        {
          "title": "exploring CHERI capabilities for a safe language - Nicholas Sim",
          "url": "https://nw0.github.io/cheri-rust.pdf",
          "excerpts": [
            "by NWS Sim · 2020 · Cited by 7 — Both Rust, a safe programming language, and CHERI, an architecture providing hardware capabil- ities, claim to provide low-overhead memory safety to prevent ..."
          ]
        },
        {
          "title": "glommio - Rust",
          "url": "https://docs.rs/glommio/latest/glommio/",
          "excerpts": [
            "Glommio is a library providing a safe Rust interface for asynchronous, thread-local I/O, based on the linux io_uring interface and Rust's async support."
          ]
        },
        {
          "title": "DataDog/glommio",
          "url": "https://github.com/DataDog/glommio",
          "excerpts": [
            "Glommio (pronounced glo-mee-jow or |glomjəʊ|) is a Cooperative Thread-per-Core crate for Rust & Linux based on io_uring . Like other rust asynchronous crates, ...",
            "Glommio is a thread-per-core crate that makes writing highly parallel asynchronous applications in a thread-per-core architecture easier for rustaceans."
          ]
        },
        {
          "title": "tokio-rs/tokio-uring: An io_uring backed runtime for Rust",
          "url": "https://github.com/tokio-rs/tokio-uring",
          "excerpts": [
            "This crate provides io-uring for Tokio by exposing a new Runtime that is compatible with Tokio but also can drive io-uring -backed resources."
          ]
        },
        {
          "title": "Announcing tokio-uring: io-uring support for Tokio",
          "url": "https://tokio.rs/blog/2021-07-tokio-uring",
          "excerpts": [
            "Jul 19, 2021 — Tokio is a runtime for writing reliable asynchronous applications with Rust. It provides async I/O, networking, scheduling, timers, ..."
          ]
        },
        {
          "title": "Tokio vs Tokio-Uring for High-Throughput Web Servers",
          "url": "https://www.reddit.com/r/rust/comments/1hhn40b/performance_comparison_tokio_vs_tokiouring_for/",
          "excerpts": [
            "io_uring is faster. It allows zero copy APIs, allows sharing read and write buffers with the kernel, and a bunch of other goodies."
          ]
        },
        {
          "title": "Zero-copy async IO in Rust? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/zero-copy-async-io-in-rust/106996",
          "excerpts": [
            "It is fundamentally impossible to do async IO from/to &[u8] / &mut [u8] without copies in Rust. The reason is that any such operation must be able to read/ ...",
            "Feb 18, 2024 — Because io-uring differs significantly from epoll, Tokio must provide a new set of APIs to take full advantage of the reduced overhead."
          ]
        },
        {
          "title": "[PDF] LibPreemptible: Enabling Fast, Adaptive, and Hardware-Assisted ...",
          "url": "https://www.csl.cornell.edu/~zhiruz/pdfs/libpreemptible-hpca2024.pdf",
          "excerpts": [
            "Compared to the prior state-of-the-art scheduling system Shinjuku, our system achieves significant tail latency and throughput improvements for various ..."
          ]
        },
        {
          "title": "IO_uring Zero-Copy Receive Support Ready For Linux ...",
          "url": "https://www.reddit.com/r/linux/comments/1ilacgo/io_uring_zerocopy_receive_support_ready_for_linux/",
          "excerpts": [
            "My basic understanding is that DPDK will bypass the kernel network stack and provide direct access to network packets in the user application."
          ]
        },
        {
          "title": "capsule - Rust - Docs.rs",
          "url": "https://docs.rs/capsule",
          "excerpts": [
            "We've created a tool to efficiently manipulate network packets while being type-safe, memory-safe, and thread-safe. Building on DPDK and Rust, Capsule offers:."
          ]
        },
        {
          "title": "datenlord/async-dpdk: DPDK API in async Rust - GitHub",
          "url": "https://github.com/datenlord/async-dpdk",
          "excerpts": [
            "DPDK API in async Rust. Contribute to datenlord/async-dpdk development by creating an account on GitHub."
          ]
        },
        {
          "title": "Zero-Copy in Rust: Challenges and Solutions",
          "url": "https://coinsbench.com/zero-copy-in-rust-challenges-and-solutions-c0d38a6468e9",
          "excerpts": [
            "Jun 8, 2025 — The concept of zero-copy in Rust refers to a technique of working with data in memory without making unnecessary copies, which significantly improves ..."
          ]
        },
        {
          "title": "[PATCH] rust: RFC/demo of safe API for Dpdk Eal, Eth and Rxq",
          "url": "https://inbox.dpdk.org/dev/9c4a970a-576c-7b0b-7685-791c4dd2689d@nvidia.com/T/",
          "excerpts": [
            "[PATCH] rust: RFC/demo of safe API for Dpdk Eal, Eth and Rxq ... DPDK provides mbuf*s: that's a large mismatch. (Yes I'm aware of ..."
          ]
        },
        {
          "title": "Resistance to Rust abstractions for DMA mapping in Linux ...",
          "url": "https://www.reddit.com/r/linux/comments/1igrime/resistance_to_rust_abstractions_for_dma_mapping/",
          "excerpts": [
            "We wrote a single piece of Rust code that abstracts the C API for all Rust drivers, which we offer to maintain ourselves."
          ]
        },
        {
          "title": "Using Capabilities to design safer, more expressive APIs in Rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/7rmgxo/using_capabilities_to_design_safer_more/",
          "excerpts": [
            "The point here being that `Capability` is a trait, which means you can implement it on any type you want.",
            "Suppose we have a `SQLite` type that implements a bunch of methods for interacting with our database.",
            "We might want to grant the capability to a function to save new comments on a thread (just as an example), but want to always first check that the caller has permission to do so. We could achieve this by implementing a new capability for our `SQLite` type. I'm just sketching code below- don't expect this to run as is.",
            "struct SQLite(Connection);",
            "// Post will contain the `Comment` we want to save and the `User` that is trying to post the comment. struct Post<T, U>(pub T, pub U);",
            "impl Capability<Post<Comment, User>> for SQLite {",
            "  type Data = Comment;",
            "  type Error = DBError;",
            "  fn perform(&self, post_comment: Post<Comment, User>) -> Result<Comment, DBError> {",
            "    // Here is where we can check permissions and do the save operation. if self.user_can_post_comments(post_comment.1) {",
            "      self.save_comment(post_comment.0)",
            "    } else {",
            "      Err(InsufficientPermission)",
            "    }",
            "fn handle_comment_post<DB>(db: &DB, comment: Comment, user: User) -> Result<(), DBError>",
            "   where DB: Capability<Post<Comment, User>>",
            "  db.perform(Post(comment, user)).map(|_| ())",
            "This way, capabilities get passed into functions from any of the function's call sites. I could have, instead of writing the `handle_comment_post` function, also have simply made `MyRequestHandler` generic on its contained values and used the `Capability` trait to specify the capabilities that it wants to have.",
            "In this scenario, I can restrict the capabilities of my functions, request handlers, etc. in my `main` function, when I set up each handler. The point here being that `Capability` is a trait, which means you can implement it on any type you want.",
            "If you wanted to create a new type that maybe wraps `SQLite`, you could implement capabilities for that type that only grant a subset of the capabilities had by `SQLite` itself.",
            "Furthermore, since `Capability` is generic on its input, you can define any other types you want, like `Save`, `Post`, `PostButCheckPermissionsFirst`, etc. to only allow callers to use a specific implementation.",
            "e could now write a function that requests this new capability.",
            "struct HandleCommentPosts<DB> {",
            "  database: DB,",
            "impl<DB> Handler for HandleCommentPosts<DB>\n ",
            "  where DB: Capability<Post<Comment, User>>",
            "{",
            "{",
            "  fn handle(&self, req: mut Request) -> IronResult<...> {",
            "    self.database.perform(Post(comment, user))",
            "  }",
            "  }",
            "}",
            "}",
            "}",
            "}",
            "This way, capabilities get passed into functions from any of the function's call sites.",
            "t `Capability` is a trait, which means you can implement it on any type you want. If you "
          ]
        },
        {
          "title": "io_uring interface and shared ring buffers (as described in the provided document)",
          "url": "https://unixism.net/loti/low_level.html",
          "excerpts": [
            "    }",
            "    }",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Sandbox Permissions - Flatpak documentation",
          "url": "https://docs.flatpak.org/en/latest/sandbox-permissions.html",
          "excerpts": [
            "Sandbox Permissions . One of Flatpak's main goals is to increase the security of desktop systems by isolating applications from one another."
          ]
        },
        {
          "title": "Snap confinement | Snapcraft documentation",
          "url": "https://snapcraft.io/docs/snap-confinement",
          "excerpts": [
            "Snap confinement determines the amount of access an application has to system resources, such as files, the network, peripherals and services."
          ]
        },
        {
          "title": "Manifests - Flatpak documentation",
          "url": "https://docs.flatpak.org/en/latest/manifests.html",
          "excerpts": [
            "This page provides information and guidance on how to use manifests, including an explanation of the most common parameters that can be specified."
          ]
        },
        {
          "title": "Snapcraft confinement & interfaces",
          "url": "https://snapcraft.io/blog/snapcraft-confinement-interfaces",
          "excerpts": [
            "Jun 6, 2019 — In this tutorial, we are going to talk about confinement and interfaces – how to restrict what your snaps can do, and then fine-tune the ..."
          ]
        },
        {
          "title": "Flatpak documentation",
          "url": "https://docs.flatpak.org/",
          "excerpts": [
            "These docs cover everything you need to know to build and distribute applications using Flatpak. They begin with a basic introduction to Flatpak."
          ]
        },
        {
          "title": "Interfaces - Snapcraft 8.11.1 documentation",
          "url": "https://documentation.ubuntu.com/snapcraft/stable/explanation/interfaces/",
          "excerpts": [
            "A strictly-confined snap is considered untrusted and runs in a restricted environment. It's only able to access a limited set of resources outside the ..."
          ]
        },
        {
          "title": "Flatpak Command Reference",
          "url": "https://docs.flatpak.org/en/latest/flatpak-command-reference.html",
          "excerpts": [
            "Flatpak is a tool for managing applications and the runtimes they use. In the Flatpak model, applications can be built and distributed independently from the ..."
          ]
        },
        {
          "title": "Rust public abi for foreign language ffi",
          "url": "https://stackoverflow.com/questions/78285226/rust-public-abi-for-foreign-language-ffi",
          "excerpts": [
            "I'm writing a language and want it to be binary compatible with rust, c++ and some other languages. The problem is that I couldn't find information on rusts ..."
          ]
        },
        {
          "title": "Rust ❤️ C++",
          "url": "https://cxx.rs/",
          "excerpts": [
            "safe interop between Rust and C++ by David Tolnay. This library provides a safe mechanism for calling C++ code from Rust and Rust code from C++."
          ]
        },
        {
          "title": "Crate abi_stable - Rust - Docs.rs",
          "url": "https://docs.rs/abi_stable/",
          "excerpts": [
            "The `abi_stable` crate is for Rust-to-Rust FFI, creating libraries loaded at startup with load-time type-checking, and allows dynamic libraries even with ..."
          ]
        },
        {
          "title": "We Need Type Information, Not Stable ABI",
          "url": "https://blaz.is/blog/post/we-dont-need-a-stable-abi/",
          "excerpts": [
            "What it seems to boil down to is parsing a portion of Rust code, collecting types within, and then emitting a C layer, as well as other language ..."
          ]
        },
        {
          "title": "cxx - Rust",
          "url": "https://docs.rs/cxx",
          "excerpts": [
            "This library provides a safe mechanism for calling C++ code from Rust and Rust code from C++, not subject to the many ways that things can go wrong."
          ]
        },
        {
          "title": "abi_stable - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/abi_stable",
          "excerpts": [
            "To run the example crates you'll generally have to build the *_impl crate, then run the *_user crate (all *_user crates should have a help ..."
          ]
        },
        {
          "title": "Experimental Rust Feature: Safer Interoperable ABI",
          "url": "https://news.ycombinator.com/item?id=34145972",
          "excerpts": [
            "Dec 27, 2022 — This proposal seems to define how to convert C ABI to/from Rust types in a standard way. This will likely improve Rust+C use cases over time."
          ]
        },
        {
          "title": "Is #[repr(C)] necessary for Rust-to-Rust FFI - help",
          "url": "https://users.rust-lang.org/t/is-repr-c-necessary-for-rust-to-rust-ffi/50596",
          "excerpts": [
            "The trouble is that in Rust when a struct is repr(Rust) (the default) it is then free to use whatever layout it thinks is most efficient for your program."
          ]
        },
        {
          "title": "The new dynamic user space tracing feature in LTTng",
          "url": "https://lttng.org/blog/2019/10/15/new-dynamic-user-space-tracing-in-lttng/",
          "excerpts": [
            "Oct 15, 2019 — This feature allows you to instrument functions in user space apps and shared libraries at run time by adding and removing user space probes."
          ]
        },
        {
          "title": "aya_ebpf - Rust - Docs.rs",
          "url": "https://docs.rs/aya-ebpf",
          "excerpts": [
            "A library to write eBPF programs. Aya-bpf is an eBPF library built with a focus on operability and developer experience. It is the kernel-space counterpart of ...",
            "A library to write eBPF programs. Aya-bpf is an eBPF library built with a focus on operability and developer experience. It is the kernel-space counterpart of ..."
          ]
        },
        {
          "title": "provide observability on how kernel handles io_uring request #467",
          "url": "https://github.com/axboe/liburing/issues/467",
          "excerpts": [
            "FWIW, perf record can track multiple trace points. // trace all io_uring events perf record -e \"io_uring:*\" -- ./app_to_trace // two specific ..."
          ]
        },
        {
          "title": "LTTng v2.13 — LTTng Documentation",
          "url": "https://lttng.org/docs/v2.13/",
          "excerpts": [
            "Nov 28, 2023 — This is a short guide to get started quickly with LTTng kernel and user space tracing. Before you follow this guide, make sure to install LTTng."
          ]
        },
        {
          "title": "aya - Rust - Docs.rs",
          "url": "https://docs.rs/aya",
          "excerpts": [
            "Aya is an eBPF library built with a focus on operability and developer experience. It does not rely on libbpf nor bcc - it's built from the ground up purely in ..."
          ]
        },
        {
          "title": "Missing Manuals - io_uring worker pool - The Cloudflare Blog",
          "url": "https://blog.cloudflare.com/missing-manuals-io_uring-worker-pool/",
          "excerpts": [
            "We can discover the tracepoints with perf list or bpftrace -l , or by browsing the events/ directory on the tracefs filesystem , usually ..."
          ]
        },
        {
          "title": "Can I view LTTng traced Userspace events and Kernel ...",
          "url": "https://stackoverflow.com/questions/60330773/can-i-view-lttng-traced-userspace-events-and-kernel-events-together-in-trace-com",
          "excerpts": [
            "I am using LTTng to trace kernel events and userspace tracepoints. I want to visualize them together in one Trace Compass window."
          ]
        },
        {
          "title": "Android Manifest Introduction",
          "url": "https://developer.android.com/guide/topics/manifest/manifest-intro",
          "excerpts": [
            "The manifest file describes essential information about your app to the Android build tools, the Android operating system, and Google Play.",
            "| `<permission>` | Declares a security permission that can be used to limit access to specific components or features of this or other applications.",
            "| `<permission-group>` | Declares a name for a logical grouping of related permissions.",
            "| `<permission-tree>` | Declares the base name for a tree of permissions."
          ]
        },
        {
          "title": "Android Permissions Documentation",
          "url": "https://developer.android.com/training/permissions/declaring",
          "excerpts": [
            "To declare a permission that your app might request, include the appropriate <uses-permission> element in your app's manifest file.",
            "For example, an app that needs to access the camera\nhas this line in `AndroidManifest.xml`:\n\n```\n<manifest ...>\n    <uses-permission android:name=\"android.permission.CAMERA\"/>\n    <application ...>\n        ...\n    </application>\n</manifest>\n```",
            "Declare hardware as optional"
          ]
        },
        {
          "title": "The Rustonomicon: Other representations (repr(C))",
          "url": "https://doc.rust-lang.org/nomicon/other-reprs.html",
          "excerpts": [
            "This is the most important `repr` . It has fairly simple intent: do what C does. The order, size, and alignment of fields is exactly what you would expect from C",
            "The interaction of `repr(C)` with Rust's more exotic data layout features must be\nkept in mind.",
            "We strongly recommend using [rust-bindgen](https://rust-lang.github.io/rust-bindgen/) and/or [cbindgen](https://github.com/eqrion/cbindgen) to manage your FFI\nboundaries for you.",
            "The Rust team works closely with those projects to ensure\nthat they work robustly and are compatible with current and future guarantees\nabout type layouts and `repr` s."
          ]
        },
        {
          "title": "The Rustonomicon - FFI",
          "url": "https://doc.rust-lang.org/nomicon/ffi.html",
          "excerpts": [
            "Most foreign code exposes a C ABI, and Rust uses the platform's C calling convention by default when calling foreign functions.",
            "\n\nThe `extern \"C\"` makes this function adhere to the C calling convention, as discussed below in \" [Foreign Calling Conventions](ffi.html) \". The `no_mangle` attribute turns off Rust's name mangling, so that it has a well defined symbol to link to.",
            "Rust guarantees that the layout of a `struct` is compatible with the platform's\nrepresentation in C only if the `#[repr(C)]` attribute is applied to it.",
            "The list of supported ABI constraints\nare:\n\n* `stdcall`\n* `aapcs`\n* `cdecl`\n* `fastcall`\n* `thiscall`\n* `vectorcall` This is currently hidden behind the `abi_vectorcall` gate and is subject to change. * `Rust`\n* `system`\n* `C`"
          ]
        },
        {
          "title": "CantripOS: seL4 + Rust",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-01-leffler.pdf",
          "excerpts": [
            "CantripOS: 100% Rust",
            "Provides a variety of developer tools.",
            "CantripOS: sel4gdb",
            "seL4-thread-aware debugging \nsupport for gdb + Renod",
            "Rust log crate integration",
            "kmem (+ bloaty): tools for inspecting memory footprint",
            "sel4-sys",
            "Rootserver runs and sets up CAmkES \nassembly using untainted memor",
            "CantripOS: Memory Footprint Tools",
            "Memory footprint = $$$ + power."
          ]
        },
        {
          "title": "cap_std - Rust - Docs.rs",
          "url": "https://docs.rs/cap-std",
          "excerpts": [
            "Capability-based APIs represent access to external resources as values which can be passed around between different parts of a program. Two notable features ..."
          ]
        },
        {
          "title": "cap-primitives - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cap-primitives",
          "excerpts": [
            "Capability-based primitives The cap-primitives crate provides primitive sandboxing operations that cap-std and cap-async-std are built on. The ..."
          ]
        },
        {
          "title": "cap-std - Rust Package Registry - Crates.io",
          "url": "https://crates.io/crates/cap-std",
          "excerpts": [
            "This crate provides a capability-based version of std , providing sandboxed filesystem, networking, and clock APIs."
          ]
        },
        {
          "title": "The Typestate Pattern in Rust",
          "url": "https://www.reddit.com/r/rust/comments/c33u9m/the_typestate_pattern_in_rust/",
          "excerpts": [
            "Typestates are a type-system features that allow you to change the type of the object. Here, you do not change the type of anything, you return a new thing ..."
          ]
        },
        {
          "title": "tokio_uring - Rust",
          "url": "https://docs.rs/tokio-uring/latest/tokio_uring/",
          "excerpts": [
            "Tokio-uring provides a safe io-uring interface for the Tokio runtime. The library requires Linux kernel 5.10 or later."
          ]
        },
        {
          "title": "DmaFile in glommio::io - Rust",
          "url": "https://docs.rs/glommio/latest/glommio/io/struct.DmaFile.html",
          "excerpts": [
            "An asynchronously accessed Direct Memory Access (DMA) file. All access uses Direct I/O, and all operations including open and close are asynchronous."
          ]
        },
        {
          "title": "I Built a Rust Zero-Copy Network Proxy That Processes 1M ...",
          "url": "https://medium.com/@FAANG/i-built-a-rust-zero-copy-network-proxy-that-processes-1m-tps-heres-how-093446529f03",
          "excerpts": [
            "In this project I designed a proxy that hijacks OS packet buffers directly, routes them between sockets with minimal Rust abstractions, and ..."
          ]
        },
        {
          "title": "I don't understand zero copy : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/18cian3/i_dont_understand_zero_copy/",
          "excerpts": [
            "There is no single \"zerocopy\" thing, it just implies that you avoid some copying of data, probably for less resource usage."
          ]
        },
        {
          "title": "GitHub - spacejam/rio: pure rust io_uring library, built on ...",
          "url": "https://github.com/spacejam/rio",
          "excerpts": [
            "... buffers until the corresponding request has completed; but it is considered safe in Rust for an object's lifetime and borrows to end without its destructor ..."
          ]
        },
        {
          "title": "Async Rust is not safe with io_uring",
          "url": "https://news.ycombinator.com/item?id=41992975",
          "excerpts": [
            "io-uring's async cancellation mechanism is just an optimization opportunity and doesn't synchronize anything, so it can't be relied on for correctness here."
          ]
        },
        {
          "title": "Structured concurrency? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1270z03/structured_concurrency/",
          "excerpts": [
            "Does Rust have a notion of structured concurrency? The reason I ask is because I'm looking at atuff that's wrapping an Arc around a Mutex."
          ]
        },
        {
          "title": "Local Async Executors and Why They Should be the Default",
          "url": "https://www.reddit.com/r/rust/comments/v8e9fa/local_async_executors_and_why_they_should_be_the/",
          "excerpts": [
            "I prefer a multithreaded executor with the potentially avoidable Send, Sync and 'static bounds sprinkled throughout."
          ]
        },
        {
          "title": "cap-primitives - Rust Package Registry - Crates.io",
          "url": "https://crates.io/crates/cap-primitives/dependencies",
          "excerpts": [
            "The module also provides useful traits that extend `Ipv4Addr` and `Ipv6Addr` with methods for `Add`, `Sub`, `BitAnd`, and `BitOr` operations."
          ]
        },
        {
          "title": "Async Rust is not safe with io_uring",
          "url": "https://www.reddit.com/r/rust/comments/1gfi5r1/async_rust_is_not_safe_with_io_uring/",
          "excerpts": [
            "The problem isn't async Rust, its libraries exposing flawed APIs. My ringbahn, that I wrote in 2019, correctly handles this case by registering a cancellation ..."
          ]
        },
        {
          "title": "PermRust: A Token-based Permission System for Rust - arXiv",
          "url": "https://arxiv.org/html/2506.11701v1",
          "excerpts": [
            "Furthermore, we need our framework to not permit ambient authority, which is “authority that is exercised, but not [explicitly] selected by its ..."
          ]
        },
        {
          "title": "Ambient Authority: The Root of all Evil | by Rico Mariani - Medium",
          "url": "https://ricomariani.medium.com/ambient-authority-the-root-of-all-evil-c3312eebe0c0",
          "excerpts": [
            "Everyone knows (“It is known”) that global variables are “bad”. Lots of global variables makes things very confusing because when your important ..."
          ]
        },
        {
          "title": "structured_spawn - Rust - Docs.rs",
          "url": "https://docs.rs/structured-spawn",
          "excerpts": [
            "Structured async task spawn implementations for Tokio. Read “Tree-Structured Concurrency” for a complete overview of what structured concurrency is, ..."
          ]
        },
        {
          "title": "Structured Concurrency Support · Issue #1879 · tokio-rs/tokio - GitHub",
          "url": "https://github.com/tokio-rs/tokio/issues/1879",
          "excerpts": [
            "Structured concurrency describes programming paradigm. Concurrent tasks are structured in a fashion where there exist clean task hierarchies."
          ]
        },
        {
          "title": "Exploring Capability-based security in software design with Rust",
          "url": "https://bora.uib.no/bora-xmlui/bitstream/handle/11250/3001153/exploring_capability-based_security_in_software_design_with_Rust.pdf?sequence=1&isAllowed=y",
          "excerpts": [
            "Restricting the user's permissions is also known as Principle of Least Privilege (PoLP).",
            "In CBAC, capabilities are unforgeable tokens describing the authorization to\naccess a resource for a principal. Capabilities may be transferred between principals.",
            "We created a capability library 5.8 we used to implement a RESTful API, simple-api 5.9,\nconnecting it with Grant Negotiation and Authorization Protocol (GNAP) into a proof-of-\nconcept capability-based system published on GitHub [10",
            "TypeState enables structs to change behavior after running a\nfunction that changes the internal state of the struct.",
            "We created a library with three procedural macros to implement the design we used in\nCapabilityApi.",
            "ted library enables the developer to specify the available CRUD operations\nfor a data structure in the RESTful API.",
            "We will use\nthis library to build a RESTful API as part of a capability system."
          ]
        },
        {
          "title": "Taming stateful computations in Rust with typestates_.pdf",
          "url": "https://novaresearch.unl.pt/files/47111984/Taming_stateful_computations_in_Rust_with_typestates_.pdf",
          "excerpts": [
            "In typestate-oriented programming objects are modeled in terms of classes and changing states, much like our Rust-based approach. B",
            ". We propose a macro which embeds a typestate description DSL in Rust which allows developers to specify\ntypestates for their APIs; the typestate is checked at compile-time for common mistakes and to ensure the\ncorrect usage of the typestate, we leverage Rust’s type system.",
            "To enforce linear resource usage when build\nthe processes the library makes use of the type system to enforce the\nconsumption of each ‘‘state’’; enforcing protocol completion is done\nthrough a closure, which takes the initial session type and returns a\nterminal End type, a session is then required to be run until completion\notherwise the return type will not be respected and the type checker\nwill raise an error.",
            "\nPart of the typestate-oriented paradigm, the Plaid language [16] is an\n\nextension of the object paradigm. In typestate-oriented programming\nobjects are modeled in terms of classes and changing states, much like\nour Rust-based approach."
          ]
        },
        {
          "title": "Structured concurrency in Rust with Tokio Beyond Tokio Spawn",
          "url": "https://medium.com/@adamszpilewicz/structured-concurrency-in-rust-with-tokio-beyond-tokio-spawn-78eefd1febb4",
          "excerpts": [
            "tructured Concurrency? Structured concurrency is about **scoping tasks** . Instead of fire-and-forget, you treat tasks like children of a parent",
            "\nWelcome to the world of **structured concurrency** — a pattern that helps you manage task lifecycles, handle cancellation, and avoid future leaks.",
            "\n\nRust’s async story is fast, safe, and incredibly powerful.",
            "Rust’s borrow checker already enforces structured memory. Structured concurrency brings that same discipline to async code."
          ]
        },
        {
          "title": "CancellationToken (tokio-util)",
          "url": "https://docs.rs/tokio-util/latest/tokio_util/sync/struct.CancellationToken.html",
          "excerpts": [
            "A token which can be used to signal a cancellation request to one or more tasks. Tasks can call CancellationToken::cancelled() in order to obtain a Future ... [Source](../../src/tokio_util/sync/cancellation_token.rs.html)",
            "#### pub async fn [run\\_until\\_cancelled\\_owned](.run_until_cancelled_owned) <F>(self, fut: F) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <F:: [Output](https://doc.rust-lang.org/nightly/core/future/future/trait.Future.html.Output \"type core::future::future::Future::Output\") >",
            "Runs a future to completion and returns its result wrapped inside of an `Option` unless the `CancellationToken` is cancelled. In that case the function returns `None` and the future gets dropped. The function takes self by value and returns a future that owns the token."
          ]
        },
        {
          "title": "Tree-structured concurrency (Yoshua Wuyts Blog)",
          "url": "https://blog.yoshuawuyts.com/tree-structured-concurrency/",
          "excerpts": [
            "When you drop a future to cancel it, it's\n  guaranteed that all futures underneath it are also cancelle",
            "When an error is created somewhere down in the\n  call-graph, it can always be propagated up to the callers until there is a\n  caller who is ready to handle",
            "When a function returns, you know it is done doing\n  wor",
            "These properties put together lead to something called a **\"black box model of\nexecution\"**: under a structured model of computing you don't need to know\nanything about the inner workings of the functions you're calling, because their\nbehavior is guaranteed. A function will return when it's done, will cancel all\nwork when you ask it to, and you'll always receive an error if there is something\nwhich needs handling. And as a result code under this model is **compo",
            "Structured concurrency is a lens I use in almost all of my\nreasoning about async Rust, and I think it might help others too."
          ]
        },
        {
          "title": "Rust Tokio Task Cancellation Patterns",
          "url": "https://cybernetist.com/2024/04/19/rust-tokio-task-cancellation-patterns/",
          "excerpts": [
            "Rust provides support for [async programming](https://rust-lang.github.io/async-book/?ref=cybernetist.com)\nwhich lets you spawn asynchronous tasks which are then scheduled for execution across OS threads via a runtime executor.",
            "As with everything in Rust, async programming has to be memory-safe so you need to make sure the borrow checker is happy.",
            "One thing the tutorial doesn’t go into much detail is task cancellations, which is something I had a need for in\none of my projects.",
            "Specifically, I needed to spin a bunch of worker tasks and I needed a way to cancel either any or\nall of them."
          ]
        },
        {
          "title": "Forging Ergonomic Rust: The Evolution of Language ...",
          "url": "https://medium.com/the-software-frontier/forging-ergonomic-rust-the-evolution-of-language-design-with-technical-precision-f4f13ca18953",
          "excerpts": [
            "This article revisits that initiative with a deep technical lens, unpacking what ergonomics means in programming languages, how Rust tackled it, ..."
          ]
        },
        {
          "title": "Resources on writing ergonomic APIs? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/9nv60v/resources_on_writing_ergonomic_apis/",
          "excerpts": [
            "Are there any resources or guidance on what exactly makes an ergonomic API in Rust, and how to do that? Thanks in advance! (Further design ..."
          ]
        },
        {
          "title": "Making Async Rust Reliable - Tyler Mandry - GitLab",
          "url": "https://tmandry.gitlab.io/blog/posts/making-async-reliable/",
          "excerpts": [
            "A Rust future can be canceled and stop executing at any await point, in theory. In practice, cancellation semantics of Rust futures is an ..."
          ]
        },
        {
          "title": "Async Rust can be a pleasure to work with (without `Send + Sync + ...",
          "url": "https://www.reddit.com/r/rust/comments/1f920z8/async_rust_can_be_a_pleasure_to_work_with_without/",
          "excerpts": [
            "You can still do that with structured concurrency, no? Structured concurrency just eliminates 'static , not necessarily Send or Sync ."
          ]
        },
        {
          "title": "Async Rust is about concurrency, not (just) performance",
          "url": "https://kobzol.github.io/rust/2025/01/15/async-rust-is-about-concurrency.html",
          "excerpts": [
            "The primary benefit of async/await is that it lets us concisely express complex concurrency; any (potential) performance improvements are just a second-order ..."
          ]
        },
        {
          "title": "io_uring nvme example : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/z0z50w/io_uring_nvme_example/",
          "excerpts": [
            "Io_uring is a next gen async io platform, and NVMe is a super fast API to talk directly with SSDs. I hope by sharing this to avoid to others all ..."
          ]
        },
        {
          "title": "FAQ - Redox - Your Next(Gen) OS",
          "url": "https://www.redox-os.org/faq/",
          "excerpts": [
            "Redox is a microkernel-based, general-purpose OS, created in 2015, aiming to be a complete alternative to Linux and BSD, and is currently in alpha development."
          ]
        },
        {
          "title": "Capability-based security for Redox",
          "url": "https://nlnet.nl/project/Capability-based-RedoxOS/",
          "excerpts": [
            "Capability-based security for Redox ... Redox OS is a Unix-like microkernel-based operating system written in Rust, intended for both the cloud and the desktop."
          ]
        },
        {
          "title": "The Security Benefits of a Rust-Based Operating System ...",
          "url": "https://www.reddit.com/r/rust/comments/1hfvjfy/the_security_benefits_of_a_rustbased_operating/",
          "excerpts": [
            "These types of devices require robust security, and a Rust-based OS could help mitigate vulnerabilities such as buffer overflows and memory- ..."
          ]
        },
        {
          "title": "Linux perf Examples",
          "url": "https://www.brendangregg.com/perf.html",
          "excerpts": [
            "It depends on the rate of the event you are tracing: the more frequent, the higher the overhead and larger the perf.data size. To really cut down overhead ..."
          ]
        },
        {
          "title": "Linux eBPF Tracing Tools",
          "url": "https://www.brendangregg.com/ebpf.html",
          "excerpts": [
            "Dec 28, 2016 — On this page I'll describe eBPF, the front-ends, and demonstrate some of the tracing tools I've developed."
          ]
        },
        {
          "title": "BPF ring buffer - Andrii Nakryiko's Blog",
          "url": "https://nakryiko.com/posts/bpf-ringbuf/",
          "excerpts": [
            "At the same time, BPF ringbuf solves the following issues with BPF perfbuf: memory overhead;; data ordering;; wasted work and extra data copying ...",
            "Being shared across all CPUs, BPF ringbuf allows using one big common buffer to\ndeal with this. Bigger buffer can absorb bigger spikes, but also might allow\nusing less RAM overall, compared to BPF perfbuf.",
            "BPF perfbuf allocates a separate buffer for each CPU. This often means that BPF\ndevelopers have to make a trade off between allocating big enough per-CPU\nbuffers (accommodating possible spikes of emitted data) or being\nmemory-efficient (by not wasting unnecessary memory for mostly empty buffers in\na steady state, but dropping data during data spikes).",
            "BPF ringbuf provides a better performance and memory efficiency, better\nordering guarantees, and better API (both kernel-side and in user-space)."
          ]
        },
        {
          "title": "eBPF Ecosystem Progress in 2024–2025",
          "url": "https://eunomia.dev/blog/2025/02/12/ebpf-ecosystem-progress-in-20242025-a-technical-deep-dive/",
          "excerpts": [
            "Feb 12, 2025 — Verifier Enhancements: The BPF verifier — which ensures that loaded eBPF programs are safe (no out-of-bounds access, no infinite loops, etc.) — ..."
          ]
        },
        {
          "title": "Aya: your tRusty eBPF companion",
          "url": "https://www.deepfence.io/blog/aya-your-trusty-ebpf-companion",
          "excerpts": [
            "Jul 22, 2022 — Although the eBPF verifier ensures memory safety, using Rust over C is still beneficial in terms of type safety. Both Rust and macros inside Aya ..."
          ]
        },
        {
          "title": "libbpf/libbpf-rs: Minimal and opinionated eBPF tooling for ...",
          "url": "https://github.com/libbpf/libbpf-rs",
          "excerpts": [
            "Idiomatic Rust wrapper around libbpf. libbpf-cargo. Helps you build and develop BPF programs with standard Rust tooling."
          ]
        },
        {
          "title": "libbpf_rs - Rust",
          "url": "https://docs.rs/libbpf-rs",
          "excerpts": [
            "libbpf-rs, together with libbpf-cargo (libbpf cargo plugin) allow you to write Compile-Once-Run-Everywhere (CO-RE) eBPF programs. Note this document uses “eBPF” ..."
          ]
        },
        {
          "title": "A Complete Guide to eBPF with Rust: Building Modern ...",
          "url": "https://blog.devgenius.io/a-complete-guide-to-ebpf-with-rust-building-modern-observability-tools-79ea23b0999c",
          "excerpts": [
            "Apr 26, 2025 — In this guide, we'll explore how to leverage eBPF using Rust, a language known for its performance and safety guarantees."
          ]
        },
        {
          "title": "A Deep Dive into Apache Arrow Flight and Its Use Cases",
          "url": "https://celerdata.com/glossary/a-deep-dive-into-apache-arrow-flight-and-its-use-cases",
          "excerpts": [
            "Jan 21, 2025 — Built on Apache Arrow, it leverages a standardized in-memory columnar format that supports zero-copy reads and efficient data processing. This ..."
          ]
        },
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Just raw, zero-copy data movement at high speed. Temporal keeps workflows running smoothly. Arrow Flight keeps data moving without friction. ...",
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency ."
          ]
        },
        {
          "title": "Powered by | Apache Arrow",
          "url": "https://arrow.apache.org/powered_by/",
          "excerpts": [
            "Uses Arrow to efficiently store Python data structures containing large arrays of numerical data. Data can be accessed with zero-copy by multiple processes ..."
          ]
        },
        {
          "title": "Apache Arrow: Use-case Example : r/dataengineering",
          "url": "https://www.reddit.com/r/dataengineering/comments/1gx33ka/apache_arrow_usecase_example/",
          "excerpts": [
            "Arrow's table can be shared with other processes running the same machine without copying the data residing in the RAM."
          ]
        },
        {
          "title": "Safe and usable kernel extensions with Rax",
          "url": "https://arxiv.org/html/2502.18832v1",
          "excerpts": [
            "Feb 26, 2025 — Aya eventually implemented its own version for both intrinsics, using a simple loop to iterate over the data to avoid ever tripping the verifier ..."
          ]
        },
        {
          "title": "Research Update: Isolated Execution Environment for eBPF",
          "url": "https://ebpf.foundation/research-update-isolated-execution-environment-for-ebpf/",
          "excerpts": [
            "This project introduces a novel execution environment designed to isolate BPF programs, offering an alternative architectural solution to enhance the security ..."
          ]
        },
        {
          "title": "Linux perf event Features and Overhead",
          "url": "https://web.eece.maine.edu/~vweaver/projects/perf_events/overhead/weaver_perfevent_overhead.pdf",
          "excerpts": [
            "by VM Weaver · Cited by 185 — It allows sampling with arbitrary performance events (or a timer if you lack performance counters) and provides frequency graphs, profiles, and stack traces."
          ]
        },
        {
          "title": "eBPF and Performance",
          "url": "https://www.brendangregg.com/Slides/SIGCOMM2024_eBPF_Performance.pdf",
          "excerpts": [
            "5) Crosscheck measured numbers. 6) Measure tool overhead. 7) <80 chars wide by default. 8) Add CLI options: follow other tool style. 9) Concise, intuitive, self ..."
          ]
        },
        {
          "title": "Pitfalls of relying on eBPF for security monitoring (and ...",
          "url": "https://blog.trailofbits.com/2023/09/25/pitfalls-of-relying-on-ebpf-for-security-monitoring-and-some-solutions/",
          "excerpts": [
            "Sep 25, 2023 — As Brendan Gregg observed: eBPF has many uses in improving computer security, but just taking eBPF observability tools as-is and using them ..."
          ]
        },
        {
          "title": "Unraveling eBPF Ring Buffers",
          "url": "https://www.deep-kondah.com/deep-dive-into-ebpf-ring-buffers/",
          "excerpts": [
            "This post is to provide an in-depth discussion of BPF ring buffers, covering their internals, including memory allocation, user-space mapping, locking ..."
          ]
        },
        {
          "title": "Performance Overhead of Perf Event Subsystem in Linux ...",
          "url": "https://stackoverflow.com/questions/2794188/performance-overhead-of-perf-event-subsystem-in-linux-kernel",
          "excerpts": [
            "The overhead of the PMU-based hardware counters should depend on how many different events you're sampling, and how often."
          ]
        },
        {
          "title": "[PDF] A Practical, Lightweight, and Flexible Confinement Framework in eBPF",
          "url": "https://www.cisl.carleton.ca/~will/written/techreport/mcs-thesis.pdf",
          "excerpts": [
            "The goal was to implement namespace remapping and security isolation for commercial server deployments in (possibly multi-tenant) Solaris environments. The."
          ]
        },
        {
          "title": "Data at the Speed of Light. The Apache Arrow Revolution",
          "url": "https://medium.com/@tfmv/data-at-the-speed-of-light-8e32da656de8",
          "excerpts": [
            "The Apache Arrow ecosystem eliminates this tax completely: In-memory columnar format optimized for modern CPUs, Zero-copy, zero-serialization data sharing ..."
          ]
        },
        {
          "title": "Our journey at F5 with Apache Arrow (part 1)",
          "url": "https://arrow.apache.org/blog/2023/04/11/our-journey-at-f5-with-apache-arrow-part-1/",
          "excerpts": [
            "Apr 11, 2023 — Our benchmarks thus far have shown promising results, with compression ratio improvements ranging from 1.5x to 5x, depending on the data type ( ..."
          ]
        },
        {
          "title": "Tracing Methods",
          "url": "https://thume.ca/2023/12/02/tracing-methods/",
          "excerpts": [
            "eBPF subsystem allows you to attach complex programs to all sorts of different things in the kernel and efficiently shuttle data back to userspace, basically subsuming all the legacy facilities like ftrace and kprobes such that I won’t talk about them.",
            "ace. You normally write BPF programs in C but there are perhaps even nicer toolkits for using [Zig](ht",
            "I could even include fields pulled from the packet header and NIC queue information, all at 1 million packets per second with no noticeable overhead."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface.html",
          "excerpts": [
            "Make it easy for third-party projects to implement support for (including partial\n  support where sufficient), with little initial investment. * \n  Allow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process. * \n  Match the Arrow array concepts closely to avoid the development of\n  yet another marshalling layer.",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow format.",
            "Expose an ABI-stable interface.",
            "llow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process.",
            "Zero-copy by design.",
            "The Arrow C data interface is inspired by the [Python buffer protocol](https://www.python.org/dev/peps/pep-3118/) ,\nwhich has proven immensely successful in allowing various Python libraries\nexchange numerical data with no knowledge of each other and near-zero\nadaptation cost.",
            "Allow zero-copy sharing of Arrow data between independent runtimes and components running in the same process. Match the Arrow array concepts closely to ...",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow forma",
            "Memory management",
            "The release callback MUST free any data area directly owned by the structure\n(such as the buffers and children members). The release callback MUST mark the structure as released, by setting\nits `release` member to NULL."
          ]
        },
        {
          "title": "Arrow C Data Interface and Streams",
          "url": "https://arrow.apache.org/docs/format/CStreamInterface.html",
          "excerpts": [
            "An Arrow C stream exposes a streaming source of data chunks, each with the same schema. Chunks are obtained by calling a blocking pull-style iteration function. [Apache Arrow v21.0.0 - Home](../_static/arrow-dark.png)](../index.html)",
            "The C stream interface is defined by a single `struct` definition:",
            "The `ArrowArrayStream` provides the required callbacks to interact with a\nstreaming source of Arrow arrays. It has the following field",
            "The `ArrowArrayStream` provides the required callbacks to interact with a\nstreaming source of Arrow arrays. It has the following field",
            "int ( * get_schema )( struct ArrowArrayStream * , struct ArrowSchema * out );"
          ]
        },
        {
          "title": "Introducing the Apache Arrow C Data Interface",
          "url": "https://arrow.apache.org/blog/2020/05/03/introducing-arrow-c-data-interface/",
          "excerpts": [
            "The C Data Interface passes Arrow data buffers through memory pointers. So,\nby construction, it allows you to share data from one runtime to\nanother without copying it. Since the data is in standard\n[Arrow in-memory format](https://arrow.apache.org/docs/format/Columnar.html),\nits layout is well-defined and unambiguous. This design also restricts the C Data Interface to *in-process* data sharing. For interprocess communication, we recommend use of the Arrow\n[IPC format",
            "Separate type and data representation",
            "For applications which produce many instances of data of a single datatype\n(for example, as a stream of record batches), repeatedly reconstructing the\ndatatype from its string encoding would represent unnecessary overhead.",
            "The C Data Interface passes Arrow data buffers through memory pointers. So,\nby construction, it allows you to share data from one runtime to\nanother without copying it.",
            "Two libraries that utilize\nthe C structures defined by the C Data Interface can do zero-copy data\ntransfers at runtime without any build-time or link-time dependency\nrequirements.",
            "The C Data Interface carries no dependencies\nexcept a shared C ABI between binaries which use it.",
            "May 3, 2020 — Apache Arrow includes a cross-language, platform-independent in-memory columnar format allowing zero-copy data sharing and transfer between heterogenous ... ",
            "For interprocess communication, we recommend use of the Arrow\n[IPC format"
          ]
        },
        {
          "title": "BPF ring buffer — The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/next/bpf/ringbuf.html",
          "excerpts": [
            "This document describes BPF ring buffer design, API, and implementation details. ... BPF ringbuf provides two sets of APIs to BPF programs:.",
            "`bpf_ringbuf_output()` allows to _copy_ data from one place to a ring\n  buffer, similarly to `bpf_perf_event_output()`",
            "`bpf_ringbuf_reserve()` / `bpf_ringbuf_commit()` / `bpf_ringbuf_discard()` APIs split the whole process into two steps. First, a fixed amount of space\n  is reserved. If successful, a pointer to a data inside ring buffer data\n  area is returned, which BPF programs can use similarly to a data inside\n  array/hash maps. Once ready, this piece of memory is either committed or\n  discarded. Discard is similar to commit, but makes consumer ignore the",
            "The ring buffer itself internally is implemented as a power-of-2 sized\ncircular buffer, with two logical and ever-increasing counters (which might\nwrap around on 32-bit architectures, that’s not a problem):",
            "consumer counter shows up to which logical position consumer consumed the\n  dat",
            "producer counter denotes amount of data reserved by all producers.",
            "Together with `BPF_RB_NO_WAKEUP` / `BPF_RB_FORCE_WAKEUP` flags for output/commit/discard\nhelpers, it allows BPF program a high degree of control and, e.g., more\nefficient batched notifications.",
            "This document describes BPF ring buffer design, API, and implementation details. ... Returned values are momentarily snapshots of ring buffer state and ..."
          ]
        },
        {
          "title": "anakryiko/bpf-ringbuf-examples",
          "url": "https://github.com/anakryiko/bpf-ringbuf-examples",
          "excerpts": [
            "This is a collection of examples showing the usage of BPF ringbuf and perfbuf APIs. Each example implements a simple tracing tool, collecting all exec() ..."
          ]
        },
        {
          "title": "C Data Interface — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/java/cdata.html",
          "excerpts": [
            "Arrow supports exchanging data without copying or serialization within the same process through the The Arrow C data interface, even between different language ..."
          ]
        },
        {
          "title": "Interface to the nanoarrow C Library",
          "url": "https://arrow.apache.org/nanoarrow/latest/r/",
          "excerpts": [
            "Example. The Arrow C Data and Arrow C Stream interfaces are comprised of three structures: the ArrowSchema which represents a data type of an array, ..."
          ]
        },
        {
          "title": "Leveraging the Arrow C Data Interface",
          "url": "https://willayd.com/leveraging-the-arrow-c-data-interface.html",
          "excerpts": [
            "Feb 20, 2024 — This blog post describes how the Arrow C Data interface works, as witnessed through transformation of the pantab library."
          ]
        },
        {
          "title": "What is eBPF? An Introduction and Deep Dive into the eBPF ...",
          "url": "https://ebpf.io/what-is-ebpf/",
          "excerpts": [
            "eBPF is a revolutionary technology with origins in the Linux kernel that can run sandboxed programs in a privileged context such as the operating system kernel."
          ]
        },
        {
          "title": "ebpf_exporter/benchmark/README.md at master",
          "url": "https://github.com/cloudflare/ebpf_exporter/blob/master/benchmark/README.md",
          "excerpts": [
            "To measure the overhead of eBPF probes we measure performance in the following cases: No probes attached; Empty probe doing nothing at all; Simple probe ..."
          ]
        },
        {
          "title": "What is the performance impact added to eBPF via kprobe ...",
          "url": "https://stackoverflow.com/questions/78572661/what-is-the-performance-impact-added-to-ebpf-via-kprobe-and-uprobe",
          "excerpts": [
            "All I can tell you is that uprobe overhead will be much higher because it has to cross to kernel space to execute the BPF program."
          ]
        },
        {
          "title": "Head Based Sampling using the OTEL Collector",
          "url": "https://squaredup.com/blog/head-based-sampling-using-the-otel-collector/",
          "excerpts": [
            "Oct 25, 2023 — Head based VS tail based sampling ... Head based sampling means that we decide whether to keep or discard each trace as early as possible (before ..."
          ]
        },
        {
          "title": "The Tail at Scale",
          "url": "https://research.google/pubs/the-tail-at-scale/",
          "excerpts": [
            "by J Dean · 2013 · Cited by 2294 — This article outlines some of the common causes of high latency episodes in large online services and describes techniques that reduce their severity."
          ]
        },
        {
          "title": "The tail at scale - Luiz André Barroso",
          "url": "https://www.barroso.org/publications/TheTailAtScale.pdf",
          "excerpts": [
            "by JR Dean · 2013 · Cited by 2294 — The 'tail' refers to high-latency episodes that can dominate performance in large-scale systems, even though rare, and are difficult to keep short.",
            "tail-tolerant software techniques form a predictable whole out of less-predictable parts.",
            "dividual components is mag-\nnified at the service level; for example, \nconsider a system where each server \ntypically responds in 10ms but with a \n99th-percentile latency of one second.",
            "Hedged requests. A simple way to \ncurb latency variability is to issue the \nsame request to multiple replicas and \nuse the results from whichever replica \nresponds fi",
            " The hedged-requests \ntechnique also has a window of vulner-\n\nability in which multiple servers can \nexecute the same request unnecessar",
            "Within Request Short-Term  \nadaptatio",
            "cross-Request  \nLong-Term adaptatio",
            "In large information-retrieval (IR) sys-\ntems, speed is more than a performance \nmetric; it is a key quality metric, as re-\nturning good results quickly is better \nthan returning the best results s"
          ]
        },
        {
          "title": "Reservoir sampling - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Reservoir_sampling",
          "excerpts": [
            "Reservoir sampling is a family of randomized algorithms for choosing a simple random sample, without replacement, of k items from a population of unknown size n"
          ]
        },
        {
          "title": "[PDF] Random Sampling with a Reservoir - UMD Computer Science",
          "url": "https://www.cs.umd.edu/~samir/498/vitter.pdf",
          "excerpts": [
            "We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown ..."
          ]
        },
        {
          "title": "The tail at scale | Communications of the ACM",
          "url": "https://dl.acm.org/doi/10.1145/2408776.2408794",
          "excerpts": [
            "Software techniques that tolerate latency variability are vital to building responsive large-scale Web services.",
            "Barroso, L.A. and Höelzle, U. The Datacenter as a Computer: An Introduction to the Design of Warehouse-scale Machines. Synthesis Series on Computer Architecture ..."
          ]
        },
        {
          "title": "Reservoir Sampling | Richard Startin's Blog",
          "url": "https://richardstartin.github.io/posts/reservoir-sampling",
          "excerpts": [
            "It's worth taking a look at the derivations of Algorithm A and Algorithm D in Vitter's paper on Faster Methods for Random Sampling first."
          ]
        },
        {
          "title": "Falco blog: Tracing Syscalls Using eBPF (Part 1)",
          "url": "https://falco.org/blog/tracing-syscalls-using-ebpf-part-1/",
          "excerpts": [
            "eBPF instrumentation will always cause a greater overhead in the system ...",
            "Ring buffers\n------------\n\neBPF ring buffer, also known as `bpf_ringbuf`, is a mechanism provided by the Linux kernel for efficient communication between eBPF programs and user-space programs"
          ]
        },
        {
          "title": "Performance of perfbuf – Patchwork patch (May 29, 2020)",
          "url": "https://patchwork.ozlabs.org/project/netdev/patch/20200529075424.3139988-5-andriin@fb.com/",
          "excerpts": [
            "May 29, 2020 — Performance of perfbuf suffers from default \"no sampling\" policy and huge overhead that causes. In sampled mode, rb-custom is winning very ... 4 benchmarks were implemented: 2 variations for each of BPF ringbuf\nand perfbuf:,\n  ",
            "  - rb-libbpf utilizes stock libbpf ring_buffer manager for reading data;",
            "  - rb-custom implements custom ring buffer setup and reading code, to\n    eliminate overheads inherent in generic libbpf code due to callback\n    functions and the need to update consumer position after each consumed\n    record, instead of batching updates (due to pessimistic assumption that\n    user callback might take long time and thus could unnecessarily hold ring\n    buffer space for too long);",
            "  - pb-libbpf uses stock libbpf perf_buffer code with all the default\n    settings, though uses higher-performance raw event callback to minimize\n    unnecessary overhead;",
            "  - pb-custom implements its own custom consumer code to minimize any possible\n    overhead of generic libbpf implementation and indirect function calls. All of the test support default, no data notification skipped, mode, as well\nas sampled mode (with --rb-sampled flag), which allows to trigger epoll\nnotification less frequently and reduce overhead. As will be shown, this mode\nis especially critical for perf buffer, which suffers from high overhead of\nwakeups in kernel. Otherwise, all benchamrks implement similar way to generate a batch of records\nby using fentry/sys_getpgid BPF program, which pushes a bunch of records in\na tight loop and records number of successful and dropped samples."
          ]
        },
        {
          "title": "Eliminating eBPF Tracing Overhead on Untraced Processes (eBPF 924, 2024)",
          "url": "https://people.cs.vt.edu/djwillia/papers/ebpf24-mookernel.pdf",
          "excerpts": [
            "Eliminating eBPF Tracing Overhead\non Untraced Processes",
            "Executing eBPF\nprograms associated with other processes not only makes tracing\nslower, but could impact the correctness of tracing by executing\neBPF programs intended for one process, on another.",
            "Copying\ntracing hookpoint state also allows for the optimization for tracing\nhookpoint text described above. After the necessary pages have been copied, the kernel view\nmanager must update the kernel page tables for each traced process.",
            "he most efficient\nper-process approach, pre-eBPF, slows down the read and sendmsg\nsystem call by 54 and 112 nanoseconds respectively, which corre-\nspond to 15% and 6% slowdown"
          ]
        },
        {
          "title": "Arrow Columnar Format",
          "url": "https://arrow.apache.org/docs/format/Columnar.html",
          "excerpts": [
            "The **Arrow columnar format** includes a language-agnostic in-memory\ndata structure specification, metadata serialization, and a protocol\nfor serialization and generic data transp",
            "Data adjacency for sequential access (scans)",
            "The Arrow columnar format provides analytical performance and data\nlocality guarantees in exchange for comparatively more expensive\nmutation operations."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html",
          "excerpts": [
            "This interface allows any library to export Arrow data structures to other libraries that understand the same protocol.",
            "The Arrow C data interface",
            " Export the object as an ArrowSchema. Returns :\n        A PyCapsule containing a C ArrowSchema representation of the\n        object. The capsule must have a name of `\"arrow_schema\"` .",
            "owSchema and ArrowArray structures. Parameters :\n        **requested\\_schema** ( _PyCapsule_ _or_ _None_ ) – A PyCapsule containing a C ArrowSchema representation\n        of a requested schema. Conversion to this schema is best-effort. See [Schema Requests]() . Returns :\n        A pair of PyCapsules containing a C ArrowSchema and ArrowArray,\n        respectively."
          ]
        },
        {
          "title": "The Apache Arrow Revolution for Data Solutions",
          "url": "https://medium.com/israeli-tech-radar/the-apache-arrow-revolution-for-data-solutions-e59bb496c60c",
          "excerpts": [
            "Apache Arrow enables composable data systems to share the same columnar data in memory or through the wire.",
            "Arrow Interop with Zero-Copy Memory Reads",
            "The Apache Arrow Revolution for Data Solutions",
            "Zero-Copy Reads. Our task is to read a bunch of XML files, process them, and write them back to disk in an ORC format. That's a given ..."
          ]
        },
        {
          "title": "OpenTelemetry Sampling",
          "url": "https://opentelemetry.io/docs/concepts/sampling/",
          "excerpts": [
            "Tail sampling is where the decision to sample a trace takes place by considering\nall or most of the spans within the trace. Tail Sampling gives you the option to\nsample your traces based on specific criteria derived from different parts of a\ntrace, which isn’t an option with Head Sampling.",
            "The OpenTelemetry Collector includes the following sampling processors:",
            "* [Probabilistic Sampling Processo",
            "* [Tail Sampling Processo",
            "Tail sampling is where the decision to sample a trace takes place by considering all or most of the spans within the trace."
          ]
        },
        {
          "title": "Tail Sampling with OpenTelemetry",
          "url": "https://opentelemetry.io/blog/2022/tail-sampling/",
          "excerpts": [
            "Tail-based sampling is where the decision to sample a trace happens *after* all\nthe spans in a request have been complete",
            "To use tail sampling in OpenTelemetry, you need to implement a component called the tail sampling processor.",
            "This component samples traces based on a set of policies that you can choose\nfrom and define.",
            "Tail sampling lets you see only the traces that are of interest to you. You also\nlower data ingest and storage costs because you’re only exporting a\npredetermined subset of your traces.",
            "There are also some limitations to consider that are related to OpenTelemetry. Note that some of these limitations also apply more broadly to any client-hosted\ntail-based sampling solution, not just OpenTelemetry.",
            "Establishing a wait period for tail sampling**: Another challenge with tail\n  sampling is that it’s hard to predict when a trace will actually be finis"
          ]
        },
        {
          "title": "eBPF Tutorial by Example 8: Monitoring Process Exit ...",
          "url": "https://medium.com/@yunwei356/ebpf-tutorial-by-example-8-monitoring-process-exit-events-print-output-with-ring-buffer-73291d5e3a50",
          "excerpts": [
            "There is now a new BPF data structure available called the eBPF ring buffer. It solves the memory efficiency and event reordering issues of the ...See more"
          ]
        },
        {
          "title": "Helper Function 'bpf_ringbuf_reserve' - eBPF Docs",
          "url": "https://docs.ebpf.io/linux/helper-function/bpf_ringbuf_reserve/",
          "excerpts": [
            "This page documents the 'bpf_ringbuf_reserve' eBPF helper function, including its definition, usage, program types that can use it, and examples."
          ]
        },
        {
          "title": "eBPF verifier",
          "url": "https://docs.kernel.org/bpf/verifier.html",
          "excerpts": [
            "eBPF verifier¶. The safety of the eBPF program is determined in two steps. First step does DAG check to disallow loops and other CFG validation."
          ]
        },
        {
          "title": "eBPF verifier — The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/v5.17/bpf/verifier.html",
          "excerpts": [
            "In order to determine the safety of an eBPF program, the verifier must track the range of possible values in each register and also in each stack slot. This is ..."
          ]
        },
        {
          "title": "Aya is an eBPF library for the Rust programming language ...",
          "url": "https://github.com/aya-rs/aya",
          "excerpts": [
            "eBPF is a technology that allows running user-supplied programs inside the Linux kernel. For more info see What is eBPF. Aya is an eBPF library built with a ..."
          ]
        },
        {
          "title": "Getting Started - Aya",
          "url": "https://aya-rs.dev/book/",
          "excerpts": [
            "This getting started guide will help you use the Rust Programming Language and Aya library to build extended Berkley Packet Filter (eBPF) programs."
          ]
        },
        {
          "title": "Classic BPF vs eBPF",
          "url": "https://www.kernel.org/doc/html/v5.17/bpf/classic_vs_extended.html",
          "excerpts": [
            "After the call the registers R1-R5 contain junk values and cannot be read. An in-kernel eBPF verifier is used to validate eBPF programs. Also in the new design, ..."
          ]
        },
        {
          "title": "Formally verifying the BPF verifier",
          "url": "https://lwn.net/Articles/1020664/",
          "excerpts": [
            "May 23, 2025 — The Linux kernel's BPF verifier is probably the first real instance of formal verification in production, Nagarakatte said."
          ]
        },
        {
          "title": "Working with Schema",
          "url": "https://arrow.apache.org/cookbook/py/schema.html",
          "excerpts": [
            "This chapter includes recipes for dealing with schemas. Contents. Working with Schema. Setting the data type of an Arrow Array. Setting the schema of a Table."
          ]
        },
        {
          "title": "C Interfaces — Apache Arrow v5.0.0",
          "url": "https://arrow.apache.org/docs/5.0/cpp/api/c_abi.html",
          "excerpts": [
            "This is documentation for an old release of Apache Arrow (version 5.0). ... The Arrow C stream interface · Other Data Structures. Libraries. Implementation ..."
          ]
        },
        {
          "title": "pyarrow.Schema — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/python/generated/pyarrow.Schema.html",
          "excerpts": [
            "A schema defines the column names and types in a record batch or table data structure. They also contain metadata about the columns."
          ]
        },
        {
          "title": "[Python] Support C stream interface of single arrays #31194 - GitHub",
          "url": "https://github.com/apache/arrow/issues/31194",
          "excerpts": [
            "It seems that the C stream interface in pyarrow currently requires the array to be a StructArray. I do not see this constraint in the spec ..."
          ]
        },
        {
          "title": "[PDF] Better algorithms for BPF - The Linux Kernel Archives",
          "url": "http://oldvger.kernel.org/bpfconf2022_material/lsfmmbpf2022-algs.pdf",
          "excerpts": [
            "- BPF_RINGBUF_SUBMIT command runs BPF prog on each sample? - Kthread to run each BPF program? - bpf_dynptr is an interface to a memory. - Need to work through ..."
          ]
        },
        {
          "title": "eBPF Verifier Code Review",
          "url": "https://www.linuxfoundation.org/hubfs/eBPF/eBPF%20Verifier%20Security%20Audit.pdf?__hstc=137369199.8da91b5f8b42a5531651a132262dd89d.1751068800153.1751068800154.1751068800155.1&__hssc=137369199.1.1751068800156&__hsfp=150561067",
          "excerpts": [
            "Nov 11, 2024 — The eBPF verifier gates eBPF programs into the kernel, verifying their safety. The review found a vulnerability to read/write kernel memory and ..."
          ]
        },
        {
          "title": "The Arrow C Device data interface",
          "url": "https://arrow.apache.org/docs/format/CDeviceDataInterface.html",
          "excerpts": [
            "The Arrow C Device data interface builds on the existing C data interface by adding a very small, stable set of C definitions",
            "Section Navigation",
            "The Arrow C Device data interface",
            "An Arrow C device stream exposes a streaming source of data chunks, each with\nthe same schema. Chunks are obtained by calling a blocking pull-style iteration\nfunction.",
            "It is expected that all chunks should be providing data on the same\ndevice type (but not necessarily the same device id).",
            "face](CStreamInterface.html) , the C Device data\ninterface also specifies a higher-level structure for easing communication\nof streaming data within a single process.",
            "Lifetime of the C stream is managed using a release callback with similar usage as in C data interface. Thread safety#. The stream source is not assumed to ..."
          ]
        },
        {
          "title": "The eBPF verifier and observability",
          "url": "https://www.groundcover.com/ebpf/ebpf-verifier",
          "excerpts": [
            "Mar 13, 2025 — The eBPF verifier is a part of the eBPF framework that checks eBPF bytecode for safety risks before they run in the Linux kernel.",
            "Directly modifying kernel source code presented the same risk, with the added drawback of requiring a tremendous amount of work.",
            "eat. Thanks to the verifier, admins can run observability code directly in kernel space without worrying about breaking their system.",
            "he verifier is not an optional component of eBPF. eBPF code _must_ pass the verifier because the kernel will execute it",
            "Thus, if you want to leverage eBPF as an observability solution – which we strongly think you should, given that [eBPF tracing](/ebpf/ebpf-tracing) offers a hyper-efficient way of monitoring and observing any process, application, or network traffic flow running on a Linux kernel – you need to use the verifier as ",
            " process, it is a key component for executing eBPF programs, which are themselves a way of collecting observability data.",
            "he eBPF verifier is not itself a tool for collecting telemetry data or otherwise assisting in the observability process, it is a key component for executing eBPF pro",
            "eBPF verifier works via a process known as static code analysis. This means it analyzes eBPF bytecode while the code is not running, looking for issues that could cause problems when the code executes",
            "Importantly, the scope of the verifier’s functionality is limited to checking for safety issues that could destabilize a system or violate kernel-level access control restrictions. It’s not a general-purpose static code analyzer.",
            "Although the verifier supports a limited range of functionality, it offers a wide range of benefits for enhancing the observability process.",
            "The design of the verifier keeps monitoring overhead low. This is because, by using the verifier to check code prior to execution, eBPF avoids having to perform checks or impose restrictions at runtime, which would be more costly in terms of CPU and memory usage.",
            "The verifier plays an important role in protecting against situations where code inside an eBPF program could access data that shouldn’t be available to it."
          ]
        },
        {
          "title": "Jan 19, 2023 — Verifying eBPF",
          "url": "https://blog.trailofbits.com/2023/01/19/ebpf-verifier-harness/",
          "excerpts": [
            "The key to eBPF safety is the eBPF verifier, which limits the set of valid eBPF programs to those that it can guarantee will not harm the kernel or cause other issues.",
            " This means that eBPF is, by design, not [Turing-complete]",
            "The verifier performs two main passes over the code. The first pass is handled by the `check_cfg()` function, which ensures that the program is guaranteed to terminate by performing an iterative depth-first search of all possible execution paths.",
            "The second pass (done in the `do_check()` function) involves static analysis of the bytecode; this pass ensures that all memory accesses are valid, that types are used consistently (e.g., scalar values are never used as pointers), and that the number of branches and total instructions is within certain complexity limits.",
            "As mentioned earlier in the post, the constraints that the verifier enforces have changed over time.",
            "One of the key benefits of eBPF is the guarantee it provides: that the loaded code will not crash the kernel, will terminate within a time limit, and will not leak information to unprivileged user processes.",
            " The harness is not the first tool that aims to improve the verifier’s testability. The IO Visor Project’s [BPF fuzzer](https://github.com/iovisor/bpf-fuzzer) has a very similar goal of running the verifier in user space and enabling efficient fuzzing—and the tool has found [at least one bug]",
            "the harness is intended to support all kernel versions, making it easy to compare the same eBPF program across kernel versions."
          ]
        },
        {
          "title": "Include build data in your program: date, rustc version, git ...",
          "url": "https://www.reddit.com/r/rust/comments/mqnbvw/builddata_include_build_data_in_your_program_date/",
          "excerpts": [
            "SOURCE_DATE_EPOCH is a standardised environment variable that distributions can set centrally and have build tools consume this in order to ...",
            "How do you calculate SOURCE_DATE_EPOCH from a git repo? I looked through the docs and didn't find a command, script, or procedure for doing it."
          ]
        },
        {
          "title": "Rust PGO and Reproducible Build Strategies (from the provided PDF)",
          "url": "https://www.datocms-assets.com/98516/1734435430-zaitsau_2024.pdf",
          "excerpts": [
            "PGO-optimized build reproducibility - save somewhere a PGO profile and use it for all builds.",
            " PGO profile reproducibility - ... Compile the program with Instrumentation:\nrustc -Cprofile-generate=/tmp/pgo-data main.rs",
            "2. Run the instrumented program with a training workload",
            "load 3. Convert the .profraw file into a .profdata file using LLVM's \nllvm-profdata  tool:",
            "llvm-profdata merge -output=merged.profdata default.profraw",
            "\n4. Compile the program again with the profiling data:\nrustc -Cprofile-use=merged.profdata main.rs",
            "29",
            "cargo-pgo - the best PGO friend",
            "Written by Jakub “ Kobzol ” Beranek ● GitHub:  https://github.com/Kobzol/cargo-pgo",
            "Supports Instrumentation PGO and LLVM BOLT",
            "Current PGO states across Rust applications",
            "PGO integration state for Rust apps",
            "\nRule of thumb: if you want PGO for something - you need to \nrebuild it",
            "Continuous Profile-Guided Optimization",
            "AFAIK, the only thing right now is \nGoogle Wide Profiler  (GWP) based  solution, \nclosed-source",
            "There is no ready-to-use open-source solution yet",
            "There is an idea about making such a platform as a part of \nGrafana  Pyroscope  or \nElasticsearch Universal Profi",
            "Can be implemented on proprietary profiling platforms like  Yandex.Perforator, Ozon.Vision, etc",
            "PGO issues in Rustc",
            "Documentation ● Toolin",
            "cargo-pgo is not ideal ○ AutoFDO migration proce",
            "Missing most advanced PGO modes",
            "Bugs",
            "[no_std] is not supported by default*\n○ But can be achieved with  mini"
          ]
        },
        {
          "title": "vadimcn/cargo-pgo: Supercharge you Rust programs!",
          "url": "https://github.com/vadimcn/cargo-pgo",
          "excerpts": [
            "Merge profiles. Before using generated profiles, they must be first merged into an 'indexed' format: cargo pgo merge."
          ]
        },
        {
          "title": "Audit trail & MIR - compiler",
          "url": "https://internals.rust-lang.org/t/audit-trail-mir/7839",
          "excerpts": [
            "Jun 30, 2018 — An auditing tool could scan for #[safe] blocks, generate their MIR, and attach it in the note as audit data. If the audited code is changed, the ..."
          ]
        },
        {
          "title": "rust-fuzz/afl.rs: 🐇 Fuzzing Rust code with American Fuzzy Lop",
          "url": "https://github.com/rust-fuzz/afl.rs",
          "excerpts": [
            "A popular, effective, and modern fuzz testing tool based on AFL. This library, afl.rs, allows one to run AFLplusplus on code written in the Rust programming ...See more"
          ]
        },
        {
          "title": "BurntSushi/quickcheck: Automated property based testing ...",
          "url": "https://github.com/BurntSushi/quickcheck",
          "excerpts": [
            "QuickCheck is a way to do property based testing using randomly generated input. This crate comes with the ability to randomly generate and shrink integers, ..."
          ]
        },
        {
          "title": "cargo-auditable - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-auditable",
          "excerpts": [
            "The embedded dependency list uses under 4kB even on large dependency trees with 400+ entries. This typically translates to between 1/1000 ..."
          ]
        },
        {
          "title": "Performing Audits - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/performing-audits.html",
          "excerpts": [
            "Cargo vet suggest can estimate the lowest-effort audits you can perform to reduce the number of entries in exemptions, and consequently, your attack surface."
          ]
        },
        {
          "title": "Reproducible Builds in June 2022",
          "url": "https://reproducible-builds.org/reports/2022-06/",
          "excerpts": [
            "Luckily, as one of the responses mentions: “the --remap-path-prefix solves this problem and has been used to great effect in build systems that rely on ..."
          ]
        },
        {
          "title": "Setting codegen-units to 1 gives even better code quality ...",
          "url": "https://news.ycombinator.com/item?id=36681703",
          "excerpts": [
            "Setting codegen-units to 1 gives even better code quality than thin local LTO, but takes longer. Some authors of binary rust crates always use that setting ..."
          ]
        },
        {
          "title": "rust-secure-code/cargo-auditable: Make production Rust binaries ...",
          "url": "https://github.com/rust-secure-code/cargo-auditable",
          "excerpts": [
            "Audit binaries for known bugs or security vulnerabilities in production, at scale, with zero bookkeeping."
          ]
        },
        {
          "title": "cargo-sbom - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-sbom",
          "excerpts": [
            "Jun 16, 2025 — This crate provides a command line tool to create software bill of materials (SBOM) for Cargo / Rust workspaces. It supports both SPDX and CycloneDX outputs."
          ]
        },
        {
          "title": "Commands - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/commands.html",
          "excerpts": [
            "This section documents the command-line interface of cargo vet. The documentation is automatically generated from the implementation, and so it may be ..."
          ]
        },
        {
          "title": "cargo-auditable - Crates.io",
          "url": "https://crates.io/crates/cargo-auditable/versions",
          "excerpts": [
            "Make production Rust binaries auditable. 20 of 20 cargo-auditable versions since July 31st, 2022. Sort by Date Date SemVer"
          ]
        },
        {
          "title": "When reproducible builds? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/jct0y4/when_reproducible_builds/",
          "excerpts": [
            "In some domains, it is very important to be able to reproducibly rebuild a binary from the sources. This is cargo/rustc pretty bad at."
          ]
        },
        {
          "title": "Caller-side inline directives - language design",
          "url": "https://internals.rust-lang.org/t/caller-side-inline-directives/19078",
          "excerpts": [
            "It would be nice if I could use a caller-side inline directive, as recently introduced by clang, instead of having to go codegen-units = 1 or fat LTO."
          ]
        },
        {
          "title": "CycloneDX/cyclonedx-rust-cargo",
          "url": "https://github.com/CycloneDX/cyclonedx-rust-cargo",
          "excerpts": [
            "The CycloneDX module for Rust (Cargo) creates a valid CycloneDX Software Bill of Materials (SBOM) containing an aggregate of all project dependencies."
          ]
        },
        {
          "title": "cargo-vet 0.10.1",
          "url": "https://docs.rs/crate/cargo-vet/latest",
          "excerpts": [
            "The cargo vet subcommand is a tool to help projects ensure that third-party Rust dependencies have been audited by a trusted entity. It strives to be ..."
          ]
        },
        {
          "title": "Rust Cargo PGO and BOLT – Kobzol blog",
          "url": "https://kobzol.github.io/rust/cargo/2023/07/28/rust-cargo-pgo.html",
          "excerpts": [
            "Jul 28, 2023 — cargo pgo has your back! With cargo pgo test or cargo pgo bench , you can generate profiles by running instrumented tests or benchmarks, and ... I created a simple example of a GitHub Actions workflow that shows how this could be done. Going beyond PGO",
            "The (LLVM-based) PGO implementation offered by the Rust compiler is just one of many existing so-called\nFeedback-directed optimization (FDO) tools, which leverage some sort of runtime profiles to better\noptimize programs.",
            "rams. Another such tool is a post-link optimizer called BOLT . “Post-link” means that it takes a fully compiled and linked program binary as an input, and then uses\nprofiles to optimize the binary, even without access to its source code. This differs from “classic”\nPGO, which optimizes the program during compilation, and thus has access to its source code. Its main\ngoal is to better reorganize instructions within the binary, in particular to improve instruction cache\nutilization. BOLT is a part of LLVM, and can provide additional performance improvements even on top of an already\nPGO-optimized binary.",
            "Last year, I have enabled BOLT for LLVM 3 used by the Rust compiler, which resulted in ~2-5% cycle improvements across the board."
          ]
        },
        {
          "title": "Hacker News discussion thread excerpt on Rust PGO and determinism",
          "url": "https://news.ycombinator.com/item?id=25060762",
          "excerpts": [
            "Does PGO mean the build products are non-deterministic? ie if you build the Rust compiler twice you get different bits.",
            "It would be deterministic for a given set of input profile data, but would likely change every time you instrumented a new profile",
            "BOLT just permutes link order? The object permutation from a BOLT run should be good for months until the underlying objects have substantially drifted?"
          ]
        },
        {
          "title": "Securing the Software Supply Chain: Recommended Practices for Developers",
          "url": "https://www.cisa.gov/sites/default/files/publications/ESF_SECURING_THE_SOFTWARE_SUPPLY_CHAIN_DEVELOPERS.PDF",
          "excerpts": [
            "The production build environment is where reproducible deliverables are built.",
            "The artifacts for builds should include, at a minimum, the source repository, the third-party \ndependencies, the build script, and the output of the build",
            "For reproducible builds, the artifact should be the \noutput of the script that compares the builds",
            "The third party's SBOM can be compared with the SBOM produced by the SCA tools."
          ]
        },
        {
          "title": "How can I include the build date in an executable - help",
          "url": "https://users.rust-lang.org/t/how-can-i-include-the-build-date-in-an-executable/102024",
          "excerpts": [
            "Nov 3, 2023 — The recommendation is to use the SOURCE_DATE_EPOCH env var if it is set: SOURCE_DATE_EPOCH — reproducible-builds.org. 6 Likes. mark November 3 ..."
          ]
        },
        {
          "title": "refix: fast, debuggable, reproducible builds",
          "url": "https://yosefk.com/blog/refix-fast-debuggable-reproducible-builds.html",
          "excerpts": [
            "There's a simple way to make your builds all of the following: Reproducible/deterministic - same binaries always built from the same source, ..."
          ]
        },
        {
          "title": "Profiles - The Cargo Book",
          "url": "https://doc.rust-lang.org/cargo/reference/profiles.html",
          "excerpts": [
            "codegen-units. The codegen-units setting controls the -C codegen-units flag which controls how many “code generation units” a crate will be split into. More ..."
          ]
        },
        {
          "title": "Codegen Options - The rustc book",
          "url": "https://doc.rust-lang.org/rustc/codegen-options/index.html",
          "excerpts": [
            "When -C lto is not specified, LTO is disabled if codegen units is 1 or optimizations are disabled ( -C opt-level=0 ). That is: When -C lto is not specified:."
          ]
        },
        {
          "title": "An Introduction To Property-Based Testing In Rust",
          "url": "https://lpalmieri.com/posts/an-introduction-to-property-based-testing-in-rust/",
          "excerpts": [
            "Jan 3, 2021 — There are two mainstream options for property-based testing in the Rust ecosystem: quickcheck and proptest . Their domains overlap, although ..."
          ]
        },
        {
          "title": "How to Sign an SBOM with Cosign",
          "url": "https://edu.chainguard.dev/open-source/sigstore/cosign/how-to-sign-an-sbom-with-cosign/",
          "excerpts": [
            "Note the warnings — a record of the attestation will be recorded to an immutable log maintained by the Sigstore project. When you're ready, ..."
          ]
        },
        {
          "title": "Introduction - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/",
          "excerpts": [
            "The cargo vet subcommand is a tool to help projects ensure that third-party Rust dependencies have been audited by a trusted entity."
          ]
        },
        {
          "title": "`cargo audit` can now scan compiled binaries : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/yk7l3w/cargo_audit_can_now_scan_compiled_binaries/",
          "excerpts": [
            "I've been working to bring vulnerability scanning to Rust binaries by creating cargo auditable, which embeds the list of dependencies and their versions into ..."
          ]
        },
        {
          "title": "Sigstore Bundle Format",
          "url": "https://docs.sigstore.dev/about/bundle/",
          "excerpts": [
            "A Sigstore bundle is everything required to verify a signature on an artifact. This is satisfied by the Verification Material and signature Content."
          ]
        },
        {
          "title": "cargo-auditable(1) - Arch Linux manual pages",
          "url": "https://man.archlinux.org/man/cargo-auditable.1.en",
          "excerpts": [
            "The embedded dependency list uses under 4kB even on large dependency trees with 400+ entries. This typically translates to between 1/1000 and 1/10,000 of the ..."
          ]
        },
        {
          "title": "Rust Internals: rustdoc binary is not reproducible",
          "url": "https://internals.rust-lang.org/t/rustdoc-binary-is-not-reproducible/20027",
          "excerpts": [
            "Hello,\n\nWe've observed that 'rustdoc' is not reproducible in our Yocto build environment. The below differences are observed between multiple builds (The rust sources are not changed between builds). The diff in shown in _\".strtab\" & \".shstrtab\"_ sections of the binary. [<img src='https://us1.discourse-cdn.com/flex002/uploads/rustlang/original/2X/9/977de908e21d44b771b12d13b0c18a3011a52891.png' alt='image-1' width='690' height='333' /",
            "PGO for something like rustdoc seems like overkill, no? <img src='https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12' alt=':slight_smile:' width='20' height='20' />",
            "`.llvm.<hash>` suffixes are added by LLVM's thinLTO to prevent symbol collisions when making a symbol marked as internal external to enable inlining across the LLVM modules that participate in thinLTO. As for why it would differ, I have no clue. (You are not using PGO, right? PGO profile generation is not deterministic due to among other things threading.)",
            "PGO `profiler = true` in our rust build environment. Setting `profiler = false` alone not fixed the issue, there is dependent option `tools = [\"rust-demangler\",]` , when these both are set the issue is fixed.",
            "`.llvm.<hash>` suffixes are added by LLVM's thinLTO to prevent symbol collisions when making a symbol marked as internal external to enable inlining across the LLVM modules that participate in thinLTO",
            "This topic was automatically closed 90 days after the last reply. New replies are no longer allowed."
          ]
        },
        {
          "title": "Timesys — SBOM Generation and Vulnerability Monitoring for the Crates.io/Rust Ecosystem",
          "url": "https://www.timesys.com/security/sbom-generation-and-vulnerability-monitoring-for-the-crates-io-rust-ecosystem/",
          "excerpts": [
            "Jun 5, 2024 — Syft is our preferred tool for generating SBOMs due to its compliance with SPDX/CycloneDX specs and compatibility with Vigiles.",
            "Jun 5, 2024 — In this post, we'll explore the Rust ecosystem, specifically Cargo/Crates.io, and discuss the significance of SBOMs and Software Composition ...",
            "An SBOM is a comprehensive inventory of software components",
            "In the Rust ecosystem, maintaining an accurate SBOM is crucial due to the rapidly evolving landscape of libraries and dependencies available on Crates.io.",
            "Streamlining SBOM and Vulnerability Management with Syft and Vigiles",
            "Vigiles pulls from multiple security advisories, including but not limited to the National Vulnerability Database (NVD) and OSV (GitHub Security Advisory, PyPI Advisory, Go Vulnerability Database, Rust Advisory, Haskell Security Advisories, OSS-Fuzz, Debian Security Advisories, RConsortium Advisory).",
            "Using Syft to generate your SBOMs allows you to maintain a detailed inventory of your software components and dependencies."
          ]
        },
        {
          "title": "debug_info_for_profiling - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/debug_info_for_profiling.html",
          "excerpts": [
            "Unlike PGO (controlled by the rustc flags -Cprofile-generate and -Cprofile-use ), a binary being profiled does not perform significantly worse, and thus it's ..."
          ]
        },
        {
          "title": "Kobzol/cargo-pgo: Cargo subcommand for optimizing Rust ...",
          "url": "https://github.com/Kobzol/cargo-pgo",
          "excerpts": [
            "Cargo subcommand that makes it easier to use PGO and BOLT to optimize Rust binaries. For an example on how to use cargo-pgo to optimize a binary on GitHub ..."
          ]
        },
        {
          "title": "Reproducible builds: Automatically remap $CARGO_HOME and ...",
          "url": "https://github.com/rust-lang/cargo/issues/5505",
          "excerpts": [
            "I tried adding --remap-path-prefix flag but still the binaries are not reproducible. But, I suspect my change is effective or not, can anyone ..."
          ]
        },
        {
          "title": "cargo_pgo - Rust",
          "url": "https://docs.rs/cargo-pgo",
          "excerpts": [
            "This crate contains a Cargo subcommand designed for simplifying the usage of feedback-directed optimizations for Rust crates."
          ]
        },
        {
          "title": "[PDF] MirChecker: Detecting Bugs in Rust Programs via Static Analysis",
          "url": "https://www.cse.cuhk.edu.hk/~cslui/PUBLICATION/CCS2021.pdf",
          "excerpts": [
            "The design of MirChecker is presented in Section 4, and we illustrate how Abstract Interpretation is performed on our language model in Section ..."
          ]
        },
        {
          "title": "MIRAI/documentation/Overview.md at main",
          "url": "https://github.com/facebookexperimental/MIRAI/blob/main/documentation/Overview.md",
          "excerpts": [
            "Aug 22, 2024 — A decision was made to use Rust, but the analysis concluded that support for static analysis tools for Rust was one of the few areas where Rust ..."
          ]
        },
        {
          "title": "Detecting Bugs in Rust Programs via Static Analysis",
          "url": "https://dl.acm.org/doi/10.1145/3460120.3484541",
          "excerpts": [
            "Nov 13, 2021 — In this paper, we present and evaluate MirChecker, a fully automated bug detection framework for Rust programs by performing static analysis on Rust's Mid- ..."
          ]
        },
        {
          "title": "facebookexperimental/MIRAI: Rust mid-level IR Abstract ...",
          "url": "https://github.com/facebookexperimental/MIRAI",
          "excerpts": [
            "Aug 22, 2024 — MIRAI is an abstract interpreter for the Rust compiler's mid-level intermediate representation (MIR). It started out as a Facebook project, but became orphaned."
          ]
        },
        {
          "title": "lizhuohua/rust-mir-checker - GitHub",
          "url": "https://github.com/lizhuohua/rust-mir-checker",
          "excerpts": [
            "This tool tries to analyze the MIR generated by the Rust compiler and emit diagnostic messages. It is based on the theory of Abstract Interpretation."
          ]
        },
        {
          "title": "Static Assurance (1/2)",
          "url": "https://highassurance.rs/chp2/static_assurance_1.html",
          "excerpts": [
            "Static analysis tools often use a layer of indirection that simplifies answering a particular question. They map the constructs of P to an analysis-specific ..."
          ]
        },
        {
          "title": "rustc_middle::mir::interpret",
          "url": "https://doc.rust-lang.org/beta/nightly-rustc/rustc_middle/mir/interpret/index.html",
          "excerpts": [
            "An interpreter for MIR used in CTFE and by miri. Modules§. allocation: The virtual memory representation of the MIR interpreter. error; pointer ..."
          ]
        },
        {
          "title": "SBOM support in Rust",
          "url": "https://ferrous-systems.com/blog/stackable-client/",
          "excerpts": [
            "Jul 30, 2024 — A project proposal to improve the generation of Software Bill of Materials (SBOM) in the Rust eco-system."
          ]
        },
        {
          "title": "CycloneDX Tool Center",
          "url": "https://cyclonedx.org/tool-center/",
          "excerpts": [
            "Beniva SBOM allows you to consume CycloneDX SBOM and Vulnerability Exploitability eXchange (VEX) within the ServiceNow platform which increases visibility of ..."
          ]
        },
        {
          "title": "Choosing an SBOM Generation Tool",
          "url": "https://openssf.org/blog/2025/06/05/choosing-an-sbom-generation-tool/",
          "excerpts": [
            "Jun 5, 2025 — Many tools exist to generate SBOMs, and we've spent some time with the different options to help you decide."
          ]
        },
        {
          "title": "Surface Rust dependency relationships #2353 - anchore/syft",
          "url": "https://github.com/anchore/syft/issues/2353",
          "excerpts": [
            "Nov 24, 2023 — What happened: Syft not created \"dependencies\" in cyclonedx report for Go, Rust, Java and etc. Cargo.lock had \"dependencies\"."
          ]
        },
        {
          "title": "Pre-RFC: Cargo SBOM",
          "url": "https://internals.rust-lang.org/t/pre-rfc-cargo-sbom/19842",
          "excerpts": [
            "Nov 8, 2023 — A SBOM (software bill of materials) is a list of all components and dependencies used to build a piece of software. The two leading SBOM formats ..."
          ]
        },
        {
          "title": "cargo::core::compiler::output_sbom",
          "url": "https://doc.rust-lang.org/nightly/nightly-rustc/cargo/core/compiler/output_sbom/index.html",
          "excerpts": [
            "Build an Sbom for the given Unit . build_sbom_graph: List all dependencies, including transitive ones. A dependency can also appear multiple times if it's ..."
          ]
        },
        {
          "title": "Rust reproducibility and PGO discussion (GitHub issue discussion)",
          "url": "https://github.com/rust-lang/rust/issues/79442",
          "excerpts": [
            "The blog post contains a step by step description of how to obtain a PGOed compiler -- but it is rather time consuming to actually do that. In order to make things easier I could provide a branch of the compiler that has all the changes already applied and, more importantly, a pre-recorded, checked-in `.profdata` file for both LLVM and rustc. Alternatively, I could just put up the final toolchain for download somewhere. Even better would be to make it available via rustup somehow.",
            "* This makes `rustc` builds non-reproducible -- something which I don't think is true. With a fixed `.profdata` file, both rustc and Clang should always generate the same output. That is `-Cprofile-use` and `-fprofile-use` do not introduce any source of randomness, as far as I can tell. So if the `.profdata` file being used is tracked by version control, we should be fine.",
            "You get the same profile data if (and only if) the workload is deterministic. If there is some source of randomness, like if pointers are being ... ](/rust-lang/rust/security)",
            "t the build into three separate tasks: the instrumented build, the profile collection, the optimized build.",
            ". For Firefox builds, we settled on being comfortable with publishing the profile data and making sure that the optimized build step was deterministic given that same input.",
            ". This also helped us enable PGO for cross-compiled builds like the macOS build on Linux.",
            "Please post any feedback that you might have below!"
          ]
        },
        {
          "title": "High Assurance Rust: Developing Secure and Robust Software",
          "url": "https://highassurance.rs/",
          "excerpts": [
            "The State-of-the-Art in Practical Software Assurance",
            "### [_Developing Secure and Robust Software_]()",
            "ou'll learn Rust - a modern, multi-paradigm language that emphasizes speed and correctness. Most programming books teach a new language by presenting a dozen small, unrealistic programs. Not this one. We'll design, write, and validate a fully-featured alternative to the ordered map and set implementations in Rust's standard library. You'll gain a deep understanding of the Rust language by re-implementing one of its major dynamic collections, one idiomatic API at a time. Unlike the standard version, our implementation will be:\n\n* \n  **Maximally Safe. ** Upholds Rust's strongest memory safety guarantees, for all possible executions. + To test properties the compiler can't prove, we'll learn advanced program analysis techniques, including _differential fuzzing_ and _deductive verification_ \\*. * \n  **Extremely Portable. ** Capable of running on every operating system, or even without one (e.g. \"bare metal\").\n+ Our library is a _hardened component_ . To integrate it within larger codebases, we'll add _CFFI bindings_ to make the Rust functions callable from other languages - including C and Python. * \n  **Highly Available. ** Offers _fallible_ APIs for handling cases that could otherwise result in a crash. + E.g. _Out-of-Memory (OOM) error_ \\- when all pre-allocated memory has been exhausted.",
            "## [The State-of-the-Art in Practical Software Assurance]()",
            "We'll use cutting-edge, open-source software assurance tools to validate the code we write in this book. Some of these tools are mature and used in commercial industry:\n\n* `rustc` (modern compiler)\n* `libFuzzer` (fuzz testing framework)\n* `rr` (\"time-travel\" debugger)\n* `qemu` (whole-system emulator)\n\nOther tools are experimental and under active research. A full inventory is available in [the appendix](../chp16_appendix/tools.html) . Visually, this book covers the below topics (contrasted roughly on tradeoff of **development speed** and **formal rigor** ). Don't worry, we'll provide clear explanations and context for each. Notice the bias toward development speed. We're interested in **lightweight processes** that, in the long run, enable us to **ship quality code faster** and spend **less time patching** security and reliability failures. Techniques you can apply to real-world code. Today.",
            "We'll use cutting-edge, open-source software assurance tools to validate the code we write in this book. Some of these tools are mature and used in commercial industry:\n\n* `rustc` (modern compiler)\n* `libFuzzer` (fuzz testing framework)\n* `rr` (\"time-travel\" debugger)\n* `qemu` (whole-system emulator)\n\nOther tools are experimental and under active research. A full inventory is available in [the appendix](../chp16_appendix/tools.html) . Visually, this book covers the below topics (contrasted roughly on tradeoff of **development speed** and **formal rigor** ). Don't worry, we'll provide clear explanations and context for each. Notice the bias toward development speed. We're interested in **lightweight processes** that, in the long run, enable us to **ship quality code faster** and spend **less time patching** security and reliability failures. Techniques you can apply to real-world code. Today."
          ]
        },
        {
          "title": "How to properly use --remap-path-prefix?",
          "url": "https://users.rust-lang.org/t/how-to-properly-use-remap-path-prefix/104406",
          "excerpts": [
            "I want to strip references to the build directory and the general setup on the computer that build the binary. As I understand it, I'm supposed to use --remap- ..."
          ]
        },
        {
          "title": "remap-path-prefix",
          "url": "https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/unstable-book/compiler-flags/remap-path-prefix.html",
          "excerpts": [
            "This is useful for bringing debuginfo paths into a well-known form and for achieving reproducible builds independent of the directory the compiler was executed ..."
          ]
        },
        {
          "title": "remap_cwd_prefix - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/remap-cwd-prefix.html",
          "excerpts": [
            "This flag will rewrite absolute paths under the current working directory, replacing the current working directory prefix with a specified value. The given ..."
          ]
        },
        {
          "title": "SOURCE_DATE_EPOCH — reproducible-builds.org",
          "url": "https://reproducible-builds.org/docs/source-date-epoch/",
          "excerpts": [
            "SOURCE_DATE_EPOCH specifies the last modification of something, usually the source code, measured in the number seconds since the Unix epoch."
          ]
        },
        {
          "title": "Deterministic build systems",
          "url": "https://reproducible-builds.org/docs/deterministic-build-systems/",
          "excerpts": [
            "A software cannot easily be built reproducibly if the source varies depending on factors that are hard or impossible to control like the ordering of files."
          ]
        },
        {
          "title": "Certifiable Rust - Electronic Design",
          "url": "https://www.electronicdesign.com/technologies/embedded/software/video/55273394/electronic-design-rust-can-be-certified-for-safe-and-secure-applications",
          "excerpts": [
            "This Rust toolset meets ISO 26262 (ASIL D), IEC 61508 (SIL 4), and IEC 62304 certifications. It's open source and available on Linux, QNX Neutrino, and various ..."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "Installing and Using Ferrocene",
          "url": "https://rust-training.ferrous-systems.com/latest/book/ferrocene-installing",
          "excerpts": [
            "Qualified, or not; Host or Cross-compiled. Qualified Targets. Production Ready; Passes the Rust Test Suite; Support is available; Signed qualification material."
          ]
        },
        {
          "title": "Software Tool Qualification in ISO 26262 Development - Embitel",
          "url": "https://www.embitel.com/blog/embedded-blog/why-is-software-tool-qualification-indispensable-in-iso-26262-based-software-development",
          "excerpts": [
            "Nov 2, 2020 — Clause 11 of Part-8 of the ISO 26262 standard comprises the ISO 26262 tool qualification methods. As per the standard, ISO 26262 tool ...",
            "a TCL is assigned, which reflects the level of confidence that can be placed in the tool to perform its intended functions without introducing unacceptable risks.",
            "The tables will make it clearer.",
            "rd**\n\nThe tool qualification methods prescribed in the standard for TCL 2 and TCL 3 are almost similar, with a slight difference based on [ASIL",
            "rd**\n\nThe tool qualification methods prescribed in the standard for TCL 2 and TCL 3 are almost similar, with a slight difference based on [ASIL"
          ]
        },
        {
          "title": "IEC 61508 – Why Tool Qualification",
          "url": "https://61508.org/wp-content/uploads/2024/11/09B-IEC-61508-Why-tool-qualification_V2_cut.pdf",
          "excerpts": [
            "... T1, T2 and T3 support tools shall be justified, for each tool in class T3, evidence shall be available that the tool conforms to its specification or ...",
            "T1 tool is selected as part of the requirement of software configuration management tool. • Deficiency of IEC 61508: tool qualification requirements for T2 & T3 ..."
          ]
        },
        {
          "title": "ISO 26262-6:2018 - Product development at the software level - GitLab",
          "url": "https://about.gitlab.com/solutions/iso-26262/",
          "excerpts": [
            "ISO 26262-6:2018 prescribes ways to identify and mitigate safety risks for automotive applications. These methods depend on so-called Automotive Safety ..."
          ]
        },
        {
          "title": "Ferrocene Update",
          "url": "https://ferrous-systems.com/blog/sealed-rust-the-plan/",
          "excerpts": [
            "Feb 13, 2020 — Ferrocene is the effort led by Ferrous Systems GmbH to qualify the Rust language and compiler for use in mission and safety-critical domains."
          ]
        },
        {
          "title": "Ferrocene - ISO 26262 and IEC 61508 qualified rust compiler",
          "url": "https://lobste.rs/s/qhohlx/ferrocene_iso_26262_iec_61508_qualified",
          "excerpts": [
            "The aim is to ensure there's a formal chain of traceability that goes from everything an end user compiled to the features you tested and found ..."
          ]
        },
        {
          "title": "Software Tools: It's as Easy as T1, T2, T3 - EngineerZone",
          "url": "https://ez.analog.com/ez-blogs/b/engineerzone-spotlight/posts/software-tools",
          "excerpts": [
            "Nov 28, 2018 — This blog discusses requirements related to offline software tools found in standards such as IEC 61508, ISO 26262 and D0-178C/D0-330."
          ]
        },
        {
          "title": "Efficient and Trustworthy Tool Qualification for Model- ...",
          "url": "https://inria.hal.science/hal-01482408v1/document",
          "excerpts": [
            "In this paper we review the tool quali- fication requirements of the standards ISO 26262 (automotive domain) and the new RTCA DO-178C (avionic ..."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "One of the primary partitioning strategies in ARINC 653 is time and space partitioning. Time partitioning involves dividing the system's ...",
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Incremental Assurance of Multicore Integrated Modular Avionics (IMA)",
          "url": "https://ieeexplore.ieee.org/document/9594404/",
          "excerpts": [
            "DO-297/ED-124 defines incremental acceptance as a \"process for obtaining credit toward approval and certification by accepting or finding that an IMA module ..."
          ]
        },
        {
          "title": "Parasoft ISO 26262 Software Compliance Technical Whitepaper",
          "url": "https://alm.parasoft.com/hubfs/New_Pages/Whitepaper%20ISO%2026262%20Software%20Compliance%20With%20Parasoft.pdf",
          "excerpts": [
            "ISO 26262 is a functional safety standard covering the entire automotive product development process, with Part 6 addressing software development. Wh",
            "Part 8, section 11, describes the software   tool qualification proces",
            "Tools that automate  software development activities and tasks can  significantly help organizations meet ISO 26262  requiremen",
            "The information presented  here is intended to serve as an introduction to  ISO 26262 software verification and validation  processes with Paraso"
          ]
        },
        {
          "title": "Ferrocene: Qualified Rust toolchain for safety-critical systems",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles. It’s qualified at ASIL-D, the highest risk class, for peace of mind.",
            "ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or your choice of RTOS.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels.",
            "Qualified for automotive, industrial and medical development. ... ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or ...See more",
            "ull qualification\ndocuments. [Read\nDocumentation](https://public-docs.ferrocene.dev/main/index.html)",
            "TÜV SÜD conducted the audit and Ferrous Systems – leading Rust experts – supports the signed installers as well as the nightly builds.",
            "The source code of Ferrocene is\nfully open source under the MIT OR Apache-2.0 license, including the full qualification\ndocuments."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "We’ve qualified\nFerrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database. ",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "This standard provides automakers\nwith guidelines that make the software being used to develop, produce, operate\nand service the automotive sectors safe to use.",
            "Beyond the automotive, Ferrocene can also be used in electronic programmable\nsystems in the industrial sector. Here the focus is on developing products or\napplications that carry out safety functions.",
            "This means we achieved qualification for the open source Ferrocene toolchain.",
            "With these qualifications, Rust can now be used to develop software for\nelectronic systems in series production road vehicles.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "This is\nthe first qualification of a Rust compiler.",
            "This is\nthe first qualification of a Rust compiler.",
            "Ferrocene is ISO 26262 and IEC 61508 qualified!"
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "formal verification in general is stronger than other\n   traditional ways of gaining trust in software such as testing in that\n   it can prove the _absence_ of bugs, not just their\n ",
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft"
          ]
        },
        {
          "title": "Implications of the seL4 Verification",
          "url": "https://sel4.systems/Verification/implications.html",
          "excerpts": [
            "The proofs not only establish functional correctness, integrity, and confidentiality, but they also imply the absence of many common programming errors. They give you the reasons why and how\n data structures work, why it is safe to optimise and leave out certain checks\n (because you know they will always be true), and why the code always\n executes in a defined and safe mann"
          ]
        },
        {
          "title": "Ferrocene Achieves IEC 62304 Qualification",
          "url": "https://ferrous-systems.com/blog/ferrocene-achieves-iec-62304-qualification/",
          "excerpts": [
            "It is qualified to automotive (ISO 26262, ASIL-D), industrial development (IEC 61508, SIL4) and medical (IEC 62304, Class C) standards, with ..."
          ]
        },
        {
          "title": "IEC 61508 Ensuring Software Compliance",
          "url": "https://www.qa-systems.com/solutions/iec-61508/",
          "excerpts": [
            "Part 3 of IEC 61508 addresses the software requirements of a safety-related system mandating the use of better development processes, including the use of ..."
          ]
        },
        {
          "title": "ISO 26262-8:2011(en), Road vehicles — Functional safety",
          "url": "https://www.iso.org/obp/ui/#iso:std:iso:26262:-8:ed-1:en",
          "excerpts": [
            "ISO 26262 includes guidance to avoid these risks by providing appropriate requirements and processes. System safety is achieved through a number of safety ..."
          ]
        },
        {
          "title": "DO-330 Introduction – Tool Qualification",
          "url": "https://afuzion.com/do-330-introduction-tool-qualification/",
          "excerpts": [
            "This DO-330 whitepaper describes the five tool categories versus criticality levels (DALs) and how to truly qualify avionics software tools."
          ]
        },
        {
          "title": "r/rust - Ferrous Systems Donates Ferrocene Language ...",
          "url": "https://www.reddit.com/r/rust/comments/1jkfovo/ferrous_systems_donates_ferrocene_language/",
          "excerpts": [
            "... DO-178C is, in my understanding, the big requirement here. ... Now that we are here: what's the progress on DO-178 (DO-330) certification?"
          ]
        },
        {
          "title": "Ferrous Systems First to Run Rust on Cortex-R52 Under ...",
          "url": "https://www.businesswire.com/news/home/20250311274388/en/Ferrous-Systems-First-to-Run-Rust-on-Cortex-R52-Under-Open-Source-License",
          "excerpts": [
            "Ferrocene is the first open-source ... certified versions of libcore and guidance on instruction tracing for software certification."
          ]
        },
        {
          "title": "Ferrocene 25.05.0 now available! - Ferrous Systems",
          "url": "https://ferrous-systems.com/blog/ferrocene-25-05-0/",
          "excerpts": [
            "ferrocene.dev) is the first Rust compiler toolchain qualified for safety- and mission-critical systems. It is qualified to ISO 26262 (TCL 3/ASIL D), IEC 61508 (T3/SIL 4) and IEC 62304 (Class C) with TÜV SÜD.",
            "In addition, we have elevated two of our experimental targets to qualified status:\n\n* Armv7E-M bare-metal (soft-float) (`thumbv7em-none-eabi`)\n* Armv7E-M bare-metal (hard-float) (`thumbv7em-none-eabi"
          ]
        },
        {
          "title": "DO-330 Software tool qualification considerations",
          "url": "https://ldra.com/do-330/",
          "excerpts": [
            "DO-330 “Software Tool Qualification Considerations” states that “Software tools are widely used in multiple domains, to assist in developing, verifying, and ..."
          ]
        },
        {
          "title": "Leveraging ISO 26262 tool certification in IEC 61508",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2020/12/17/leveraging-iso-26262-tool-certification-in-iec-61508/",
          "excerpts": [
            "Dec 17, 2020 — Tools are assessed as T1, T2 or T3. T1 tools are tools which have no impact on safety or where there is a high degree of confidence that tool ..."
          ]
        },
        {
          "title": "Industry Standards | MOSA DO-178C FAA FACE EASA ...",
          "url": "https://www.ddci.com/resources/industry-standards/",
          "excerpts": [
            "Nov 15, 2024 — ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning ... DO-178C DAL A for this ...",
            "ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning in safety-critical avionics that ..."
          ]
        },
        {
          "title": "Shenango: achieving high CPU efficiency for latency-sensitive ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323265",
          "excerpts": [
            "Shenango achieves comparable latencies but at far greater CPU efficiency. It reallocates cores across applications at very fine granularity--every 5 μs."
          ]
        },
        {
          "title": "Clearing the Fog of ISO 26262 Tool Qualification",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2022/04/13/clearing-the-fog-of-iso-26262-tool-qualification/",
          "excerpts": [
            "The setting of TI and TD ultimately determines the TCL for the tool based on the table below, found in ISO 26262-8:2018 Clause 11.4.5.",
            "ISO 26262 dictates that tools used in the development of safety-critical electronics be assessed, and it guides this analysis by defining three terms:",
            "Tool Impact (TI): | This is an evaluation of the potential of a tool to introduce or fail to detect error",
            " Tool Detection (TD) | This is an evaluation of the confidence that the tool will prevent the malfunctioning of a software tool, and the standard defines:  **TD1**:  High confidence that a malfunction will be prevented or detected. **TD2**: Medium confidence that a malfunction will be prevented or detected. **TD3**:",
            "Tool Confidence Level (TCL) | An establishment of tool confidence based on TI and TD and the standard defines:  **TCL1**:  High level of confidence. No further qualification methods are required. **TCL2**:  Medium level of confidence. Further qualification methods are required. **TCL3**: Low level of confidence. Further qualification metho",
            " provides four methods for performing tool qualification (ISO 26262-8:2018 Clause 11.4.6)."
          ]
        },
        {
          "title": "MathWorks/Avionics Certification – A complete guide to DO-178 (tool qualification overview for ISO 26262, IEC 61508, and DO-178C)",
          "url": "https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/m/61793_CMR10-16.pdf",
          "excerpts": [
            " \nSoftware Tool Documentation",
            " \nSoftware Tool Classification Analysis",
            " \nSoftware Tool Qualification Report",
            " Tool qualification can be carried out for individual tools as well as for \ntool chains or sets of tools.",
            "The ISO/DIS 26262 tool qualification process requires the creation of the following tool \nqualification work products (ISO/DIS 26262-8, 11.5; see the appendix for a summary):",
            " \nSoftware Tool Qualification Plan",
            " \nSoftware Tool Qualification Plan",
            "• Software Tool Documentation",
            "• Software Tool Classification Analysis",
            "\n• Software Tool Qualification Report",
            ". 2.4 Software Tool Documentation (STD)",
            ". 2.6 Software Tool Qualification Report (STQR)"
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage.",
            "Proofs and Certification\n\nThe traditional way to achieve high levels of assurance are schemes\nsuch as Common Criteria, ISO-26262, and DO-178C. The seL4 proofs go\nbeyond what these certification schemes require for software\ndevelopment at their most stringent levels.",
            "The traditional way to achieve high levels of assurance are schemes such as Common Criteria, ISO-26262, and DO-178C."
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Remote attestation Implementation - BlindAI - Mithril Security",
          "url": "https://blindai.mithrilsecurity.io/en/latest/docs/security/remote_attestation/",
          "excerpts": [
            "The first one, is EPID attestation which relies on using Intel services to attest that an enclave on specific platforms is verified. The second one is DCAP ( ..."
          ]
        },
        {
          "title": "GlobalPlatform Entity Attestation Protocol Specification",
          "url": "https://globalplatform.org/wp-content/uploads/2024/07/GPP_EntityAttestationProtocolSpec_v0.0.0.26_PublicRvw2.pdf",
          "excerpts": [
            "Remote Attestation \nThe process by which attestation information is assembled by an Entity \nAttestation Service, transferred to a Relying Party, and processe",
            "The IETF NNNN specification ([draft-ietf-rats-eat]) introduces the concept of Attestation, which is a mechanism \n45 \nby which an Entity can provide information about itself with some level of assurance to a Relying Par",
            "During Attestation, an Entity \n47 \nAttestation Service builds a set of Claims, each of which consists of a piece of evidence provided by a Clai"
          ]
        },
        {
          "title": "seL4: formal verification of an OS kernel",
          "url": "https://cseweb.ucsd.edu/~dstefan/cse227-spring20/papers/sel4.pdf",
          "excerpts": [
            "by G Klein · 2009 · Cited by 3032 — ABSTRACT. Complete formal verification is the only known way to guar- antee that a system is free of programming errors."
          ]
        },
        {
          "title": "The seL4 Microkernel An Introduction",
          "url": "https://cdn.hackaday.io/files/1713937332878112/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 1 — This white paper gives an overview of seL4. ... In a capability-based system, such as seL4, invoking a capability is the one and only way."
          ]
        },
        {
          "title": "Introduction to SGX - Gramine documentation - Read the Docs",
          "url": "https://gramine.readthedocs.io/en/stable/sgx-intro.html",
          "excerpts": [
            "The Provisioning Certification Enclave is used in DCAP based remote attestation. This enclave communicates with the Intel Provisioning Certification Service ( ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.11/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM ... Refresh expired {TCB info, PCK CRLs, QE Identity, QvE Identity,. Root CA CRL} ..."
          ]
        },
        {
          "title": "[PDF] Intel® Software Guard Extensions (Intel® SGX) Data Center ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.7/linux/docs/Intel_SGX_ECDSA_QuoteLibReference_DCAP_API.pdf",
          "excerpts": [
            "Deployment Tool for PCK Certificate Chain Retrieval for Intel® SGX DCAP ... the PCK Certificate that the quote verifier uses to certify the attestation key."
          ]
        },
        {
          "title": "in-toto and SLSA",
          "url": "https://slsa.dev/blog/2023/05/in-toto-and-slsa",
          "excerpts": [
            "May 2, 2023 — It defines the Provenance predicate to record the build characteristics of the produced artifacts. The specification describes how to verify ..."
          ]
        },
        {
          "title": "Overview",
          "url": "https://docs.sigstore.dev/cosign/signing/overview/",
          "excerpts": [
            "This document explains how identity-based, or “keyless” signing works in Sigstore. To learn more about OIDC, please review OIDC Usage in Fulcio."
          ]
        },
        {
          "title": "Provenance",
          "url": "https://slsa.dev/spec/v0.1/provenance",
          "excerpts": [
            "Description of SLSA provenance specification for verifying where, when, and how something was produced."
          ]
        },
        {
          "title": "Secure Software Updates via TUF — Part 2",
          "url": "https://medium.com/@mulgundmath/secure-software-updates-via-tuf-part-2-412c6a2b10ab",
          "excerpts": [
            "Next in the file is the assignment of keys to roles such as root, targets, snapshot, and timestamp; all four need to be mandatorily listed ( ..."
          ]
        },
        {
          "title": "Use Sigstore for keyless signing and verification",
          "url": "https://docs.gitlab.com/ci/yaml/signing_examples/",
          "excerpts": [
            "The Sigstore project provides a CLI called Cosign which can be used for keyless signing of container images built with GitLab CI/CD."
          ]
        },
        {
          "title": "Securing the Software Supply Chain: How in-toto and TUF ...",
          "url": "https://www.infoq.com/presentations/software-supply-chain-security/",
          "excerpts": [
            "Nov 28, 2023 — Marina Moore covers the fundamentals of both in-toto and TUF, and discusses how to combine them with a real world case study where Datadog has been using two ..."
          ]
        },
        {
          "title": "Securing the Software Supply Chain: How in-toto and TUF ...",
          "url": "https://qconnewyork.com/presentation/jun2023/securing-software-supply-chain-how-toto-and-tuf-work-together-combat-supply",
          "excerpts": [
            "Jun 13, 2023 — The framework connects security efforts such as SLSA, Sigstore, and SBOMs, where signed and verifiable in-toto attestations are used to express ..."
          ]
        },
        {
          "title": "Signing Containers",
          "url": "https://docs.sigstore.dev/cosign/signing/signing_with_containers/",
          "excerpts": [
            "You can use Cosign to sign containers with ephemeral keys by authenticating with an OIDC (OpenID Connect) protocol supported by Sigstore."
          ]
        },
        {
          "title": "SigstoreCon 2024: Advancing Software Supply Chain ...",
          "url": "https://openssf.org/blog/2024/12/16/sigstorecon-2024-advancing-software-supply-chain-security/",
          "excerpts": [
            "Dec 16, 2024 — The one-day conference brought together developers, maintainers, and security experts to explore how Sigstore is transforming software supply chain security."
          ]
        },
        {
          "title": "Intel SGX DCAP Orientation Guide",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.9/linux/docs/Intel_SGX_DCAP_ECDSA_Orientation.pdf",
          "excerpts": [
            "Attestation is the process of demonstrating that a software executable is properly instantiated on a platform.",
            "The Intel® SGX Provisioning Certification \nService offers APIs for retrieving \nprovisioning certification key (PCK) \ncertificates, certificate revocation lists, \nTrusted Computing Base \n(TCB) information, the Intel quoting enclave (QE) \nidentity, and the Intel quote verification enclave \n(QVE) id",
            "The caching service for the Intel® SGX provisioning certification \nservice allows a CSP or a datacenter to cache PCK certificates, \nPCK certificate revocation lists (CRL), TCB Information, QE \nidentity and QVE Identity structures for all platforms in its data \ncen",
            "The current release of the reference can be \nconfigured to fill its cache in a few ways. i. Fill the cache using a push mechanism. The caching service will queue the PCK Certificate IDs \nuploaded by the PCK Certificate ID Retrieval Too",
            "The platform quote provider library provides a set of APIs \nthat abstract platform implementation specific functions",
            "e platform quote provider library \nthat works in conjunction with the reference caching \nservice (see ‘Caching Service for the Intel® SGX \nprovisioning certification service’ below) to provide this \ninformation to the quote lib",
            "The quote verification library can run on both platforms \nwith SGX and without SGX. When the platform supports \nSGX, the library can return an SGX REPORT authenticating \nthe verification result was produced by the Intel® SGX \nQuote Verification Enclave (Q"
          ]
        },
        {
          "title": "Remote Attestation on Arm TrustZone OP-TEE with ...",
          "url": "https://fosdem.org/2025/schedule/event/fosdem-2025-4952-remote-attestation-on-arm-trustzone-op-tee-with-veraison-verifier-current-status-and-future-plan-/",
          "excerpts": [
            "We report on the attestation mechanism implemented in OP-TEE, a trusted OS running on the Arm Cortex-A TrustZone. This mechanism generates attestation evidence ..."
          ]
        },
        {
          "title": "OP-TEE Remote Attestation with VERAISON Verification",
          "url": "https://github.com/OP-TEE/optee_os/issues/6921",
          "excerpts": [
            "Jun 27, 2024 — The PTA provides a general mechanism to make a RA evidence. It measures the hash of the TA and signs the hash. The RA evidence is verified by Veraison verifier.",
            "Jun 27, 2024 — We have customized OP-TEE (a Secure OS for Arm Cortex-A TrustZone) to enable Remote Attestation with VERAISON Verification."
          ]
        },
        {
          "title": "RFC 9783 - Arm's Platform Security Architecture (PSA) Attestation ...",
          "url": "https://datatracker.ietf.org/doc/rfc9783/",
          "excerpts": [
            "This document specifies the structure and semantics of the PSA attestation token. The PSA attestation token is a profile of the Entity Attestation Token (EAT)."
          ]
        },
        {
          "title": "RFC 9711 - The Entity Attestation Token (EAT) - IETF Datatracker",
          "url": "https://datatracker.ietf.org/doc/rfc9711/",
          "excerpts": [
            "An Entity Attestation Token (EAT) is a message made up of claims about an entity. An entity may be a device, some hardware, or some software."
          ]
        },
        {
          "title": "Attestation & Entity Attestation Tokens Explained - PSA Certified",
          "url": "https://www.psacertified.org/blog/what-is-an-entity-attestation-token/",
          "excerpts": [
            "An EAT token is encoded in either one of two standardized data formats: a compact binary format (CBOR) or in the text-based format JSON. A ..."
          ]
        },
        {
          "title": "draft-ietf-rats-eat-21 - The Entity Attestation Token (EAT)",
          "url": "https://datatracker.ietf.org/doc/draft-ietf-rats-eat/21/",
          "excerpts": [
            "The Entity Attestation Token (EAT) draft-ietf-rats-eat-21 · Authors, Laurence Lundblade , Giridhar Mandyam , Jeremy O'Donoghue , Carl Wallace · Last updated ..."
          ]
        },
        {
          "title": "Threat modeling for drivers (Windows hardware drivers threat model)",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/driversecurity/threat-modeling-for-drivers",
          "excerpts": [
            "Aug 31, 2023 — This section applies the principles of threat modeling to driver design and provides examples of threats to which a driver might be susceptible. ](images/sampledataflowdiagramkernelmodedriver.gif)\n\n",
            "Kernel-mode drivers must validate data that originates in user mode.",
            "The driver in the figure receives data from a user process in the following types of requests:\n\n* Create, read, and write requests (IRP\\_MJ\\_CREATE, IRP\\_MJ\\_READ, or IRP\\_MJ\\_WRITE)\n* Public device I/O control requests (IRP\\_MJ\\_DEVICE\\_ CON",
            "In response to these requests, output data and status information flow from the driver back to the user process.",
            "ess. Finally, the driver receives data from the device because of device I/O operations or user actions (such as opening the tray on a CD drive) that change device status.",
            "The previous figure shows driver data flow at a broad conceptual level. Each circle represents a relatively large task and lacks detail.",
            "Information enters the driver because of requests from the operating system, requests from a user process, or requests (typically interrupts) from the device.",
            "Information enters the driver because of requests from the operating system, requests from a user process, or requests (typically interrupts) from the device. The driver in the previous figure receives data from the operating system in several types of req",
            "the circle labeled “Handle I/O Requests” might be expanded into a separate diagram, similar to the following figure. ! [Expanded data flow diagram for I/O requests, showing separate tasks for each type of I/O request. ](images/expandeddataflowdiagramiorequests.gif)",
            "The second diagram shows separate tasks for each type of I/O request in the first diagram. (For simplicity, data paths to the device have been omitted.)",
            "...",
            "The resulting images could be corrupted, but system administrators would have no way to determine which user caused the problem.",
            "Information disclosure** threats are exactly as the name implies: the disclosure of information to a user who does not have permission to see it. Any driver that passes information to or from a user buffer is susceptible to information disclosure threat",
            "Denial-of-service** attacks threaten the ability of valid users to access resource"
          ]
        },
        {
          "title": "The CHERI capability model: Revisiting RISC in an age of ...",
          "url": "https://ieeexplore.ieee.org/document/6853201",
          "excerpts": [
            "by J Woodruff · 2014 · Cited by 475 — We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection."
          ]
        },
        {
          "title": "CHERI OS-feature matrix",
          "url": "https://www.morello-project.org/cheri-feature-matrix/",
          "excerpts": [
            "Operating systems can implement CHERI software features along several axes. This table captures key axes, and describes the maturity of those features for ..."
          ]
        },
        {
          "title": "Arm Morello Program",
          "url": "https://www.arm.com/architecture/cpu/morello",
          "excerpts": [
            "Morello is a research program with the potential to radically change the way we design and program processors in the future to improve built-in security."
          ]
        },
        {
          "title": "Morello Prototype Architecture - Arm Developer",
          "url": "https://developer.arm.com/Architectures/Morello",
          "excerpts": [
            "The Morello architecture is a prototype CPU architecture that introduces a new approach to security and is part of the wider Morello program."
          ]
        },
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        },
        {
          "title": "Review the TPM measured boot log",
          "url": "https://developer.arm.com/documentation/107981/latest/SystemReady-compliance-testing---BBSR-and-Security-Interface-Testing-FAQ/How-do-I-test-for-Base-Boot-Security-Requirements--BBSR--compliance-/Review-the-ACS-test-result-logs/Review-the-TPM-measured-boot-log",
          "excerpts": [
            "Verify that the cumulative SHA256 measurements from the event log match the TPM PCRs 0-7. The events logged in the TPM event log must match the actual ..."
          ]
        },
        {
          "title": "IMA and EVM Concepts — IMA 1.0 documentation",
          "url": "https://ima-doc.readthedocs.io/en/latest/ima-concepts.html",
          "excerpts": [
            "The IMA-Appraisal feature is local, and requires neither a TPM nor a separate verifier. IMA-Audit augments the system's audit log with the file hash. This can ..."
          ]
        },
        {
          "title": "Forward Secure Sealing (FSS) in Systemd-Journal - Learn Netdata",
          "url": "https://learn.netdata.cloud/docs/logs/systemd-journal-logs/forward-secure-sealing-fss-in-systemd-journal",
          "excerpts": [
            "Forward Secure Sealing (FSS) is a feature in the systemd journal designed to detect log file tampering . Given that attackers often try to hide their actions by modifying or deleting log file entries, FSS provides administrators with a mechanism to identify any such unauthorized alterations."
          ]
        },
        {
          "title": "[PDF] Security Threats and Opportunities in One-Sided Network ...",
          "url": "https://cseweb.ucsd.edu/~yiying/one-sided-security.pdf",
          "excerpts": [
            "One-sided network communication technologies such as. RDMA and NVMe-over-Fabrics are quickly gaining adoption in production software and in datacenters."
          ]
        },
        {
          "title": "[PDF] Changes in NVM Express® Specifications",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM-Express-Revision-Changes-2025.08.01.pdf",
          "excerpts": [
            "This technical proposal enables sanitize operations to be performed on individual namespaces, as opposed to the entire. NVM subsystem. 2.1.1.1."
          ]
        },
        {
          "title": "A journey to optimize GDRDMA in cloud scenario",
          "url": "https://lpc.events/event/18/contributions/1685/attachments/1424/3047/ATS%20vs%20IOMMU-lyan.pdf",
          "excerpts": [
            "The journey involves optimizing GDRDMA in cloud, using GPU Direct RDMA, ACS/ATS, IOMMU, and enabling ATS from both RC and EP."
          ]
        },
        {
          "title": "[PDF] Securing RDMA for High-Performance Datacenter Storage Systems",
          "url": "https://www.usenix.org/system/files/hotcloud20_paper_simpson.pdf",
          "excerpts": [
            "In general, systems leverage one-sided RDMA operations when possible, as these operations are faster and reduce remote. CPU usage. This section analyzes the ..."
          ]
        },
        {
          "title": "7 Incident Response Metrics and How to Use Them",
          "url": "https://securityscorecard.com/blog/how-to-use-incident-response-metrics/",
          "excerpts": [
            "These seven incident response metrics and how to use them can provide you with a way to reduce risk and respond to incidents more efficiently."
          ]
        },
        {
          "title": "Security Analysis of Forward Secure Log Sealing in Journald",
          "url": "https://eprint.iacr.org/2023/867",
          "excerpts": [
            "Forward-secure log sealing is a cryptographic technique used to ensure the integrity of past log entries even in the event of a full system ..."
          ]
        },
        {
          "title": "Trusted Platform Module (TPM) event logs",
          "url": "https://docs.trustauthority.intel.com/main/articles/articles/ita/tpm-log.html",
          "excerpts": [
            "Oct 25, 2024 — By replaying the event log and comparing the result with the PCR value, you can verify the integrity of the log itself. Once the log integrity ..."
          ]
        },
        {
          "title": "Integrity Measurement Architecture (IMA) / Wiki / Home",
          "url": "https://sourceforge.net/p/linux-ima/wiki/Home/",
          "excerpts": [
            "Before EVM is activated, any requested integrity appraisals are unknown, so the EVM startup should be done early in the boot process, preferably entirely within ..."
          ]
        },
        {
          "title": "What is Security Logging and Monitoring?",
          "url": "https://www.bitlyft.com/resources/what-is-security-logging-and-monitoring",
          "excerpts": [
            "System logs are designed to provide relevant information that allows you to understand and identify issues that become threats to your network."
          ]
        },
        {
          "title": "An Introduction to CHERI",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/",
          "excerpts": [
            "CHERI is a\nhybrid capability architecture in that it is able to blend\narchitectural capabilities with conventional MMU-based\narchitectures and microarchitectures,\nand with conventional software stacks based on virtual memory and C/C++. This approach allows incremental deployment within existing software\necosystems, which we have demonstrated through extensive hardware and software\nprototyping.",
            "We formalise key intended security properties of the ISA specifications, and establish that these hold with mechanised proof."
          ]
        },
        {
          "title": "CHERI/Morello Security and End-to-End Model",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-morello.html",
          "excerpts": [
            "Morello is an industrial demonstrator of a capability architecture: a prototype System-on-Chip (SoC) and development board, developed by Arm."
          ]
        },
        {
          "title": "CHERIoT: a study in CHERI (RISCV.org blog)",
          "url": "https://riscv.org/blog/2024/08/cheriot-a-study-in-cheri/",
          "excerpts": [
            "CHERIoT provides a layered security model. At the core, CHERIoT provides object-granularity (spatial and temporal) memory safety.",
            "The hardware provides low-level guarantees, such as unforgeable pointers, the ability to ensure that pointers to marked memory regions cannot be used, and a lightweight way of making pointers into opaque tamper-proof tokens.",
            "Sealing a CHERI capability turns it into an opaque token. You can pass it around as you would any other pointer, but you cannot dereference or modify it.",
            "The seal operation takes another capability with a permit-seal permission and embeds the value of that capability in the *object type* of the sealed capabilit",
            "A CHERI capability can be stored in memory or in registers and is protected by *guarded manipulation*: Operations may reduce the rights that a capability conveys, but not increase the",
            "The tag bit is a simple attestation from the hardware that says that this capability was created by following these rules, starting with one of the all-powerful capabilities provided at boot and then constrained by layers of software in the system.",
            "CHERI capability, that can be used to represent pointers. These carry bounds and permissions, in addition to an address. A CHERI capability ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 9.0.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-9.0.1.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree ... By calling seL4 CNode Revoke() on the original capability to an ...",
            "The tree structure so generated is termed the capability derivation tree (CDT). ... The seL4 CNode Revoke() method will seL4 CNode Delete ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/latest/dcap-latest/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "TCB Info,. QE Identity. QVE Identity. PCK Certificate. IDs. +. Cached PCK, CRLs ... DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM. DCAP ..."
          ]
        },
        {
          "title": "[PDF] PSA Certified Attestation API 1.0 - GitHub Pages",
          "url": "https://arm-software.github.io/psa-api/attestation/1.0/IHI0085-PSA_Certified_Attestation_API-1.0.3.pdf",
          "excerpts": [
            "IETF Entity Attestation Token (EAT), Draft. ... defined in Arm's Platform Security Architecture (PSA) Attestation Token [PSATOKEN]."
          ]
        },
        {
          "title": "ietf-rats-wg/eat: Entity Attestation Token IETF Draft Standard - GitHub",
          "url": "https://github.com/ietf-rats-wg/eat",
          "excerpts": [
            "This is the working area for the IETF RATS Working Group Internet-Draft, \"The Entity Attestation Token (EAT)\". Editor's Copy · Working Group Draft ..."
          ]
        },
        {
          "title": "Sealing and unsealing data in TPM",
          "url": "https://community.infineon.com/t5/Blogs/Sealing-and-unsealing-data-in-TPM/ba-p/465547",
          "excerpts": [
            "Aug 9, 2023 — Sealing is essentially encrypting data based on certain conditions. TPM allows decryption only if the conditions defined during encryption are satisfied."
          ]
        },
        {
          "title": "Part 4: Under the Hood — DMA, IOMMU, BARs, and VFIO | ...",
          "url": "https://medium.com/gpu-kernel-hacking-for-engineers/part-4-under-the-hood-dma-iommu-bars-and-vfio-45b4f13e545c",
          "excerpts": [
            "VFIO (Virtual Function I/O) allows safe, isolated access to PCI devices from user space, making it critical for: Containerized GPU apps ..."
          ]
        },
        {
          "title": "Understand PCR banks on TPM 2.0 devices",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/tpm/switch-pcr-banks-on-tpm-2-0-devices",
          "excerpts": [
            "To bind the use of a TPM based key to a certain state of the device, the key can be sealed to an expected set of PCR values. For instance, PCRs 0 through 7 ..."
          ]
        },
        {
          "title": "[PDF] Trusted Platform Module 2.0 Library Part 1: Architecture",
          "url": "https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-1-Architecture-Version-184-rc2_20Dec24.pdf",
          "excerpts": [
            "An NV Index is space that is defined by a user of the TPM. The ... For a Counter NV Index with the TPMA_NV_ORDERLY attribute, Index ..."
          ]
        },
        {
          "title": "[PDF] TPM 2.0 Part 1 - Architecture - Trusted Computing Group",
          "url": "https://trustedcomputinggroup.org/wp-content/uploads/TPM-Rev-2.0-Part-1-Architecture-01.07-2014-03-13.pdf",
          "excerpts": [
            "15.3 NV Index Handles (MSO=0116). An NV Index is associated with a persistent TPM resource created by TPM2_NV_DefineSpace(). 15.4 Session ..."
          ]
        },
        {
          "title": "10. Security Support - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides/howto/security.html",
          "excerpts": [
            "This document describes the security features of interest for DPDK. This guide will provides information on each protocol, including supported algorithms."
          ]
        },
        {
          "title": "Unlocking Secure High-Performance Networking with ...",
          "url": "https://www.dpdk.org/high-performance-networking-with-dpdk-security-framework/",
          "excerpts": [
            "This document outlines the security protocols and implementations supported within DPDK, serving as a guide for both users and contributors."
          ]
        },
        {
          "title": "wolfTPM support for sealing/unsealing based on externally ...",
          "url": "https://www.wolfssl.com/wolftpm-support-for-sealing-unsealing-based-on-externally-signed-pcr/",
          "excerpts": [
            "Dec 14, 2023 — With the TPM 2.0 specification, it's possible to seal/unseal secrets via cryptographic signatures of the PCR's, removing the requirement to ..."
          ]
        },
        {
          "title": "Leveraging Trusted Platform Modules (TPM) for Cryptographic ...",
          "url": "https://www.researchgate.net/publication/392693928_Leveraging_Trusted_Platform_Modules_TPM_for_Cryptographic_Anchoring_and_Remote_Attestation_of_UEFI_Capsule_Updates_in_Secure_Boot_Environments",
          "excerpts": [
            "A TPM monotonic counter is a non-volatile register that ... ○ PCR extension and monotonic counter simulation to verify rollback protection."
          ]
        },
        {
          "title": "Verify Boot | Android Open Source Project",
          "url": "https://source.android.com/docs/security/features/verifiedboot/verified-boot",
          "excerpts": [
            "Rollback protection is typically implemented by using tamper-evident storage to record the most recent version of the Android and refusing to ..."
          ]
        },
        {
          "title": "2. Features Overview - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-18.05/nics/features.html",
          "excerpts": [
            "Supports starting/stopping a specific Rx/Tx queue of a port. [implements] eth_dev_ops: rx_queue_start , rx_queue_stop , tx_queue_start , tx_queue_stop ..."
          ]
        },
        {
          "title": "[PATCH v3 24/25] net/spnic: support Tx/Rx queue start/stop ...",
          "url": "http://inbox.dpdk.org/dev/1bc4636e940682b02279711ae1714b22c958086a.1640332922.git.songyl@ramaxel.com/",
          "excerpts": [
            "... packets can be received to host. when stopping rx queue, the PMD driver will poll the rx queue until it is empty and release the mbuf, then the PMD driver ..."
          ]
        },
        {
          "title": "lib/librte_ether/rte_ethdev.h File Reference - DPDK",
          "url": "https://doc.dpdk.org/api-1.6/rte__ethdev_8h.html",
          "excerpts": [
            "Check if the DD bit of the specific RX descriptor in the queue has been set. Parameters. port_id, The port identifier of the Ethernet device. queue_id, The ..."
          ]
        },
        {
          "title": "rte_eth_dev_owner_delete(3) — dpdk-doc — Debian testing",
          "url": "https://manpages.debian.org/testing/dpdk-doc/rte_eth_dev_owner_delete.3",
          "excerpts": [
            "Check the status of a Rx descriptor in the queue. It should be called in a similar context than the Rx function: on a dataplane core; not ..."
          ]
        },
        {
          "title": "[RFE] Quiesce filesystem during VM snapshots · Issue #1795 - GitHub",
          "url": "https://github.com/flatcar/Flatcar/issues/1795",
          "excerpts": [
            "Missing: DMA NIC NVMe GPU rings checkpoint"
          ]
        },
        {
          "title": "Best practice for Snapshots? : r/vmware - Reddit",
          "url": "https://www.reddit.com/r/vmware/comments/bh80jx/best_practice_for_snapshots/",
          "excerpts": [
            "Missing: DMA NVMe GPU rings checkpoint"
          ]
        },
        {
          "title": "ccNVMe: Crash-Consistent NVMe over PCIe (RDMA and PCIe integration) – ACM/DL basis",
          "url": "https://dl.acm.org/doi/full/10.1145/3568428",
          "excerpts": [
            "The key idea of ccNVMe is to couple the crash consistency to the data dissemination; a transaction (a set of requests that must be executed atomically) is guaranteed to be crash consistent when it is about to be dispatched over PCIe.",
            "ccNVMe makes the submission queues durable in case of a sudden crash, and rings the doorbells in the unit of a transaction rather than a request, to let the requests of a transaction reach the same state (e.g., all or nothing), thereby achieving atomicity.",
            "ccNVMe rings the doorbell when all requests within a transaction arrive or when the number of work requests exceeds a pre-defined threshold (half of the queue depth by default), whichever happens earlier; this reduces the number of CPU-initiated doorbells and resolves issue 1 from Section 3.2 .",
            "The transaction-aware doorbell can also improve the performance of NIC-initiated DMAs.",
            "During crash recovery, ccNVMe finds the unfinished transactions and leaves the specific recovery algorithms (e.g., rollback) to upper layer systems.",
            "The data dissemination mechanism of the original NVMe already tracks the lifecycle (e.g., submitted or completed) of each request in the hardware queues and doorbells.",
            "ccNVMe leverages this feature to submit and complete the transaction in an ordered and atomic fashion, and makes the tracked lifecycles persistent for recovery, thereby letting the software ensure crash consistency by taking the free rides of the data dissemination MMIOs."
          ]
        },
        {
          "title": "XRSTOR — Restore Processor Extended States",
          "url": "https://www.felixcloutier.com/x86/xrstor",
          "excerpts": [
            "Performs a full or partial restore of processor state components from the XSAVE area located at the memory address specified by the source operand."
          ]
        },
        {
          "title": "How Debuggers Work: Getting and Setting x86 Registers, Part 2",
          "url": "https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/",
          "excerpts": [
            "The XSAVE and XRSTOR family of instructions can be used to save and restore the registers introduced by newer instruction sets, eg the YMM registers introduced ..."
          ]
        },
        {
          "title": "Intel x86-64 XSAVE/XRSTOR",
          "url": "https://stackoverflow.com/questions/22105247/intel-x86-64-xsave-xrstor",
          "excerpts": [
            "I'm a CS student writing in Intel x86-64 assembly, compiling with nasm , and running on an Core i7 processor with Ubuntu 12.04 as the guest OS."
          ]
        },
        {
          "title": "managing state using the xsave feature set",
          "url": "https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol1/o_7281d5ea06a5b67a-307.html",
          "excerpts": [
            "CHAPTER 13. MANAGING STATE USING THE XSAVE FEATURE SET. The XSAVE feature set extends the functionality of the FXSAVE and FXRSTOR instructions (see Section ..."
          ]
        },
        {
          "title": "setcontext - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Setcontext",
          "excerpts": [
            "setcontext is one of a family of C library functions (the others being getcontext, makecontext and swapcontext) used for context control."
          ]
        },
        {
          "title": "getcontext or setcontext Subroutine - IBM",
          "url": "https://www.ibm.com/docs/en/aix/7.3.0?topic=g-getcontext-setcontext-subroutine",
          "excerpts": [
            "The getcontext subroutine initalizes the structure pointed to by ucp to the current user context of the calling process."
          ]
        },
        {
          "title": "Can you explain the concept of CUDA context switching and its ...",
          "url": "https://massedcompute.com/faq-answers/?question=Can%20you%20explain%20the%20concept%20of%20CUDA%20context%20switching%20and%20its%20impact%20on%20application%20performance?",
          "excerpts": [
            "Latency Overhead: Each context switch requires time to save and restore GPU states, leading to delays in execution. Reduced GPU Utilization: Frequent ..."
          ]
        },
        {
          "title": "What is the context switching mechanism in GPU? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/6605581/what-is-the-context-switching-mechanism-in-gpu",
          "excerpts": [
            "As I know, GPUs switch between warps to hide the memory latency. ... context switch requires saving registers to memory and restoring them."
          ]
        },
        {
          "title": "CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads",
          "url": "https://arxiv.org/html/2502.16631v1",
          "excerpts": [
            "Feb 23, 2025 — The AMD GPU plugin enables transparent checkpoint/restore using input/output control (ioctl) operations with the Kernel Fusion Driver (KFD)."
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage: 4 Key Features, Ecosystem & ...",
          "url": "https://cloudian.com/guides/data-security/nvidia-gpudirect-storage-4-key-features-ecosystem-use-cases/",
          "excerpts": [
            "By ensuring data coherence, GPUDirect Storage minimizes synchronization issues and supports real-time processing requirements. This feature is crucial for ..."
          ]
        },
        {
          "title": "Jetson tk1 took long latency for image transfer to device through ...",
          "url": "https://forums.developer.nvidia.com/t/jetson-tk1-took-long-latency-for-image-transfer-to-device-through-opencv-gpu/43229",
          "excerpts": [
            "The overall process takes long latency ( gpuImage.upload → debayer → gpuImage.download ) It's about 1.8ms for average, and sometimes it swift to 10ms!"
          ]
        },
        {
          "title": "ASRock hidden Memory Context Restore overrides AMD's option ...",
          "url": "https://www.reddit.com/r/overclocking/comments/18avhx1/psa_asrock_hidden_memory_context_restore/",
          "excerpts": [
            "The Asrock memory context restore option only appears when you set the memory clock to something other than \"Auto.\" And apparently, this option overrides AMD's ..."
          ]
        },
        {
          "title": "How to re-init the context after cudaResetDevice, now ERROR",
          "url": "https://forums.developer.nvidia.com/t/how-to-re-init-the-context-after-cudaresetdevice-now-error-cudaerrorcontextisdestroyed/263505",
          "excerpts": [
            "There is no cudaResetDevice, but there is a cudaDeviceReset(). The only recovery method when using the runtime API is to terminate the owning host process."
          ]
        },
        {
          "title": "SPDK NVMe Driver I/O Path - My Blog",
          "url": "https://jingliu.me/posts/2021-01-20-spdkio.html",
          "excerpts": [
            "Jan 20, 2021 — The NVMe completion queue is an array of completion queue entries. Inside those entries is a CID value that SPDK provided on command submission."
          ]
        },
        {
          "title": "PyNVMe3 Script Development Guide",
          "url": "https://pynv.me/ssd/dev-guide/",
          "excerpts": [
            "Feb 19, 2025 — PyNVMe3 supports different policies for updating admin SQ Doorbell when initializing the Admin queue. By default, PyNVMe3's NVMe driver updates ..."
          ]
        },
        {
          "title": "Dataflow function offload to reconfigurable processors",
          "url": "https://patents.google.com/patent/US11392740B2/en",
          "excerpts": [
            "... RDMA, VXLAN overlays and NVMe-oF functionality. A SmartNIC may include host kernel-bypass logic for sending and receiving packets to/from nodes and ..."
          ]
        },
        {
          "title": "IBM z17 (9175) Technical Guide",
          "url": "https://www.redbooks.ibm.com/redbooks/pdfs/sg248579.pdf",
          "excerpts": [
            "... restore steady-state operations quickly. z/OS SVC memory dump processing and ... (RDMA) over Converged Ethernet. (RoCE) is a network protocol that ..."
          ]
        },
        {
          "title": "DPDK MLX5 PMD RX queue deferred start",
          "url": "https://forums.developer.nvidia.com/t/dpdk-mlx5-pmd-rx-queue-deferred-start/250805",
          "excerpts": [
            "Hi, I'm using DPDK with the MLX5 PMD to receive UDP packets. In order to receive UDP packets only, I use DPDK's Flow API, which requires ..."
          ]
        },
        {
          "title": "X86-64 Context Saving Practices",
          "url": "https://stackoverflow.com/questions/75680863/which-contexts-need-to-be-saved-in-x86-64-with-a-c-function-return",
          "excerpts": [
            "For x86-64 System V, that's only RSP, RBP, RBX, and R12-R15. Everything else is call clobbered, like RFLAGS, all the vector regs, AVX-512 mask regs, and x87",
            "The status bits in MXCSR are also basically call-clobbered, but if you want different threads to have different FP environments (e.g. rounding mode and FTZ/DAZ), then you *do* need to save/restore that. Same for the x87 control register, maybe not the status register. MPX is deprecated now so you probably don't need to worry about `bnd0-3`. If you want to have per-task performance-counter stuff, you could save/restore the PMU performance counters like Linux does of PAPI / perf.",
            "Thread-local storage using `fsbase` or `gsbase` should be saved/restored if your OS or user-space uses it. There are MSRs for the segment bases (so you can leave the actual segment register values as 0, the null selector). Or if you enable it (for use in user-space or kernel) on a CPU that supports it, [`rdfsbase` / `wrfsbase`](https://www.felixcloutier.com/x86/rdfsbase:rdgsbase) can copy the segment base to/from an integer register even more easily and efficiently than `rdmsr` / `wrmsr`. (x86-64 SysV uses FS for thread-local storage.) ---",
            "An asm caller should treat `call thrd_yield` exactly like a call to a compiler-generated function, assuming it clobbers all call-clobbered registers, leaving others unmodified.",
            "\nThe way Linux manages it is roughly:\n\n* Entering the kernel in the first place saves state of integer registers, on a per-thread kernel stack. This will be restored later when returning to user-space for this task, potentially between any two instructions so it's safe for async interrupts. * The vector regs aren't used by kernel code (unless it calls `kernel_fpu_begin()` first). So the interrupt and system call entry points don't have to run `xsave`; that can be deferred until switching to a new user-space task. At which point you do `xsave` (or `xsaveopt` or whatever) for the old context, then `xrstor` to load the new after switching to the new task's kernel stack. * Calling `switch_to` (see *[How does schedule()+switch\\_to() functions from linux kernel actually work? ](https://stackoverflow.com/questions/6525905/how-does-scheduleswitch-to-functions-from-linux-kernel-actually-work)*) just switches call-preserved integer registers (of the kernel state of the caller), and saves/restores the user-space FP/SIMD state from the vector regs. (Older kernels used to try to defer this, but modern user-space uses `movaps` all the time for memcpy and stuff.) * When that new kernel state eventually returns back to the syscall or interrupt entry point that got that task into the kernel, the user-space state will be restored.\nThe call-preserved registers will already have been restored by the kernel C functions, but Linux saves/restores all the registers anyway so debuggers (the `ptrace` system call) can modify that state all in one place. [Share](/a/75681072 \"Short permalink to this answer\")"
          ]
        },
        {
          "title": "RDMA GPU Direct Slow - CUDA - NVIDIA Developer Forums",
          "url": "https://forums.developer.nvidia.com/t/rdma-gpu-direct-slow/69946",
          "excerpts": [
            "Missing: deterministic sub- millisecond checkpoints DMA quiescence ring cursor NVMe"
          ]
        },
        {
          "title": "userfaultfd(2) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man2/userfaultfd.2.html",
          "excerpts": [
            "It can also be used to implement lazy restore for checkpoint/restore mechanisms, as well as post-copy migration to allow (nearly) uninterrupted execution ..."
          ]
        },
        {
          "title": "io_uring_enter2(2) - Linux manual page - man7.org",
          "url": "https://man7.org/linux/man-pages/man2/io_uring_enter2.2.html",
          "excerpts": [
            "IORING_ENTER_SQ_WAKEUP If the ring has been created with IORING_SETUP_SQPOLL, then this flag asks the kernel to wakeup the SQ kernel thread to submit IO.",
            "The CQE flags field will have IORING_CQE_F_MORE set on completion if the application should expect further CQE entries from the original request. If this flag ..."
          ]
        },
        {
          "title": "QP state machine",
          "url": "https://www.rdmamojo.com/2012/05/05/qp-state-machine/",
          "excerpts": [
            "May 5, 2012 — A QP is being created in the Reset state. Any QP can be transitioned to Reset or Error state by calling ibv_modify_qp() from any state."
          ]
        },
        {
          "title": "[dpdk-dev] [RFC 0/9] get Rx and Tx used descriptors",
          "url": "http://mails.dpdk.org/archives/dev/2016-November/050679.html",
          "excerpts": [
            "Missing: rx_queue_stop tx_queue_stop drain"
          ]
        },
        {
          "title": "Events",
          "url": "https://docs.nvidia.com/networking/display/RDMAAwareProgrammingv17/Events",
          "excerpts": [
            "May 23, 2023 — These errors usually occur because of bugs in the user code. When this happens, the QP is automatically transitioned to the IBV_QPS_ERR state by ..."
          ]
        },
        {
          "title": "Problem with NVMe driver : r/osdev",
          "url": "https://www.reddit.com/r/osdev/comments/1f2qc4q/problem_with_nvme_driver/",
          "excerpts": [
            "The reset deletes all I/O Submission Queues and I/O Completion Queues, resets the Admin Submission Queue and Completion Queue, and brings the ..."
          ]
        },
        {
          "title": "firecracker/docs/snapshotting/snapshot-support.md at main",
          "url": "https://github.com/firecracker-microvm/firecracker/blob/main/docs/snapshotting/snapshot-support.md?plain=1",
          "excerpts": [
            "Firecracker exposes the following APIs for manipulating snapshots: `Pause`,. `Resume` and `CreateSnapshot` can be called only after booting the microVM,. while ..."
          ]
        },
        {
          "title": "A Hot Distributed Snapshot System For Virtual Machine Cluster",
          "url": "https://www.usenix.org/conference/lisa13/technical-sessions/presentation/cui",
          "excerpts": [
            "This paper proposes HotSnap, a VMC snapshot approach designed to enable taking hot distributed snapshot with milliseconds system downtime and TCP backoff ..."
          ]
        },
        {
          "title": "io_uring_setup_buf_ring(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_setup_buf_ring.3.html",
          "excerpts": [
            "The io_uring_setup_buf_ring(3) function registers a shared buffer ring to be used with provided buffers. For the request types that support it, provided buffers ..."
          ]
        },
        {
          "title": "Can the --lazy-page feature be adapted for restoring process over ...",
          "url": "https://github.com/checkpoint-restore/criu/issues/1502",
          "excerpts": [
            "Missing: latency microseconds milliseconds"
          ]
        },
        {
          "title": "Userfaultfd",
          "url": "https://docs.kernel.org/admin-guide/mm/userfaultfd.html",
          "excerpts": [
            "In async mode, there will be no message generated when a write operation happens, meanwhile the write-protection will be resolved automatically by the kernel."
          ]
        },
        {
          "title": "userfaultfd(2) — Arch manual pages",
          "url": "https://man.archlinux.org/man/userfaultfd.2.en",
          "excerpts": [
            "Since Linux 5.7, userfaultfd supports write-protect mode for anonymous memory. The user needs to first check availability of this feature using UFFDIO_API ioctl ..."
          ]
        },
        {
          "title": "Articles - CRIU",
          "url": "https://criu.org/index.php?title=Articles&mobileaction=toggle_view_desktop",
          "excerpts": [
            "This is a collection of external articles regarding the CRIU project, sorted by date. 2025-08-13, Software Availability Protection in ..."
          ]
        },
        {
          "title": "[PDF] A Hot Distributed Snapshot System For Virtual Machine Cluster",
          "url": "https://www.usenix.org/system/files/conference/lisa13/lisa13-cui.pdf",
          "excerpts": [
            "This paper proposes HotSnap, a VMC snapshot approach designed to enable taking hot distributed snapshot with millisec- onds system downtime and ..."
          ]
        },
        {
          "title": "how AWS Lambda SnapStart optimizes function startup ...",
          "url": "https://aws.amazon.com/blogs/compute/under-the-hood-how-aws-lambda-snapstart-optimizes-function-startup-latency/",
          "excerpts": [
            "Lambda runs your function code in an isolated, secure execution environment that uses Firecracker microVM technology. ... snapshot restore latency ..."
          ]
        },
        {
          "title": "Derecho: RDMA-based state machine replication (Cornell dissertation)",
          "url": "https://www.cs.cornell.edu/projects/Quicksilver/public_pdfs/dissertation.pdf",
          "excerpts": [
            "Rather than rely on an explicitly co-\n\nordinated global checkpoint, as in [62] and [42], or attempt to record a dependency graph\n\nbetween locally-recorded checkpoints, as in [15], our system incorporates the dependency\n\ninformation already recorded in SMR updates to derive a globally consistent system snap-\n\nshot from loc",
            "RDMA (remote direct memory access) is a zero-copy communication standard. It has\n\nbeen used for many years on Infiniband, but is now also working robustly on standard\n\ndatacenter Ethernet [73,104",
            "To achieve the lowest possible latency, RDMA requires continuously polling for com-\n\npletion events, but this creates excessive CPU usage if no RDMA transfers are taking\n\npl",
            "The updates that happen asynchronously through one-sided RDMA writes must be dis-\n\ncovered very rapidly to take maximum advantage of high RDMA spee",
            " \nRDMA-enabled NICs additionally can write in-\n\ncoming network data to application memory through a DMA write and send data stored in\n\napplication memory over the network with a DMA read, therefore avoiding any memory",
            "One-sided RDMA writes do the\n\nopposite: the initiator node writes data directly to a remote node’s memory from its own\n\nmemory. Obviously, quite a bit of information is required for these to work, and in partic-\n\nular, the applications running on the two nodes need to be aware of the relevant memory\n\naddresses required for data tra",
            "This happens in the connection phase: When form-\n\ning a connection (binding), the applications exchange maps of one-other’s virtual memory\n\naddresses. Later, they reference these maps when exchanging d"
          ]
        },
        {
          "title": "NVM Express Revision 1.3",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM_Express_Revision_1.3.pdf",
          "excerpts": [
            "May 1, 2017 — Submission Queue 0 Tail Doorbell (Admin). 1000h + (1 *. (4 << CAP ... Completion Queue 0 Head Doorbell (Admin). 1000h + (2 *. (4 << CAP ..."
          ]
        },
        {
          "title": "Base Specification, Revision 2.3",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM-Express-Base-Specification-Revision-2.3-2025.08.01-Ratified.pdf",
          "excerpts": [
            "Jul 31, 2025 — 1.1 Overview. The NVM Express® (NVMe®) interface allows a host to communicate with a non-volatile memory subsystem. (NVM subsystem)."
          ]
        },
        {
          "title": "ibv_poll_cq()",
          "url": "https://www.rdmamojo.com/2013/02/15/ibv_poll_cq/",
          "excerpts": [
            "Feb 15, 2013 — When a Work Requests end, a Work Completion is being added to the tail of the CQ that this Work Queue is associated with. ibv_poll_cq() check if ..."
          ]
        },
        {
          "title": "RDMA Aware Networks Programming User Manual",
          "url": "https://docs.nvidia.com/rdma-aware-networks-programming-user-manual-1-7.pdf",
          "excerpts": [
            "Mar 3, 2011 — action will result in any posted work requests being flushed to the completion queue. rdma_disconnect may be called by both the client and ..."
          ]
        },
        {
          "title": "ibv_req_notify_cq()",
          "url": "https://www.rdmamojo.com/2013/02/22/ibv_req_notify_cq/",
          "excerpts": [
            "Feb 22, 2013 — ibv_req_notify_cq() requests a notification when the next Work Completion of a requested type is added to the CQ. Any Work Completions that ..."
          ]
        },
        {
          "title": "ibv_modify_qp() - RDMAmojo",
          "url": "https://www.rdmamojo.com/2013/01/12/ibv_modify_qp/",
          "excerpts": [
            "ibv_modify_qp() modifies the attributes of a Queue Pair. The changed attributes describe the send and receive attributes of the QP."
          ]
        },
        {
          "title": "ibv_modify_qp - man pages section 3: Library Interfaces and Headers",
          "url": "https://docs.oracle.com/cd/E88353_01/html/E37842/ibv-modify-qp-3.html",
          "excerpts": [
            "Missing: IBV_QPS_ERR IBV_QPS_RESET"
          ]
        },
        {
          "title": "lib/ring/rte_ring_peek_zc.h File Reference - Documentation - DPDK",
          "url": "https://doc.dpdk.org/api/rte__ring__peek__zc_8h.html",
          "excerpts": [
            "Note that currently these APIs are available only for two sync modes: 1) Single Producer/Single Consumer (RTE_RING_SYNC_ST) 2) Serialized Producer/Serialized ..."
          ]
        },
        {
          "title": "[PDF] Operational and Declarative Models of RDMA on TSO Architectures",
          "url": "https://www.soundandcomplete.org/papers/OOPSLA2024/RDMA/rdma-extended.pdf",
          "excerpts": [
            "Our focus here is on the IB Verbs model defined by IBTA [2022], using PCIe as the internal fabric. It was designed for InfiniBand and reused for RoCE, the two ..."
          ]
        },
        {
          "title": "[CRIU] Looking into checkpoint/restore of ROCm applications",
          "url": "http://lists.openvz.org/pipermail/criu/2020-June/045032.html",
          "excerpts": [
            "Jun 18, 2020 — ... [CRIU] Looking into checkpoint/restore of ROCm ... kfd with a cr_plugin_dump_file >> callback in a plugin. I've spent some time reading ..."
          ]
        },
        {
          "title": "Changelog - ROCm Documentation - AMD",
          "url": "https://rocm.docs.amd.com/en/docs-6.0.0/about/CHANGELOG.html",
          "excerpts": [
            "CRIU lacked the support for checkpoint restore applications that used device files such as a GPU. With this ROCm release, CRIU is enhanced with a new plugin ..."
          ]
        },
        {
          "title": "Checkpointing Tensorflow-rocm with CRIU · Issue #1763 - GitHub",
          "url": "https://github.com/RadeonOpenCompute/ROCm/issues/1763",
          "excerpts": [
            "So I'm trying to checkpoint and restore a tensorflow-rocm (2.9.1) application running on my GPU (Raedeon RX 6950 XT), however, have been so far ..."
          ]
        },
        {
          "title": "Using CUDA's checkpoint/restore API to reduce cold boot time by 12x",
          "url": "https://www.reddit.com/r/CUDA/comments/1mebckd/using_cudas_checkpointrestore_api_to_reduce_cold/",
          "excerpts": [
            "The API allows us to checkpoint and restore CUDA state, including: Device memory contents (GPU vRAM), such as model weights. CUDA kernels. CUDA ..."
          ]
        },
        {
          "title": "Checkpointing Preemptible Training Workloads",
          "url": "https://run-ai-docs.nvidia.com/self-hosted/workloads-in-nvidia-run-ai/using-training/checkpointing-preemptible-workloads",
          "excerpts": [
            "Aug 10, 2025 — NVIDIA Run:ai allows you to define whether a workload is preemptible, meaning the NVIDIA Run:ai Scheduler may pause a running workload and ..."
          ]
        },
        {
          "title": "PhoenixOS: Concurrent OS-level GPU Checkpoint and Restore with ...",
          "url": "https://arxiv.org/html/2405.12079v2",
          "excerpts": [
            "PhoenixOS (PhOS) is the first OS service that can concurrently checkpoint and restore (C/R) GPU processes—a fundamental capability for critical ..."
          ]
        },
        {
          "title": "ROCm-SMI Fails to Restore Full Power After Setting Low Profile #4257",
          "url": "https://github.com/ROCm/ROCm/issues/4257",
          "excerpts": [
            "Problem begins when I revert the performance level using: rocm-smi --setperflevel auto The power does not reach the peak as it used to..it reaches 143W max."
          ]
        },
        {
          "title": "CUDA Checkpoint/Restore Documentation",
          "url": "https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CHECKPOINT.html",
          "excerpts": [
            "CUDA API versioning support\n\nThis sections describes the checkpoint and restore functions of the low-level CUDA driver application programming interface. The CUDA checkpoint and restore API's provide a way to save and restore GPU state for full process checkpoints when used with\n CPU side process checkpointing solutions.",
            "cuCheckpointProcessCheckpoint ( int pid , [CUcheckpointCheckpointArgs](structCUcheckpointCheckpointArgs.html) \\* args )\n    Checkpoint a CUDA process's GPU memory contents."
          ]
        },
        {
          "title": "Checkpointing CUDA Applications with CRIU (NVIDIA Technical Blog)",
          "url": "https://developer.nvidia.com/blog/checkpointing-cuda-applications-with-criu/",
          "excerpts": [
            "This utility can be used to transparently checkpoint and restore CUDA state within a running Linux process.",
            "`cuda-checkpoint` checkpoints and restores the CUDA state of a single Linux process.",
            "%2F)\n\nCheckpoint and restore functionality for CUDA is exposed through a command-line utility called [cuda-checkpoint]",
            "CRIU exposes its functionality through a command line program called `criu` and operates by checkpointing and restoring every kernel mode resource associated with a process.",
            "The `cuda-checkpoint` binary can toggle the CUDA state of a process, specified by PID, between suspended and running.",
            "A running-to-suspended transition is called a *suspend* and the opposite transition is called a *resu"
          ]
        },
        {
          "title": "Morello for A-profile Architecture",
          "url": "https://developer.arm.com/documentation/ddi0606/latest/",
          "excerpts": [
            "Arm Architecture Reference Manual Supplement - Morello for A-profile Architecture. This document is only available in a PDF version. Click Download to view."
          ]
        },
        {
          "title": "Sentries for control-flow integrity",
          "url": "https://cheriot.org/isa/ibex/2024/06/26/sentries-cfi.html",
          "excerpts": [
            "Jun 26, 2024 — For a long time, CHERI platforms have had a notion of a sealed entry (sentry) capability. These use the sealing mechanism (that makes a ..."
          ]
        },
        {
          "title": "RISC-V Specification for CHERI Extensions - GitHub Pages",
          "url": "https://riscv.github.io/riscv-cheri/",
          "excerpts": [
            "If the capability tag is set, the capability is valid and can be dereferenced (contingent on checks such as permissions or bounds). All registers or memory ..."
          ]
        },
        {
          "title": "Morello Platform Model Reference Guide Version 2.0",
          "url": "https://developer.arm.com/documentation/102225/latest/Reference-information",
          "excerpts": [
            "This chapter provides reference information for the Morello Platform Model including differences between the model implementation and the Morello specification, ..."
          ]
        },
        {
          "title": "What are the purposes of sealed capabilities?",
          "url": "https://capabilitiesforcoders.com/faq/purposes_of_sealed_capabilities.html",
          "excerpts": [
            "CHERI can prevent ROP attacks by sealing automatically sealing function pointers (i.e., creating a sentry) and the return address (link register). Memory Safety."
          ]
        },
        {
          "title": "seL4 Debugging Guide",
          "url": "https://www.cse.unsw.edu.au/~cs9242/18/project/debugging.shtml",
          "excerpts": [
            "Jul 19, 2018 — The kernel exports fault handling policies to user level by sending an IPC to the appropriate IPC endpoint (see Chapter 5 of the seL4 manual)."
          ]
        },
        {
          "title": "LLP08-seL4-6up.pdf",
          "url": "https://web.cecs.pdx.edu/~mpj/llp/slides/LLP08-seL4-6up.pdf",
          "excerpts": [
            "• Kernel tracks use via the “capability derivation tree” (CDT). • Cannot retype an untyped memory area if it is already in use. (i.e., if it has children in ...",
            "• seL4 tackles this problem by introducing a special \"Reply\" capability type: • The Call system call combines a Send and a Wait. • The kernel gives a new ..."
          ]
        },
        {
          "title": "model-driven development of arinc 653 configuration tables",
          "url": "https://www.gmv.com/sites/default/files/content/file/2020/06/03/1/dasc_paper.pdf",
          "excerpts": [
            "by Á Horváth · Cited by 44 — The group consists of steps to define the Health. Monitoring tables for module, partition and application level along with the different error."
          ]
        },
        {
          "title": "Towards a Real-time Component Framework for Software ... - C3",
          "url": "https://c3.ndc.nasa.gov/dashlink/static/media/other/ISIS-TR-09-111.pdf",
          "excerpts": [
            "by A Dubey · Cited by 12 — ARINC-653 supports a health monitoring service at each layer (Partition/Module/System) which is configured by the user with the appropriate response (functions) ..."
          ]
        },
        {
          "title": "Model-driven development of ARINC 653 configuration ...",
          "url": "https://www.researchgate.net/publication/224202064_Model-driven_development_of_ARINC_653_configuration_tables",
          "excerpts": [
            "In the scope of the project, a tool chain was implemented that generates ARINC 653 configuration tables from high-level architecture models. The tool chain was ..."
          ]
        },
        {
          "title": "CHERI Software Compartmentalization",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-compartmentalization.html",
          "excerpts": [
            "The CHERI protection model provides a set of low-level primitives that enable scalable, fine-grained software compartmentalization.",
            "[CHERI-seL4](cheri-sel4.html)"
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI's capability system is blended with a conventional RISC\nusermode architecture without disrupting the majority of key design\ndecisions.",
            "CHERI is a hybrid capability system in several senses:",
            "CHERI capabilities are a low-level primitive usable for many purposes.",
            "The advent of the open RISC-V ISA provides us with a richer spectrum of\nbaseline processor designs, and as the architecture matures over time, we\nhope also a similarly rich software ecosystem."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "\nCHERI represents a new system design that blocks exploits. Architectural changes to the CPU and memory systems add integrity checks to pointers that prevent reading, writing, or executing from memory that is out of bounds or using corrupted pointers, the most common classes of severe vulnerabilities. CHERI is supported by a complete compiler toolchain, multiple operating systems, is open source, and already implemented for several different RISC CPUs including Arm’s recently released Morello prototype.",
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "Capabilities are created at boot time, and capabilities derived from these initial ones are more restrictive. The new instructions for manipulating capabilities also mean changing the instruction set architecture, or ISA.",
            " of CHERI architectures for MIPS, RISC-V, and Arm began with the Sail instruction set definition language. Sail generates sequential emulators, in C and OCaml, and theorem-prover definitions, in Coq, HOL4, and Isabelle, and SMT. These versions allow for both a means of testing in emulation and creating formal proofs of the correctness of the design.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Fault Management (MDPI)",
          "url": "https://www.mdpi.com/2076-3417/12/4/2014",
          "excerpts": [
            "ARINC 653 provides a health monitor configuration table and error handler process for managing errors. In the health monitor configuration table, the level of error is defined as a process, partition and module and the recovery method for each error is specified to enable action appropriate to the situation.",
            "In the health monitor configuration table, the level of error is defined as a process, partition and module and the recovery method for each error is specified to enable action appropriate to the situation.",
            "— ARINC 653 provides health monitoring to detect and recover hardware and software errors at the process, partition and module levels. It isolates errors and ...",
            " ARINC 653 is an integrated modular avionic (IMA)-based real-time operating system (RTOS). It is an avionic system that integrates and operates an environment where multiple computer systems are operated in a distributed manner.",
            "The FACE consists of five local segments, such as operating system segment (OSS), input/out services segment (IOSS), platform-specific services segment (PSSS), transport services segment (TSS), portable components segment (PCS). The FACE provides OS-level health monitoring and fault management (HMFM) and system-level HMFM for HMSs."
          ]
        },
        {
          "title": "[PDF] CHERIoT Architecture specification Version 0.6 (draft)",
          "url": "https://cheriot.org/cheriot-sail/cheriot-architecture.pdf",
          "excerpts": [
            "To mitigate the availability concerns this could create, the. CHERIoT RTOS provides a mechanism for recovering from faults in a controlled way. Compartments can ...",
            "by S Amar · 2024 — The first is a sealed capability to a structure describing the entry point in the callee. The second is a sentry capability to the compartment switcher. The ..."
          ]
        },
        {
          "title": "CHERIoT Architecture specification Version 0.6 (draft)",
          "url": "https://lists.riscv.org/g/tech-tg-cheri/attachment/14/0/cheriot-architecture.pdf",
          "excerpts": [
            "by S Amar · 2024 — The sealed capability is passed in a register when the sentry capability is called. A CHERI sentry is a capability that can be jumped to but ..."
          ]
        },
        {
          "title": "Secure Scripting with CHERIoT MicroPython - ACM Digital Library",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3708493.3712694",
          "excerpts": [
            "However, this register is zeroed by CHERIoT-RTOS on return from any cross-compartment call. Correct usage of this register would require its contents to be ..."
          ]
        },
        {
          "title": "Efficient and Provable Local Capability Revocation using ...",
          "url": "https://iris-project.org/pdfs/2021-popl-ucaps-final.pdf",
          "excerpts": [
            "by AL GEORGES · 2021 · Cited by 44 — On many capability machines, including CHERI, memory capabilities are designed to directly replace pointers, thus adding native bounds and permission checks ..."
          ]
        },
        {
          "title": "Building Safety by Design: CHERI in Critical…",
          "url": "https://blog.adacore.com/building-safety-by-design-cheri-in-critical-systems-development",
          "excerpts": [
            "Dec 17, 2024 — Our paper discusses examples of how cyber-attack detection, resilience, recovery, and new failure mode strategies like \"fail secure but degraded ..."
          ]
        },
        {
          "title": "ARINC Specification 653-2",
          "url": "https://mail.kia.prz.edu.pl/~ssamolej/vxworks/ARINC_653P1-2.pdf",
          "excerpts": [
            "The Health Monitor (HM) is the function of the O/S responsible for monitoring and reporting\n\nhardware, application and O/S software faults and failures. The HM helps to isolate faults and to\n\nprevent failures from propagatin",
            "Fault responses to process level errors are determined by the application programmer using a\n\nspecial (highest priority) process of the partition, the error handler process. The error handler\n\nprocess is active in NORMAL mode only. The programmer can identify the error and the faulty\n\nprocess via a HM service and then takes the recovery action at the process level (e.g., stop, start\n\nprocess) or at the partition level (e.g., set partition mode: IDLE, COLD\\_START, WARM\\_S",
            "Fault responses to partition level errors are handled in the following way:",
            "The O/S Kernel looks up the reference to the HM Callback in the HM\n\nConfiguration tables and calls the procedure if one has been identified for the\n\npartitio",
            "On completion of the HM Callback the O/S Kernel looks up the error code\n\nresponse action in the HM configuration tables",
            "The O/S Kernel performs the response identified in the configuration table.",
            "The recovery actions for process level errors are defined by the application programmer\n\nin a special error handler process"
          ]
        },
        {
          "title": "sima Command Line Tools Application Development and ...",
          "url": "https://www.gmv.com/sites/default/files/content/file/2020/06/03/1/user_manual.pdf",
          "excerpts": [
            "Jun 3, 2020 — The partition scheduling is defined in the arinc 653 configuration file in three hier- ... Figure 16 shows the structure of the arinc 653 system ..."
          ]
        },
        {
          "title": "Configuration Tool for ARINC 653 Operating Systems",
          "url": "https://gvpress.com/journals/IJMUE/vol9_no4/8.pdf",
          "excerpts": [
            "by ET Choi · 2014 · Cited by 5 — From the figure, An ARINC 653 Module consist of seven major elements, one or more Partitions, a System HM table, a Module. HM table, a Connection table, one or ..."
          ]
        },
        {
          "title": "CHERI Instruction-Set Architecture (Version 8)",
          "url": "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-951.pdf",
          "excerpts": [
            "by RNM Watson · 2020 · Cited by 158 — This hybrid approach, inspired by the Capsicum security model, addresses the performance and robustness issues that arise when trying to express more secure.",
            "by RNM Watson · 2020 · Cited by 158 — CHERI's hybrid approach allows incremental adoption of capability-oriented design: crit- ical components can be ported and recompiled to use capabilities ..."
          ]
        },
        {
          "title": "CHERI Instruction-Set Architecture (Version 9)",
          "url": "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-987.pdf",
          "excerpts": [
            "by RNM Watson · 2023 · Cited by 158 — ... Failure modes and exception delivery (Section 2.3.15). • Capability revocation (Section 2.3.16). These features allow capabilities to be architectural ..."
          ]
        },
        {
          "title": "(PDF) Configuration tool for ARINC 653 operating systems",
          "url": "https://www.researchgate.net/publication/262418287_Configuration_tool_for_ARINC_653_operating_systems",
          "excerpts": [
            "Aug 10, 2025 — This paper presents a configuration tool for ARINC 653 OS that consist of Wizard module which generates the basic configuration data for IMA based on XML ..."
          ]
        },
        {
          "title": "Behind the last line of defense: Surviving SoC faults and ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0167404822003121",
          "excerpts": [
            "by IP Gouveia · 2022 · Cited by 16 — In particular, faulty replicas may fail a subordinate vote, but agree to reset the voter, which erases the error information about the failed vote from the ..."
          ]
        },
        {
          "title": "nevill-master-capabilities.pdf - The Barrelfish OS",
          "url": "https://barrelfish.org/publications/nevill-master-capabilities.pdf",
          "excerpts": [
            "by M Nevill — Given a generic memory capability (referred to as “untyped memory”, or UM), seL4 allows this to be retyped to a mappable “virtual mem- ory” (VM) ..."
          ]
        },
        {
          "title": "CHERI Hardware and CHERIoT Overview",
          "url": "https://cheriot.org/cheri/2024/08/06/how-to-talk-about-CHERI.html",
          "excerpts": [
            "In CHERIoT, we use sealed objects for almost anything where one compartment wants to provide a handle that lets other compartments ask it to do something. This includes allocating memory, reading or writing message queues, connecting to network servers, and so on.",
            "The software model defines what valid paths exist between the initial boot state and normal execution with you holding a pointer to a heap object, the hardware guarantees that some such path must have existed for you to hold that pointer.",
            "CHERI capabilities were designed to allow everything that correct C does with pointers, which is a superset of what most safer languages permit.",
            "CHERIoT provides a trusted stack for cross-compartment calls and a switcher that enforces a lot of properties on both the call and return path."
          ]
        },
        {
          "title": "Improving Security with Hardware Support: CHERI and Arm's Morello",
          "url": "https://www.govinfo.gov/content/pkg/GPO-TNW-24-1-2023/pdf/GPO-TNW-24-1-2023-3.pdf",
          "excerpts": [
            "Three kinds of specialized sentry (sealed \nentry) capabilities may be used transparently by \ndirect branch instructions, memory-indirect branch \ninstructions, and memory-indirect branch-to-pair \ninstruction",
            "sealing capabilities, they can be labeled with an object \ntype, if the authorizing capability has that object \ntype in its bounds. The “branch to sealed capabili-\nty pair” instruction invokes a given code capability \nand also an argument data capability, checking their \nobject types match, providing object-style encap-\nsulati",
            "Three kinds of specialized sentry (sealed \nentry) capabilities may be used transparently by \ndirect branch instructions, memory-indirect branch \ninstructions, and memory-indirect branch-to-pair \ninstructions, respectiv",
            "and exception handling is also extended. Exception handling preserves extended capability \nregister state, and there are new exception cause \ncodes associated with CHERI failures such as bounds \nviolations or untagged memory accesses.",
            "CHERI capabilities are an architectural primitive \nthat can be used for a variety of software purposes \nup and down the software stack, with potential uses \nin firmware and boot loaders, OSs, language run-\ntimes, CHERI-specific compartmentalization librar-\nies, and compiler-generated code for the C and C++ \napplication p"
          ]
        },
        {
          "title": "seL4 discussion on page faults and revocation in seL4 ecosystem",
          "url": "https://sel4.com/hyperkitty/list/devel@sel4.systems/thread/QAYR2OHU7GPWTAFKJH4O3RF7TWQIKBQK/",
          "excerpts": [
            "The page-fault handler finds that the fault is due to a page shared with the client and takes appropriate action.",
            "Effectively, in seL4, if my understanding above is correct, one\nstructures the system in such a manner that revocation is eliminated,\ni.e., the client cannot revoke its pages.",
            "the client\ntrusts the driver to release the pages back via the TCB when connection\nis teared down.",
            "In other words, what is the killer use-case for fine-grained revocation\nin your opinion? I.e., what kind of system is impossible without it? Or\neven: did you see scenarios on top of seL4 when people rely on\nfine-grained revocation (i.e., revoke pages, memory regions, access to\ndevices) instead of a rather coarse-grained termination of the entire\nprocesses?"
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            " Recovery actions at the partition level are triggered when the error is a partition level error and the error handler has not been created in that partition",
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        },
        {
          "title": "[PDF] Arm® Architecture Reference Manual Supplement Morello for A ...",
          "url": "http://kib.kiev.ua/x86docs/ARM/Morello/DDI0606_A.j_morello_architecture_external.pdf",
          "excerpts": [
            "Morello is a prototype architecture, which has a particular meaning to Arm of which the recipient must be aware as follows: Subject to change without consent ..."
          ]
        },
        {
          "title": "Capability Hardware Enhanced RISC Instructions",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/20240116-cheri-web-compressed.pdf",
          "excerpts": [
            "Jan 16, 2024 — Sealed capabilities, CCall/CReturn. 2015. ISAv4. MMU-CHERI integration (TLB permissions). ISA support for compressed 128-bit capabilities. HW ..."
          ]
        },
        {
          "title": "SECURITY ANALYSIS OF CHERI ISA - GitHub",
          "url": "https://raw.githubusercontent.com/microsoft/MSRC-Security-Research/master/papers/2020/Security%20analysis%20of%20CHERI%20ISA.pdf",
          "excerpts": [
            "Exceptions where the architectural provenance chain is broken to support abstract capabilities in a real system include implementations for program startup, ..."
          ]
        },
        {
          "title": "2. The RTOS Core",
          "url": "https://cheriot.org/book/core_rtos.html",
          "excerpts": [
            "A trusted stack is a region of memory containing the register save area for context switches and a small frame for every cross-compartment call that allows a ..."
          ]
        },
        {
          "title": "The RTOS components for the CHERIoT research platform",
          "url": "https://github.com/CHERIoT-Platform/cheriot-rtos",
          "excerpts": [
            "trusted_stack_frames specifies the number of trusted stack frames (the maximum depth of cross-compartment calls possible on this thread). Note that any call ..."
          ]
        },
        {
          "title": "5. Compartments and libraries",
          "url": "https://cheriot.org/book/compartments.html",
          "excerpts": [
            "In the core of the RTOS, the scheduler is written as a safebox. It does not trust anything on the outside and assumes that everything else is trying to make it ..."
          ]
        },
        {
          "title": "seL4 Libraries: IPC",
          "url": "https://docs.sel4.systems/Tutorials/libraries-2.html",
          "excerpts": [
            "seL4 Libraries: IPC. The tutorial is designed to teach the basics of seL4 IPC using Endpoint objects, and userspace paging management."
          ]
        },
        {
          "title": "Genode on seL4 - IPC and virtual memory",
          "url": "https://genode.org/documentation/articles/sel4_part_2",
          "excerpts": [
            "In the L4 universe, the term IPC (inter-process communication) usually stands for synchronous communication between two threads. In seL4, IPC has two uses."
          ]
        },
        {
          "title": "FAILSAFE Health Management for Embedded Systems",
          "url": "https://www.techbriefs.com/component/content/article/8430-npo-46981",
          "excerpts": [
            "Under ARINC 653, the health monitoring (HM) service is invoked by an application calling the application error service, or by the operating ..."
          ]
        },
        {
          "title": "Modeling and Validation of ARINC653 architectures",
          "url": "https://hal.science/hal-02269428v1/document",
          "excerpts": [
            "by J Delange · 2010 · Cited by 12 — The Health Monitoring service detects faults at different levels (module, partition, process) and executes a recovering procedure for each one."
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "Constant bandwidth servers with constrained deadlines",
          "url": "https://dl.acm.org/doi/10.1145/3139258.3139285",
          "excerpts": [
            "The Hard Constant Bandwidth Server (H-CBS) is a reservation-based scheduling algorithm often used to mix hard and soft real-time tasks on the same system."
          ]
        },
        {
          "title": "Constant bandwidth server revisited | ACM SIGBED Review",
          "url": "https://dl.acm.org/doi/10.1145/2724942.2724945",
          "excerpts": [
            "The Constant Bandwidth Server (CBS) is an algorithm for providing temporal protection and real-time guarantees to real-time sporadic tasks."
          ]
        },
        {
          "title": "io_uring and networking in 2023 · axboe/liburing Wiki",
          "url": "https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023",
          "excerpts": [
            "Feb 15, 2023 — The simplest way to use ring messages is to just transfer 8 bytes of data between them. io_uring treats the data as a cookie and doesn't ..."
          ]
        },
        {
          "title": "NUMA, Multi-Queue NICs and CPU Affinity - Networking Notes",
          "url": "https://null.53bits.co.uk/page/numa-and-queue-affinity",
          "excerpts": [
            "Apr 17, 2016 — RPS has some advantages over RSS: 1) it can be used with any NIC, 2) software filters can easily be added to hash over new protocols, 3) it does ..."
          ]
        },
        {
          "title": "Scaling in the Linux Networking Stack",
          "url": "https://docs.kernel.org/networking/scaling.html",
          "excerpts": [
            "Each receive queue has a separate IRQ associated with it. The NIC triggers this to notify a CPU when new packets arrive on the given queue. The signaling path ..."
          ]
        },
        {
          "title": "RSS, IRQ affinity and RPS on Linux - Andreas Karis Blog",
          "url": "https://andreaskaris.github.io/blog/networking/rss-irq-affinity-and-rps/",
          "excerpts": [
            "Aug 12, 2024 — RSS, short for Receive Side Scaling, is an in-hardware feature that allows a NIC to \"send different packets to different queues to distribute ...",
            "In this blog post, we are going to have a look at the tuning of Linux receive queues and their interrupt requests. We are going to learn a bit ..."
          ]
        },
        {
          "title": "The RPS/RSS seems not take effect in platform Xavier/Orin",
          "url": "https://forums.developer.nvidia.com/t/the-rps-rss-seems-not-take-effect-in-platform-xavier-orin/218593",
          "excerpts": [
            "Jun 23, 2022 — I tried to dispatch udp packet to multi-CPU over RPS/RSS, but it seems not available. The steps are as follow: list all net rx queues:"
          ]
        },
        {
          "title": "Is it a good practice to set interrupt affinity and io handling ...",
          "url": "https://stackoverflow.com/questions/48659720/is-it-a-good-practice-to-set-interrupt-affinity-and-io-handling-thread-affinity",
          "excerpts": [
            "IRQ affinity is a double edged sword. In my experience it can improve performance but only in a very specific configuration with a pre-defined workload."
          ]
        },
        {
          "title": "Efficient Distributed Memory Management with RDMA and ...",
          "url": "https://www.vldb.org/pvldb/vol11/p1604-cai.pdf",
          "excerpts": [
            "by Q Cai · 2018 · Cited by 145 — Due to the limited size of the on-NIC cache, it is important to keep, as small as possible, the data needed by RDMA NIC, which typically include the page table, ..."
          ]
        },
        {
          "title": "Understanding CPU Interrupts in Linux",
          "url": "https://www.alibabacloud.com/blog/597128",
          "excerpts": [
            "The SMP IRQ affinity requires NICs to support multiple queues. A NIC supporting multiple queues has multiple interrupt numbers, which can be ..."
          ]
        },
        {
          "title": "[PDF] The IX Operating System: Combining Low Latency, High Throughput ...",
          "url": "https://anakli.inf.ethz.ch/papers/IX_TOCS.pdf",
          "excerpts": [
            "We present IX, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ...",
            "by G PREKAS · Cited by 96 — The IX dataplane allows for networking stacks that optimize for both bandwidth and latency. It is designed around a native, zero-copy API that supports ...",
            "by G PREKAS · Cited by 96 — Our evaluation with mem- cached, a widely deployed key-value store, shows that IX improves upon Linux by up to 6.4× in terms of throughput at a given 99th ..."
          ]
        },
        {
          "title": "Constant Bandwidth Server Revisited",
          "url": "https://ceur-ws.org/Vol-1291/ewili14_5.pdf",
          "excerpts": [
            "by L Abeni · Cited by 31 — The Constant Bandwidth Server (CBS) [1] is a reservation- based scheduling algorithm originally introduced in 1998 to handle tasks characterised by variable ...",
            "by L Abeni · Cited by 31 — ABSTRACT. The Constant Bandwidth Server (CBS) is an algorithm for providing temporal protection and real-time guarantees to real-time sporadic tasks."
          ]
        },
        {
          "title": "DPDK buffers received from the RX ring and freeded on ...",
          "url": "https://stackoverflow.com/questions/59581822/dpdk-buffers-received-from-the-rx-ring-and-freeded-on-the-tx-path",
          "excerpts": [
            "The buffers successfully put in the Tx queue will be freed by the PMD. That's the only option, so yes it's a good practice."
          ]
        },
        {
          "title": "SPDK: Changelog",
          "url": "https://spdk.io/doc/changelog.html",
          "excerpts": [
            "spdk_thread_create() now takes an optional CPU affinity mask that is passed to the scheduler. ... Users should use the -m or –cpumask command line option to ...",
            "This mode is currently supported at PCIe layer, which tracks the qpair creation with state machine and returns to the user immediately. Default mode is set to ...",
            "Added support for ZNS zone append command with new API spdk_nvme_zns_zone_append and spdk_nvme_zns_zone_append_with_md . nvmf. nvmf_fc_lld_fini now takes ..."
          ]
        },
        {
          "title": "Sharing an NVMe SSD with Multiple Processes · Issue #566",
          "url": "https://github.com/spdk/spdk/issues/566",
          "excerpts": [
            "Jan 9, 2019 — I also create a pthread and set its core affinity as 1 (called thread 1). ... The submission qpair is created on main process through master core."
          ]
        },
        {
          "title": "[PDF] Zero Copy Rx with io_uring - LPC 2023",
          "url": "https://lpc.events/event/17/contributions/1596/attachments/1346/2694/Zero%20Copy%20Rx%20with%20io_uring%20-%20LPC%202023.pdf",
          "excerpts": [
            "Hybrid solution. ○ Standard control plane using kernel networking stack. ○ Fast ZC Rx data plane using io_uring. ○ Two parts:."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet 800 Series — Linux Performance Tuning Guide",
          "url": "https://cdrdv2-public.intel.com/636781/636781_Intel%C2%AE%20Ethernet%20800%20Series_Tuning%20Guide_rev1.3.pdf",
          "excerpts": [
            "IRQ Affinity. Configuring IRQ affinity to ensure interrupts for the hardware Tx/Rx queues are affinitized to proper CPU cores can have a huge ..."
          ]
        },
        {
          "title": "DPDK SORING (Staged Ordered Ring) API Documentation",
          "url": "https://doc.dpdk.org/api/rte__soring_8h.html",
          "excerpts": [
            "This file contains definition of DPDK soring (Staged Ordered Ring) public API. Brief description: enqueue/dequeue works the same as for conventional [rte\\_ring](structrte__ring.html) : any [rte\\_ring](structrte__ring.html) sync types can be used, etc. Plus there could be multiple 'stages'. For each stage there is an acquire (start) and release (finish) operation. after some elems are 'acquired' - user can safely assume having exclusive possession of these elems till 'release' for them is done. Note that right now user has to release exactly the same number of elems acquired before. After 'release', elems can be 'acquired'",
            "he number of bytes needed for a soring, given the expected parameters for it. This value is the sum of the size of the internal metadata and the size of the memory needed by the actual soring elements and their metadata. The value is aligned to a cache line si"
          ]
        },
        {
          "title": "DPDK rte_ring - Struct Reference",
          "url": "https://doc.dpdk.org/api/structrte__ring.html",
          "excerpts": [
            "An RTE ring structure. The producer and the consumer have a head and a tail index.",
            "The particularity of these index is that they are not between 0 and size(ring)-1. These indexes are between 0 and 2^32 -1, and we mask their value when we access the ring[] field. Thanks to this assumption, we can do subtractions between 2 index values in a modulo-32bit base: that's why the overflow of the indexes is not a problem.",
            "Name of the ring.",
            "Size of ring.",
            "Mask (size-1) of ring.",
            "Usable size of ring"
          ]
        },
        {
          "title": "USENIX OSDSI 2014 Arrakis/IX paper",
          "url": "https://www.usenix.org/sites/default/files/osdi14_full_proceedings.pdf",
          "excerpts": [
            "The Arrakis operating system is based upon a fork of the\n\nBarrelfish [10] multicore OS code base",
            "The interface between an application and the Arrakis\n\ncontrol plane is used to request resources from the system\n\nand direct I/O flows to and from user program",
            "Doorbells are exposed to\n\nArrakis programs via regular event delivery mechanisms\n\n(e.g., a file descriptor event) and are fully integrated\n\nwith existing I/O multiplexing interfaces (e.g., selec",
            "We extended Barrelfish with support for SR-IOV, which\n\nrequired modifying the existing PCI device manager to rec-\n\nognize and handle SR-IOV extended PCI capabilit",
            "Who Put the Kernel in My OS Conference? Arrakis: The Operating System is the Control Plane . . . . . . . . . . . . . . . . ."
          ]
        },
        {
          "title": "[dpdk-dev] [RFC PATCH 00/11] generalise rte_ring to allow different ...",
          "url": "https://dev.dpdk.narkive.com/9Yt1Dnxo/dpdk-rfc-patch-00-11-generalise-rte-ring-to-allow-different-datatypes",
          "excerpts": [
            "The rte_ring library in DPDK provides an excellent high-performance mechanism which can be used for passing pointers between cores and"
          ]
        },
        {
          "title": "Constant Bandwidth Servers with Constrained Deadlines",
          "url": "https://retis.sssup.it/~a.biondi/papers/CBS_CD_RTNS17.pdf",
          "excerpts": [
            "by D Casini · 2017 · Cited by 14 — ABSTRACT. The Hard Constant Bandwidth Server (H-CBS) is a reservation-based scheduling algorithm often used to mix hard and soft real-time tasks."
          ]
        },
        {
          "title": "Tips and tricks to optimize your RDMA code",
          "url": "https://www.rdmamojo.com/2013/06/08/tips-and-tricks-to-optimize-your-rdma-code/",
          "excerpts": [
            "Jun 8, 2013 — Configure the Queue Pair to allow several RDMA Reads and Atomic in parallel. If one uses RDMA Read or Atomic operations, it is advised to ..."
          ]
        },
        {
          "title": "io_uring_setup — Lord of the io_uring documentation",
          "url": "https://unixism.net/loti/ref-iouring/io_uring_setup.html",
          "excerpts": [
            "The io_uring_setup() system call sets up a submission queue (SQ) and completion queue (CQ) with at least entries entries, and returns a file descriptor."
          ]
        },
        {
          "title": "In DPDK, how should the memory pool and ring be ...",
          "url": "https://stackoverflow.com/questions/79334801/in-dpdk-how-should-the-memory-pool-and-ring-be-configured-to-minimize-cache-mis",
          "excerpts": [
            "When using rte_mempool_create, set the cache_size and element_size to multiples of the cache line. 1.2: Local Cache: Enable the local cache of ..."
          ]
        },
        {
          "title": "[dpdk-dev] [PATCH v2 2/5] ring: add a non-blocking implementation",
          "url": "https://mails.dpdk.org/archives/dev/2019-January/123477.html",
          "excerpts": [
            "[dpdk-dev] [PATCH v2 2/5] ring: add a non-blocking implementation. Gage Eads gage.eads at intel.com. Wed Jan 16 00:52:24 CET 2019."
          ]
        },
        {
          "title": "[dpdk-dev] [PATCH] doc: announce ring ABI and API changes",
          "url": "https://inbox.dpdk.org/dev/20190513114632.hT__qIK2lJyTbr2YXfpKiEth8O5Q0b3wF2nJcf9X0tA@z/T/",
          "excerpts": [
            "... ring structure. * @@ -97,11 +106,19 @@ struct rte_ring { char pad0 __rte_cache_aligned; /**< empty cache line */ /** Ring producer status. */ - struct ..."
          ]
        },
        {
          "title": "Active Queue Pair Operations",
          "url": "https://docs.nvidia.com/networking/display/rdmaawareprogrammingv17/active+queue+pair+operations",
          "excerpts": [
            "May 23, 2023 — A QP can be queried staring at the point it was created and once a queue pair is completely operational, you may query it, be notified of events and conduct ..."
          ]
        },
        {
          "title": "spdk_nvmf_qpair Struct Reference - SPDK",
          "url": "https://spdk.io/doc/structspdk__nvmf__qpair.html",
          "excerpts": [
            "spdk_nvmf_qpair Struct Reference ; uint8_t, rsvd ; uint16_t, qid ; uint16_t, sq_head."
          ]
        },
        {
          "title": "RTE Ring Core Header Reference",
          "url": "https://doc.dpdk.org/api/rte__ring__core_8h.html",
          "excerpts": [
            "The maximum length of a ring name. Examples"
          ]
        },
        {
          "title": "Compute Functions — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/compute.html",
          "excerpts": [
            "Functions represent compute operations over inputs of possibly varying types. Internally, a function is implemented by one or several “kernels”, depending on ..."
          ]
        },
        {
          "title": "Compute Functions — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/api/compute.html",
          "excerpts": [
            "Apache Arrow compute functions are implementations of the `Function` class, with kernels for specific types, and are registered in a central registry."
          ]
        },
        {
          "title": "arrow/cpp/src/arrow/compute/kernel.h at main · apache/arrow - GitHub",
          "url": "https://github.com/apache/arrow/blob/master/cpp/src/arrow/compute/kernel.h",
          "excerpts": [
            "Apache Arrow is the universal columnar format and multi-language toolbox for fast data interchange and in-memory analytics ..."
          ]
        },
        {
          "title": "facebookincubator/velox: A composable and fully extensible C++ ...",
          "url": "https://github.com/facebookincubator/velox",
          "excerpts": [
            "Velox is a composable execution engine distributed as an open source C++\nlibrary. It provides reusable, extensible, and high-performance data processing\ncomponents that can be (re-)used to build data management systems focused on\ndifferent analytical workloads, including batch, interactive, stream\nprocessing, and AI/ML.",
            "Velox provides the following high-level components:",
            "* **Type** : a generic typing system that supports scalar, complex, and nested\n  types, such as structs, maps, arrays, et",
            "* **Vector** : an [Arrow-compatible columnar memory layout\n  module](https://facebookincubator.github.io/velox/develop/vectors.html) ,\n  providing encodings such as Flat, Dictionary, Constant, and Sequence/RLE, in\n  addition to a lazy materialization pattern and support for out-of-order\n ",
            "* **Expression Eval** : a [fully vectorized expression evaluation\n  engine](https://facebookincubator.github.io/velox/develop/expression-evaluation.html) that allows expressions to be efficiently executed on top of Vector/Arrow\n  encoded d",
            "* **Functions** : sets of vectorized scalar, aggregates, and window functions\n  implementations following the Presto and Spark semanti",
            "* **Operators** : implementation of relational operators such as scans, writes,\n  projections, filtering, grouping, ordering, shuffle/exchange, [hash, merge,\n  and nested loop joins](https://facebookincubator.github.io/velox/develop/joins.html) ,\n  unnest, and",
            "* **I/O** : a connector interface for extensible data sources and sinks,\n  supporting different file formats (ORC/DWRF, Parquet, Nimble), and storage\n  adapters (S3, HDFS, GCS, ABFS, local files) to be u",
            "* **Network Serializers** : an interface where different wire protocols can be\n  implemented, used for network communication, supporting [PrestoPage](https://prestodb.io/docs/current/develop/serialized-page.html) and Spark's UnsafeRo",
            "* **Resource Management** : a collection of primitives for handling\n  computational resources, such as [memory\n  arenas](https://facebookincubator.github.io/velox/develop/arena.html) and\n  buffer management, tasks, drivers, and thread pools for CPU and thread\n  execution, spilling, and "
          ]
        },
        {
          "title": "Velox | Open-Source Composable Execution Engine",
          "url": "https://velox-lib.io/",
          "excerpts": [
            "Velox is a high-performance, open-source execution engine designed for flexibility and reuse. Distributed as a C++ library, it offers modular, composable ..."
          ]
        },
        {
          "title": "io_uring_prep_timeout(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_prep_timeout.3.html",
          "excerpts": [
            "The io_uring_prep_timeout(3) function prepares a timeout request. The submission queue entry sqe is setup to arm a timeout specified by ts and with a timeout ..."
          ]
        },
        {
          "title": "Configuration Settings — Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/user-guide/configs.html",
          "excerpts": [
            "datafusion.execution.batch_size. 8192. Default batch size while creating new batches, it's especially useful for buffer-in-memory batches since creating tiny ...",
            "Setting this to true ensures that newlines in values are parsed successfully, which may reduce performance. datafusion.execution.batch_size. 8192. Default batch ..."
          ]
        },
        {
          "title": "chore: Investigate impact of small batches on performance · ...",
          "url": "https://github.com/apache/datafusion-comet/issues/495",
          "excerpts": [
            "When running TPC-H q16 with DataFusion, there is a significant difference in performance between runs with coalesce batches enabled vs disabled."
          ]
        },
        {
          "title": "jorgecarleitao/arrow2: Transmute-free Rust library to work ...",
          "url": "https://github.com/jorgecarleitao/arrow2",
          "excerpts": [
            "Feb 18, 2024 — A Rust crate to work with Apache Arrow. The most feature-complete implementation of the Arrow format after the C++ implementation.See more"
          ]
        },
        {
          "title": "Can reference a part of a slice via Rc to achieve zero copy?",
          "url": "https://users.rust-lang.org/t/can-reference-a-part-of-a-slice-via-rc-to-achieve-zero-copy/73719",
          "excerpts": [
            "Apr 1, 2022 — I'm trying to achieve zero-copy parsing of a file by saving the borrow of &'a [u8] , but soon &'a messes up the lifecycle.See more"
          ]
        },
        {
          "title": "Monitor the columnar engine | AlloyDB Omni 16.8.0 - Google Cloud",
          "url": "https://cloud.google.com/alloydb/omni/16.8.0/docs/columnar-engine/monitor",
          "excerpts": [
            "This page describes how to monitor utilization of the columnar engine. Verify usage of the columnar engine using EXPLAIN."
          ]
        },
        {
          "title": "Data Cloud - Zero Copy Connectivity | Salesforce US",
          "url": "https://www.salesforce.com/data/connectivity/zero-copy/",
          "excerpts": [
            "Zero copy is a data federation technology that enables enterprises to access and query data without copying it."
          ]
        },
        {
          "title": "OceanBase Database V4.3 Feature Breakdown: In-depth Analysis of ...",
          "url": "https://medium.com/@wpleonardo0537/oceanbase-database-v4-3-feature-breakdown-in-depth-analysis-of-columnar-storage-af31254daf6c",
          "excerpts": [
            "In row-based storage mode, OceanBase Database realizes seamless integration with the vectorized storage engine to support vectorized execution ..."
          ]
        },
        {
          "title": "Zero-copy convert slice of integers to slice of bytes",
          "url": "https://stackoverflow.com/questions/74503746/zero-copy-convert-slice-of-integers-to-slice-of-bytes",
          "excerpts": [
            "Reinterpret a slice of T as a slice of bytes without copying. Only use with simple copy types like integers, floats, bools, etc. Don't use with structs or ...See more"
          ]
        },
        {
          "title": "Zero-Copy Cloning & Time Travel: Boosting Development ... - Medium",
          "url": "https://medium.com/@pascalpfffle/zero-copy-cloning-time-travel-boosting-development-and-testing-efficiency-in-snowflake-d44078daee5c",
          "excerpts": [
            "Missing: ingestion buffers"
          ]
        },
        {
          "title": "Research for Practice: OS Scheduling - Communications of the ACM",
          "url": "https://cacm.acm.org/practice/research-for-practice-os-scheduling/",
          "excerpts": [
            "The key to achieving microsecond-scale core reallocation in the Shenango operating system is the use of a dedicated scheduling core that ..."
          ]
        },
        {
          "title": "Why does io_uring_wait_cqe_timeout always have a ...",
          "url": "https://github.com/axboe/liburing/issues/531",
          "excerpts": [
            "No, it only relates to the timespec being passed in for waiting on events. IORING_OP_TIMEOUT should be sane already in this regard. ... io_uring: ..."
          ]
        },
        {
          "title": "Zero-Copy Sharing using Apache Arrow and Golang",
          "url": "https://voltrondata.com/blog/zero-copy-sharing-using-apache-arrow-and-golang",
          "excerpts": [
            "Jul 20, 2023 — In this post, we're covering a different situation: sending data within the same process by sharing the memory directly without copying.",
            "Zero-Copy Sharing using Apache Arrow and Golang",
            "sending data within the same process by sharing the memory directly without copying. Let’s hop down this rabbit hole!",
            "What if we could hand the utility a pointer to the data and then use it “as-is” without any copying? With the Arrow C data interface, _you c",
            "the Go package provides utilities to both import and export data via this interface.",
            "Central to this vision is the Apache Arrow project.",
            "This series will help users get started with Arrow and Go and see how you can use both to build effective data science workflows.",
            "It’s time for the final post in our series to get you started with Apache Arrow and Golang."
          ]
        },
        {
          "title": "Insights from paper: Apache Arrow DataFusion",
          "url": "https://www.hemantkgupta.com/p/insights-from-paper-apache-arrow",
          "excerpts": [
            "Aug 11, 2024 — Apache Arrow DataFusion is a fast, embeddable, and extensible query engine. It is written in Rust programming language and uses Apache Arrow as its memory ..."
          ]
        },
        {
          "title": "Execution Format",
          "url": "https://duckdb.org/docs/stable/internals/vector.html",
          "excerpts": [
            "The default STANDARD_VECTOR_SIZE is 2048 tuples. Vector Format. Vectors logically represent arrays that contain data of a single type. DuckDB supports different ..."
          ]
        },
        {
          "title": "relationship / unification of arrow-rs and arrow2 going forward · Issue ...",
          "url": "https://github.com/apache/arrow-rs/issues/1176",
          "excerpts": [
            "Zero-copy Vec conversion (#3516) (#1176) #3756 adds zero-copy conversion between Vec and Buffer. Together these work towards allowing us to ..."
          ]
        },
        {
          "title": "Acero: A C++ streaming execution engine",
          "url": "https://arrow.apache.org/docs/12.0/cpp/streaming_execution.html",
          "excerpts": [
            "Push versus pull-based loop fusion in query engines. Journal of Functional ... Substrait defines a broad set of operators and functions for many different ..."
          ]
        },
        {
          "title": "Checkpointing | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/fault-tolerance/checkpointing/",
          "excerpts": [
            "Exactly-once is preferable for most applications. At-least-once may be relevant for certain super-low-latency (consistently few milliseconds) applications."
          ]
        },
        {
          "title": "Aligned checkpoints",
          "url": "https://aws.amazon.com/blogs/big-data/optimize-checkpointing-in-your-amazon-managed-service-for-apache-flink-applications-with-buffer-debloating-and-unaligned-checkpoints-part-2/",
          "excerpts": [
            "Sep 14, 2023 — The alignment of checkpoint barriers is crucial for achieving exactly-once consistency in Apache Flink applications during checkpoint runs."
          ]
        },
        {
          "title": "A Deep-Dive into Flink's Network Stack - Apache Flink",
          "url": "https://flink.apache.org/2019/06/05/a-deep-dive-into-flinks-network-stack/",
          "excerpts": [
            "Jun 5, 2019 — Flink's network stack is one of the core components that make up the flink-runtime module and sit at the heart of every Flink job."
          ]
        },
        {
          "title": "Monitoring Checkpointing | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/ops/monitoring/checkpoint_monitoring/",
          "excerpts": [
            "Flink's web interface provides a tab to monitor the checkpoints of jobs. These stats are also available after the job has terminated."
          ]
        },
        {
          "title": "Flink Network Stack Vol. 2: Monitoring, Metrics, and that ...",
          "url": "https://flink.apache.org/2019/07/23/flink-network-stack-vol.-2-monitoring-metrics-and-that-backpressure-thing/",
          "excerpts": [
            "Jul 23, 2019 — Flink offers two mechanisms for identifying where the bottleneck is: directly via Flink's web UI and its backpressure monitor, or; indirectly ..."
          ]
        },
        {
          "title": "Backpressure mechanism in Spring Web-Flux - java - Stack Overflow",
          "url": "https://stackoverflow.com/questions/52244808/backpressure-mechanism-in-spring-web-flux",
          "excerpts": [
            "The backpressure is a mechanism that regulates the demand through the transmission (notification) of how many elements recipient can consume."
          ]
        },
        {
          "title": "Streaming Batch Model and Heterogeneous Execution (arXiv:2501.12407)",
          "url": "https://arxiv.org/html/2501.12407v1",
          "excerpts": [
            "We introduce the streaming batch model, a hybrid of the two models that enables efficient and fault-tolerant heterogeneous execution.",
            " materialize and send the batch to a downstream executor. If the downstream executor ",
            "backpressure is applied to limit memory.",
            "There is a common tradeoff among stream processing systems between run-time overheads vs. reconfigurability and recovery overhead",
            "Many systems use asynchronous global checkpointing   [ 28 , 9 ] . This typically imposes low execution overheads, but any failure causes a global rollback to the la",
            "irst, for heterogeneous operators, fusion is often impractical. For example, Figure   2(b) does not fuse A and C because B requires a GPU."
          ]
        },
        {
          "title": "arrow-rs/arrow/examples/zero_copy_ipc.rs at main",
          "url": "https://github.com/apache/arrow-rs/blob/main/arrow/examples/zero_copy_ipc.rs",
          "excerpts": [
            "Zero copy in this case means the Arrow arrays refer directly to a user //! ... Arrow `Buffer` to back the arrow arrays. We // do this by first creating a ..."
          ]
        },
        {
          "title": "arrow2 - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/arrow2/0.4.0",
          "excerpts": [
            "fbs. MUST lay out memory according to the arrow specification; MUST support reading from and writing to the C data interface at zero-copy."
          ]
        },
        {
          "title": "arrow::buffer - Rust",
          "url": "https://docs.rs/arrow/latest/arrow/buffer/index.html",
          "excerpts": [
            "A MutableBuffer is Arrow's interface to build a Buffer out of items or slices of items. NullBuffer: A BooleanBuffer used to encode validity for Arrow arrays ..."
          ]
        },
        {
          "title": "A Case for Informed Request Scheduling at the NIC",
          "url": "https://www.scs.stanford.edu/~dm/home/papers/humphries:gap.pdf",
          "excerpts": [
            "by JT Humphries · 2019 · Cited by 42 — Shinjuku's use of low-overhead interrupts for preemptive scheduling allows it to co-schedule workloads ranging from the microsecond to the ...See more"
          ]
        },
        {
          "title": "Don't Worry About Reactive Backpressure | by Matthew Casperson",
          "url": "https://medium.com/@matthewcasperson/dont-worry-about-reactive-backpressure-f813880fdf05",
          "excerpts": [
            "Backpressure is a complex sounding concept found in reactive systems, but the general idea is very simple."
          ]
        },
        {
          "title": "Integration Testing — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/format/Integration.html",
          "excerpts": [
            "The Arrow project includes cross-language integration tests which are regularly run as Continuous Integration tasks.See more"
          ]
        },
        {
          "title": "Event-driven Applications | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/learn-flink/event_driven/",
          "excerpts": [
            "A ProcessFunction combines event processing with timers and state, making it a powerful building block for stream processing applications."
          ]
        },
        {
          "title": "Mutiny - Flow control and Back-pressure - Quarkus",
          "url": "https://quarkus.io/blog/mutiny-back-pressure/",
          "excerpts": [
            "This post described the different approaches offered by Mutiny to handle back-pressure. The Reactive Streams protocol works well when you can control the pace ..."
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        },
        {
          "title": "The IX Operating System: Combining Low Latency, High ...",
          "url": "https://dl.acm.org/doi/10.1145/2997641",
          "excerpts": [
            "We present ix, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ..."
          ]
        },
        {
          "title": "Benchmarking Tools",
          "url": "https://docs.sel4.systems/projects/sel4-tutorials/benchmarking-guide.html",
          "excerpts": [
            "During each context switch, the kernel adds how long the current thread has run before being switched, and resets the start time for the next thread. The in ...",
            "Benchmarking Tools. The sel4bench-manifest repository collection provides a set of tools which can be used to analyse kernel and workload performance."
          ]
        },
        {
          "title": "Understanding overhead cost of context switching",
          "url": "https://unix.stackexchange.com/questions/681096/understanding-overhead-cost-of-context-switching",
          "excerpts": [
            "Dec 11, 2021 — The cost of context switching is the cost of saving all of the cpu state relating to the process context, and then loading in the context of a new process."
          ]
        },
        {
          "title": "Context Switching & Performance: What Every Developer ...",
          "url": "https://blog.codingconfessions.com/p/context-switching-and-performance",
          "excerpts": [
            "Dec 12, 2024 — For instance, the following infographic puts its cost into a really large bracket of 10,000 to 1 million CPU cycles."
          ]
        },
        {
          "title": "What is P99 latency? [closed]",
          "url": "https://stackoverflow.com/questions/12808934/what-is-p99-latency",
          "excerpts": [
            "It's 99th percentile. It means that 99% of the requests should be faster than given latency. In other words only 1% of the requests are expected to be slower.See more"
          ]
        },
        {
          "title": "Context Switching Overhead ELI5 : r/RISCV",
          "url": "https://www.reddit.com/r/RISCV/comments/ve71m5/context_switching_overhead_eli5/",
          "excerpts": [
            "An seL4 benchmark shows that an Itanium could perform a context switch in 36 cycles ... FAR lower than any other chip (a RISC-V core requires 500)."
          ]
        },
        {
          "title": "What? 80 Million I/O Per Second with a Standard 2U Intel® ...",
          "url": "https://spdk.io/news/2021/05/06/nvme-80m-iops/",
          "excerpts": [
            "80 MILLION IOPS at an amazing average latency of just 25.54 microseconds ... Additionally, the SPDK NVMe driver achieves linear IOPS scalability ..."
          ]
        },
        {
          "title": "Boosting Data Ingest Throughput with GPUDirect Storage ...",
          "url": "https://developer.nvidia.com/blog/boosting-data-ingest-throughput-with-gpudirect-storage-and-rapids-cudf/",
          "excerpts": [
            "To increase the end-to-end read throughput, cuDF uses the cuFile APIs in its data ingest interfaces, like read_parquet and read_orc . As cuDF ...",
            "May 27, 2022 — GPUDirect Storage provides a direct data path to the GPU, reducing latency and increasing throughput for I/O operations. RAPIDS cuDF leverages ..."
          ]
        },
        {
          "title": "Performance Characterization of NVMe Flash Devices with ...",
          "url": "https://arxiv.org/pdf/2310.19094",
          "excerpts": [
            "by K Doekemeijer · 2023 · Cited by 18 — In this paper, we characterize the performance and interfer- ence properties of the Western Digital Ultrastar DC ZN540. SSD, a large-zone ZNS SSD, using a ...",
            "by K Doekemeijer · 2023 · Cited by 18 — We report on the performance features of a commercially available ZNS SSD (13 key observations), explain how these features can be incorpo- rated into publicly ...See more"
          ]
        },
        {
          "title": "Austin Labs - Zoned Namespace (ZNS) Testing Services",
          "url": "https://www.teledynelecroy.com/doc/al-testing-zns-brochure",
          "excerpts": [
            "By dividing the NVMe namespace into zones, ZNS improves latency, throughput and drive capacity, making it ideal for hyper-scale, all-flash array, and large ..."
          ]
        },
        {
          "title": "'Apples to Apples' Zoned Namespaces (ZNS) vs. FTL SSD ...",
          "url": "https://www.radianmemory.com/about/news/apples-to-apples-zoned-namespaces-zns-vs-ftl-ssd-performance-benchmark/",
          "excerpts": [
            "The ultimate performance tests for today's data center applications show tail latencies (99.99% or greater QoS) and include IOPS in the same measurement, ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage ...",
          "url": "https://blogs.oracle.com/cloud-infrastructure/post/accelerate-ai-ml-workloads-oci-nvidia-ibm",
          "excerpts": [
            "Sep 14, 2023 — RAPIDS cuDF Parquet reader benchmark: Uses an open source suite of GPU-accelerated Python libraries to improve data science and analytics ..."
          ]
        },
        {
          "title": "Statistics Behind Latency Metrics: Understanding P90, P95, and P99",
          "url": "https://medium.com/tuanhdotnet/statistics-behind-latency-metrics-understanding-p90-p95-and-p99-dc87420d505d",
          "excerpts": [
            "Latency percentiles, such as P90, P95, and P99, are statistical measures that indicate how response times are distributed.",
            "P99 (99th Percentile): The P99 metric means that 99% of the requests have a response time less than or equal to this value. It focuses on the ..."
          ]
        },
        {
          "title": "On the Costs of Syscalls (2021) - Hacker News",
          "url": "https://news.ycombinator.com/item?id=39174674",
          "excerpts": [
            "This micro benchmark measures the direct cost of system calls. But flushing the TLB and trashing the caches carries an indirect cost too."
          ]
        },
        {
          "title": "Which one affects IPC performance more? context switch ...",
          "url": "https://stackoverflow.com/questions/28856089/which-one-affects-ipc-performance-more-context-switch-or-number-of-processes",
          "excerpts": [
            "In my impression, when talking about improving IPC performance or lower the latency involved, context switch seems to be the most important factor."
          ]
        },
        {
          "title": "Performance characteristics of GDS",
          "url": "https://hps.vi4io.org/_media/events/2024/mst3.pdf",
          "excerpts": [
            "GPUDirect Storage (GDS) or Nvidia Magnum IO provides a direct DMA path\nbetween GPU and PCIe attached storage via the cuFile API in a Nvidia ConnectX-4+\nbased fabric",
            "Summary\n\nI/O based on cuFile API provides large performance gains for reading compared\nto traditional CUDA I/",
            "Results 1\n\nlocal NVME\nCPU POSIX\nCUDA\ncuFile (GDS)\n\n4k rand read IOPS\n934.276\n349.722\n828.3",
            "Results 2\n\nLustre 1 node\nCPU POSIX\nCUDA\ncuFile (GDS)\n\n4k rand read IOPS\n1.124.942\n263.014\n1.054.3",
            "Results 3\n\nLustre 2 nodes\nCPU POSIX\nCUDA\ncuFile (GDS)\n\n4k rand read IOPS\n2.190.572\n497.150\n2.215.7",
            "age limited to systems with Nvidia interconnect and installed MOFED"
          ]
        },
        {
          "title": "Investigation of context switches and asynchronous I/O (B Ingimarsson, 2024)",
          "url": "https://atlarge-research.com/pdfs/2024-bingimarsson-msc_thesis.pdf",
          "excerpts": [
            "by B Ingimarsson · 2024 — 1 shows the IOPS, average and p99 latency, and context switches per second. We do not observe any difference in performance with or without",
            "2.2.2\nContext Switches",
            "On Linux, every process has its own context, which includes a private virtual memory space, and the values of registers. When an application makes a system call, most of the context remains, but execution switches into kernel mode, a special per-process kernel stack is used, and the kernel’s address space becomes accessible."
          ]
        },
        {
          "title": "On the Costs of Syscalls",
          "url": "https://gms.tf/on-the-costs-of-syscalls.html",
          "excerpts": [
            "The costs of a context switch match what others are measuring (modulo division by two).",
            "The fastest host is\nxg6256 which manages to switch modes in\nless than 100 ns.",
            "The user-kernel mode-switch micro-benchmark uses Google's benchmark library for the measurements and is available in\na git repository .",
            "For the benchmark a bunch of syscalls is called that are expected\nto be very cheap, such as getting the user id (UID), the program id\n(PID), closing an invalid file descriptor, calling an\nnon-existent syscall etc.",
            "Thus, the other nanosleep cases set a minimal timer slack of 1\nns which reduces the runtime, as expected. However, it's still\nmuch more expensive than the other syscalls.",
            "the median value of 100 repetitions is reported (real time in\nnanoseconds).",
            "In the following sections\nthe median value of 100 repetitions is reported (real time in\nnanoseconds).",
            "So looking at the real syscalls, the user-kernel mode switches\ncost in the order of a few hundred nanoseconds, on all hosts.",
            "the\nbenchmark process is running under the standard scheduling policy\nand on Linux",
            ". The table shows that on RHEL 7 querying\nCLOCK_MONOTIC_RAW and\nCLOCK_TAI invokes a real syscall while\non Fedora 33 kernels (5.12/5.13) these clock readings are also\nimplemented as vDSO."
          ]
        },
        {
          "title": "Tail Latency: Key in Large-Scale Distributed Systems - Last9",
          "url": "https://last9.io/blog/tail-latency/",
          "excerpts": [
            "p50 (median): This indicates what the \"typical\" request looks like. p95: 95% of requests are faster than this value. p99: This is where tail ..."
          ]
        },
        {
          "title": "In microkernel, do messages between applications/servers goes ...",
          "url": "https://www.quora.com/In-microkernel-do-messages-between-applications-servers-goes-through-the-kernel-or-it-is-possible-to-context-switch-directly",
          "excerpts": [
            "A context switch is the mechanism to store and restore the state or context of a CPU in Process Control block (PCB) so that a process execution ..."
          ]
        },
        {
          "title": "linux - What is the overhead of a context-switch?",
          "url": "https://stackoverflow.com/questions/21887797/what-is-the-overhead-of-a-context-switch",
          "excerpts": [
            "A context switch will not result in the flushing of the TLB – but just changing the tag of the current address space to the tag of the address space of the new ..."
          ]
        },
        {
          "title": "NSDI '19 Technical Sessions",
          "url": "https://www.usenix.org/conference/nsdi19/technical-sessions",
          "excerpts": [
            "For the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency. ... 6.6x ..."
          ]
        },
        {
          "title": "The Kingman Formula – Variation, Utilization, and Lead Time",
          "url": "https://www.allaboutlean.com/kingman-formula/",
          "excerpts": [
            "The Kingman equation (also known as Kingman formula or Kingman approximation) gives you an approximation of the waiting time of the parts for a single process."
          ]
        },
        {
          "title": "Long-Tail Latency Problem in Microservices",
          "url": "https://www.geeksforgeeks.org/system-design/long-tail-latency-problem-in-microservices/",
          "excerpts": [
            "In a microservices architecture, this issue can manifest when a few service calls have notably longer response times compared to the average."
          ]
        },
        {
          "title": "Lead-time variability in a homogeneous queueing model of ...",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/S0925527398000292",
          "excerpts": [
            "by R Kuik · 1999 · Cited by 32 — In addition, they state that the batching decision that minimizes the average queueing delay also tends to minimize the variance in the waiting time. In this ..."
          ]
        },
        {
          "title": "NIC の⾼速化と システムソフトウェア研究",
          "url": "https://seminar-materials.iijlab.net/iijlab-seminar/iijlab-seminar-20231017.pdf",
          "excerpts": [
            "Oct 17, 2023 — • Shinjuku (NSDI 2019). • TAS (EuroSys 2019). • Caladan (OSDI 2020) ... Tail Latency. In 16th USENIX Symposium on Networked Systems Design ..."
          ]
        },
        {
          "title": "seL4/sel4bench: sel4 benchmarking applications and support library.",
          "url": "https://github.com/seL4/sel4bench",
          "excerpts": [
            "Missing: cycles microbenchmark"
          ]
        },
        {
          "title": "L4 microkernel family - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/L4_microkernel_family",
          "excerpts": [
            "L4 is a family of second-generation microkernels, used to implement a variety of types of operating systems (OS)"
          ]
        },
        {
          "title": "r/linux on Reddit: L4 Microkernels: The Lessons from 20 Years of ...",
          "url": "https://www.reddit.com/r/linux/comments/4ef9ab/l4_microkernels_the_lessons_from_20_years_of/",
          "excerpts": [
            "I often hear the pure microkernel architecture is slow because it requires more context switches line, but according to these figures, it would ..."
          ]
        },
        {
          "title": "Learning Unified System Representations for Microservice ...",
          "url": "https://arxiv.org/html/2508.01635v1",
          "excerpts": [
            "In this paper, we presented USRFNet, a dual-stream fusion network for predicting window-level P95 tail latency in microservice systems."
          ]
        },
        {
          "title": "An Analysis of Holistic Tail Latency Behaviors of Java ...",
          "url": "https://ieeexplore.ieee.org/document/8855342",
          "excerpts": [
            "by P Tennage · 2019 · Cited by 7 — In this paper, we focus on analyzing and characterizing the behaviour of tail latency values of microservices workloads under service's peak sustainable ..."
          ]
        },
        {
          "title": "Predicting bounds on queuing delay for batch-scheduled ...",
          "url": "https://dl.acm.org/doi/10.1145/1122971.1122989",
          "excerpts": [
            "by J Brevik · 2006 · Cited by 110 — In this work, we explore a new method for providing end-users with predictions for the bounds on the queuing delay individual jobs will experience. We evaluate ..."
          ]
        },
        {
          "title": "A Small Dice Game for the Kingman Formula",
          "url": "https://inria.hal.science/hal-02164892v1/document",
          "excerpts": [
            "by C Roser · 2018 · Cited by 1 — For the general G/G/1 queue, there exist different approximations. The most com- mon one is the Kingman approximation as shown in equation (2)."
          ]
        },
        {
          "title": "Kingman's formula",
          "url": "https://en.wikipedia.org/wiki/Kingman%27s_formula",
          "excerpts": [
            "Kingman's formula, also known as the VUT equation, is an approximation for the mean waiting time in a G/G/1 queue."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". Arrakis: The Operating System is the Control\nPlane. OSDI, 2014.",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        },
        {
          "title": "Network Interface Controller Drivers - Download",
          "url": "https://fast.dpdk.org/doc/pdf-guides-20.02/nics-20.02.pdf",
          "excerpts": [
            "May 18, 2020 — The SR-IOV NIC switch forwards the packet to a specific VM according to the. MAC destination address which belongs to the destination VF on ..."
          ]
        },
        {
          "title": "Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOoroPxwW5RK38PZBdOI2YMlE1W5qR4wyNfP0NTN08UNbtRkAXUOs",
          "excerpts": [
            "May 23, 2023 — Page 1. Revision 2.6. May 2023. 613875-008. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ..."
          ]
        },
        {
          "title": "Intel® Ethernet Network Adapter E810-2CQDA2",
          "url": "https://cdrdv2-public.intel.com/639389/Intel%20Ethernet%20Network%20Adapter%20E810-2CQDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 512 SR-IOV Virtual Functions**. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized ...",
          "url": "https://semiconductor.samsung.com/news-events/news/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Samsung Electronics, today unveiled its new enterprise solid-state drive (SSD) featuring Zoned Namespace (ZNS) technology — the PM1731a.",
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ports, ensuring ..."
          ]
        },
        {
          "title": "What are the system requirements for GPUDirect RDMA?",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20system%20requirements%20for%20GPUDirect%20RDMA?",
          "excerpts": [
            "Hardware Requirements  PCIe Bus Support: The system must support PCIe Gen3 or higher for optimal performance. RDMA-Capable Network Adapter: The network interface card (NIC) must support GPUDirect RDMA (e.g., Mellanox ConnectX-6/7, NVIDIA BlueField DPU, or other compatible adapters)."
          ]
        },
        {
          "title": "31. Shared Virtual Addressing (SVA) with ENQCMD",
          "url": "https://www.kernel.org/doc/html/next/x86/sva.html",
          "excerpts": [
            "Use of SVA requires IOMMU support in the platform. IOMMU is also required to support the PCIe features ATS and PRI. ATS allows devices to cache translations ..."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 — Feature Support Matrix",
          "url": "https://cdrdv2-public.intel.com/630155/630155_E810%20Feature%20Summary_rev3_4.pdf",
          "excerpts": [
            "Sep 16, 2022 — Use case assumes up to 256 VFs with SR-IOV, assign them to containers, 1 VF per container. Table 10. Configuration Maximums. Host OS. Max VFs."
          ]
        },
        {
          "title": "Using SR-IOV VF in CT with DPDK - Proxmox Support Forum",
          "url": "https://forum.proxmox.com/threads/using-sr-iov-vf-in-ct-with-dpdk.110959/",
          "excerpts": [
            "I am trying to use some VFs of a NIC in a CT. What I did so far: 1. Enable SR-IOV in bios 2. Enable IOMMU with pass through 3. Load kernel modules on startup."
          ]
        },
        {
          "title": "Change log : Hirsute (21.04) : linux-raspi package : Ubuntu",
          "url": "https://launchpad.net/ubuntu/hirsute/+source/linux-raspi/+changelog",
          "excerpts": [
            "... count transport header in UFO - i40e: Fix correct max_pkt_size on VF RX queue - i40e: Fix NULL ptr dereference on VSI filter sync - i40e: Fix changing ..."
          ]
        },
        {
          "title": "Device sharing and memory disaggregation in PCIe ...",
          "url": "https://home.simula.no/~paalh/students/JonasMarkussen-phd.pdf",
          "excerpts": [
            "To facilitate device sharing and memory disaggregation among machines connected using PCIe non-transparent bridges, we present SmartIO. SmartIO makes all."
          ]
        },
        {
          "title": "[FAQ] what is CUDA GPU direct nvme equivalent thing in ROCm",
          "url": "https://github.com/ROCm/ROCm/issues/2251",
          "excerpts": [
            "Missing: peer- peer DMA GDS"
          ]
        },
        {
          "title": "System Requirements and Recommendations - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/networking/display/GPUDirectRDMAv18/System+Requirements+and+Recommendations",
          "excerpts": [
            "To achieve the best performance for GPUDirect RDMA, it is required that both the HCA and the GPU be physically located on the same PCIe IO root complex."
          ]
        },
        {
          "title": "The relationship between GPUDirect RDMA, GPUDirect P2P, NVidia ...",
          "url": "https://forums.developer.nvidia.com/t/the-relationship-between-gpudirect-rdma-gpudirect-p2p-nvidia-ipc-nccl-and-nvshmem/316874",
          "excerpts": [
            "GPUDirect RDMA at the lowest level provides for data exchange “directly” between a GPU and a non-GPU device like a Networking Adapter or ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            "Missing: ROCm equivalent",
            "The Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver.",
            "The prerequisites for configuring GPUDirect RDMA or GPUDirect Storage depend on whether you use DMA-BUF from the Linux kernel or the legacy `nvidia-peermem` kernel module.",
            "To support GPUDirect RDMA, userspace CUDA APIs are required. The kernel mode support is provided by one of two approaches: DMA-BUF from the Linux kernel or ...",
            "GPU Driver | An Open Kernel module driver is required.",
            "CUDA | CUDA 11.7 or higher. The CUDA runtime is provided by the driver.",
            "GPU | Turing architecture data center, Quadro RTX, and RTX GPU or higher.",
            "Network Device Drivers | MLNX\\_OFED or DOCA-OFED are optional. You can use the Linux driver packages from the package manager",
            "Linux Kernel | 5\\.12 or higher",
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "ROCE/RDMA to/from GPU memory-space with UCX? : r/ROCm",
          "url": "https://www.reddit.com/r/ROCm/comments/1jmqmwq/rocerdma_tofrom_gpu_memoryspace_with_ucx/",
          "excerpts": [
            "Missing: peer- peer DMA equivalent"
          ]
        },
        {
          "title": "The mlx5 Ethernet poll mode driver ( librte_net_mlx5 )",
          "url": "https://doc.dpdk.org/guides/nics/mlx5.html",
          "excerpts": [
            "The mlx5 Ethernet poll mode driver ( librte_net_mlx5 ) provides support for NVIDIA NIC and DPU device families.",
            "* Additional Tx acceleration for small packets is achieved\nby saving PCI bandwidth with enhanced Multi-Packet Write (eMPW) .",
            "The mlx5 PMD provides a comprehensive set of counters designed for debugging and diagnostics related to packet scheduling during transmission. These counters ...",
            "39.2.2. Flow Steering",
            "A major benefit of the mlx5 devices",
            "is the bifurcated driver capability.",
            "It allows to route some flows from the device to the kernel\nwhile other flows go directly to the userspace PMD.",
            "This capability allows the PMD to coexist with kernel network interfaces\nwhich remain functional, although they stop receiving unicast packets\nas long as they share the same MAC address.",
            "This means Linux control tools (ethtool, iproute and more)\ncan operate on the same network interfaces as ones owned by the DPDK application.",
            "When using flow offload extensively,\nthe configuration of the flow rules becomes performance-critical.",
            "That’s why the hardware is evolving to offer faster flow steering access.",
            "The steering engine was accelerated by introducing Direct Verbs,\nand even more with Direct Rules.",
            "At this stage, a lot of flow rules manipulations were done in software. This technology is named software steering (SWS).",
            "Later the performance was a lot more improved\nwith hardware steering (HWS) ,\na WQE-based high scaling and safer flow insertion/destruction.",
            "It allows to insert millions of rules per second.",
            "While using the synchronous flow API is convenient and easy to manage,\nit is not efficient enough at a large scale."
          ]
        },
        {
          "title": "1. Getting Started with GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/gpudirect-storage/getting-started/index.html",
          "excerpts": [
            "NVIDIA® GPUDirect® Storage (GDS) enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce ..."
          ]
        },
        {
          "title": "How to enable GPU Direct Storage (GDS) with P2PDMA",
          "url": "https://forums.developer.nvidia.com/t/how-to-enable-gpu-direct-storage-gds-with-p2pdma/340055",
          "excerpts": [
            "Does enabling GDS in P2PDMA mode only require installing CUDA 12.8, or are there other necessary steps or configurations? What are the exact ...",
            "GDS can be enabled in two ways: using the GDS NVIDIA kernel driver (nvidia-fs.ko) and updating the NVMe driver patches, or optionally as of 12.8 ..."
          ]
        },
        {
          "title": "P2PDMA Support Added to Linux Kernel 4.20 RC1",
          "url": "https://www.eideticom.com/blog/p2pdma-support-added-to-linux-kernel-4-20-rc1-eideticom-blog",
          "excerpts": [
            "Nov 5, 2018 — It is possible p2pdma can be the basis for a legitimate upstream version of GPUDirect for example, which has failed to be accepted for ..."
          ]
        },
        {
          "title": "What are the hardware requirements for using GPUDirect ...",
          "url": "https://massedcompute.com/faq-answers/?question=What%20are%20the%20hardware%20requirements%20for%20using%20GPUDirect%20with%20NVIDIA%20GPUs?",
          "excerpts": [
            "GPUDirect RDMA (Remote Direct Memory Access) and GPUDirect Storage have additional hardware prerequisites: RDMA-Capable NICs: For GPUDirect RDMA, the ..."
          ]
        },
        {
          "title": "NVIDIA MELLANOX CONNECTX-6 DX",
          "url": "https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/documents/nvidia-connectx-6-dx-en-hpe-datasheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities, and supports up to 8 million rules. > Advanced Quality of Service ..."
          ]
        },
        {
          "title": "5. NVIDIA MLX5 Common Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-23.11/platform/mlx5.html",
          "excerpts": [
            "The mlx5 kernel modules are part of upstream Linux. The minimal supported kernel version is 4.14. For 32-bit, version 4.14.41 or above is required. The ..."
          ]
        },
        {
          "title": "Intel® Ethernet Controller E810 Datasheet",
          "url": "https://www.intel.com/content/www/us/en/content-details/613875/intel-ethernet-controller-e810-datasheet.html",
          "excerpts": [
            "This document describes the external architecture (including device operation, pin descriptions, register definitions, and so on) for the Intel® Ethernet ..."
          ]
        },
        {
          "title": "32. Intel Virtual Function Driver - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-23.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "27. Intel Virtual Function Driver - Documentation",
          "url": "https://doc.dpdk.org/guides-20.11/nics/intel_vf.html",
          "excerpts": [
            "The DPDK uses the SR-IOV feature for hardware-based I/O sharing in IOV mode. Therefore, it is possible to partition SR-IOV capability on Ethernet controller NIC ..."
          ]
        },
        {
          "title": "NVIDIA Mellanox ConnectX-6 Ethernet SmartNIC Data Sheet",
          "url": "https://www.cisco.com/c/dam/en/us/products/collateral/servers-unified-computing/ucs-c-series-rack-servers/nvidia-mellanox-connectx-6-ethernet-smartnic-data-sheet.pdf",
          "excerpts": [
            "ConnectX-6 Dx ASAP2 offers both SR-IOV and VirtIO in-hardware offload capabilities and supports up to 8 million rules. > Advanced quality of service (QoS)— ..."
          ]
        },
        {
          "title": "Blazing Fast NVMEs and Direct Storage API for PCs *spawn*",
          "url": "https://forum.beyond3d.com/threads/blazing-fast-nvmes-and-direct-storage-api-for-pcs-spawn.61761/page-5",
          "excerpts": [
            "May 18, 2020 — Only PCIe Switches (virtual PCI-PCI bridges) are required to support P2P ... This still won't enable GPUDirect Storage or RDMA on desktops."
          ]
        },
        {
          "title": "Loading data to GPU *directly* from the SSD drive, almost ...",
          "url": "https://www.reddit.com/r/deeplearning/comments/13aks7g/directstorage_loading_data_to_gpu_directly_from/",
          "excerpts": [
            "Is it possible in major frameworks (TF or PyTorch) to load all data to GPU directly from a fast SSD disc, without using the CPU? Is it possible today?See more"
          ]
        },
        {
          "title": "spdk_nvme_zns_zone_report Struct Reference",
          "url": "https://spdk.io/doc/structspdk__nvme__zns__zone__report.html",
          "excerpts": [
            "The documentation for this struct was generated from the following file: nvme_spec.h."
          ]
        },
        {
          "title": "[PDF] Ultrastar DC ZN540 ZNS SSD Product Brief - Western Digital",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/product-brief/product-brief-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar® DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set as ..."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "Intel Ethernet Controller E810 Datasheet",
          "url": "https://www.mouser.com/datasheet/2/612/E810_Datasheet_Rev2_6-3314030.pdf?srsltid=AfmBOor5ApmFnwwg4_sjoGyYFRDMov7pVhelbBHwS9gYnaanBWrfRXnA",
          "excerpts": [
            ". SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K queue ...",
            "RDMA\n•\niWARP and RoCE v2. •\n256K Queue Pairs (QPs",
            "The E810 fully supports Next Generation VMDq mode and SR-IOV.",
            "irtualization (enhanced SR-IOV \nsupport with up to 256 VFs and backward compatibility VF driver support)"
          ]
        },
        {
          "title": "Magnum IO GPUDirect Storage",
          "url": "https://developer.nvidia.com/gpudirect-storage",
          "excerpts": [
            "NVIDIA Magnum IO GPUDirect® Storage (GDS) is now part of CUDA. See https://docs.nvidia.com/gpudirect-storage/index.html for more information. GDS is currently ..."
          ]
        },
        {
          "title": "GDS - GPUDirect Storage",
          "url": "https://docs.nvidia.com/cuda/archive/11.7.1/pdf/GDS.pdf",
          "excerpts": [
            "GDS enables a direct data path for direct memory access (DMA) transfers between GPU memory and storage. This direct path increases system bandwidth and ..."
          ]
        },
        {
          "title": "28. ICE Poll Mode Driver - Documentation",
          "url": "https://doc.dpdk.org/guides/nics/ice.html",
          "excerpts": [
            "The ice PMD (librte_net_ice) provides poll mode driver support for 10/25/50/100/200 Gbps Intel® Ethernet 800 Series Network Adapters based on the following ..."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA2",
          "url": "https://cdrdv2-public.intel.com/641674/Intel%20Ethernet%20Network%20Adapter%20E810-XXVDA2%20Product%20Brief.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "[PDF] Intel® Ethernet Network Adapter E810-XXVDA4",
          "url": "https://cdrdv2-public.intel.com/742008/Dell_Intel%20Ethernet%20Network%20Adatper%20E810-XXVDA4.pdf",
          "excerpts": [
            "• Host virtualization via VMDQ and SR-IOV. • Up to 256 SR-IOV Virtual Functions. • Stateless offloads for tunneled packets. (network virtualization support)."
          ]
        },
        {
          "title": "How to Reach the Max Bandwidth Speed of a Single RDMA QPS ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000088729/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "The E810s cannot reach the max bandwidth speed of a single RDMA QPS (queue pairs) in either iWARP or RoCEv2 mode.Columbiaville is designed to deliver best ..."
          ]
        },
        {
          "title": "iWARP Throughput Performance Issue on Intel® Ethernet Network ...",
          "url": "https://www.intel.com/content/www/us/en/support/articles/000059783/ethernet-products/800-series-network-adapters-up-to-200gbe.html",
          "excerpts": [
            "Intel® Ethernet Network Adapter E810-CQDA2 is designed to deliver best performance using multiple Queue Pairs (QP) hence, it cannot reach maximum bandwidth ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet' s Performance Report with DPDK 22.11",
          "url": "https://fast.dpdk.org/doc/perf/DPDK_22_11_Intel_NIC_performance_report.pdf",
          "excerpts": [
            "Figure 14: ice PMD Single core performance on 2x Intel® Ethernet Network Adapter E810-. QCDA2 with turbo boost comparison. Page 21. Intel ..."
          ]
        },
        {
          "title": "[PDF] Intel Ethernet Controller E810",
          "url": "https://www.mouser.com/datasheet/2/612/613875_E810_Datasheet_Rev2_7-3314030.pdf?srsltid=AfmBOopOVGq1VlDC61e6xt9KhgfHGjfbQA4NBSKRxAMyy195mgxFyoAu",
          "excerpts": [
            "Page 1. Revision 2.7. March 2024. 613875-009. Intel. ®. Ethernet Controller E810. Datasheet ... SR-IOV: 8 PFs, 256 VFs, 256 Queues per PF, 2K ..."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "What is NVMe? | An In-Depth Overview ... - Dell Technologies Info Hub",
          "url": "https://infohub.delltechnologies.com/en-us/l/an-in-depth-overview-of-nvme-and-nvme-of/what-is-nvme/",
          "excerpts": [
            "The current set of NVMe command specifications are: NVMe Command Set Specification, Revision 1.1; NVMe Zoned Namespaces Command Set Specification, Revision 1.2 ..."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "GPUDirect Storage O_DIRECT Requirements Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/o-direct-guide/index.html",
          "excerpts": [
            "GPUDirect® Storage (GDS) is the newest addition to the GPUDirect family. GDS enables a direct data\npath for direct memory access (DMA) transfers between GPU memory and storage, which avoids a bounce buffer\nthrough the CPU. Using this direct path can relieve effective system bandwidth bottlenecks and decrease the\nlatency and utilization load on t",
            "The kernel storage driver can perform a DMA of user data to or from GPU memory by using addresses\n  that were obtained from callbacks to the GDS kernel module, `nvidia-fs.ko`",
            "The device near the storage has a DMA engine that can reach the GPU memory buffer via PCIe. + \n        For local storage, an NVMe device performs DMA. + \n        For remote storage, a NIC",
            "The file system stack that operates at the user-level, or the kernel-level, or both, and never\n  needs to access the data in CPU system memory. > Instead, data is transferred directly between storage and GPU memory, which is achieved by file\n> systems that exclusively use the O\\_DIRECT mode for a give",
            "O\\_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7). CUDA 12.2 (GDS version 1.7)\nintroduces support for non O\\_DIRECT file descriptor",
            "O_DIRECT is the only supported mode before CUDA toolkit 12.2 (GDS version 1.7).",
            "CUDA 12.2 (GDS version 1.7) introduces support for non O_DIRECT file descriptors ... This can be viewed as the compatibility\nmode leveraging the page cache that can typically be used for smaller file I/Os with a high degree of\ntemporal locality, like the case of application headers or metadata",
            "The direct data path between the NIC and GPU memory happens on the client. To enable this direct path, client-side drivers must first be enabled with GDS.",
            "RDMA is a protocol to access remote data over a network and uses the NIC to DMA directly into client-side memory.",
            "Using RDMA also relies on server-side support. File system implementations that do not support RDMA on the server side will not support GDS."
          ]
        },
        {
          "title": "Intel SR-IOV Configuration Guide",
          "url": "https://cdrdv2-public.intel.com/630211/630211_E810%20SR-IOV%20RHEL8%20ConfigGuide_Rev1.2.pdf",
          "excerpts": [
            "Hardware Requirements",
            "ments**\n\n• An Intel <sup>®</sup> Ethernet 800 Series Network Adapter (or other adapter based on an Intel <sup>®</sup> Ethernet 800\n\nSeries Controller).",
            "roller). • A server platform that supports Intel <sup>®</sup> Virtualization Technology for Directed I/O (Intel <sup>®</sup> VT-d) and\n\nthe PCI-SIG Single Root I/O Virtualization and Sharing (SR-IOV) specification.",
            " • A server platform with an available PCI Express Gen 4.0/3.0 x16 or x8 slot, depending on the\n\nspecific board. **1",
            "Software Requirements",
            "• Red Hat Enterprise Linux Version 8.0 (RHEL 8).",
            ").\n• Intel <sup>®</sup> Ethernet 800 Series Linux Drivers for PF and VF, available at:\n\nhttp://sourceforge.net/projects/e1000/files/\n\nhttp",
            "https://downloadscenter.intel.com",
            "Note:"
          ]
        },
        {
          "title": "Intel Ethernet 800 Series Product Brief",
          "url": "https://gzhls.at/blob/ldb/5/8/6/7/6b497d7cb6eb6fa2fbf214f8c2f7c7a97e22.pdf",
          "excerpts": [
            "\nIntel® Ethernet 800 Series supports up to 100Gb/s throughput for a \nvariety of workloads.",
            "Support both iWARP and RoCEv2 RDMA, selectable via software  \n\nper port for low-latency, high-throughput workloa",
            "Application Device Queues (ADQ) to increase application  \n\npredictability, reduce application latency and improve  \napplication throu",
            " \n\nVFs, 768 VSIs\n",
            "\n\nMove data faster with Intel® Ethernet 800 Series",
            "Intel® Ethernet Controller  \nE810-CAM2/CAM1/XXVAM2"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications.",
            "Missing: RustHallows competitive landscape"
          ]
        },
        {
          "title": "Performance Characterization of NVMe Flash Devices with ...",
          "url": "https://atlarge-research.com/pdfs/2023-cluster-zns-performance-kdoekemeijer.pdf",
          "excerpts": [
            "by K Doekemeijer · Cited by 18 — We report on the performance features of a commercially available ZNS SSD (13 key observations), explain how these features can be incorpo-.See more"
          ]
        },
        {
          "title": "[HELP] Nvidia GPUDirect storage benchmark for an AI400 ...",
          "url": "https://www.reddit.com/r/HPC/comments/qni6cs/help_nvidia_gpudirect_storage_benchmark_for_an/",
          "excerpts": [
            "We are supposed to benchmark the GPU direct storage performance however I cannot seem to find the appropriate benchmarking tool to use."
          ]
        },
        {
          "title": "DO-178C Costs vs Benefits Analysis",
          "url": "https://afuzion.com/do-178c-costs-versus-benefits/",
          "excerpts": [
            "Now, DO-178C increases initial software engineering costs by 25% – 40%. The top ten ways to reduce DO-178C costs are listed below (download the rest of this ..."
          ]
        },
        {
          "title": "Software certifications for safety critical applications : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/cc5nky/software_certifications_for_safety_critical/",
          "excerpts": [
            "Some certifications an embedded system should pass on a safety critical application, some of such certifications (as far as I know) are UL 991 and 1998."
          ]
        },
        {
          "title": "Performance evaluation of containers for low-latency ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0166531624000476",
          "excerpts": [
            "por F Wiedner · 2024 · Mencionado por 5 — Our results demonstrate that containers exhibit similar latency performance with more predictable tail-latency behavior than bare metal packet processing."
          ]
        },
        {
          "title": "Benchmark of SPDK · eunomia-bpf/bpftime Wiki",
          "url": "https://github.com/eunomia-bpf/bpftime/wiki/Benchmark-of-SPDK",
          "excerpts": [
            "Nov 20, 2023 — SPDK is a high-performance user space storage application framework. It has its own tracing capability. We have tried to use bpftrace with SPDK, but the ..."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            "This handbook takes you through the whole DO-178C journey with a focus on verification, leaving you with an understanding of the compliance process as a whole."
          ]
        },
        {
          "title": "DO-178C",
          "url": "https://en.wikipedia.org/wiki/DO-178C",
          "excerpts": [
            "The new document is called DO-178C/ED-12C and was completed in November 2011 and approved by the RTCA in December 2011. It became available for sale and use in ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification is the primary document by which the certification authorities such as FAA, ..."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds.",
            " By avoiding intermediate buffers and memory copies, this approach reduces latency by 50–100 nanoseconds per packet—a meaningful gain in HFT systems.",
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "However, zero-copy networking introduces greater development complexity, requiring careful buffer management, error handling, and integration with kernel-level APIs.",
            "The next section integrates these concepts into a practical low-latency architecture.",
            "Practical Design Example: Building a Low-Latency Pipeline",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay."
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "QNX OS for Safety 8.0",
          "url": "https://blackberry.qnx.com/en/products/safety-certified/qnx-os-for-safety",
          "excerpts": [
            "The QNX OS for Safety is a microkernel OS for embedded systems certified to IEC 61508 SIL 3, ISO 26262 ASIL D and IEC 62304 Class C."
          ]
        },
        {
          "title": "QNX Safety Certifications | ISO 26262, IEC 61508, IEC 62304",
          "url": "https://blackberry.qnx.com/en/developers/certifications",
          "excerpts": [
            "Streamline safety certifications and compliance with embedded software solutions from QNX. Learn more."
          ]
        },
        {
          "title": "Wind River Store - Buy VxWorks, Diab Compiler & More ...",
          "url": "https://www.windriver.com/store",
          "excerpts": [
            "Purchase up to three seats of the world's #1 real-time operating system (RTOS), starting at $19,500 per seat. VxWorks® is a deterministic, priority-based ..."
          ]
        },
        {
          "title": "Linux Licensing Cost - TCO Calculator",
          "url": "https://www.windriver.com/products/linux/tco-calculator",
          "excerpts": [
            "Calculate the costs of building your own embedded Linux product with our TCO Calculator. Find out how market-leading Wind River Linux can save you money!"
          ]
        },
        {
          "title": "AWS Marketplace: QNX OS for Safety 2.2.3",
          "url": "https://aws.amazon.com/marketplace/pp/prodview-26pvihq76slfa",
          "excerpts": [
            "3. Pricing is based on actual usage, with charges varying according to how much you consume."
          ]
        },
        {
          "title": "Green Hills Software: Real-Time Operating Systems (RTOS ...",
          "url": "https://www.ghs.com/",
          "excerpts": [
            "Green Hills Software is the worldwide leader in embedded safety and security. With the most safety and security certifications and the best track record."
          ]
        },
        {
          "title": "QNX Developer License Options",
          "url": "https://blackberry.qnx.com/en/products/qnx-everywhere/licensing",
          "excerpts": [
            "Missing: per unit"
          ]
        },
        {
          "title": "QNX license cost discussion on Reddit",
          "url": "https://www.reddit.com/r/embedded/comments/1e72fip/qnx_license_cost/",
          "excerpts": [
            "There are a few places that are indicating that the dev platform license is ~$15k/yr. QNX license cost? : r/embedded"
          ]
        },
        {
          "title": "What Is DO-178C? - Wind River Systems",
          "url": "https://www.windriver.com/solutions/learning/do-178c",
          "excerpts": [
            "It is the standard that directs software certification for airborne systems for the commercial segment. (Its ramifications for military aerospace will be ...",
            "DO-178C, Software Considerations in Airborne Systems and Equipment Certification, is the principal certification document used by certification agencies ..."
          ]
        },
        {
          "title": "Your Complete DO-178C Guide to Aerospace Software Compliance",
          "url": "https://ldra.com/do-178/",
          "excerpts": [
            "DO-178C is a formal process standard that covers the complete software lifecycle – the planning process, development process, and integral processes."
          ]
        },
        {
          "title": "IEC Certification Kit (for ISO 26262 and IEC 61508)",
          "url": "https://www.mathworks.com/products/iec-61508.html",
          "excerpts": [
            "IEC Certification Kit provides tool classification and tool qualification work products, together with templates, certificates, and validation suites."
          ]
        },
        {
          "title": "Tool Qualification Support Package (TQSP)",
          "url": "https://ldra.com/products/tool-qualification-support-packs-tqsp/",
          "excerpts": [
            "A TQSP is an optional module available for the LDRA tool suite. Each TQSP module provides artefacts and guidance to simplify the process of qualifying the LDRA ..."
          ]
        },
        {
          "title": "DO-178C Intro, Compliance: Free Tools/ Papers / Resources - AFuzion",
          "url": "https://afuzion.com/do-178-introduction/",
          "excerpts": [
            "DO-178C (ED-12C in Europe) is a living document with continual changes including integration with the new ARP4761A and ARP4754B, plus new rules for multicore ..."
          ]
        },
        {
          "title": "IEC 61508 Functional Safety - TÜV SÜD Training Course",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/22-05-20-0101",
          "excerpts": [
            "IEC 61508: The Basic Functional Safety Standard ... This course qualifies for a 10% early-bird discount: Book 30+ days in advance and save on your registration!"
          ]
        },
        {
          "title": "IEC 61508 UL Certified Functional Safety Professional Training",
          "url": "https://www.ul.com/services/iec-61508-ul-certified-functional-safety-professional-training",
          "excerpts": [
            "This course is designed for engineers, developers and managers seeking to successfully apply IEC 61508 to their safety-related electrical systems."
          ]
        },
        {
          "title": "Data Plane Development Kit (DPDK) latency in Red Hat ...",
          "url": "https://www.redhat.com/en/blog/dpdk-latency-red-hat-openshift-1",
          "excerpts": [
            "Oct 11, 2023 — This article offers a comprehensive analysis of DPDK latency in single node OpenShift clusters and provides valuable insights into the performance of network ..."
          ]
        },
        {
          "title": "Kernel Bypass Techniques in Linux for High-Frequency Trading",
          "url": "https://lambdafunc.medium.com/kernel-bypass-techniques-in-linux-for-high-frequency-trading-a-deep-dive-de347ccd5407",
          "excerpts": [
            "Use Cases in HFT: DPDK's fast packet handling is perfect for building HFT trading systems that require extremely low latency. PF_RING ZC ..."
          ]
        },
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
          "url": "https://www.lynx.com/challenges/safety-certification",
          "excerpts": [
            "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
            "Delays in certification due to software non-compliance can be costly and de rail project timelines. Lynx empowers teams across industries with modular platforms, pre-certified components, and advanced tools to simplify compliance with DO-178C, ISO 26262, and IEC 61508. Deliver safer, certifiable systems faster and with greater confidence. Seize the Edge with Lynx to achieve 30% faster certification and reduce project complexity.",
            "pre-certified software components",
            "Backed by a track record of successful certifications, LynxSecure and LynxOS-178 deliver DO-178C and FAA RSC compliance while reducing project complexity.",
            "Safety-Critical GPU Solutions",
            "Empower your systems with our certifiable GPU solutions. Achieve high-performance graphics for avionics and automotive applications while maintaining ISO 26262 and DO-178C compliance.",
            "Advanced Vulnerability Management",
            "Ensure system integrity with Vigiles, the industry-leading tool for SBOM-based CVE triage and lifecycle vulnerability management, reducing false positives by 95%.",
            "Certification Consulting Services",
            "Leverage decades of experience in certification-compliant development with expert guidance tailored to DO-178C, ISO 26262, and IEC 61508 projects.",
            "Streamlining DO-178C Certification for Avionics",
            "Our pre-certified components and modular platforms reduce integration complexity and enable seamless compliance with DO-178C DAL A standards.",
            "Ensuring ISO 26262 Compliance in Automotive Systems",
            "ISO 26262 compliance isn’t just a checkbox—it’s the key to safe and reliable ADAS and autonomous systems. Lynx simplifies compliance with certifiable GPU compute solutions and pre-certified software components, ensuring your program stays on track and ahead of the competition.",
            "Streamlining IEC 61508 Certification for Industrial Systems",
            "From robotics to critical infrastructure, Lynx provides the tools to meet IEC 61508 certification requirements.",
            "30% faster certification",
            "Streamline processes and reduce certification timelines with modular pre-certified platforms like LynxSecure and LynxOS-178.",
            "95% Fewer False Positives",
            "Ensure accuracy in vulnerability management with Vigiles, reducing unnecessary manual triage."
          ]
        },
        {
          "title": "AMD Pensando™ DPU Technology",
          "url": "https://www.amd.com/en/products/data-processing-units/pensando.html",
          "excerpts": [
            "The AMD Pensando™ Giglio DPU builds on second-generation architecture with enhanced power and performance efficiency, delivering dual 200 Gbps line-rate offload ..."
          ]
        },
        {
          "title": "Compression Analysis for BlueField-2/-3 Data Processing ...",
          "url": "https://par.nsf.gov/servlets/purl/10538184",
          "excerpts": [
            "by Y Li · 2024 · Cited by 6 — Our study encompasses a comprehensive per- formance analysis of Nvidia BlueField DPUs, specifically focusing on one lossy (SZ34) and three."
          ]
        },
        {
          "title": "Economics And The Inevitability Of The DPU",
          "url": "https://www.nextplatform.com/2022/11/03/economics-and-the-inevitability-of-the-dpu/",
          "excerpts": [
            "Nov 3, 2022 — ... performance of the two ports on the DPU, at 49 Gb/sec. There is an obvious performance benefit, but this is more like getting the performance ..."
          ]
        },
        {
          "title": "Boosting Performance with SPDK and DPDK Solutions - Mirror Review",
          "url": "https://www.mirrorreview.com/spdk-and-dpdk-solutions/",
          "excerpts": [
            "Missing: RustHallows TCO Linux"
          ]
        },
        {
          "title": "Linux Kernel vs DPDK: HTTP Performance Showdown | talawah.io",
          "url": "https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/",
          "excerpts": [
            "Missing: RustHallows competitive"
          ]
        },
        {
          "title": "What is the Cost of a Real-time Operating System (RTOS)?",
          "url": "https://www.lynx.com/embedded-systems-learning-center/cost-of-a-real-time-operating-system-rtos",
          "excerpts": [
            "Generally speaking, purchasing a commercial RTOS will cost about $10K – $20K for the RTOS and one seat of development tools."
          ]
        },
        {
          "title": "RTOS | Wind River Studio",
          "url": "https://www.windriver.com/studio/edge-devices/real-time-os",
          "excerpts": [
            "Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat. Log in or create an account to get ..."
          ]
        },
        {
          "title": "LynxOS-178: Based on Open Standards",
          "url": "https://www.lynx.com/products/lynxos-178-do-178c-certified-posix-rtos",
          "excerpts": [
            "LynxOS-178 is a COTS RTOS supporting x86, Arm, and PowerPC platforms. It is based on open standards and is designed specifically to fulfill the stringent needs ..."
          ]
        },
        {
          "title": "Free Access to QNX SDP 8.0 for Non-Commercial Use",
          "url": "https://www.qnx.com/products/everywhere/",
          "excerpts": [
            "You are now able to get a free QNX SDP 8.0 license for your personal non-commercial use. You must first have a myQNX account which will allow you to access ..."
          ]
        },
        {
          "title": "GreenHills costs what and has Python 2.3? : r/embedded",
          "url": "https://www.reddit.com/r/embedded/comments/7kw1a3/greenhills_costs_what_and_has_python_23/",
          "excerpts": [
            "GreenHills costs what and has Python 2.3? ... I've mainly used WindRiver's diab and got moved to a certified project. It's my first experience ..."
          ]
        },
        {
          "title": "Licensing Information",
          "url": "http://licensing.qnx.com/info/",
          "excerpts": [
            "This folder contains PDF copies of QNX licensing documents associated with QNX Software Development Platform versions 7.x and 8.0, and associated compatible ..."
          ]
        },
        {
          "title": "VxWorks Reviews in 2025",
          "url": "https://sourceforge.net/software/product/VxWorks/",
          "excerpts": [
            "$18,500 / seat. Pricing Details: Now you can buy up to three seats of VxWorks online in the U.S., Canada, Europe, and Japan, starting at $18,500 per seat."
          ]
        },
        {
          "title": "ISO 26262 Functional Safety Training & Certification Program",
          "url": "https://www.tuvsud.com/en-us/store/academy-us/transportation-industry/safety/36-34-20-0006",
          "excerpts": [
            "Course Agenda. The certified Functional Safety according to ISO 26262 is a training spanned across 4 and a half days comprising of the following: Day 1 - ..."
          ]
        },
        {
          "title": "IEC 61508: A comprehensive guide to functional safety ...",
          "url": "https://spyro-soft.com/blog/industry-4-0/iec-61508",
          "excerpts": [
            "SIL 3: High level of safety integrity, with a significantly lower probability of failure than SIL 2. SIL 4: Highest level of safety integrity, ..."
          ]
        },
        {
          "title": "VxWorks Safety Platforms - Wind River Systems",
          "url": "https://www.windriver.com/products/vxworks/safety-platforms",
          "excerpts": [
            "An RTOS platform for safety-critical applications that require DO-178C, IEC 61508, or ISO 26262 certification evidence in the avionics, transportation, ..."
          ]
        },
        {
          "title": "DO-178C Explained",
          "url": "https://consunova.com/do-178c-explained/",
          "excerpts": [
            "Mar 31, 2024 — DO-178C defines five levels (A, B, C, D, and E) to classify the criticality of software functions based on their potential impact on aircraft ..."
          ]
        },
        {
          "title": "Guidance on Using IEC 61508 SIL Certification to Support ...",
          "url": "https://www.nrc.gov/docs/ML2130/ML21305A001.pdf",
          "excerpts": [
            "The SIL certification process involves manufacturers seeking compliance with IEC 61508, a separate entity called the CB that reviews the ..."
          ]
        },
        {
          "title": "How developers can leverage RTOS functional safety certification",
          "url": "https://www.embedded.com/how-developers-can-leverage-rtos-functional-safety-certification/",
          "excerpts": [
            "RTOS functional safety certification benefits not only safety-critical devices but all embedded devices as a means to improve time-to-market ..."
          ]
        },
        {
          "title": "How to get started with iso 26262 as a firmware developer?",
          "url": "https://www.reddit.com/r/embedded/comments/14icplp/how_to_get_started_with_iso_26262_as_a_firmware/",
          "excerpts": [
            "Your first step at estimating cost is to get a static analysis tool and find out how many warnings there are in your code base, and writing up a ..."
          ]
        },
        {
          "title": "Low Latency 5G UPF Using Priority Based Packet Classification",
          "url": "https://builders.intel.com/docs/networkbuilders/low-latency-5g-upf-using-priority-based-5g-packet-classification.pdf",
          "excerpts": [
            "SA UPF, developed by Intel and SK Telecom, shows improved performance in latency and jitter for high priority traffic while still running.",
            "Foundational NICs do not \ntypically offer offloads for functions \nsuch as vSwitch acceleration, VXLAN \nTEP or inline IPS",
            "They do, however, \noffer advanced features in order to \nscale the VNF performance by \noptimizing packet steering in the \nser",
            "Dynamic Device Personalization (DDP) \nis a capability that was introduced with \nIntel® Ethernet 700 Series Network \nAdapters to load an additional package \nto enable classification and steering of \nadditional specified packet types and \nperformance of additional inline \nact",
            "DDP can be used to optimize \npacket processing performance for \ndifferent network functions, native or \nrunning in a virtual environme",
            "By \napplying a DDP profile to the network \ncontroller the following use cases can \nbe address",
            "Extended support for protocols:\n\n• 5G GTP support for 5G user plane.",
            "• 5G SDAP/PDCP support for 5G NR\nuser plane.",
            "• 5G/4G PFCP (CP-UP separation)\nsupport.",
            "• IP protocols as new flow types, for\nexample L2TPv3, ESP/AH for\nIPSec.",
            "• Legacy protocols: PPPoE,\nPPPoL2TPv2.",
            "• New protocols/standards: eCPRI/\nORAN, Radio over Ethernet (RoE).",
            "• Extensibility for custom protocol\nparsing/classification.",
            "The Intel® Ethernet 800 Series provides \nthe capability to steer packets of \ndifferent priority into specific queue \ngroups as described in Figure 5",
            "software receiving and processing \n\npackets must be aware of the receive \nqueue priority mechanism to enable the \nefficient handling of high priority \npackets",
            "The User Plane Function (UPF) \napplication used in the context of this \nwork is based on the FD.io Vector Packet \nProcessor (VPP) framewo",
            "This \nframework utilizes Data Plane \nDevelopment Kit (DPDK) functionality to \nfetch received packets from the NIC \nqueues and deliver them for further \nproces",
            "The DPDK plugin is a part of \nthe VPP project that exposes packet \nreceive functionality over the dpdk-input \nno",
            "Default implementation of the \ndpdk-input node enables handling of \nmultiple RX queues in the context of a \nsingle worker thre",
            "re 6 implements \nstrict priority logic where packets from \nhigher priority queues are always \nfetched first and next priority queues \nare not served until all packets from \nhigh priority queues are in the \nprocessing stage."
          ]
        },
        {
          "title": "DOCA Perftest RDMA benchmarking tool",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Perftest/index.html",
          "excerpts": [
            "DOCA Perftest is an RDMA benchmarking tool designed for compute clusters, enabling fine-tuned evaluation of bandwidth, message rate, and latency. [Dependencies](.DOCAPerftestv3.0.0-Dependencies)",
            "  + CUDA 12.8 or later, required for GPUDirect RDMA benchmarks"
          ]
        },
        {
          "title": "DOCA Accelerated UPF Reference Application Guide",
          "url": "https://docs.nvidia.com/doca/sdk/DOCA+Accelerated+UPF+Reference+Application+Guide/index.html",
          "excerpts": [
            "The Accelerated UPF-RAP provides a reference implementation of an accelerated data path of UPF on top of the NVIDIA® BlueField-3®. Tas",
            "Tasks like GTP-U encapsulation/decapsulation, flow tagging, QoS enforcement, and packet forwarding are handled by the NIC, providing deterministic performance and scalability.",
            "Subsequent packets of that flow will be fully processed by Bluefiled-3 HW and forward to their destination without going through the host/UPF-RAP."
          ]
        },
        {
          "title": "performance | microkerneldude",
          "url": "https://microkerneldude.org/tag/performance/",
          "excerpts": [
            "And that means verified seL4 outperforms any microkernel. In almost all cases that's by about a factor of 10 in IPC latency. The closest in ..."
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "I'm Not Dead Yet!: The Role of the Operating System in a Kernel ...",
          "url": "https://dl.acm.org/doi/10.1145/3317550.3321422",
          "excerpts": [
            "This paper argues for a new high-level, device-agnostic I/O abstraction for kernel-bypass devices. We propose the Demikernel, a new library OS architecture for ..."
          ]
        },
        {
          "title": "seL4 Formal Verification Paper (SOSP 2009)",
          "url": "https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf",
          "excerpts": [
            ", is a third-generation\n\nmicrokernel, and is broadly based on L4 [46] and  \ninfluenced by EROS [58].",
            "Complete formal verification is the only known way to guarantee that a system is free of programming errors.",
            "ts. We present seL4, a member of the L4 [46] microker-\n\nnel family, designed to provide this ultimate degree  \nof assurance of functional correctness by machine-  \nassisted and machine-checked formal proof.",
            "e  \nshown the correctness of a very detailed, low-level  \ndesign of seL4 and we have formally verified its C  \nimplementation.",
            "To our knowledge, seL4 is the first-ever general-\n\npurpose OS kernel that is fully formally verified for  \nfunctional correctn"
          ]
        },
        {
          "title": "avionics application software standard interface part 0 overview of ...",
          "url": "https://www.sae.org/standards/content/arinc653p0-3/",
          "excerpts": [
            "The primary objective of ARINC 653 is to define a general-purpose APplication/EXecutive (APEX) interface (API = Application Program Interface)"
          ]
        },
        {
          "title": "[PDF] ARINC-653 Inter-partition Communications and the Ravenscar Profile",
          "url": "https://oa.upm.es/42418/1/INVE_MEM_2015_228287.pdf",
          "excerpts": [
            "The ARINC-653 standard [1] defines an inter-partition communication (IPC) mechanism that can be used to exchange messages between ARINC partitions running on ..."
          ]
        },
        {
          "title": "[PDF] ARINC 653",
          "url": "http://retis.sssup.it/~giorgio/slides/cbsd/cbsd-arinc-2p.pdf",
          "excerpts": [
            "ARINC 653 Services. ➢ Inter-partition communication. ▫ Communication between two or more partitions via messages;. ▫ Two types of communication services are ..."
          ]
        },
        {
          "title": "ARINC 653 on PikeOS - SYSGO",
          "url": "https://www.sysgo.com/arinc-653",
          "excerpts": [
            "The ARINC 653 standard specifies an operational environment for application software used in Integrated Modular Avionics (IMA) modules."
          ]
        },
        {
          "title": "avionics application software standard interface part 1 required ...",
          "url": "https://www.sae.org/standards/content/arinc653p1-5/",
          "excerpts": [
            "This standard defines a general-purpose Application/Executive (APEX) software interface between the Operating System of an avionics computer ..."
          ]
        },
        {
          "title": "[PDF] Using IOMMU for DMA Protection in UEFI Firmware - Intel",
          "url": "https://www.intel.com/content/dam/develop/external/us/en/documents/intel-whitepaper-using-iommu-for-dma-protection-in-uefi-820238.pdf",
          "excerpts": [
            "This paper proposes using IOMMU to resist DMA attacks in firmware, where bus mastering can allow malicious devices to access system memory."
          ]
        },
        {
          "title": "Single Root IO Virtualization (SR-IOV)",
          "url": "https://docs.nvidia.com/networking/display/OFED/Single+Root+IO+Virtualization+(SR-IOV)",
          "excerpts": [
            "Feb 29, 2024 — Single Root IO Virtualization (SR-IOV) is a technology that allows a physical PCIe device to present itself multiple times through the PCIe bus."
          ]
        },
        {
          "title": "IOMMU DMA Remapping - Windows drivers - Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/display/iommu-dma-remapping",
          "excerpts": [
            "IOMMU DMA remapping allows the GPU to access memory through logical addresses that are no longer mapped 1:1. Instead, Dxgkrnl is able to provide logically ..."
          ]
        },
        {
          "title": "Is it possible SR-IOV inside VM? : r/VFIO",
          "url": "https://www.reddit.com/r/VFIO/comments/1emladg/is_it_possible_sriov_inside_vm/",
          "excerpts": [
            "I have a Broadcom NIC with SR-IOV support and would like to create VFs inside the VM, i.e. pass PF to the VM with SR-IOV enabled."
          ]
        },
        {
          "title": "Kernel DMA Protection | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/kernel-dma-protection-for-thunderbolt",
          "excerpts": [
            "Learn how Kernel DMA Protection protects Windows devices against drive-by Direct Memory Access (DMA) attacks using PCI hot plug devices."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "Key Benefits of io_uring. Reduced Overhead: Batched submissions and completions cut system calls drastically.",
            "Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir )",
            "Completion Queue (CQ) : The kernel posts results as Completion Queue Entries (CQEs).",
            "scribe\nThis design minimizes system calls and context switches. Instead of invoking a syscall per operation, the kernel polls the SQ for new entries, while user space checks the CQ for completions — enabling true asynchronous processing.",
            "Key Benefits of io_uring",
            "* Reduced Overhead : Batched submissions and completions cut system calls drastically.",
            "* Versatility : Supports files, sockets, pipes, and even filesystem operations (e.g.,\nmkdir ).",
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency.",
            "* Ease of Use : The\nliburing library simplifies setup and management."
          ]
        },
        {
          "title": "Put an io_uring on it - Exploiting the Linux Kernel",
          "url": "https://chomp.ie/Blog+Posts/Put+an+io_uring+on+it+-+Exploiting+the+Linux+Kernel",
          "excerpts": [
            "It can be particularly useful for applications that are server/backend related, where a significant proportion of the application time is spent waiting on I/O."
          ]
        },
        {
          "title": "The IOMMU Impact - I/O Memory Management Units",
          "url": "https://medium.com/@mike.anderson007/the-iommu-impact-i-o-memory-management-units-feb7ea95b819",
          "excerpts": [
            "The IOMMU serves as a hardware abstraction layer that provides device isolation, memory protection, and address translation, much like how a traditional Memory Management Unit (MMU) governs virtual memory for CPUs.",
            "IOMMUs abstract this dependency by allowing devices to use I/O virtual addresses.",
            "IOMMU enforces **isolation** between devices and memory regions, a critical security feat",
            "In systems without an IOMMU, a misbehaving or compromised device could write to arbitrary memory regions, leading to system crashes, data leaks, or privilege escalation.",
            "These faults are invaluable for debugging DMA-related issues and for building **resilient systems** that can withstand partial hardware or software failures without complete system cras",
            "SR-IOV takes this a step further by allowing a single physical device to expose multiple **Virtual Functions (VFs)** — lightweight virtual devices that can be independently assigned to different ",
            "Intel VT-d",
            "AMD-Vi (IOMMU)",
            "ARM’s equivalent is the **System Memory Management Unit (SMM",
            "M’s SMMU enables secure execution environments, supporting trusted execution, real-time processing, and virtualization on low-power hardware.",
            "While IOMMUs introduce security and flexibility, they can also add **latency** to I/O operations due to address translation overhead. To mitigate this, modern IOMMUs use **Translation Lookaside Buffers (IOTLBs)** to cache recent address mappings, much like C"
          ]
        },
        {
          "title": "Design Guidelines for High Performance RDMA Systems",
          "url": "https://www.usenix.org/system/files/login/articles/login_fall16_07_kalia.pdf",
          "excerpts": [
            "Queue pairs: RDMA hosts communicate by posting verbs to interfaces called queue pairs (QPs). On completing a verb, the requester's NIC optionally signals ..."
          ]
        },
        {
          "title": "Planning for GPUDirect Storage - IBM",
          "url": "https://www.ibm.com/docs/en/storage-scale/5.2.1?topic=considerations-planning-gpudirect-storage",
          "excerpts": [
            "Supported hardware · GDS clients: x86 with a GPU model that supports GDS. For more details, see NVIDIA GDS documentation. · Network: EDR or HDR InfiniBand, ..."
          ]
        },
        {
          "title": "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified!",
          "url": "https://www.reddit.com/r/rust/comments/17qi9v0/its_official_ferrocene_is_iso_26262_and_iec_61508/",
          "excerpts": [
            "Ferrocene is upstream rustc but with some extra targets, long term support, and qualifications so you can use them in safety critical contexts."
          ]
        },
        {
          "title": "ECDSA Attestation with Intel Software Guard Extensions ...",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/quote-verification-attestation-with-intel-sgx-dcap.html",
          "excerpts": [
            "In this article, we'll demonstrate a remote attestation using the sample code from the Intel SGX DCAP source code repository."
          ]
        },
        {
          "title": "Arrakis: The Operating System Is the Control Plane",
          "url": "https://dl.acm.org/doi/10.1145/2812806",
          "excerpts": [
            "We have designed and implemented a new operating system, Arrakis, that splits the traditional role of the kernel in two."
          ]
        },
        {
          "title": "IX: A Protected Dataplane Operating System for High ...",
          "url": "https://web.eecs.umich.edu/~sugih/courses/eecs589/f16/39-ChunYu+Xinghao.pdf",
          "excerpts": [
            "by A Belay · Cited by 629 — In this paper, the authors introduce a new approach to improve the throughput and reduce the latency with a customized dataplane operating system, called IX ..."
          ]
        }
      ],
      "reasoning": "The field value aggregates explicit references to foundational and inspirational technologies that shape the RustHallows concept. Excerpts clearly identify seL4 as a high-assurance microkernel with capabilities-based access control and formal verification, which maps to the field's first item about a capability-based kernel and strong isolation. Several excerpts discuss ARINC 653 and partitioning concepts (Horcrux Partitions) as deterministic time/space partitioning models, aligning with the field's ARINC 653 inspiration. Arrakis and IX papers illustrate kernel-bypass I/O architectures, including moving the data plane into user space and separating control, aligning with the Field's Arrakis/IX inspiration. The Shinjuku/Shenango/Caladan family is documented as microsecond-scale schedulers and their coordination with low-latency dataplanes, matching Time-Turner Scheduler in the field value. io_uring appears as a modern Linux I/O interface enabling zero-copy, shared-ring data paths, matching Hallows Rings. DPDK and SPDK are cited as user-space, kernel-bypass I/O stacks for NIC/storage, aligning with Floo Network and Gringotts components. GPUDirect Storage and related GPUDirect RDMA/DMA mechanisms are described in several GPUDirect Storage references, including NIC-to-GPU direct data paths, aligning with Nimbus 2000. NVMe Zoned Namespaces and zone append operations are described in NVMe ZNS specifications, Gringotts ZNS, and related docs, matching Gringotts/ZNS loglets. CHERI/Morello/CHERIoT are discussed as hardware capability architectures enabling compartmentalization and memory safety, mapping to Fidelius/Horcrux FCUs. Intel SGX and TrustZone as TEEs are mentioned in the context of enclaves and attestation, aligning with FerFel (Fidelius) and related toolchains. Ferrocene is shown as a Rust toolchain qualified for safety certifications, mapping to Hermione. Apache Arrow, Arrow C Data Interface, and zero-copy data sharing are described, aligning with Pensieve/Goblins Ledger concepts. Overall, the excerpts collectively substantiate each technology listed in the fine-grained field value, with strongest support found in direct technical descriptions of each technology and its role in the stack. Confidence is high because the field value components are directly instantiated by multiple excerpts and are not contradicted by others. The most relevant excerpts are those that explicitly describe seL4 and its capabilities-based isolation, ARINC 653, Arrakis/IX, Shinjuku/Shenango/Caladan schedulers, io_uring, DPDK/SPDK, GPUDirect Storage, NVMe ZNS, CHERI/Morello/CHERIoT, SGX/TrustZone, Ferrocene, and Apache Arrow, followed by excerpts that discuss these items in the context of the stack's architecture and safety assurances.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.8",
      "citations": [
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "In addition, the MCS configuration of seL4 has a scheduling model that supports the kind of temporal isolation that is required for supporting mixed-criticality ..."
          ]
        },
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky · Cited by 417 — In this paper, we show that a general- purpose RPC library called eRPC can provide state-of-the-art performance on commodity datacenter networks without."
          ]
        },
        {
          "title": "eRPC - Low latency and performance metrics",
          "url": "https://github.com/erpc-io/eRPC",
          "excerpts": [
            "Low latency: 2.3 microseconds round-trip RPC latency with UDP over Ethernet\n    * Performance for small 32-byte RPCs: ~10M RPCs/sec with one CPU core,\n60--80M RPCs/sec with one"
          ]
        }
      ],
      "reasoning": "The most directly relevant content describes a networking stack that emphasizes RDMA-enabled cross-host RPC fabrics and user-space dataplanes. One excerpt explains a Floo-Network style setup with a userspace NIC dataplane and a cross-host RPC fabric that can employ a RDMA transport, which aligns with the idea of Portkeys/Floo-RDMA providing an ultra-low-latency path for memory-access and inter-service communication. The RDMA concept is further reinforced by excerpts that discuss FaRM-style remote memory and one-sided RDMA, which illustrate direct memory access to remote memory without CPU involvement and the associated latency benefits. Additionally, general RPC frameworks for datacenters (eRPC) are cited as high-performance RDMA-enabled RPC systems, underscoring the role of RDMA in achieving low latency and high throughput. Finally, another excerpt explicitly cites RDMA in the context of kernel-bypass networking and high-performance data paths, reinforcing that RDMA is a core mechanism for bypassing traditional kernel stacks to achieve near-zero-copy, low-latency memory access across machines. Taken together, these excerpts support the field value by illustrating a concrete RDMA-based memory-path paradigm, its role in cross-host RPC fabrics, and its place within user-space dataplanes and zero-copy data movement ecosystems.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.13",
      "citations": [
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency .",
            "Just raw, zero-copy data movement at high speed. Temporal keeps workflows running smoothly. Arrow Flight keeps data moving without friction. ..."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface.html",
          "excerpts": [
            "Make it easy for third-party projects to implement support for (including partial\n  support where sufficient), with little initial investment. * \n  Allow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process. * \n  Match the Arrow array concepts closely to avoid the development of\n  yet another marshalling layer.",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow format.",
            "Expose an ABI-stable interface.",
            "llow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process.",
            "Zero-copy by design.",
            "The Arrow C data interface is inspired by the [Python buffer protocol](https://www.python.org/dev/peps/pep-3118/) ,\nwhich has proven immensely successful in allowing various Python libraries\nexchange numerical data with no knowledge of each other and near-zero\nadaptation cost.",
            "Allow zero-copy sharing of Arrow data between independent runtimes and components running in the same process. Match the Arrow array concepts closely to ..."
          ]
        },
        {
          "title": "Powered by | Apache Arrow",
          "url": "https://arrow.apache.org/powered_by/",
          "excerpts": [
            "Uses Arrow to efficiently store Python data structures containing large arrays of numerical data. Data can be accessed with zero-copy by multiple processes ..."
          ]
        },
        {
          "title": "Insights from paper: Apache Arrow DataFusion",
          "url": "https://www.hemantkgupta.com/p/insights-from-paper-apache-arrow",
          "excerpts": [
            "Aug 11, 2024 — Apache Arrow DataFusion is a fast, embeddable, and extensible query engine. It is written in Rust programming language and uses Apache Arrow as its memory ..."
          ]
        },
        {
          "title": "arrow-rs/arrow/examples/zero_copy_ipc.rs at main",
          "url": "https://github.com/apache/arrow-rs/blob/main/arrow/examples/zero_copy_ipc.rs",
          "excerpts": [
            "Zero copy in this case means the Arrow arrays refer directly to a user //! ... Arrow `Buffer` to back the arrow arrays. We // do this by first creating a ..."
          ]
        },
        {
          "title": "arrow2 - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/arrow2/0.4.0",
          "excerpts": [
            "fbs. MUST lay out memory according to the arrow specification; MUST support reading from and writing to the C data interface at zero-copy."
          ]
        },
        {
          "title": "arrow::buffer - Rust",
          "url": "https://docs.rs/arrow/latest/arrow/buffer/index.html",
          "excerpts": [
            "A MutableBuffer is Arrow's interface to build a Buffer out of items or slices of items. NullBuffer: A BooleanBuffer used to encode validity for Arrow arrays ..."
          ]
        },
        {
          "title": "Event-driven Applications | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/learn-flink/event_driven/",
          "excerpts": [
            "A ProcessFunction combines event processing with timers and state, making it a powerful building block for stream processing applications."
          ]
        },
        {
          "title": "Mutiny - Flow control and Back-pressure - Quarkus",
          "url": "https://quarkus.io/blog/mutiny-back-pressure/",
          "excerpts": [
            "This post described the different approaches offered by Mutiny to handle back-pressure. The Reactive Streams protocol works well when you can control the pace ..."
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on Apache Arrow as an in-memory, columnar data format optimized for zero-copy sharing across systems and languages, with inspiration from Pensieve/Goblins Ledger. Excerpts that explicitly name Arrow as a columnar in-memory format establish the core description of Arrow's data layout and its performance characteristics. The cited material that specifically calls out the Arrow C Data Interface shows how data can be shared without copies between runtimes, which directly supports the zero-copy sharing aspect. Excerpts describing the Arrow C Data Interface in detail—its small, stable C definitions, the ability to export Arrow data structures across languages, and the emphasis on zero-copy sharing—provide concrete evidence for the zero-copy, cross-language data sharing claim. Additional excerpts that discuss Arrow integrations in Rust (e.g., Rust bindings like arrow-rs/arrow2, and DataFusion in Arrow's Rust ecosystem) corroborate the ecosystem's cross-language and high-performance analytics use, aligning with the \"Pensieve / Goblins' Ledger\" inspiration note. The inclusion of Arrow-related materials about Arrow Columnar Format further supports the columnar, analytical data layout aspect, reinforcing how Arrow enables efficient analytics workloads. Taken together, these excerpts directly substantiate the field value's assertion about Arrow's role, data layout, zero-copy sharing capabilities, and cross-language ecosystem connections. The strongest, direct matches are those stating \"Arrow is a columnar format designed for zero-copy data sharing\" and \"The Arrow C Data Interface enables zero-copy data transfers between runtimes,\" followed by evidence of Arrow in Rust contexts and Arrow DataFusion usage.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.7",
      "citations": [
        {
          "title": "cuFile Compatibility Mode - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/cuda/archive/11.4.0/gds/api-reference-guide/topics/cufile-compatibility.html",
          "excerpts": [
            "The cuFile library provides a mechanism for cuFile reads and writes to use compatibility mode using POSIX pread and pwrite APIS respectively to system memory ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "GDS cuFile API",
          "url": "https://training.continuumlabs.ai/infrastructure/storage/introduction-to-nvidia-gpudirect-storage-gds/gds-cufile-api",
          "excerpts": [
            "Jun 27, 2024 — The cuFile APIs are most effective in scenarios where there is a need for high-performance data transfer between GPU memory and storage."
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "GPU buffers need to be exposed to third-party devices to enable DMA by those devices. The set of pages that\nspan those buffers in the GPU virtual address space need to be mapped to the Base Address Register (BAR) space,\nand this mapping is an overhead. The mechanism to accomplish this mapping is called registration. Explicit GPU buffer registration with the `cuFileBufRegister` API is optional.",
            "If a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer. The following table and IO pattern descriptions provide guidance on whether registration is profitable."
          ]
        }
      ],
      "reasoning": "Direct GPUDirect Storage (GDS) establishes a direct DMA path between GPU memory and storage, bypassing CPU RAM and the CPU, which directly aligns with the field's description of a direct data path from storage devices to GPU memory. The most relevant excerpt explicitly states Nimbus 2000 provides a GPU-direct path and mentions GPUDirect Storage as part of its design, illustrating the inspiration and practical realization of a direct NVMe-to-GPU pathway. Additional excerpts from NVIDIA documentation describe GDS as enabling a direct data path for DMA between GPU memory and storage, reinforcing the core claim. Other excerpts reinforce the GPUDirect Storage concept by detailing the CUDA/GDS ecosystem, cuFile APIs, and the server-side/driver components involved in enabling this direct path, further supporting the field value that such a direct path exists and is engineered to bypass CPU involvement. Collectively, these excerpts converge on the existence and architecture of GPUDirect Storage as a direct NVMe-to-GPU data path, with Nimbus 2000 serving as the inspiration and Nimbus-like design cues echoed in the GPUDirect Storage material. The top entries provide direct statements about GPUDirect Storage enabling a GPU-direct data path, while the surrounding entries expand on the specific APIs (cuFile), drivers, and NVIDIA documentation that operationalize the feature. ",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.1",
      "citations": [
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.11/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM ... Refresh expired {TCB info, PCK CRLs, QE Identity, QvE Identity,. Root CA CRL} ..."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant material defines and discusses ARINC 653 and its use in avionics partitioning. One excerpt explicitly presents ARINC 653 as a standard for inter-partition communication and as a framework for space and time partitioning in avionics, which aligns with the idea of fixed partitions and deterministic scheduling needed by safety-critical systems. Another excerpt surveys ARINC 653 in the context of health monitoring and fault management, illustrating how partitioned environments are coupled with reliability and safety considerations in real-world avionics software. A third excerpt foregrounds ARINC 653 in the context of health monitoring and recovery within an avionic software stack, reinforcing the partitioning paradigm as a foundational architectural element. Additional excerpts discuss ARINC 653 in more general terms (e.g., architecture guides, inter-partition communications) and provide broader context on ARINC 653 configuration and scheduling, which supports the idea of fixed, partitioned execution environments central to the field value. The Arrakis/IX style discussions and other avionics-oriented sources, while not always naming ARINC 653 explicitly, reinforce the practical importance of partitioning, real-time guarantees, and health monitoring in avionics-like environments, thus providing contextual support for the field value. Overall, the most persuasive support comes from excerpts that explicitly describe ARINC 653 as a standard for space/time partitioning and from those that tie ARINC 653 to health monitoring and deterministic partitioning concepts relevant to Horcrux-like partitioning models. ",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.2",
      "citations": [
        {
          "title": "USENIX OSDSI 2014 Arrakis/IX paper",
          "url": "https://www.usenix.org/sites/default/files/osdi14_full_proceedings.pdf",
          "excerpts": [
            "The Arrakis operating system is based upon a fork of the\n\nBarrelfish [10] multicore OS code base",
            "The interface between an application and the Arrakis\n\ncontrol plane is used to request resources from the system\n\nand direct I/O flows to and from user program",
            "Doorbells are exposed to\n\nArrakis programs via regular event delivery mechanisms\n\n(e.g., a file descriptor event) and are fully integrated\n\nwith existing I/O multiplexing interfaces (e.g., selec",
            "We extended Barrelfish with support for SR-IOV, which\n\nrequired modifying the existing PCI device manager to rec-\n\nognize and handle SR-IOV extended PCI capabilit"
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        },
        {
          "title": "The IX Operating System: Combining Low Latency, High ...",
          "url": "https://dl.acm.org/doi/10.1145/2997641",
          "excerpts": [
            "We present ix, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ..."
          ]
        },
        {
          "title": "Benchmarking Tools",
          "url": "https://docs.sel4.systems/projects/sel4-tutorials/benchmarking-guide.html",
          "excerpts": [
            "During each context switch, the kernel adds how long the current thread has run before being switched, and resets the start time for the next thread. The in ..."
          ]
        },
        {
          "title": "Mutiny - Flow control and Back-pressure - Quarkus",
          "url": "https://quarkus.io/blog/mutiny-back-pressure/",
          "excerpts": [
            "This post described the different approaches offered by Mutiny to handle back-pressure. The Reactive Streams protocol works well when you can control the pace ..."
          ]
        }
      ],
      "reasoning": "Direct Arrakis references describe the system as Arrakis: The Operating System is the Control Plane, highlighting Arrakis's approach to exposing I/O resources to applications while using SR-IOV and IOMMU to manage access. The Arrakis papers outline the control-plane interface that applications use to request resources and direct I/O flows, which aligns with the idea of moving the dataplane to user space while preserving kernel control for policy. This directly supports the field value's claim about Arrakis moving the I/O datapath to user space and granting applications protected access to hardware queues, with policy in the kernel.\n\nThe IX operating system papers describe a dataplane OS designed for very low latency and high throughput, focusing on zero-copy, direct device interaction, and kernel-bypass style data paths. This contextualizes Arrakis as part of a broader research lineage that explores moving dataplanes into user space to achieve tight performance guarantees while maintaining isolation and control via the kernel. Accordingly, IX-based material substantiates the description of a research-driven, high-performance, kernel-bypass dataplane pattern that Arrakis exemplifies or participates in.\n\nCollectively, these excerpts support the field value by (a) naming Arrakis as a dataplane-focused OS with user-space IO access and (b) aligning IX with similar kernel-bypass, high-performance dataplane design goals. The most direct Arrakis content provides concrete evidence of moving data paths to user space and exposing hardware queues to applications under kernel-managed policies, while the IX materials reinforce the general architectural philosophy of ultra-low latency data planes and direct device access.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.9",
      "citations": [
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized ...",
          "url": "https://semiconductor.samsung.com/news-events/news/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Samsung Electronics, today unveiled its new enterprise solid-state drive (SSD) featuring Zoned Namespace (ZNS) technology — the PM1731a."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
          "url": "https://www.lynx.com/challenges/safety-certification",
          "excerpts": [
            "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems"
          ]
        }
      ],
      "reasoning": "The fine-grained field value asserts a definition of NVMe Zoned Namespaces (ZNS) as an NVMe command set that exposes media as zones requiring sequential writes, enabling data placement optimizations and tail-latency improvements. The clearest supporting excerpt provides a direct definition and context for ZNS, explaining that it defines zones and sequencing semantics, which underpins why ZNS can reduce write amplification and tail latency. The following excerpts reinforce the concept by reporting actual ZNS-enabled SSD products and their specifications: a Samsung PM1731a SSD with ZNS support illustrates real-world deployment of ZNS in NVMe storage; Western Digital Ultrastar DC ZN540 is another ZNS-enabled SSD example; and multiple excerpts discuss Samsung PM1731a and WD ZNS drives, grounding the concept in concrete hardware. Further corroboration comes from a separate excerpt explicitly describing the ZNS concept and its purpose (addressing write amplification and tail latency), which aligns with the field value's description. The additional excerpts mentioning ZNS-related benchmarks or benchmarks of ZNS-enabled storage further support the practical impact of ZNS in storage systems. Taken together, these excerpts collectively validate the existence, hardware embodiments, and intended benefits of ZNS in NVMe, consistent with the field value. The excerpts about ZNS in various vendors' products and explicit definitions are the most technically aligned, while related but broader topics (e.g., GPUDirect or io_uring) provide peripheral context but do not directly substantiate the ZNS definition itself.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.6",
      "citations": [
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "Missing: RustHallows competitive landscape",
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "[HELP] Nvidia GPUDirect storage benchmark for an AI400 ...",
          "url": "https://www.reddit.com/r/HPC/comments/qni6cs/help_nvidia_gpudirect_storage_benchmark_for_an/",
          "excerpts": [
            "We are supposed to benchmark the GPU direct storage performance however I cannot seem to find the appropriate benchmarking tool to use."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly identifies SPDK as Storage Performance Development Kit, a library for high-performance NVMe storage that operates in user space to bypass kernel involvement. This precisely aligns with the fine-grained field value describing SPDK as a set of libraries and poll-mode drivers for high-performance I/O that bypasses the kernel, and it notes the Gringotts inspiration as part of the architecture. The next set of excerpts provide explicit mentions of SPDK in a straightforward way, reinforcing its role as a user-space storage toolkit and its prominence in performance-oriented storage discussions. Then, several excerpts discuss SPDK in the context of performance updates, underscoring SPDK's practical impact on storage throughput and latency measurements. These latter excerpts support the field value by illustrating SPDK's real-world performance implications, even if they are not literal SPDK feature descriptions. Finally, excerpts that discuss SPDK alongside broader kernel-bypass technologies (e.g., GPUDirect Storage or io_uring) help situate SPDK within the ecosystem of high-performance I/O but do not directly define SPDK themselves; they are useful for context but less directly supportive of the exact field value.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.4",
      "citations": [
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ...",
            "A Key Distinction: Unlike full kernel bypass solutions like DPDK, io_uring ZC Rx still processes packet headers through the kernel's TCP stack."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency."
          ]
        },
        {
          "title": "The IOMMU Impact - I/O Memory Management Units",
          "url": "https://medium.com/@mike.anderson007/the-iommu-impact-i-o-memory-management-units-feb7ea95b819",
          "excerpts": [
            "The IOMMU serves as a hardware abstraction layer that provides device isolation, memory protection, and address translation, much like how a traditional Memory Management Unit (MMU) governs virtual memory for CPUs."
          ]
        }
      ],
      "reasoning": "The target field describes io_uring as a Linux asynchronous I/O interface using shared submission and completion rings, enabling near-zero overhead and high-throughput I/O. The most directly supportive material states io_uring provides zero-copy reception at the network path, explicitly describing how data can flow directly into user space without kernel copies. This aligns with the field's emphasis on low overhead and zero-copy data movement in I/O paths. A companion discussion presents a deeper dive into io_uring's zero-copy networking implications, reinforcing that the core mechanism enables zero-copy transfers and reduces syscall overhead, which is central to the field value. Additional excerpts discuss io_uring in conjunction with zero-copy at the networking layer and when paired with user-space data paths, further validating the core concept of shared rings enabling efficient, low- overhead IO. A broader set of excerpts elaborates on io_uring's performance benefits and its role in modern, high-throughput stacks, which corroborates the described architecture's goals for 10-40x perf through kernel-bypass-inspired design choices. Collectively, these excerpts support the field value by (a) naming io_uring as the key interface, (b) describing its ring-based, kernel-bypass-friendly zero-copy potential, and (c) connecting it to high-performance I/O stacks analogous to Hallows Rings-inspired design ideas.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.10",
      "citations": [
        {
          "title": "The CHERI capability model: Revisiting RISC in an age of ...",
          "url": "https://ieeexplore.ieee.org/document/6853201",
          "excerpts": [
            "by J Woodruff · 2014 · Cited by 475 — We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection."
          ]
        },
        {
          "title": "CHERI OS-feature matrix",
          "url": "https://www.morello-project.org/cheri-feature-matrix/",
          "excerpts": [
            "Operating systems can implement CHERI software features along several axes. This table captures key axes, and describes the maturity of those features for ..."
          ]
        },
        {
          "title": "Arm Morello Program",
          "url": "https://www.arm.com/architecture/cpu/morello",
          "excerpts": [
            "Morello is a research program with the potential to radically change the way we design and program processors in the future to improve built-in security."
          ]
        },
        {
          "title": "Morello Prototype Architecture - Arm Developer",
          "url": "https://developer.arm.com/Architectures/Morello",
          "excerpts": [
            "The Morello architecture is a prototype CPU architecture that introduces a new approach to security and is part of the wider Morello program."
          ]
        },
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        },
        {
          "title": "Review the TPM measured boot log",
          "url": "https://developer.arm.com/documentation/107981/latest/SystemReady-compliance-testing---BBSR-and-Security-Interface-Testing-FAQ/How-do-I-test-for-Base-Boot-Security-Requirements--BBSR--compliance-/Review-the-ACS-test-result-logs/Review-the-TPM-measured-boot-log",
          "excerpts": [
            "Verify that the cumulative SHA256 measurements from the event log match the TPM PCRs 0-7. The events logged in the TPM event log must match the actual ..."
          ]
        },
        {
          "title": "IMA and EVM Concepts — IMA 1.0 documentation",
          "url": "https://ima-doc.readthedocs.io/en/latest/ima-concepts.html",
          "excerpts": [
            "The IMA-Appraisal feature is local, and requires neither a TPM nor a separate verifier. IMA-Audit augments the system's audit log with the file hash. This can ..."
          ]
        },
        {
          "title": "CHERIoT: a study in CHERI (RISCV.org blog)",
          "url": "https://riscv.org/blog/2024/08/cheriot-a-study-in-cheri/",
          "excerpts": [
            "CHERIoT provides a layered security model. At the core, CHERIoT provides object-granularity (spatial and temporal) memory safety.",
            "The hardware provides low-level guarantees, such as unforgeable pointers, the ability to ensure that pointers to marked memory regions cannot be used, and a lightweight way of making pointers into opaque tamper-proof tokens.",
            "Sealing a CHERI capability turns it into an opaque token. You can pass it around as you would any other pointer, but you cannot dereference or modify it.",
            "The seal operation takes another capability with a permit-seal permission and embeds the value of that capability in the *object type* of the sealed capabilit",
            "A CHERI capability can be stored in memory or in registers and is protected by *guarded manipulation*: Operations may reduce the rights that a capability conveys, but not increase the",
            "The tag bit is a simple attestation from the hardware that says that this capability was created by following these rules, starting with one of the all-powerful capabilities provided at boot and then constrained by layers of software in the system.",
            "CHERI capability, that can be used to represent pointers. These carry bounds and permissions, in addition to an address. A CHERI capability ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        },
        {
          "title": "Towards a Real-time Component Framework for Software ... - C3",
          "url": "https://c3.ndc.nasa.gov/dashlink/static/media/other/ISIS-TR-09-111.pdf",
          "excerpts": [
            "by A Dubey · Cited by 12 — ARINC-653 supports a health monitoring service at each layer (Partition/Module/System) which is configured by the user with the appropriate response (functions) ..."
          ]
        },
        {
          "title": "Model-driven development of ARINC 653 configuration ...",
          "url": "https://www.researchgate.net/publication/224202064_Model-driven_development_of_ARINC_653_configuration_tables",
          "excerpts": [
            "In the scope of the project, a tool chain was implemented that generates ARINC 653 configuration tables from high-level architecture models. The tool chain was ..."
          ]
        },
        {
          "title": "CHERI Software Compartmentalization",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-compartmentalization.html",
          "excerpts": [
            "The CHERI protection model provides a set of low-level primitives that enable scalable, fine-grained software compartmentalization.",
            "[CHERI-seL4](cheri-sel4.html)"
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI's capability system is blended with a conventional RISC\nusermode architecture without disrupting the majority of key design\ndecisions.",
            "CHERI is a hybrid capability system in several senses:",
            "CHERI capabilities are a low-level primitive usable for many purposes.",
            "The advent of the open RISC-V ISA provides us with a richer spectrum of\nbaseline processor designs, and as the architecture matures over time, we\nhope also a similarly rich software ecosystem."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "\nCHERI represents a new system design that blocks exploits. Architectural changes to the CPU and memory systems add integrity checks to pointers that prevent reading, writing, or executing from memory that is out of bounds or using corrupted pointers, the most common classes of severe vulnerabilities. CHERI is supported by a complete compiler toolchain, multiple operating systems, is open source, and already implemented for several different RISC CPUs including Arm’s recently released Morello prototype.",
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "Capabilities are created at boot time, and capabilities derived from these initial ones are more restrictive. The new instructions for manipulating capabilities also mean changing the instruction set architecture, or ISA.",
            " of CHERI architectures for MIPS, RISC-V, and Arm began with the Sail instruction set definition language. Sail generates sequential emulators, in C and OCaml, and theorem-prover definitions, in Coq, HOL4, and Isabelle, and SMT. These versions allow for both a means of testing in emulation and creating formal proofs of the correctness of the design.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        }
      ],
      "reasoning": "The CHERI family is introduced as a capability-based hardware model that replaces traditional pointers with capabilities, providing fine-grained bounds, permissions, and isolation. This directly supports the idea of hardware-enforced capabilities acting as precise memory protections and compartmentalization mechanisms. The Morello program is presented as an industrial demonstrator of CHERI, illustrating concrete paths to mainstream adoption and practical integration into Arm architectures. CHERIoT expands the CHERI concept into embedded contexts, showing how sealed capabilities and compartmentalization can be extended across devices and RTOS environments. The CHERI architecture overview and formal discussions outline how sealing, sentry capabilities, and boundary enforcement operate at the hardware level, which aligns with the proposed field value describing hardware-enforced capabilities that replace traditional pointers and enable strict isolation. Additional entries detail the CHERI-related software stacks, such as CHERI-enabled RTOS (CHERIoT) and CHERI-enabled OS features, reinforcing the ecosystem narrative of capabilities embedded in hardware and software layers. Citations describing the CHERI protection model, sealed capabilities, and how CHERI-based isolation underpins secure cross-compartment calls provide direct support for the field value's core claim. Contextual CHERI-related materials (including Morello platform references and CHERI FAQs) further corroborate the notion of hardware-enforced capabilities as a foundational technology and show its application in safety-critical and secure systems domains. The gathered excerpts collectively establish a chain from CHERI architectural primitive to practical implementations (Morello, CHERIoT) and concrete security/performance narratives that this fine-grained field value is capturing.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.5",
      "citations": [
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "I'm Not Dead Yet!: The Role of the Operating System in a Kernel ...",
          "url": "https://dl.acm.org/doi/10.1145/3317550.3321422",
          "excerpts": [
            "This paper argues for a new high-level, device-agnostic I/O abstraction for kernel-bypass devices. We propose the Demikernel, a new library OS architecture for ..."
          ]
        },
        {
          "title": "seL4 Formal Verification Paper (SOSP 2009)",
          "url": "https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf",
          "excerpts": [
            ", is a third-generation\n\nmicrokernel, and is broadly based on L4 [46] and  \ninfluenced by EROS [58]."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt explicitly describes Floo Network as a user-space NIC dataplane, with per-service virtual NICs, SR-IOV, IOMMU, and direct device access—precisely the kernel-bypass, user-space NIC stack idea that the finegrained field value names as a DP DK-like concept. Supporting evidence shows a broader ecosystem of kernel-bypass approaches (Arrakis lineage, Demikernel, IX) that share the same architectural theme: moving NIC datapath into user space, enabling zero-copy and reduced syscall overhead. Additional excerpts discuss io_uring-based zero-copy reception and general discussions of bypassing kernel NIC stacks to achieve high throughput with low latency, further corroborating the same design space described by the field value. Together, these excerpts establish a coherent mapping from the DP DK concept to concrete, cited realizations in the excerpts (Floo Network inspiration, kernel bypass, and Arrakis/IX line of research). The included material also references related performance mechanisms (SR-IOV, DMA, and GDS) that align with a high-performance, kernel-bypass data path, reinforcing the association.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.11",
      "citations": [
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        },
        {
          "title": "arXiv:1801.05863 - Design and Implementation of RA-TLS for Intel SGX Enclaves",
          "url": "https://arxiv.org/pdf/1801.05863",
          "excerpts": [
            "e propose to\n\ninclude additional information into the X.509\n\ncertificate exchanged during a TLS handshake",
            "**Attestation Verification Report. ** This is the reply\n\nreceived from the Intel Attestation Service (IAS) when\n\nsubmitting a quote for verification [10]. IAS reports\n\nwhether the quote was generated on a genuine Intel\n\nSGX platform by a genuine encl",
            "**Attestation Verification Report Signature. ** The\n\nattestation verification report is signed by IAS. The\n\nsignature ensures that report is authentic and\n\nunmodifi",
            "**Attestation Report Signing Certificate. ** To verify the\n\nsignature over the attestation report, the client must\n\nknow the keys used to create the signatur",
            "**Non-standard X.509 extensions. ** We embed the SGX\n\nidentity information in custom X.509 extensions",
            "**Quoting Enclave Identity. ** The latest identity of Intel’s\n\nquoting enclave including its code measurement and\n\nsecurity versions number"
          ]
        },
        {
          "title": "Reusable Infrastructure for Linearizability(RIFL)",
          "url": "https://www.linkedin.com/pulse/reusable-infrastructure-linearizabilityrifl-hohuan-chang",
          "excerpts": [
            "RIFL aims to solve linearizability problems on large scale distributed systems by providing \"exactly once\" delivery. In fact that thing is not ..."
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Remote attestation Implementation - BlindAI - Mithril Security",
          "url": "https://blindai.mithrilsecurity.io/en/latest/docs/security/remote_attestation/",
          "excerpts": [
            "The first one, is EPID attestation which relies on using Intel services to attest that an enclave on specific platforms is verified. The second one is DCAP ( ..."
          ]
        },
        {
          "title": "GlobalPlatform Entity Attestation Protocol Specification",
          "url": "https://globalplatform.org/wp-content/uploads/2024/07/GPP_EntityAttestationProtocolSpec_v0.0.0.26_PublicRvw2.pdf",
          "excerpts": [
            "Remote Attestation \nThe process by which attestation information is assembled by an Entity \nAttestation Service, transferred to a Relying Party, and processe",
            "The IETF NNNN specification ([draft-ietf-rats-eat]) introduces the concept of Attestation, which is a mechanism \n45 \nby which an Entity can provide information about itself with some level of assurance to a Relying Par",
            "During Attestation, an Entity \n47 \nAttestation Service builds a set of Claims, each of which consists of a piece of evidence provided by a Clai"
          ]
        },
        {
          "title": "seL4: formal verification of an OS kernel",
          "url": "https://cseweb.ucsd.edu/~dstefan/cse227-spring20/papers/sel4.pdf",
          "excerpts": [
            "by G Klein · 2009 · Cited by 3032 — ABSTRACT. Complete formal verification is the only known way to guar- antee that a system is free of programming errors."
          ]
        },
        {
          "title": "The seL4 Microkernel An Introduction",
          "url": "https://cdn.hackaday.io/files/1713937332878112/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 1 — This white paper gives an overview of seL4. ... In a capability-based system, such as seL4, invoking a capability is the one and only way."
          ]
        },
        {
          "title": "Introduction to SGX - Gramine documentation - Read the Docs",
          "url": "https://gramine.readthedocs.io/en/stable/sgx-intro.html",
          "excerpts": [
            "The Provisioning Certification Enclave is used in DCAP based remote attestation. This enclave communicates with the Intel Provisioning Certification Service ( ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.11/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM ... Refresh expired {TCB info, PCK CRLs, QE Identity, QvE Identity,. Root CA CRL} ..."
          ]
        }
      ],
      "reasoning": "The explicit reference to a hardware-based trusted execution environment (TEEs) such as Intel SGX and ARM TrustZone aligns with excerpts that describe SGX/DCAP attestation chains, remote attestation workflows, and attestation verification services. In particular, a dedicated excerpt on Fidelius directly mentions protecting user secrets from compromised browsers, signaling a capability- or isolation-focused security primitive that inspires the field's described component. Related excerpts discuss Attestation Verification Reports signed by attestation services (IAS) and the flow of remote attestation evidence, which underpins how TEEs establish trust for processing sensitive data. Additional excerpts describe SOC-level or platform-wide attestation design guides (DCAP caching, QVE/IAS interactions) that illuminate how TEEs achieve secure enclaves and verifiable trust in practice. Together, these excerpts support the field value's claim that TEEs (Intel SGX and ARM TrustZone) are the hardware-based trust substrate, and that Fidelius serves as an inspiration for the secrets-protecting component within the architecture. The presence of RA-TLS discussions further corroborates how attestation outputs can be bound to secure communications with TEEs in a cryptographic, verifiable manner, which matches the field's emphasis on isolated, encrypted memory regions used for sensitive processing. The cited excerpts also cover the broader landscape of attestation tooling and verification (IAS, QVE, DCAP) that underpins a Fidelius-like design in the RustHallows context. In short, the strongest evidence ties Fidelius-inspired secrecy services to SGX/TrustZone-style TEEs and their attestation infrastructure, with additional context from RA-TLS and DCAP documentation to flesh out verification workflows and trust establishment.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.12",
      "citations": [
        {
          "title": "Ferrocene - ISO 26262 and IEC 61508 qualified rust compiler",
          "url": "https://lobste.rs/s/qhohlx/ferrocene_iso_26262_iec_61508_qualified",
          "excerpts": [
            "The aim is to ensure there's a formal chain of traceability that goes from everything an end user compiled to the features you tested and found ..."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more",
            "We’ve qualified\nFerrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database. ",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "This standard provides automakers\nwith guidelines that make the software being used to develop, produce, operate\nand service the automotive sectors safe to use.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene is ISO 26262 and IEC 61508 qualified!"
          ]
        },
        {
          "title": "Ferrocene: Qualified Rust toolchain for safety-critical systems",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Qualified for automotive, industrial and medical development. ... ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or ...See more",
            "ull qualification\ndocuments. [Read\nDocumentation](https://public-docs.ferrocene.dev/main/index.html)",
            "TÜV SÜD conducted the audit and Ferrous Systems – leading Rust experts – supports the signed installers as well as the nightly builds.",
            "The source code of Ferrocene is\nfully open source under the MIT OR Apache-2.0 license, including the full qualification\ndocuments.",
            "Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles. It’s qualified at ASIL-D, the highest risk class, for peace of mind.",
            "ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or your choice of RTOS.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels."
          ]
        },
        {
          "title": "Parasoft ISO 26262 Software Compliance Technical Whitepaper",
          "url": "https://alm.parasoft.com/hubfs/New_Pages/Whitepaper%20ISO%2026262%20Software%20Compliance%20With%20Parasoft.pdf",
          "excerpts": [
            "The information presented  here is intended to serve as an introduction to  ISO 26262 software verification and validation  processes with Paraso"
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on Ferrocene as a qualified Rust compiler toolchain for safety-critical contexts and its use in certifiable software development. The most decisive support comes from an excerpt stating that Ferrocene is a \"Qualified Rust toolchain for safety-critical systems\" and other excerpts explicitly noting ISO 26262/IEC 61508 qualification. Additional excerpts describe Ferrocene's status and its role in safety-certification workflows, including references to ISO 26262 and IEC 61508 qualification and the broader safety-certification narrative around Ferrocene, which aligns with the described use in the Hermione assurance pipeline. The earliest and most direct claim anchors Ferrocene as a safety-certified Rust toolchain, while subsequent excerpts reinforce the certification context and provide concrete standards (ISO 26262, IEC 61508). The alignment is strongest where Ferrocene is labeled as qualified and explicitly tied to safety standards; slightly weaker evidence comes from follow-on mentions of updates or related safety-certification discourse, but these still corroborate the main point that Ferrocene is a certifiable Rust toolchain used in safety contexts.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.1.technology_name",
      "citations": [
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        }
      ],
      "reasoning": "The fine-grained value identifies ARINC 653 as a foundational technology in the ARINC 653 ecosystem, which centers on partitioning, scheduling, and health/flight-critical system guarantees. The most directly relevant excerpt discusses ARINC 653 as a basis for partitioning strategies, certification considerations, memory management, fault tolerance, and testing in real-time avionics, which aligns with the core role of ARINC 653 in enforcing isolation and determinism. A closely related excerpt focuses on ARINC-653 partition scheduling design, highlighting how time allocation to partitions is static and cyclic, which directly ties to the scheduling aspect of ARINC 653. A third excerpt addresses ARINC 653 health monitoring and recovery, describing health actuation rules under system, partition, and application failures, which maps to the reliability and fault-management promises of ARINC 653. Together, these excerpts corroborate the field value by covering partitioning, static scheduling, and health monitoring, which are the key pillars of ARINC 653 as a foundational technology in safety-critical partitioned real-time systems.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.8.technology_name",
      "citations": [
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly references RDMA extensively, describing how RDMA enables reading data directly and writing into remote buffers, effectively bypassing the kernel and achieving high performance. This directly supports the field value by illustrating the core capability and its benefits in a data-path context. The next most relevant excerpt discusses one-sided RDMA verbs, which allow a compute server to access remote memory without involving the remote CPU, reinforcing the same RDMA mechanism and its performance advantages. While other excerpts discuss related fast networking and IPC techniques (eRPC and similar), they do not explicitly mention RDMA, making them less directly supportive of the specific field value. Together, these two excerpts provide clear, direct evidence that RDMA is a foundational technology discussed in the material and is central to the described high-performance data-path strategies.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.8.description",
      "citations": [
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        },
        {
          "title": "eRPC - Low latency and performance metrics",
          "url": "https://github.com/erpc-io/eRPC",
          "excerpts": [
            "Low latency: 2.3 microseconds round-trip RPC latency with UDP over Ethernet\n    * Performance for small 32-byte RPCs: ~10M RPCs/sec with one CPU core,\n60--80M RPCs/sec with one"
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky · Cited by 417 — In this paper, we show that a general- purpose RPC library called eRPC can provide state-of-the-art performance on commodity datacenter networks without."
          ]
        },
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "In addition, the MCS configuration of seL4 has a scheduling model that supports the kind of temporal isolation that is required for supporting mixed-criticality ..."
          ]
        }
      ],
      "reasoning": "The field value describes a networking technology that enables a host to directly access a remote host's memory without involving the remote CPU or OS, resulting in extremely low latency and high bandwidth. Excerpts that discuss direct access to remote memory and bypassing the remote CPU/OS directly support this claim. Specifically, one excerpt notes the use of RDMA extensively and describes reads/writes into remote buffers in a way that bypasses the kernel, which aligns with the idea of remote memory access without remote CPU involvement. Another excerpt explains that RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU, which is a precise articulation of the same concept. A third excerpt highlights a low-latency RPC framework with performance measurements, reinforcing the emphasis on high-performance, low-latency networking, which is complementary to the finegrained field value though not exclusively about remote memory bypass. Additional excerpts discuss fast datapath RPC and userspace networking stacks that resemble kernel-bypass, supporting the general theme of bypassing traditional OS pathways for performance, further corroborating the intended architecture. Taken together, these excerpts coherently support the notion of a networking technology enabling direct remote-memory access with minimal remote involvement and high performance. ",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.7.description",
      "citations": [
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "If a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer. The following table and IO pattern descriptions provide guidance on whether registration is profitable.",
            "GPU buffers need to be exposed to third-party devices to enable DMA by those devices. The set of pages that\nspan those buffers in the GPU virtual address space need to be mapped to the Base Address Register (BAR) space,\nand this mapping is an overhead. The mechanism to accomplish this mapping is called registration. Explicit GPU buffer registration with the `cuFileBufRegister` API is optional."
          ]
        },
        {
          "title": "GDS cuFile API",
          "url": "https://training.continuumlabs.ai/infrastructure/storage/introduction-to-nvidia-gpudirect-storage-gds/gds-cufile-api",
          "excerpts": [
            "Jun 27, 2024 — The cuFile APIs are most effective in scenarios where there is a need for high-performance data transfer between GPU memory and storage."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        }
      ],
      "reasoning": "The most relevant content directly states GPUDirect RDMA and GPUDirect Storage enable a direct data path between storage devices (NVMe/NVMe over Fabrics) and GPU memory, which is the core idea of the requested field value. The excerpts describing a direct data path between local/remote storage and GPU memory capture the primary claim about bypassing CPU/system RAM. Additional excerpts discuss cuFile APIs and best practices around registering GPU buffers, which are related to optimization and implementation, but the central claim about a direct storage-to-GPU path is best supported by the excerpts explicitly naming GPUDirect Storage and GPUDirect RDMA and their described data paths. The remaining excerpts add context about related NVIDIA storage/GPU integration facilities and practices, reinforcing the overall concept but not changing its core meaning.\n",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.7.technology_name",
      "citations": [
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "If a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer. The following table and IO pattern descriptions provide guidance on whether registration is profitable.",
            "GPU buffers need to be exposed to third-party devices to enable DMA by those devices. The set of pages that\nspan those buffers in the GPU virtual address space need to be mapped to the Base Address Register (BAR) space,\nand this mapping is an overhead. The mechanism to accomplish this mapping is called registration. Explicit GPU buffer registration with the `cuFileBufRegister` API is optional."
          ]
        },
        {
          "title": "GDS cuFile API",
          "url": "https://training.continuumlabs.ai/infrastructure/storage/introduction-to-nvidia-gpudirect-storage-gds/gds-cufile-api",
          "excerpts": [
            "Jun 27, 2024 — The cuFile APIs are most effective in scenarios where there is a need for high-performance data transfer between GPU memory and storage."
          ]
        },
        {
          "title": "cuFile Compatibility Mode - NVIDIA Docs Hub",
          "url": "https://docs.nvidia.com/cuda/archive/11.4.0/gds/api-reference-guide/topics/cufile-compatibility.html",
          "excerpts": [
            "The cuFile library provides a mechanism for cuFile reads and writes to use compatibility mode using POSIX pread and pwrite APIS respectively to system memory ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        }
      ],
      "reasoning": "The most relevant passages directly identify GPUDirect Storage as a technology enabling a direct data path between GPU memory (GPU memory) and storage or as part of GPUDirect RDMA/Storage capabilities. The first highly relevant passages explicitly name GPUDirect RDMA and GPUDirect Storage and discuss their role in enabling direct data paths (for example, a document describing GPUDirect RDMA and GPUDirect Storage and another document describing GPUDirect Storage as a direct data path between local or remote storage and GPU memory). Additional closely related excerpts discuss supporting components and mechanisms (such as cuFile APIs and buffer registration) that enable GPUDirect Storage functionality. Other excerpts describe best practices and related GDS tooling, which further corroborate the GPUDirect Storage ecosystem and its integration points. Taken together, these excerpts squarely support the field value of GPUDirect Storage within the specified path by demonstrating its role and context in GPU-storage direct-path data flows, APIs, and implementation details.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.3",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores.",
            "t preempt requests as often as every 5µsec",
            "\nFor the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores. For the many real-world scenarios where request service times follow distributions with high dispersion or a heavy tail, they allow short requests to be blocked behind long requests, which leads to poor tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The most compelling support comes from passages that explicitly discuss the Shinjuku scheduler and its μs-scale preemption capabilities, which anchors the target trio in concrete design work. The narrative frames Shinjuku as a scheduler capable of μs-scale preemption, which aligns with the field's emphasis on microsecond-scale performance. The same source also introduces the idea of a Time-Turner style scheduler as part of a design motif, signaling a conceptual link between fast, time-aware scheduling and the named schedulers. The next strongest support includes mentions of the triple-portfolio scheduling theme, where Shinjuku is described alongside Shenango and Caladan as part of a broader scheduling family; this triangulates the field's three schedulers as a cohesive research motif rather than isolated tools. Additional passages reinforce the trio's role by detailing Shenango's core reallocation for CPU efficiency and Caladan's role in mitigating interference between co-located tasks, which substantiate the field value's characterisation of the three components as a composite solution for tight temporal isolation and high throughput. Further excerpts extend the discussion to related scheduling ideas and benefits (e.g., frequent preemption, tail latency improvements, multi-core coordination) which provide supportive context for a Time-Turner-inspired, highly time-aware scheduling ecosystem. The surrounding material also mentions related concepts (e.g., policy blending, instrumentation-driven policy decisions) that complement the Time-Turner motif, reinforcing that the field value is about a time-centric orchestration of multiple schedulers rather than a single monolithic scheduler. In sum, the most relevant excerpts directly name Shinjuku and its μs-scale preemption, articulate Shenango's core-reallocation approach, and describe Caladan's interference-control role; they also explicitly name the Time-Turner concept as a coordinating or inspirational element in the scheduling landscape. The remaining excerpts contribute contextual scaffolding about related microkernel, dataplane, and scheduling research that underpins the main three-scheduler narrative but are somewhat less targeted to the exact trio and the Time-Turner linkage.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.0",
      "citations": [
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "Endpoints are used to perform protected function calls;",
            "Reply Objects represent a return path from a protected procedure call;",
            "Address Spaces provide the sandboxes around components (thin wrappers\nabstracting hardware page tables);"
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "formal verification in general is stronger than other\n   traditional ways of gaining trust in software such as testing in that\n   it can prove the _absence_ of bugs, not just their\n ",
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft"
          ]
        },
        {
          "title": "Implications of the seL4 Verification",
          "url": "https://sel4.systems/Verification/implications.html",
          "excerpts": [
            "The proofs not only establish functional correctness, integrity, and confidentiality, but they also imply the absence of many common programming errors. They give you the reasons why and how\n data structures work, why it is safe to optimise and leave out certain checks\n (because you know they will always be true), and why the code always\n executes in a defined and safe mann"
          ]
        },
        {
          "title": "Ferrocene Achieves IEC 62304 Qualification",
          "url": "https://ferrous-systems.com/blog/ferrocene-achieves-iec-62304-qualification/",
          "excerpts": [
            "It is qualified to automotive (ISO 26262, ASIL-D), industrial development (IEC 61508, SIL4) and medical (IEC 62304, Class C) standards, with ..."
          ]
        },
        {
          "title": "IEC 61508 Ensuring Software Compliance",
          "url": "https://www.qa-systems.com/solutions/iec-61508/",
          "excerpts": [
            "Part 3 of IEC 61508 addresses the software requirements of a safety-related system mandating the use of better development processes, including the use of ..."
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage.",
            "Proofs and Certification\n\nThe traditional way to achieve high levels of assurance are schemes\nsuch as Common Criteria, ISO-26262, and DO-178C. The seL4 proofs go\nbeyond what these certification schemes require for software\ndevelopment at their most stringent levels."
          ]
        },
        {
          "title": "CantripOS: seL4 + Rust",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-01-leffler.pdf",
          "excerpts": [
            "CantripOS: 100% Rust",
            "Provides a variety of developer tools.",
            "CantripOS: sel4gdb"
          ]
        },
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "In the model used by L4 microkernels (and seL4 is no exception), an initial user-level task (the root task) is given full rights to all resources left over once ...",
            "A capability encapsulates an object reference plus access rights. In a capability system, such as seL4, any operation is authorised by a capability.",
            "IPC is via Endpoint objects.",
            "In addition, the MCS configuration of seL4 has a scheduling model that supports the kind of temporal isolation that is required for supporting mixed-criticality ..."
          ]
        }
      ],
      "reasoning": "The field value describes seL4 as a high-assurance microkernel with formal verification and a capability-based access model yielding strong isolation, and notes inspiration from a fictional entity (\"Ministry of Magic\"). Direct references in the excerpts clearly support this: the SeL4 Whitepaper discusses rigorous WCET analysis, formal proofs, and the capability-based model that underpins sandboxing and protected IPC; it explicitly anchors seL4 in strong isolation guarantees and security properties. The Whitepaper repeatedly emphasizes that capabilities are access tokens governing resource rights and that endpoints facilitate protected function calls, aligning with the finegrained field value's emphasis on fine-grained access control and protected interactions. Further, multiple excerpts summarize seL4 proofs and certification, underscoring formal verification as the cornerstone for safety guarantees, which matches the field value's emphasis on machine-checked correctness and certification readiness. The CantripOS slides referencing \"seL4 + Rust\" illustrate how the seL4 foundation is being combined with Rust in contemporary stacks, reinforcing the interpretation that seL4 serves as the architectural core for high-assurance systems in this context. Additional excerpts discussing root tasks, capability concepts (capability encapsulates object reference plus rights), and endpoints for IPC reinforce how the seL4 model operationalizes isolation and controlled access in practice. The remaining supportive excerpts describe ancillary safety/certification frameworks and general seL4 verification narrative, which corroborate the claim of formal verification and certification implications that the field value asserts. Taken together, these excerpts directly substantiate the field's claims about seL4's nature, its capability-based access model, and its formal verification/certification posture, while the 'Ministry of Magic' nomenclature is reflected in the whitepaper's tone and metaphorical framing around the kernel's architecture and invariants.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.2.inspired_component",
      "citations": [
        {
          "title": "Mutiny - Flow control and Back-pressure - Quarkus",
          "url": "https://quarkus.io/blog/mutiny-back-pressure/",
          "excerpts": [
            "This post described the different approaches offered by Mutiny to handle back-pressure. The Reactive Streams protocol works well when you can control the pace ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt explicitly names the Floo Network and describes it as a userspace NIC dataplane with per-queue rings, zero-copy buffers, and batched completion. It also notes a Rust-safe API and a kernel-bypass design pattern (DPDK-like ethos), which precisely aligns with the idea of a user-space fast-path architecture for I/O. This excerpt provides concrete, specific evidence for Floo Network as a user-space, fast-path I/O component, supporting the field value. Other excerpts discuss Arrakis/IX or related dataplane concepts (e.g., Arrakis control plane, SR-IOV integration, SR-IOV PCI considerations, and dataplane-focused architectures) but do not mention Floo Network itself, so they offer contextual relevance but not direct support for the exact field value. Therefore, the direct Floo Network excerpt is the strongest and sole direct match, with surrounding references offering peripheral context about user-space dataplane ideas in the same design landscape. ",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.1.description",
      "citations": [
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        }
      ],
      "reasoning": "The field value points to a standard for space and time partitioning used in safety-critical avionics to achieve deterministic multi-tenancy by allocating fixed time slices and protected memory regions to different applications. The first excerpt explicitly discusses ARINC 653 in the context of partitioning strategies, certification considerations, and deterministic paths for hard real-time guarantees, which directly supports the notion of a standard that enables space/time partitioning in avionics. The fourth excerpt analyzes model-based optimization of ARINC-653 partition scheduling, which reinforces the idea that ARINC-653 governs how partitions are scheduled and how their temporal guarantees are achieved, aligning with the concept of fixed time slices for determinism. The third excerpt focuses on ARINC-653 health monitoring and recovery, including intra-partition communication and partition attributes, which, while centered on health aspects, still references partitioning as a core mechanism, thereby supporting the association between ARINC-653 and partitioned safety-critical environments. Together, these excerpts corroborate that ARINC 653 is the standard instrumental to space/time partitioning and deterministic multi-tenancy in avionics safety-critical systems, as described by the field value.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.1.inspired_component",
      "citations": [
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        }
      ],
      "reasoning": "Horcrux Partitions corresponds to a partitioning mechanism inspired by ARINC 653 to enforce time/space separation and determinism. The most directly relevant material describes ARINC-653 partitioning practices and how partitioning supports deterministic behavior and safety requirements. One excerpt explicitly covers partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing in the context of ARINC 653, which aligns with the notion of partitioned isolation domains. Another excerpt discusses model-based optimization for ARINC-653 partition scheduling, which maps directly to how Horcrux Partitions would allocate time and resources to partitions to meet determinism goals. A third excerpt focuses on ARINC-653 health monitoring and recovery, which ties into how partitions should be observed and actuated in failure scenarios, reinforcing the isolation and fault containment aspects of Horcrux Partitions. A fourth excerpt, while focused on Arrakis, describes direct I/O and partition-agnostic OS design concepts; its relevance is more peripheral but can still inform the hardware/software boundary considerations that influence partitioning approaches. Collectively, these excerpts support the interpretation of Horcrux Partitions as ARINC-653–style partitions with deterministic timing, isolation, and safety-related concerns, as described in the target field value, and help illustrate how such partitioning would be implemented and evaluated in a Rust-based system.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.8.inspired_component",
      "citations": [
        {
          "title": "eRPC - Low latency and performance metrics",
          "url": "https://github.com/erpc-io/eRPC",
          "excerpts": [
            "Low latency: 2.3 microseconds round-trip RPC latency with UDP over Ethernet\n    * Performance for small 32-byte RPCs: ~10M RPCs/sec with one CPU core,\n60--80M RPCs/sec with one"
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky · Cited by 417 — In this paper, we show that a general- purpose RPC library called eRPC can provide state-of-the-art performance on commodity datacenter networks without."
          ]
        }
      ],
      "reasoning": "The strongest support comes from content that explicitly mentions a Floo Network-like design: a user-level NIC dataplane with per-service virtual NICs and a RDMA module, which aligns directly with the Portkeys / Floo-RDMA concept. This excerpt also references an architecture that mirrors io_uring-like patterns and kernel-bypass ideas, reinforcing the idea of a user-space NIC stack with zero-copy paths suitable for high-performance networking. The next strongest support is from material describing one-sided RDMA, which describes bypassing the remote CPU to read or write directly to remote memory, a key capability that underpins RDMA-based communications in a flow like Floo-RDMA Letters. This connection helps justify the feasibility and performance rationale of a RDMA-enabled, user-space network path. The third piece discusses general, high-performance RPCs (eRPC) and datacenter RPCs, which provide context for building fast, kernel-bypass communication stacks but are less specific to the Floo-Network and RDMA module design; however, they corroborate the importance of low-latency, scalable RPCs in a rich NIC/dataplane ecosystem and thus offer supporting context for the Portkeys/Letters concept.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.13.technology_name",
      "citations": [
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency ."
          ]
        },
        {
          "title": "Powered by | Apache Arrow",
          "url": "https://arrow.apache.org/powered_by/",
          "excerpts": [
            "Uses Arrow to efficiently store Python data structures containing large arrays of numerical data. Data can be accessed with zero-copy by multiple processes ..."
          ]
        },
        {
          "title": "Insights from paper: Apache Arrow DataFusion",
          "url": "https://www.hemantkgupta.com/p/insights-from-paper-apache-arrow",
          "excerpts": [
            "Aug 11, 2024 — Apache Arrow DataFusion is a fast, embeddable, and extensible query engine. It is written in Rust programming language and uses Apache Arrow as its memory ..."
          ]
        },
        {
          "title": "arrow-rs/arrow/examples/zero_copy_ipc.rs at main",
          "url": "https://github.com/apache/arrow-rs/blob/main/arrow/examples/zero_copy_ipc.rs",
          "excerpts": [
            "Zero copy in this case means the Arrow arrays refer directly to a user //! ... Arrow `Buffer` to back the arrow arrays. We // do this by first creating a ..."
          ]
        },
        {
          "title": "arrow2 - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/arrow2/0.4.0",
          "excerpts": [
            "fbs. MUST lay out memory according to the arrow specification; MUST support reading from and writing to the C data interface at zero-copy."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface.html",
          "excerpts": [
            "Make it easy for third-party projects to implement support for (including partial\n  support where sufficient), with little initial investment. * \n  Allow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process. * \n  Match the Arrow array concepts closely to avoid the development of\n  yet another marshalling layer.",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow format.",
            "Expose an ABI-stable interface.",
            "llow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process.",
            "Zero-copy by design.",
            "Allow zero-copy sharing of Arrow data between independent runtimes and components running in the same process. Match the Arrow array concepts closely to ...",
            "The Arrow C data interface is inspired by the [Python buffer protocol](https://www.python.org/dev/peps/pep-3118/) ,\nwhich has proven immensely successful in allowing various Python libraries\nexchange numerical data with no knowledge of each other and near-zero\nadaptation cost."
          ]
        },
        {
          "title": "arrow::buffer - Rust",
          "url": "https://docs.rs/arrow/latest/arrow/buffer/index.html",
          "excerpts": [
            "A MutableBuffer is Arrow's interface to build a Buffer out of items or slices of items. NullBuffer: A BooleanBuffer used to encode validity for Arrow arrays ..."
          ]
        }
      ],
      "reasoning": "The strongest support comes from excerpts that explicitly name Apache Arrow and describe its hallmark characteristics. One excerpt highlights Apache Arrow's columnar format enabling zero-copy transfers and vectorized execution, which directly aligns with Arrow's core design as a high-performance data interchange format. Several excerpts discuss the Arrow C data interface as a minimal, ABI-stable pathway for zero-copy sharing of Arrow data between independent runtimes, which reinforces the specific technology value in the field path. Additional excerpts describe Arrow-related components and ecosystems (e.g., Arrow data interchange, zero-copy sharing across runtimes, and the Rust ecosystem's integration with Arrow-based data processing) that further corroborate the technology name and its practical implications. Some excerpts refer to Arrow in related contexts (such as Python interoperability or DataFusion in Rust) that reinforce the Arrow ecosystem but are slightly more indirect in naming the technology itself. Collectively, these excerpts corroborate the presence and importance of Apache Arrow as the foundational technology value in the given field path, with the most direct evidence focusing on Arrow's zero-copy, ABI-stable data interface and columnar format, followed by ecosystem and integration references that expand on its utilities.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.4.description",
      "citations": [
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "A Key Distinction: Unlike full kernel bypass solutions like DPDK, io_uring ZC Rx still processes packet headers through the kernel's TCP stack.",
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ..."
          ]
        },
        {
          "title": "The IOMMU Impact - I/O Memory Management Units",
          "url": "https://medium.com/@mike.anderson007/the-iommu-impact-i-o-memory-management-units-feb7ea95b819",
          "excerpts": [
            "The IOMMU serves as a hardware abstraction layer that provides device isolation, memory protection, and address translation, much like how a traditional Memory Management Unit (MMU) governs virtual memory for CPUs."
          ]
        }
      ],
      "reasoning": "The description of io_uring zero-copy reception shows a direct pathway where data can be placed into user-space buffers without extra kernel copies, illustrating reduced overhead on the receive path and alignment with high-throughput, low-latency goals. A separate discussion highlights that io_uring relies on shared ring buffers between user space and kernel space, which is central to the asynchronous I/O model and the reduction in system call overhead implied by the modern interface. Additional analysis points out that while io_uring offers performance improvements, it does not constitute a full kernel-bypass solution like some DPDK-style stacks, since packet headers may still traverse the kernel TCP stack. The performance-focused write-up underscores that io_uring can outperform traditional models in throughput and latency, reinforcing the claim of improved I/O efficiency through shared rings. A broader piece on system I/O memory management notes the IOMMU role in isolation and protection, which is tangential but contextual to the hardware/software ecosystem enabling such interfaces.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.4.technology_name",
      "citations": [
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "A Key Distinction: Unlike full kernel bypass solutions like DPDK, io_uring ZC Rx still processes packet headers through the kernel's TCP stack.",
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ..."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency."
          ]
        }
      ],
      "reasoning": "The most directly relevant content explicitly discusses io_uring in the context of zero-copy network receive paths and direct user-space I/O. This directly supports the field value by naming io_uring as a mechanism for reducing kernel-user data copies and enabling high-performance I/O paths. A second excerpt reinforces the concept of io_uring in the framework of zero-copy receive paths, noting its role in ring-based data exchange and its relationship to kernel bypass concepts, which is closely aligned with the mechanism's core idea. A third excerpt broadens the discussion to performance advantages associated with io_uring, highlighting its benchmark-driven gains relative to traditional approaches, which strengthens understanding of io_uring's impact in practice. The fourth excerpt explicitly mentions io_uring within an overview of related I/O performance topics, reinforcing its relevance through additional context, even if it is not as singularly focused on io_uring as the top excerpts. Collectively, these excerpts corroborate the field value by detailing io_uring's role in zero-copy, user-space I/O paths, and performance improvements.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.2.description",
      "citations": [
        {
          "title": "The IX Operating System: Combining Low Latency, High ...",
          "url": "https://dl.acm.org/doi/10.1145/2997641",
          "excerpts": [
            "We present ix, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ..."
          ]
        },
        {
          "title": "USENIX OSDSI 2014 Arrakis/IX paper",
          "url": "https://www.usenix.org/sites/default/files/osdi14_full_proceedings.pdf",
          "excerpts": [
            "The Arrakis operating system is based upon a fork of the\n\nBarrelfish [10] multicore OS code base",
            "The interface between an application and the Arrakis\n\ncontrol plane is used to request resources from the system\n\nand direct I/O flows to and from user program",
            "Doorbells are exposed to\n\nArrakis programs via regular event delivery mechanisms\n\n(e.g., a file descriptor event) and are fully integrated\n\nwith existing I/O multiplexing interfaces (e.g., selec",
            "We extended Barrelfish with support for SR-IOV, which\n\nrequired modifying the existing PCI device manager to rec-\n\nognize and handle SR-IOV extended PCI capabilit"
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant evidence comes from a source describing a dataplane operating system designed for high I/O performance and isolation, which aligns with the claim about moving the I/O data plane to user space while preserving kernel control. It explicitly states it provides high I/O performance and isolation, i.e., protection and separation, in a dataplane OS design. Additional surrounding discussion describes Arrakis as an OS extension that provides interfaces for applications to request resources and direct I/O flows to and from user programs, which illustrates the model of user-space dataplanes managed within an OS architecture. Other excerpts elaborate on mechanisms that support user-space I/O, such as doorbells integrated with existing I/O multiplexing interfaces and SR-IOV augmentations to PCI device management, which further demonstrate practical arrangements for user-space access to hardware while maintaining kernel governance. Lastly, a paper on Arrakis (and IX) explicitly ties these ideas to low-latency, high-performance dataplane goals and frames them within Barrelfish-derived foundations, reinforcing the association between user-space dataplanes and performance benefits. The Best Paper note reinforces that such approaches enable unprecedented OS customizability and performance, which corroborates the overall claim about performance gains from user-space I/O data planes.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.9.description",
      "citations": [
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        }
      ],
      "reasoning": "The field value describes an NVMe command set that partitions the storage media into zones to enforce sequential writes, enabling the host to optimize data placement, reduce write amplification, and improve tail latency. An excerpt explicitly defining Zoned Namespaces (ZNS) states that ZNS reduces device-side write amplification, over-provisioning, and DRAM while improving tail latency, throughput, and drive capacity. This directly aligns with the described NVMe feature and its intended benefits. Several excerpts discuss real-world ZNS implementations in SSDs, such as the PM1731a with ZNS support and the Ultrastar DC ZN540, which highlight ZNS as a storage technology enabling higher throughput, lower costs, and improved performance characteristics in cloud and data-center contexts. Additional product and data-sheet excerpts further describe ZNS SSDs and their specifications, reinforcing that ZNS encapsulates the concept of organizing storage into zones with sequential writes to optimize performance and endurance. Supporting benchmarks and discussions around ZNS-augmented stacks (e.g., SPDK benchmarks for ZNS) provide empirical context for performance improvements and tail-latency considerations, reinforcing the practical benefits of the technology described in the field value. Together, these excerpts form a coherent evidentiary base that the finegrained field value accurately reflects the concept and its advantages in modern NVMe storage devices.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.6.technology_name",
      "citations": [
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications.",
            "Missing: RustHallows competitive landscape"
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to SPDK, the Storage Performance Development Kit. The most relevant excerpts explicitly describe SPDK as a toolkit for high-performance, user-space storage applications, establishing its purpose and domain. Additional excerpts reinforce SPDK's role by detailing how it achieves high performance through user-space drivers and polled mode, and by noting its tooling for high-performance storage work. A benchmark-focused excerpt demonstrates real-world performance implications tied to SPDK, further validating its significance. An excerpt that mentions SPDK only in the context of the RustHallows competitive landscape still references the technology but provides less direct information about its nature, capabilities, or performance, making it somewhat less relevant. Another excerpt discusses a related Nvidia GPUDirect storage benchmark but does not focus on SPDK itself, and is therefore the least relevant among the SPDK-focused items. Taken together, the strongest support comes from the excerpts that define SPDK and describe its performance-oriented user-space design, followed by benchmarks and tooling discussions, with peripheral mentions providing context but weaker direct evidence.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.9.technology_name",
      "citations": [
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized ...",
          "url": "https://semiconductor.samsung.com/news-events/news/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Samsung Electronics, today unveiled its new enterprise solid-state drive (SSD) featuring Zoned Namespace (ZNS) technology — the PM1731a."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Samsung Introduces its First ZNS SSD with Maximized ...",
          "url": "https://news.samsung.com/us/samsung-introduces-first-zns-ssd-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Jun 1, 2021 — Based on ZNS, the new Samsung SSD can achieve a WAF close to one, a major improvement over typical server SSD values between three and four."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        },
        {
          "title": "Inside ScyllaDB's Continuous Optimizations for Reducing ...",
          "url": "https://www.scylladb.com/2024/08/14/inside-scylladbs-continuous-optimizations-for-reducing-p99-latency/",
          "excerpts": [
            "During this period, the P99 latency was 3.87 ms for writes and 9.41 ms for reads. In comparison, during the “steady state” (when no ..."
          ]
        },
        {
          "title": "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems",
          "url": "https://www.lynx.com/challenges/safety-certification",
          "excerpts": [
            "Accelerate Safety Certification for Aerospace, Automotive, and Critical Systems"
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to NVMe Zoned Namespaces (ZNS), a technology discussed across multiple excerpts. The most directly relevant excerpts explicitly address ZNS concepts, its impact on performance and endurance, and its implementation in concrete products. For example, one excerpt defines ZNS and links it to reduced device-side write amplification and improved tail latency, which aligns with the core concept of ZNS. Several excerpts describe ZNS-enabled SSDs from major vendors, including product announcements and datasheets, showing practical deployments of ZNS in NVMe devices. Additional excerpts present SPDK benchmarks and performance discussions around ZNS operations, illustrating real-world performance considerations and validation. Some excerpts mention ZNS in relation to specific products (e.g., Samsung PM1731a variants and Western Digital Ultrastar ZN540), reinforcing the direct association with NVMe ZNS technology. A couple of excerpts discuss broader topics (latency reductions or safety certification) that are tangential to ZNS but do not define or describe ZNS itself, so they are considered less central. Overall, the strongest support comes from excerpts that define ZNS and show explicit ZNS-enabled hardware and benchmarking, with decreasing relevance for excerpts that touch on broader performance topics or certification rather than ZNS specifics.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.13.inspired_component",
      "citations": [
        {
          "title": "arrow2 - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/arrow2/0.4.0",
          "excerpts": [
            "fbs. MUST lay out memory according to the arrow specification; MUST support reading from and writing to the C data interface at zero-copy."
          ]
        },
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency ."
          ]
        }
      ],
      "reasoning": "The target field value consists of two related technologies: Goblins' Ledger and Pensieve. The excerpt that directly names Goblins' Ledger describes it as a columnar analytics runtime with zero-copy from Pensieve buffers, which exactly aligns with the notion of a Goblins' Ledger in the system. The Pensieve-related excerpt explicitly references Pensieve telemetry and Pensieve buffers, establishing a concrete connection to Pensieve as part of the observability/runtime stack. Together, these excerpts support both facets of the field value: Goblins' Ledger as a concrete analytics component, and Pensieve as a telemetry/observability capability linked to data paths and buffers. The combination of a direct match and corroborating Pensieve context makes the linkage strong.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.2.technology_name",
      "citations": [
        {
          "title": "USENIX OSDSI 2014 Arrakis/IX paper",
          "url": "https://www.usenix.org/sites/default/files/osdi14_full_proceedings.pdf",
          "excerpts": [
            "The Arrakis operating system is based upon a fork of the\n\nBarrelfish [10] multicore OS code base",
            "The interface between an application and the Arrakis\n\ncontrol plane is used to request resources from the system\n\nand direct I/O flows to and from user program",
            "Doorbells are exposed to\n\nArrakis programs via regular event delivery mechanisms\n\n(e.g., a file descriptor event) and are fully integrated\n\nwith existing I/O multiplexing interfaces (e.g., selec",
            "We extended Barrelfish with support for SR-IOV, which\n\nrequired modifying the existing PCI device manager to rec-\n\nognize and handle SR-IOV extended PCI capabilit"
          ]
        },
        {
          "title": "The IX Operating System: Combining Low Latency, High ...",
          "url": "https://dl.acm.org/doi/10.1145/2997641",
          "excerpts": [
            "We present ix, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ..."
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        }
      ],
      "reasoning": "The target term Arrakis / IX is clearly identified in several excerpts. The most directly relevant piece states that Arrakis is a fork of the Barrelfish multicore OS, establishing its lineage and core design motivation. Another excerpt describes IX as a dataplane operating system delivering high I/O performance with protection and isolation, which aligns with a dataplane-oriented interpretation of Arrakis/IX. Additional excerpts discuss the Arrakis control plane interface for resource requests and directing I/O flows to and from user programs, illustrating how Arrakis/IX interacts with applications. Further details mention Arrakis-specific concepts like SR-IOV integration in the PCI device manager, which ties Arrakis to low-level device virtualization features. One excerpt notes Arrakis as the OSDI '14 Best Paper, underscoring its recognition and impact in the field. Together, these excerpts corroborate the field value as Arrakis / IX, providing both lineage (Barrelfish fork) and functional characteristics (dataplane OS with high I/O performance, user-space I/O, and virtualization features).",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.13.description",
      "citations": [
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency .",
            "Just raw, zero-copy data movement at high speed. Temporal keeps workflows running smoothly. Arrow Flight keeps data moving without friction. ..."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface.html",
          "excerpts": [
            "Zero-copy by design.",
            "The Arrow C data interface is inspired by the [Python buffer protocol](https://www.python.org/dev/peps/pep-3118/) ,\nwhich has proven immensely successful in allowing various Python libraries\nexchange numerical data with no knowledge of each other and near-zero\nadaptation cost.",
            "Allow zero-copy sharing of Arrow data between independent runtimes and components running in the same process. Match the Arrow array concepts closely to ...",
            "Make it easy for third-party projects to implement support for (including partial\n  support where sufficient), with little initial investment. * \n  Allow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process. * \n  Match the Arrow array concepts closely to avoid the development of\n  yet another marshalling layer.",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow format.",
            "Expose an ABI-stable interface.",
            "llow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process."
          ]
        },
        {
          "title": "Powered by | Apache Arrow",
          "url": "https://arrow.apache.org/powered_by/",
          "excerpts": [
            "Uses Arrow to efficiently store Python data structures containing large arrays of numerical data. Data can be accessed with zero-copy by multiple processes ..."
          ]
        },
        {
          "title": "Insights from paper: Apache Arrow DataFusion",
          "url": "https://www.hemantkgupta.com/p/insights-from-paper-apache-arrow",
          "excerpts": [
            "Aug 11, 2024 — Apache Arrow DataFusion is a fast, embeddable, and extensible query engine. It is written in Rust programming language and uses Apache Arrow as its memory ..."
          ]
        },
        {
          "title": "arrow-rs/arrow/examples/zero_copy_ipc.rs at main",
          "url": "https://github.com/apache/arrow-rs/blob/main/arrow/examples/zero_copy_ipc.rs",
          "excerpts": [
            "Zero copy in this case means the Arrow arrays refer directly to a user //! ... Arrow `Buffer` to back the arrow arrays. We // do this by first creating a ..."
          ]
        },
        {
          "title": "arrow2 - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/arrow2/0.4.0",
          "excerpts": [
            "fbs. MUST lay out memory according to the arrow specification; MUST support reading from and writing to the C data interface at zero-copy."
          ]
        },
        {
          "title": "arrow::buffer - Rust",
          "url": "https://docs.rs/arrow/latest/arrow/buffer/index.html",
          "excerpts": [
            "A MutableBuffer is Arrow's interface to build a Buffer out of items or slices of items. NullBuffer: A BooleanBuffer used to encode validity for Arrow arrays ..."
          ]
        },
        {
          "title": "Event-driven Applications | Apache Flink",
          "url": "https://nightlies.apache.org/flink/flink-docs-master/docs/learn-flink/event_driven/",
          "excerpts": [
            "A ProcessFunction combines event processing with timers and state, making it a powerful building block for stream processing applications."
          ]
        },
        {
          "title": "Mutiny - Flow control and Back-pressure - Quarkus",
          "url": "https://quarkus.io/blog/mutiny-back-pressure/",
          "excerpts": [
            "This post described the different approaches offered by Mutiny to handle back-pressure. The Reactive Streams protocol works well when you can control the pace ..."
          ]
        },
        {
          "title": "UW CSE's Arrakis is OSDI '14 Best Paper",
          "url": "https://news.cs.washington.edu/2014/10/06/uw-cses-arrakis-is-osdi-14-best-paper/",
          "excerpts": [
            "This allows for unprecedented OS customizability, reliability and performance. Interesting research questions arise in this scenario.” More ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes an in-memory columnar data format optimized for zero-copy sharing and processing across different systems and languages, with strong emphasis on analytics workloads and SIMD suitability. The most relevant excerpts explicitly reference zero-copy data movement and sharing, as well as the Arrow project and its interfaces. Excerpts detailing zero-copy sharing between independent runtimes and components in the same process align directly with the described capability. Excerpts about the Arrow C data interface further corroborate the design goal of a stable, ABI-compatible, zero-copy data interchange mechanism for columnar data across components. Excerpts mentioning Arrow Flight, DataFusion, and Rust-based Arrow ecosystems reinforce the practical realization of such a format in modern analytics stacks. While some excerpts discuss broader OS/IR concepts or related tooling, they are less central to the exact field value but still supportive of the general data-centric, zero-copy ecosystem. Taken together, these excerpts coherently support the notion of an in-memory, columnar, zero-copy data format designed for cross-system sharing and high-performance analytics, with Arrow as a primary example and archetype.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.6.description",
      "citations": [
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead.",
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications"
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        }
      ],
      "reasoning": "The field value describes libraries and user-space, poll-mode drivers for NVMe storage that bypass the kernel. Excerpt 1 explicitly identifies the Storage Performance Development Kit (SPDK) as tools and libraries for writing high-performance, scalable, user-mode storage applications, which matches the notion of user-space tooling for high-performance I/O. Excerpt 3 discusses SPDK's performance update and notes that it achieves high performance by moving drivers into userspace and operating in a polled mode, which directly supports the kernel-bypass and poll-mode aspects of the field value. Excerpt 4 reiterates that SPDK provides tools and libraries for writing high-performance, scalable, user-mode storage applications, reinforcing the core idea of user-space I/O and bypassing kernel pathways. Excerpt 2 provides concrete performance outcomes associated with SPDK (e.g., 10 million 4KiB I/O/s on real hardware), which reinforces the performance emphasis of the field value and corroborates the practical impact of such libraries and drivers. Collectively, these excerpts map directly to the description of a set of libraries and user-space, poll-mode drivers enabling high-performance NVMe I/O by bypassing the kernel. ",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.6.inspired_component",
      "citations": [
        {
          "title": "Storage Performance Development Kit Blog",
          "url": "https://spdk.io/blog/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "SPDK Development",
          "url": "https://spdk.io/development/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications."
          ]
        },
        {
          "title": "Storage Performance Development Kit",
          "url": "https://spdk.io/",
          "excerpts": [
            "The Storage Performance Development Kit (SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications.",
            "Missing: RustHallows competitive landscape"
          ]
        },
        {
          "title": "SPDK Performance Update",
          "url": "https://spdk.io/news/2024/04/10/Performance_Report_Update/",
          "excerpts": [
            "SPDK) provides a set of tools and libraries for writing high performance, scalable, user-mode storage applications",
            "It achieves high performance by moving all of the necessary drivers into userspace and operating in a polled mode instead of relying on interrupts, which avoids kernel context switches and eliminates interrupt handling overhead."
          ]
        },
        {
          "title": "10.39M Storage I/O Per Second From One Thread",
          "url": "https://spdk.io/news/2019/05/06/nvme/",
          "excerpts": [
            "May 6, 2019 — We'll show some benchmarks where SPDK is performing more than 10 million 4KiB random read I/O per second, on real hardware available today, ..."
          ]
        }
      ],
      "reasoning": "Gringotts is described as a zoned, NVMe/ZNS storage stack implemented in userspace with SPDK-style completion paths. Excerpts that define SPDK as a toolset for high-performance, user-mode storage applications, and those that discuss moving drivers into userspace and avoiding kernel overhead, directly map to the architectural goals of Gringotts. Specifically, an excerpt that states SPDK provides tools and libraries for high-performance, scalable, user-mode storage applications supports Gringotts' design intention of a userspace storage stack with zero-copy, queue pairs, and SPDK-style completion semantics. Excerpts detailing SPDK performance improvements through userspace operation and polled mode (as opposed to kernel-driven interrupts) further corroborate the performance characteristics Gringotts aims to achieve. An excerpt that mentions SPDK-related performance benchmarks reinforces the baseline capabilities Gringotts would leverage. Finally, an excerpt that references SPDK in a performance update context helps to anchor Gringotts within the SPDK ecosystem and its real-world performance characteristics. While none of the excerpts expressly name Gringotts, they collectively establish the SPDK-inspired foundation and high-performance storage stack concepts that Gringotts embodies.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.7.inspired_component",
      "citations": [
        {
          "title": "GPUDirect RDMA and GPUDirect Storage — NVIDIA GPU Operator",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party "
          ]
        },
        {
          "title": "GPUDirect RDMA and GPUDirect Storage - NVIDIA Documentation",
          "url": "https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/24.3.0/gpu-operator-rdma.html",
          "excerpts": [
            " a technology in NVIDIA GPUs that enables direct\ndata exchange between GPUs and a third-party peer device using PCI Express. The third-party ",
            "uide/index.html)) enables a direct data path between local or remote storage, like NFS server or NVMe/NVMe over Fabric (NVMe-oF), and GPU memory.",
            "To support GPUDirect RDMA, a userspace CUDA APIs and kernel mode drivers are required.",
            "rator, the Operator uses GDS driver version 2.17.5 or newer. This version and higher is only supported with the NVIDIA Open GPU Kernel module driver. The"
          ]
        },
        {
          "title": "GDS cuFile API",
          "url": "https://training.continuumlabs.ai/infrastructure/storage/introduction-to-nvidia-gpudirect-storage-gds/gds-cufile-api",
          "excerpts": [
            "Jun 27, 2024 — The cuFile APIs are most effective in scenarios where there is a need for high-performance data transfer between GPU memory and storage."
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "GPU buffers need to be exposed to third-party devices to enable DMA by those devices. The set of pages that\nspan those buffers in the GPU virtual address space need to be mapped to the Base Address Register (BAR) space,\nand this mapping is an overhead. The mechanism to accomplish this mapping is called registration. Explicit GPU buffer registration with the `cuFileBufRegister` API is optional.",
            "If a user buffer is not registered, an intermediate pre-registered GPU\nbuffer that is owned by the cuFile implementation is used, and there is an extra copy from there to the user\nbuffer. The following table and IO pattern descriptions provide guidance on whether registration is profitable."
          ]
        }
      ],
      "reasoning": "Nimbus 2000 is a GPU direct-path I/O concept that would sit in the same thematic space as GPU direct memory access and storage interfaces. Excerpts that discuss GPUDirect RDMA and GPUDirect Storage describe direct data paths between GPU memory and storage or devices, including the use of user-space paths and zero-copy buffering, which are the kinds of architectural mechanisms Nimbus 2000 would leverage. Other excerpts outline cuFile APIs and best practices for registering GPU buffers to enable DMA by third-party devices; these details provide concrete context for how GPU-direct I/O can be implemented or optimized, which is pertinent when imagining a component like Nimbus 2000 in a Rust-centric, zero-copy, kernel-bypass stack. While none of the excerpts explicitly mention the Nimbus 2000 label, they collectively establish the technical substrate (GPU direct paths, GDSP/GPUDirect Storage concepts, and related kernel/userspace interactions) that Nimbus 2000 would inhabit, thereby supporting the field value's domain alignment and feasibility. The absence of an exact mention means the support is indirect rather than explicit, which lowers the strength of the match, but the thematic alignment remains strong.",
      "confidence": "low"
    },
    {
      "field": "foundational_technologies_and_inspirations.10.description",
      "citations": [
        {
          "title": "The CHERI capability model: Revisiting RISC in an age of ...",
          "url": "https://ieeexplore.ieee.org/document/6853201",
          "excerpts": [
            "by J Woodruff · 2014 · Cited by 475 — We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection."
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI is a hybrid capability system in several senses:",
            "CHERI capabilities are a low-level primitive usable for many purposes.",
            "The advent of the open RISC-V ISA provides us with a richer spectrum of\nbaseline processor designs, and as the architecture matures over time, we\nhope also a similarly rich software ecosystem."
          ]
        },
        {
          "title": "CHERI Software Compartmentalization",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-compartmentalization.html",
          "excerpts": [
            "[CHERI-seL4](cheri-sel4.html)",
            "The CHERI protection model provides a set of low-level primitives that enable scalable, fine-grained software compartmentalization."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "\nCHERI represents a new system design that blocks exploits. Architectural changes to the CPU and memory systems add integrity checks to pointers that prevent reading, writing, or executing from memory that is out of bounds or using corrupted pointers, the most common classes of severe vulnerabilities. CHERI is supported by a complete compiler toolchain, multiple operating systems, is open source, and already implemented for several different RISC CPUs including Arm’s recently released Morello prototype.",
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "Capabilities are created at boot time, and capabilities derived from these initial ones are more restrictive. The new instructions for manipulating capabilities also mean changing the instruction set architecture, or ISA.",
            " of CHERI architectures for MIPS, RISC-V, and Arm began with the Sail instruction set definition language. Sail generates sequential emulators, in C and OCaml, and theorem-prover definitions, in Coq, HOL4, and Isabelle, and SMT. These versions allow for both a means of testing in emulation and creating formal proofs of the correctness of the design.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        },
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        }
      ],
      "reasoning": "The requested fine-grained field value describes a hardware instruction set architecture that replaces traditional pointers with hardware-enforced capabilities to provide fine-grained memory protection and compartmentalization. The most directly supporting excerpts explicitly discuss CHERI as a capability-based memory protection model that augments pointers with bounds, permissions, and other metadata enforced by hardware. For example, CHERI is presented as a capability model that extends pointer semantics with memory protection metadata and non-forgeable pointers, which aligns exactly with the described hardware-backed capabilities architecture. Additional CHERI-focused materials explain that CHERI capabilities carry bounds and permissions, are guards at the hardware level, and enable fine-grained software compartmentalization, which reinforces the connection to a hardware-enforced capability-based ISA. Related CHERI material covers how these capabilities provide isolation and security guarantees across software boundaries, including discussions of sealing, guarded manipulation, and attestation primitives, all of which illustrate how hardware enforcement of capabilities underpins memory safety and compartmentalization. Several CHERI-centric entries expand on compartmentalization, integration with seL4-style capability systems, and the impact on system architecture, further grounding the field value in the context of hardware-supported capabilities replacing traditional pointers. The CHERI hardware-focused discussions (Morello, CHERI FAQs, CHERI compartmentalization pages) emphasize that capabilities are a hardware-implemented primitive with bounds, permissions, and non-forgeability properties, and that they can be stored in registers, protected by tag bits, and manipulated by hardware semantics. SeL4-related material on capability derivation trees also underpins the notion of a capability-based memory protection model as a foundational architectural primitive. Taken together, these excerpts provide a coherent evidentiary base that a hardware instruction set architecture leveraging hardware-enforced capabilities replaces traditional pointers with capability-based protections to enable fine-grained memory safety and compartmentalization. The most supportive pieces explicitly define the CHERI approach and its hardware-enforced properties, while the companion CHERI compartmentalization and Morello materials elaborate the practical implications and implementation details that reinforce the overall claim. The result is a strong, multi-faceted alignment between the field value and the cited materials.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.5.technology_name",
      "citations": [
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication"
          ]
        },
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpt explicitly references DPDK as a kernel-bypass option for user-space access to NICs, indicating a concrete technology name tied to kernel-bypass I/O paths. The next excerpt discusses Arrakis and related concepts of direct application-level access to I/O devices, which aligns with the same architectural goal of bypassing kernel paths, though it does not name DPDK. A third excerpt explicitly mentions kernel interposition over the network dataplane, which is a core idea behind using kernel-bypass stacks like DPDK; this supports the field value by describing the same class of approach. An additional excerpt covers io_uring zero-copy Rx, which, while centered on a modern kernel-I/O mechanism rather than DPDK itself, is thematically adjacent as it discusses zero-copy and bypass-related concepts in the I/O path. Finally, excerpts discussing kernel-bypass references in MIT/academic contexts (Arrakis, Shenango, ZygOS) provide supporting background on the bypass paradigm and related scheduling/architecture considerations, even though they do not name DPDK explicitly. Taken together, these excerpts collectively support the idea of DPDK as a representative technology within kernel-bypass I/O strategies and provide contextual backing for its role in a high-performance I/O stack.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.4.inspired_component",
      "citations": [
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ...",
            "A Key Distinction: Unlike full kernel bypass solutions like DPDK, io_uring ZC Rx still processes packet headers through the kernel's TCP stack."
          ]
        },
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "io_uring and virtualization overview (Medium article)",
          "url": "https://medium.com/@alpesh.ccet/unleashing-i-o-performance-with-io-uring-a-deep-dive-54924e64791f",
          "excerpts": [
            "* Performance : Benchmarks show io_uring outperforming\nlibaio and\nepoll in throughput and latency."
          ]
        }
      ],
      "reasoning": "Hallows Rings refers to a shared-ring data structure concept guiding submission and completion paths for high-performance I/O. The most relevant excerpt explicitly discusses shared, circular ring buffers between user space and kernel space, which aligns with the idea of per-queue ring pairs enabling zero-copy I/O for NIC/NVMe/GPU workflows. Related content that describes zero-copy data paths via io_uring reinforces the ring-based approach, highlighting how ring buffers facilitate direct data placement and reduced syscalls, which supports the notion of a rings-based I/O substrate. Additional excerpts discuss io_uring's performance advantages and the delineation between kernel-bypass and kernel-assisted paths, further illustrating the practical implications of ring-based designs. A more general piece on IOMMU and memory management, while tangentially related to performance isolation and device access, does not discuss ring-based submission/completion mechanics and thus is less supportive of the Hallows Rings concept.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.5.description",
      "citations": [
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "I'm Not Dead Yet!: The Role of the Operating System in a Kernel ...",
          "url": "https://dl.acm.org/doi/10.1145/3317550.3321422",
          "excerpts": [
            "This paper argues for a new high-level, device-agnostic I/O abstraction for kernel-bypass devices. We propose the Demikernel, a new library OS architecture for ..."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay.",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space."
          ]
        },
        {
          "title": "io_uring zero copy Rx",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "The magic of io_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. Submission Queue ..."
          ]
        }
      ],
      "reasoning": "The field describes libraries and poll-mode drivers enabling fast packet processing in user space and explicitly bypassing the kernel networking stack. Strongly relevant excerpts discuss kernel-bypass concepts and user-space networking stacks: one excerpt details Arrakis providing direct application-level access to I/O devices using SR-IOV and the IOMMU, which is a canonical example of kernel bypass for I/O. Another excerpt discusses kernel interposition over the network dataplane, which directly addresses runtime interfaces that bypass the kernel for networking. A third excerpt references a Demikernel architecture, which is a library OS approach designed for kernel-bypass networking. Additional references from MIT and other sources discuss kernel-bypass, schedulers, and tail-latency systems in the context of networked stacks, reinforcing the topic of user-space, poll-mode, and direct I/O paths. Taken together, these excerpts provide clear, multi-faceted support for the concept of libraries and poll-mode drivers enabling fast, user-space packet processing that bypasses the traditional kernel network stack, including concrete architectural precedents and implementation strategies. The most supportive pieces explicitly describe kernel-bypass networking stacks and direct device access, while other excerpts elaborate on related techniques (zero-copy, DPDK/SPDK-inspired approaches, and OS/library designs) that underpin such libraries and drivers.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.9.inspired_component",
      "citations": [
        {
          "title": "NVMe Zoned Namespaces (ZNS) Command Set Specification",
          "url": "https://nvmexpress.org/specification/nvme-zoned-namespaces-zns-command-set-specification/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "What are Zoned Namespaces (ZNS)? - NVM Express",
          "url": "https://nvmexpress.org/faq-items/what-are-zoned-namespaces-zns/",
          "excerpts": [
            "ZNS reduces device-side write amplification, over-provisioning and DRAM while improving tail latency, throughput and drive capacity."
          ]
        },
        {
          "title": "Samsung PM1731a SSD with ZNS Support - ServeTheHome",
          "url": "https://www.servethehome.com/samsung-pm1731a-ssd-with-zns-support/",
          "excerpts": [
            "The new Samsung PM1731a brings ZNS which is somewhat akin to SMR for hard drives to SSDs for higher write endurance and lower costs."
          ]
        },
        {
          "title": "Ultrastar DC ZN540 - HDStorageWorks.com",
          "url": "https://www.hdstorageworks.com/Ultrastar-DC-ZN540.asp",
          "excerpts": [
            "The Ultrastar DC ZN540 is a 2.5-inch NVMe SSD using ZNS technology for improved performance, up to 4x throughput and 2.5x QoS, for cloud and enterprise data ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized User ...",
          "url": "https://news.samsung.com/global/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan",
          "excerpts": [
            "Built upon Samsung's sixth-generation V-NAND, the 2.5-inch PM1731a will come in two terabyte (TB) and four TB models. The SSD will feature dual ..."
          ]
        },
        {
          "title": "Samsung Introduces Its First ZNS SSD With Maximized ...",
          "url": "https://semiconductor.samsung.com/news-events/news/samsung-introduces-its-first-zns-ssd-with-maximized-user-capacity-and-enhanced-lifespan/",
          "excerpts": [
            "Samsung Electronics, today unveiled its new enterprise solid-state drive (SSD) featuring Zoned Namespace (ZNS) technology — the PM1731a."
          ]
        },
        {
          "title": "[PDF] Data Sheet: Western Digital Ultrastar DC ZN540",
          "url": "https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/product/ultrastar-dc-zn540-ssd/data-sheet-ultrastar-dc-zn540.pdf",
          "excerpts": [
            "The Ultrastar DC ZN540 ZNS NVMe SSD is Western Digital's zoned storage SSD for cloud and enterprise data center customers. It implements the ZNS command set ...",
            "The Ultrastar DC ZN540 is a 2.5-inch U.2 NVMe ZNS SSD with up to 4x performance improvement, dual-port controller, and 3.5 DW/D endurance, for data centers."
          ]
        },
        {
          "title": "Krien/ZNS_SPDK_Benchmarks: Benchmarks for ZNS ...",
          "url": "https://github.com/Krien/ZNS_SPDK_Benchmarks",
          "excerpts": [
            "The SPDK directory contains benchmarks for ZNS operations when using SPDK. It also contains plotting tools and some some general results that these benchmarks ..."
          ]
        }
      ],
      "reasoning": "Gringotts ZNS Loglets describes a zoned storage stack built in userspace with queue pairs and a SPDK-like completion path. Excerpts that discuss Zoned Namespaces (ZNS) explain how ZNS reduces write amplification, over-provisioning, and tail latency, which is foundational to a zoned storage design. Excerpts about ZNS SSD introductions and capabilities (such as PM1731a and Ultrastar DC ZN540) illustrate concrete implementations and expected performance characteristics of ZNS devices, which are relevant when planning a user-space storage stack that relies on such hardware. SPDK benchmarks and discussions of SPDK-style completion paths provide direct alignment with a SPDK-inspired approach for a Gringotts-like in-userspace storage layer, reinforcing the feasibility and design patterns (queue pairs, completion paths, and DMA considerations) that Gringotts would adopt. Discussions of related technologies (e.g., io_uring-inspired concepts and zero-copy pathways) further support the architectural direction of a high-performance, user-space, SPDK-like storage stack. Collectively, these excerpts underpin the rationale for implementing a ZNS-based, SPDK-inspired Gringotts component with zoned log-structuring, while offering concrete references to existing ZNS hardware and software ecosystems that inform design choices and expected performance characteristics. ",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.10.technology_name",
      "citations": [
        {
          "title": "The CHERI capability model: Revisiting RISC in an age of ...",
          "url": "https://ieeexplore.ieee.org/document/6853201",
          "excerpts": [
            "by J Woodruff · 2014 · Cited by 475 — We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        },
        {
          "title": "Morello Prototype Architecture - Arm Developer",
          "url": "https://developer.arm.com/Architectures/Morello",
          "excerpts": [
            "The Morello architecture is a prototype CPU architecture that introduces a new approach to security and is part of the wider Morello program."
          ]
        },
        {
          "title": "Arm Morello Program",
          "url": "https://www.arm.com/architecture/cpu/morello",
          "excerpts": [
            "Morello is a research program with the potential to radically change the way we design and program processors in the future to improve built-in security."
          ]
        },
        {
          "title": "CHERIoT: a study in CHERI (RISCV.org blog)",
          "url": "https://riscv.org/blog/2024/08/cheriot-a-study-in-cheri/",
          "excerpts": [
            "CHERIoT provides a layered security model. At the core, CHERIoT provides object-granularity (spatial and temporal) memory safety."
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI is a hybrid capability system in several senses:"
          ]
        },
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        },
        {
          "title": "CHERI OS-feature matrix",
          "url": "https://www.morello-project.org/cheri-feature-matrix/",
          "excerpts": [
            "Operating systems can implement CHERI software features along several axes. This table captures key axes, and describes the maturity of those features for ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        }
      ],
      "reasoning": "The field value corresponds to the CHERI family of hardware-assisted memory safety and related security models, including CHERI itself, the Morello project, and CHERIoT. Excerpts that explicitly describe CHERI's capability-based protection, bounds, and non-forgeable pointers establish the core concept of CHERI as a hardware-assisted memory-safety primitive. Excerpts about Morello as a prototype architecture and program illustrate how CHERI ideas are instantiated in Arm-design efforts, which directly supports the specific technology name grouping CHERI / Morello / CHERIoT. Excerpts detailing CHERIoT and CHERI software compartmentalization extend the CHERI family into embedded contexts and software isolation at the OS/software level. Additional CHERI FAQ and hardware-focused discussions reinforce how CHERI capabilities provide protection, including sealing, tagging, and non-bypassable pointers, which are central to the fine-grained field value. In sum, the most directly supportive content centers on CHERI's capability paradigm, Morello's hardware/prototype efforts, and CHERIoT's hardware-assisted memory safety and compartmentalization, with additional corroborating material from CHERI-focused FAQs and security assessments providing a broader context about capabilities, protection granularity, and hardware evidence.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.11.inspired_component",
      "citations": [
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to a secrets service named Fidelius that provides capability-scoped secret management and supports enclaves/backends such as SGX, TrustZone, and CHERI. The most relevant excerpt explicitly states that Fidelius is described as a capability-scoped secrets service and mentions its support for enclaves/compartments across SGX/TrustZone/CHERI backends, which directly aligns with the field value. Other excerpts discuss related attestation, SGX attestation reports, or generic seL4/seL-based concepts, but do not specifically describe Fidelius or its secret-management role, so they provide only indirect context.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.3.inspired_component",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "t preempt requests as often as every 5µsec",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores. For the many real-world scenarios where request service times follow distributions with high dispersion or a heavy tail, they allow short requests to be blocked behind long requests, which leads to poor tail latency.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores.",
            "\nFor the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The Time-Turner Scheduler is a concept of a scheduler operating at microsecond-scale with the ability to preempt and reallocate resources quickly, and to blend policies based on telemetry. Excerpts describing Shinjuku demonstrate preemption as often as every 5 microseconds and show that centralized scheduling policies can be applied at very fine granularity, which directly supports the idea of a microsecond-scale, policy-driven scheduler. Several excerpts emphasize improvements in tail latency and throughput when using μs-scale scheduling compared to alternatives, reinforcing that a Time-Turner-like component would enable tight control over scheduling decisions at sub-millisecond timescales. Additionally, mentions of dataplanes and comparisons to IX/ZygOS illustrate the practical context where such a scheduler is beneficial for microsecond-scale scheduling. Collectively, these points establish that a μs-scale, policy-blending scheduler akin to Time-Turner would be a plausible and advantageous component in this architecture, and that the cited works provide concrete evidence of the viability and impact of such scheduling behavior.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.12.description",
      "citations": [
        {
          "title": "Ferrocene: Qualified Rust toolchain for safety-critical systems",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Qualified for automotive, industrial and medical development. ... ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or ...See more",
            "ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or your choice of RTOS.",
            "Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles. It’s qualified at ASIL-D, the highest risk class, for peace of mind.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels.",
            "TÜV SÜD conducted the audit and Ferrous Systems – leading Rust experts – supports the signed installers as well as the nightly builds.",
            "The source code of Ferrocene is\nfully open source under the MIT OR Apache-2.0 license, including the full qualification\ndocuments.",
            "ull qualification\ndocuments. [Read\nDocumentation](https://public-docs.ferrocene.dev/main/index.html)"
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Ferrocene is ISO 26262 and IEC 61508 qualified!",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more",
            "We’ve qualified\nFerrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database. ",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "This standard provides automakers\nwith guidelines that make the software being used to develop, produce, operate\nand service the automotive sectors safe to use."
          ]
        },
        {
          "title": "Ferrocene - ISO 26262 and IEC 61508 qualified rust compiler",
          "url": "https://lobste.rs/s/qhohlx/ferrocene_iso_26262_iec_61508_qualified",
          "excerpts": [
            "The aim is to ensure there's a formal chain of traceability that goes from everything an end user compiled to the features you tested and found ..."
          ]
        },
        {
          "title": "Parasoft ISO 26262 Software Compliance Technical Whitepaper",
          "url": "https://alm.parasoft.com/hubfs/New_Pages/Whitepaper%20ISO%2026262%20Software%20Compliance%20With%20Parasoft.pdf",
          "excerpts": [
            "The information presented  here is intended to serve as an introduction to  ISO 26262 software verification and validation  processes with Paraso"
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a Rust toolchain that is qualified for safety-critical use under ISO 26262 and IEC 61508, enabling a viable path to certification for Rust-based software. Excerpts that clearly state Ferrocene is ISO 26262 and IEC 61508 qualified provide direct support for this claim. For instance, one excerpt explicitly notes that Ferrocene is qualified for safety-critical systems with ISO 26262 and IEC 61508, and mentions use in environments up to ASIL D, which aligns with a high-assurance certification path. Other excerpts reinforce the same conclusion by confirming official qualification status, certification certificates, and applicability to safety-critical domains. Additional excerpts discuss the disciplined, safety-focused qualification process (audits, certificates) and general statements about Ferrocene's qualification scope and standards coverage, all of which corroborate the claim that Ferrocene provides a certified Rust toolchain suitable for safety-critical development and certification workflows. Taken together, these excerpts consistently support the field value that Ferrocene is a qualified Rust toolchain for safety-critical standards and certification pathways. The strongest support comes from statements that Ferrocene is ISO 26262 and IEC 61508 qualified and capable of supporting environments up to the highest Automotive Safety Integrity Level, which directly map to the requested field value. The remaining excerpts add corroborating context about the certification process, official qualification announcements, and the scope of standards coverage, reinforcing the overall reliability of the claim.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.5.inspired_component",
      "citations": [
        {
          "title": "Arrakis: The Operating System is the Control Plane",
          "url": "https://web.eecs.umich.edu/~mosharaf/Readings/Arrakis.pdf",
          "excerpts": [
            "by S Peter · Cited by 614 — In Arrakis, we use SR-IOV, the IOMMU, and supporting adapters to provide direct application-level access to I/O devices. This is a modern implementation of ..."
          ]
        },
        {
          "title": "[PDF] We Need Kernel Interposition Over the Network Dataplane",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s08-sadok.pdf",
          "excerpts": [
            "The key idea behind kernel bypass is to allow applications to interface directly with I/O devices and. Permission to make digital or hard ..."
          ]
        },
        {
          "title": "MIT.pdf (References and excerpts on kernel-bypass, schedulers, and tail-latency systems such as Shenango, Arrakis, ZygOS)",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "— Together both ksched and DirectPath measurably reduce tail latency by freeing up the IOKernel to spend its time monitoring and reacting to.",
            "shnan. Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI\n2019, Boston, MA, ",
            ". ZygOS: Achieving Low Tail\nLatency for Microsecond-scale Networked Tasks. In SOSP, 2017."
          ]
        },
        {
          "title": "Building an ultra-low latency system (Medium article excerpt)",
          "url": "https://medium.com/@SourenAM/ultra-low-latency-and-light-speed-performance-system-design-7b3481ff8ca6",
          "excerpts": [
            "Networking is a critical pillar of ultra-low latency systems, particularly in high-frequency trading (HFT), where market data and trade orders must be transmitted within microseconds. Achieving low-latency communication involves minimizing protocol overhead, reducing system calls, and optimizing data paths.",
            "For HFT platforms, combining UDP with kernel bypass techniques— such as DPDK or `io_uring` — enables near light-speed communication",
            "zero-copy I/O, eliminating redundant data transfers between kernel and user space.",
            "This technique allows applications to directly map user-space buffers to network interfaces, achieving sub-microsecond latencies.",
            "Networking: Achieving Zero-Copy Communication",
            "These networking optimizations complement concurrency tuning and memory management strategies, forming the backbone of a truly low-latency pipeline.",
            "Building an ultra-low latency system requires integrating concurrency, memory optimization, and careful architectural choices to process data with minimal delay."
          ]
        }
      ],
      "reasoning": "The FLOO Network concept is a user-space NIC dataplane that bypasses the kernel for lower latency and higher throughput. Direct application-level access to I/O devices, as discussed in Arrakis, is a core mechanism for enabling such a design. Kernel interposition and kernel-bypass discussions further establish the feasibility and design space for moving NIC data paths into user space, which is the essential idea behind a Floo Network. Foundational MIT references tying kernel-bypass techniques to low tail latency further corroborate the architectural approach and rationale for a Floo Network. Additional material on zero-copy networking and io_uring-based paths reinforces how a user-space NIC dataplane can achieve the low-latency, high-throughput goals described in Floo Network. Collectively, the excerpts map directly to the principles and components that a Floo Network would embody, including direct user-space device access, kernel-bypass data paths, and performance-oriented design patterns.",
      "confidence": "high"
    },
    {
      "field": "gpu_and_accelerator_components.0",
      "citations": [
        {
          "title": "GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html",
          "excerpts": [
            " Linux has added support for PCI P2PDMA in Linux kernel version 6.2 and above kernels, enabling `ZONE_DEVICE` address pointers to GPU memory to be passed through the VFS without causing a page fault, in the case of NVMe, `nvidia-fs.ko`",
            "cuFileRead",
            "The cuFile library, `libcufile.so` , services those calls and makes appropriate IOCTL calls to the `nvidia-fs.ko` driver."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "PCI Peer-to-Peer DMA Support",
          "url": "https://docs.kernel.org/driver-api/pci/p2pdma.html",
          "excerpts": [
            "The NVMe PCI driver is both a client, provider and orchestrator in that it exposes any CMB (Controller Memory Buffer) as a P2P memory resource (provider), it ..."
          ]
        },
        {
          "title": "HowTo Implement PeerDirect Client using MLNX_OFED",
          "url": "https://enterprise-support.nvidia.com/s/article/howto-implement-peerdirect-client-using-mlnx-ofed",
          "excerpts": [
            "The AMD ROCnRDMA module provides PeerDirect support for AMD GPUs as part of the ROCm project. Peer Memory Registration/Deregistration. Memory Regions (MRs) are ..."
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage Best Practices",
          "url": "https://docs.nvidia.com/gpudirect-storage/best-practices-guide/index.html",
          "excerpts": [
            "In the above example, the initialization of `file_offset` is on line 10. 1. After allocating 1 GB of GPU memory, `cuFileBufRegister` is immediately invoked for the entire\n   range of 1 GB as seen on line 15. 2. Fill the entire 1 GB GPU memory by reading 100 MB at a time from file as seen in the following lo",
            "This example demonstrates using `cuFileRead` / `cuFileWrite` when IO is unaligned. The `devPtr_base + devPtr_offset` that are issued to `cuFileRead` or `cuFileWrite` are not 4K aligned. If the IO is unaligned, the cuFile library will issue IO through its internal GPU bounce buffer\ncache. However, if the allocation of the internal cache fails, the IO will fail. To avoid IO failure in this\ncase, you can set `allow_compat_mode` to `true` in the `/etc/cufile.json` file.",
            "Before you install GDS, you must disable IOMMU. Refer to Installing GPUDirect Storage for more information. Note. To determine whether the IOMMU setting is ..."
          ]
        },
        {
          "title": "LWN - Peer-to-peer DMA",
          "url": "https://lwn.net/Articles/931668/",
          "excerpts": [
            "Peer-to-peer DMA",
            "The idea is to\nremove the host system's participation in a transfer of data from one\nPCIe-connected device to another.",
            "The feature was originally aimed at NVMe\nSSDs so that data could simply be copied directly to and from the storage\ndevice without needing to move it to system memory and then from\nthere to somewhere else.",
            "P2PDMA is available in the NVMe driver but only devices\nthat have a CMB can be a DMA source or destination.",
            "NVMe devices are the\nonly systems currently supported as DMA masters as well.",
            "The IOMMU can also play a safeguard\nrole to ensure that errant DMA operations are not actually performed.",
            "The amdgpu/amdkfd driver has supported PCIe P2PDMA between AMD GPUs since 6.0."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky · Cited by 417 — In this paper, we show that a general- purpose RPC library called eRPC can provide state-of-the-art performance on commodity datacenter networks without."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kalia",
          "excerpts": [
            "by A Kalia · 2019 · Cited by 417 — eRPC is a new general-purpose remote procedure call (RPC) library that offers performance comparable to specialized systems, while running on commodity CPUs."
          ]
        },
        {
          "title": "Synchronizing Disaggregated Data Structures with One-Sided RDMA",
          "url": "https://dl.acm.org/doi/10.1145/3716377",
          "excerpts": [
            "In particular, RDMA's one-sided verbs allow a compute server to read or write directly to a remote memory server while bypassing the remote CPU."
          ]
        },
        {
          "title": "[PDF] FaRM: Fast Remote Memory - USENIX",
          "url": "https://www.usenix.org/system/files/conference/nsdi14/nsdi14-paper-dragojevic.pdf",
          "excerpts": [
            "FaRM uses one-sided RDMA reads to access data di- rectly and it uses RDMA writes to implement a fast message passing primitive. This ...",
            "by A Dragojević · 2014 · Cited by 1162 — It achieves low latency and high throughput because it bypasses the kernel, avoids the overheads of complex protocol stacks, and performs re-.See more"
          ]
        },
        {
          "title": "[PDF] FaSST: Fast, Scalable and Simple Distributed Transactions with Two ...",
          "url": "https://www.usenix.org/system/files/conference/osdi16/osdi16-kalia.pdf",
          "excerpts": [
            "RPCs involve the remote CPU in message processing and are more flexible than one-sided. RDMA, allowing data access in a single round trip [15]."
          ]
        },
        {
          "title": "picoquic with support for DPDK (work in progress) - GitHub",
          "url": "https://github.com/IPNetworkingLab/picoquic-dpdk",
          "excerpts": [
            "This is a version of PICOQUIC with support for DPDK, which provides better performance by bypassing the kernel networking stack."
          ]
        },
        {
          "title": "Towards Zero-Copy Serialization with NIC Scatter-Gather",
          "url": "https://sigops.org/s/conferences/hotos/2021/papers/hotos21-s10-raghavan.pdf",
          "excerpts": [
            "by D Raghavan · 2021 · Cited by 46 — We use a minimal UDP networking stack for DPDK based on LWIP [7]. We show the results in Figure 2. The “No Serialization” line removes ..."
          ]
        },
        {
          "title": "Efficient Remote Procedure Calls for Datacenters",
          "url": "https://www.pdl.cmu.edu/PDL-FTP/CloudComputing/CMU-CS-19-126.pdf",
          "excerpts": [
            "by A Kalia · 2019 — Currently, eRPC is primarily optimized for Mellanox NICs. eRPC also works with DPDK- capable NICs that support flow steering. For Mellanox Ethernet NICs, we ..."
          ]
        },
        {
          "title": "Datacenter RPCs Can Be General and Fast",
          "url": "https://www.usenix.org/system/files/login/articles/login_summer19_05_kalia.pdf",
          "excerpts": [
            "by D Andersen — eRPC is implemented in 6200 SLOC of C++, excluding tests and benchmarks. We evaluated eRPC's performance both in micro- benchmarks and real applications."
          ]
        },
        {
          "title": "Lecture 3: RPC",
          "url": "https://courses.cs.washington.edu/courses/cse452/22wi/lecture/L3/",
          "excerpts": [
            "Three options for RPC semantics: At least once (NFS, DNS, lab 1b); At most once (common, lab 1c); Exactly once. RPC Semantics.See more"
          ]
        },
        {
          "title": "at-most-once and exactly-once - rpc",
          "url": "https://stackoverflow.com/questions/13566869/at-most-once-and-exactly-once",
          "excerpts": [
            "Exactly-once semantics means that each message is delivered precisely once. The message can neither be lost nor delivered twice (or more times).See more"
          ]
        },
        {
          "title": "Exploiting Commutativity For Practical Fast Replication",
          "url": "https://www.usenix.org/system/files/nsdi19-park.pdf",
          "excerpts": [
            "by SJ Park · 2019 · Cited by 61 — To avoid duplicate executions of the requests that are already replicated to backups, CURP relies on exactly-once semantics provided by RIFL [20] ..."
          ]
        },
        {
          "title": "Logical Physical Clocks and Consistent Snapshots in Globally ...",
          "url": "https://cse.buffalo.edu/tech-reports/2014-04.pdf",
          "excerpts": [
            "In this paper, we introduced the hybrid logical clocks. (HLC) that combines the benefits of logical clocks (LC) and physical time (PT) while overcoming their ..."
          ]
        },
        {
          "title": "Hybrid Logical Clock (HLC)",
          "url": "https://sergeiturukin.com/2017/06/26/hybrid-logical-clocks.html",
          "excerpts": [
            "HLC combines the benefits of logical clocks (LC) and physical time (PT) while overcoming their shortcomings."
          ]
        },
        {
          "title": "Balance Performance in MsQuic and XDP",
          "url": "https://techcommunity.microsoft.com/t5/networking-blog/balance-performance-in-msquic-and-xdp/ba-p/3627665",
          "excerpts": [
            "Sep 16, 2022 — We look at two performance metrics here: Our goal is to get as low as possible latency while maintaining the highest RPS."
          ]
        },
        {
          "title": "Open-sourcing mvfst-rl, a research platform for managing ...",
          "url": "https://ai.meta.com/blog/open-sourcing-mvfst-rl-a-research-platform-for-managing-network-congestion-with-reinforcement-learning/",
          "excerpts": [
            "Oct 14, 2019 — Mvfst-rl implements congestion control with an asynchronous RL agent, making the training environment more realistic for real-world deployment."
          ]
        },
        {
          "title": "mvfst/quic/state/StateData.h at main",
          "url": "https://github.com/facebookincubator/mvfst/blob/master/quic/state/StateData.h",
          "excerpts": [
            "An implementation of the QUIC transport protocol. Contribute to facebook/mvfst development by creating an account on GitHub."
          ]
        },
        {
          "title": "MsQuic Performance Dashboard - Microsoft Open Source",
          "url": "https://microsoft.github.io/msquic/",
          "excerpts": [
            "MsQuic performance tests have standardized on the draft-banks-quic-performance specification for all scenarios, and are implemented in the MsQuic tool ..."
          ]
        },
        {
          "title": "picoquic-dpdk/README.picoquic.md at main - GitHub",
          "url": "https://github.com/IPNetworkingLab/picoquic-dpdk/blob/main/README.picoquic.md",
          "excerpts": [
            "Picoquic is currently developed as a Visual Studio 2017 project, and simultaneously tested on Windows and on Linux. It has a dependency on the Picotls ..."
          ]
        },
        {
          "title": "Understanding QUIC's Throughput Speedbumps",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3744200.3744780",
          "excerpts": [
            "by S Mukherjee · 2025 — Moreover, kernel-bypass stacks have even higher throughput than the Linux UDP stack. • Crypto:This stage keeps track of all crypto metadata ...See more"
          ]
        },
        {
          "title": "QUIC for the kernel",
          "url": "https://news.ycombinator.com/item?id=44746948",
          "excerpts": [
            "Jul 31, 2025 — This could be achieved by encapsulating TCP in UDP and running a custom TCP stack in userspace on the client. That would allow protocol ...See more"
          ]
        },
        {
          "title": "RPCValet: NI-Driven Tail-Aware Balancing of μs-Scale RPCs",
          "url": "https://faculty.cc.gatech.edu/~adaglis3/files/papers/RPCValet_asplos19.pdf",
          "excerpts": [
            "RPCValet, an NI-driven dynamic load-balancing design\nthat outperforms existing hardware mechanisms for load\ndistribution, and approaches the theoretical maximum\nperformance predicted by queuing models.",
            "Hardware and protocol extensions to soNUMA for na-\ntive messaging support, a required feature for efficient\nRPC handlin",
            "We distinguish RPCValet from\nthese software-only systems by our focus on balancing the\nload of incoming RPCs across the CPU cores.",
            "An RPCValet implementation on soNUMA that delivers\nnear-ideal RPC throughput under strict SLOs, attaining\nwithin 3–16% of the theoretically optimal queuing model.",
            "For µs-scale RPCs, RPCValet outperforms software-based\nand RSS-like hardware-driven load distribution by 2.3–\n2.7× and 29–76%, respectively",
            "RPCValet performs within 3–15% of the ideal single-\nqueue system and significantly outperforms current RPC\nload-balancing approaches",
            "To lower communication overheads and tighten tail la-\ntency, there has been an intensive evolution effort in data-\ncenter-scale networking hardware and software, away from\ntraditional POSIX sockets and TCP/IP and towards lean user-\nlevel protocols such as InfiniBand/RDMA [21] or dataplanes\nsuch as IX a"
          ]
        },
        {
          "title": "RIFL: Reusable Infrastructure for Linearizability (Stanford paper)",
          "url": "https://web.stanford.edu/~ouster/cgi-bin/papers/rifl.pdf",
          "excerpts": [
            "In this paper we describe RIFL (Reusable Infrastruc-\nture for Linearizability), which is a mechanism for ensur-\ning “exactly-once semantics” in large-scale syst",
            "RIFL\nrecords the results of completed remote procedure calls\n(RPCs) durably; if an RPC is retried after it has completed,\nRIFL ensures that the correct result is returned without re-\nexecuting the RPC",
            "RIFL provides a\ngeneral-purpose mechanism for converting at-least-once\nRPC semantics to exactly-once semantics, thereby mak-\ning it easy to turn non-linearizable operations into lineariz-\nable ones.",
            "RAMCloud has several properties that make it an\nattractive target for RIFL. It is already designed for large\nscale and it offers low latency (small remote reads take\n4.7 µs end to end, small durable writes take 13.5 µs);",
            "[8], which have end-to-end RPC times as low as\n5 µs.\n ... \nThese systems offer latencies as\nlow as 5 µs end-to-end for remote operations; the overheads\nintroduced by RIFL must not significantly impact these la-\ntencies. For examp",
            "FaRM [8], which have end-to-end RPC times as low as\n5 µs."
          ]
        },
        {
          "title": "RIFL exactly-once semantics and deduplication mechanisms",
          "url": "https://www.cncf.io/blog/2024/01/19/xline-command-deduplication-mechanism-part-one-introduction-to-rifl/",
          "excerpts": [
            "When the system implements this deduplication mechanism, it can realize exactly-once semantics of command execution, and thus realize a higher ...",
            " The RIFL paper mentions that servers can cache the expiration time of a client\\_id lease and query the Lease Manager only as it nears expiration, reducing network communication.",
            " In the aforementioned processes, either checkDuplicate or processAck involves at least one O(n) complexity operation (either checking duplicates in sequenceNumber order or filtering unordered sequenceNumbers but needing to traverse and filter those less than first\\_incomplete for processAck).",
            "Compared to the O(1) complexity of the previous IndexSet approach, RIFL incurs some additional overhead.",
            "Performance can be optimized by making processAck a separate RPC to notify the server to recycle completion records."
          ]
        },
        {
          "title": "Kernel-bypass network stacks performance (USENIX ATC 2025, Awamoto)",
          "url": "https://www.usenix.org/system/files/atc25-awamoto.pdf",
          "excerpts": [
            "\nDemikernel, which achieves 13 µs , the lowest among all the\n\nstacks we test."
          ]
        },
        {
          "title": "arXiv:2505.14358 - Latency-Aware Networking for Ultra-Low-Latency RPCs",
          "url": "https://arxiv.org/html/2505.14358v1",
          "excerpts": [
            "Pirate accurately estimates response latencies over an encrypted transport (mvfst QUIC [31] ).",
            "Figure 9 compares the accuracy of Pirate against\nthe ground truth response latency and the\nrequest-to-triggered-request latency, for a connection\nrunning for over a minute.",
            "The Pirate algorithm runs on the switch-facing ingress\ninterface of the vantage point.",
            "g loads, the\nlatency-aware Katran is able to produce a sizable\nbenefit in tail latency, and also leads to more\npredictable tail latencies (shorter error bars).",
            "The\nlatency awareness provided by continuous and real-time\nresponse latency measurement enables reducing the 99th\npercentile tail response latency by 37% on average\nacross loads.",
            "In the future, we believe that\neither an extension to the protocol, or heuristics\nbased on payload sizes, may be applied to accurately\nidentify pure ACKs (scenario -ack ) and\npractically realize these benefits",
            "Figure 9: CDF of measured response latencies for a\nQUIC connection, in scenarios that do or do not\ngenerate pure ACK frames ( -ack and -noack ).",
            "G4. Capable of being run “online,” in\nparticular on software middleboxes. Measurement and\nmonitoring devices are frequently deployed in the form\nof virtual network functions managed through a\nsoftware-defined measurement infrastructure, e.g. [ 89 , 35 ] ."
          ]
        },
        {
          "title": "Paper review: Implementing Linearizability at Large Scale and Low ...",
          "url": "http://muratbuffalo.blogspot.com/2016/02/paper-review-implementing.html",
          "excerpts": [
            "In order to implement exactly-once semantics, RIFL must solve 4 problems: RPC identification, completion record durability, retry rendezvous, ..."
          ]
        },
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        },
        {
          "title": "[PDF] RAMCloud RPC Performance Over 10G Ethernet Fabric",
          "url": "https://www.scs.stanford.edu/14au-cs244b/labs/projects/montazeri.pdf",
          "excerpts": [
            "RAMCloud RPC system is one of the lowest latency RPC systems designed up until today. The low latency characteristics in RAMCloud's RPC has been achieved using."
          ]
        },
        {
          "title": "[PDF] RAMCloud and the Low- Latency Datacenter - SNIA.org",
          "url": "https://www.snia.org/sites/default/files/JohnOusterhout_RAMCloud.pdf",
          "excerpts": [
            "▫ Bad for latency. ▫ E.g. RAMCloud threading structure costs 200-300ns/RPC. ▫ Virtualization is potential problem. ○ Buffering. ▫ Network ..."
          ]
        },
        {
          "title": "intel-sgx-dcap-ecdsa-orientation.pdf",
          "url": "https://www.intel.com/content/dam/develop/public/us/en/documents/intel-sgx-dcap-ecdsa-orientation.pdf",
          "excerpts": [
            "This orientation guide describes various third party attestation collaterals provided by Intel that you can use to enable remote attestation of Intel® SGX ...",
            "\nThe Intel® SGX provisioning certificate service offers\n\nAPIs for retrieving provisioning certification key (PCK)\n\ncertificates, revocation lists, Trusted Computing Base\n\n(TCB) information, and the quoting enclave (QE) identity\n\nfor platforms with Intel® SGX enabled, all provided to an\n\non-premise caching service for the Intel® SGX\n\nprovisioning certificate service.",
            "The caching service for Intel® SGX provisioning certification\n\nservice allows a CSP or a datacenter to cache PCK\n\ncertificates, PCK certificate revocation lists (CRL), TCB\n\nInformation, and QE identity structures for all platforms in\n\nits cloud or data center",
            " The CSP or data center can request the attestation data\n\nstructures from Intel for each of its platforms during a\n\ndeployment phase. To request the attestation data from\n\nthe Intel® SGX provisioning certificate service, a proxy\n\nserver with controlled access to the Internet is used. During runtime, the ECDSA based Intel® SGX quote can be\n\nverified using the data cached in the caching service for\n\nthe Intel® SGX provisioning certificate service.",
            "\nThe main limitation is\n\nthat it requires run-time access to the internet to acquire\n\nthe PCK certificates from the Intel® SGX provisioning\n\ncertificate service. I.e. it does not support APIs to retrieve\n\nPCK certificates at deployment time.",
            "t**\n\nIntel has developed a quote format for Intel® SGX ECDSA\n\nbased quotes. This format is used by both the Intel SGX\n\nECDSA quote generation library and the Intel® SGX ECDSA\n\nQuote Verification Library.",
            "**\n\nThe platform quote provider library provides a set of APIs\n\nthat allow the Intel® SGX ECDSA quote generation library\n\nto get platform specific services",
            " platform quote provider library API documentation,\n\nsee https://download.01.org/intel-sgx/dcap-\n\n1\\.1/linux/docs/Intel\\_SGX\\_ECDSA\\_QuoteGenReference\\_DC\n\nAP\\_API\\_Linux",
            ". ** **ECDSA quote format**\n\nIntel has developed a quote format for Intel® SGX ECDSA\n\nbased quotes. This format is used by both the Intel SGX\n\nECDSA quote generation library and the Intel® SGX ECDSA\n\nQuote Verification Library.",
            "This orientation guide describes various third party attestation collaterals provided by Intel that you can use to enable remote attestation of Intel® SGX ..."
          ]
        },
        {
          "title": "[PDF] ReDMArk: Bypassing RDMA Security Mechanisms - USENIX",
          "url": "https://www.usenix.org/system/files/sec21-rothenberger.pdf",
          "excerpts": [
            "They raise concerns about the pre- dictability of hardware-managed memory protection key and the potential misuse of one-sided RDMA ..."
          ]
        },
        {
          "title": "intel/SGX-TDX-DCAP-QuoteVerificationService",
          "url": "https://github.com/intel/SGX-TDX-DCAP-QuoteVerificationService",
          "excerpts": [
            "Quote Verification Service is a stateless server endpoint implementation that verifies attestation evidence (quote) of ISV (Independent Software Vendor) ..."
          ]
        },
        {
          "title": "RDMA IP Core for RoCE v2 from Grovf - BittWare",
          "url": "https://www.bittware.com/partners/grovf-rdma/",
          "excerpts": [
            "MACsec + IPsec. Featuring Xiphera's IP running these popular security protocols in hardware has never been easier! MACsec @ Up to 100G · IPsec @ up to 200G · On ..."
          ]
        },
        {
          "title": "eRPC - Low latency and performance metrics",
          "url": "https://github.com/erpc-io/eRPC",
          "excerpts": [
            "Low latency: 2.3 microseconds round-trip RPC latency with UDP over Ethernet\n    * Performance for small 32-byte RPCs: ~10M RPCs/sec with one CPU core,\n60--80M RPCs/sec with one",
            "Bandwidth for large RPC: 75 Gbps on one connection (one CPU core at server\nand client) for 8 MB RPCs",
            "Scalability: 20000 RPC sessions per server",
            "End-to-end congestion control that tolerates 100-way incasts"
          ]
        },
        {
          "title": "eRPC: A high-performance RPC system for datacenter networks",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/erpc_2019.pdf",
          "excerpts": [
            "eRPC is at most 800 ns slower than RDMA reads.",
            " eRPC's median latency on CX5 is only 2.3 µs",
            "In microbenchmarks, one CPU\ncore can handle up to 10 million small RPCs per second",
            "zero-copy transmission\nin the presence of retransmissions, node failures, and\nrate limiting",
            "eRPC works well in commodity, lossy datacenter networks.",
            "eRPC uses userspace net-\nworking with polling, as in most prior high-performance\nnetworked system"
          ]
        },
        {
          "title": "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics (RAMCloud)",
          "url": "https://dl.acm.org/doi/10.1145/2815400.2815416",
          "excerpts": [
            "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics to exactly-once semantics, thereby making it easy to turn non-linearizable ...",
            "RIFL is designed for large-scale systems and is lightweight enough to be used in low-latency environments.",
            "RIFL handles data migration by associating linearizability metadata with objects in the underlying store and migrating metadata with the corresponding objects.",
            "It uses a lease mechanism to implement garbage collection for metadata.",
            "We have implemented RIFL in the RAMCloud storage system and used it to make basic operations such as writes and atomic increments linearizable; RIFL adds only 530 ns to the 13.5 μs base latency for durable writes.",
            "We also used RIFL to construct a new multi-object transaction mechanism in RAMCloud; RIFL's facilities significantly simplified the transaction implementation.",
            "The transaction mechanism can commit simple distributed transactions in about 20 μs and it outperforms the H-Store main-memory database system for the TPC-C benchmark."
          ]
        },
        {
          "title": "arXiv:1801.05863 - Design and Implementation of RA-TLS for Intel SGX Enclaves",
          "url": "https://arxiv.org/pdf/1801.05863",
          "excerpts": [
            "e propose to\n\ninclude additional information into the X.509\n\ncertificate exchanged during a TLS handshake",
            "**Attestation Verification Report. ** This is the reply\n\nreceived from the Intel Attestation Service (IAS) when\n\nsubmitting a quote for verification [10]. IAS reports\n\nwhether the quote was generated on a genuine Intel\n\nSGX platform by a genuine encl",
            "**Attestation Verification Report Signature. ** The\n\nattestation verification report is signed by IAS. The\n\nsignature ensures that report is authentic and\n\nunmodifi",
            "**Attestation Report Signing Certificate. ** To verify the\n\nsignature over the attestation report, the client must\n\nknow the keys used to create the signatur",
            "**Non-standard X.509 extensions. ** We embed the SGX\n\nidentity information in custom X.509 extensions",
            "**Quoting Enclave Identity. ** The latest identity of Intel’s\n\nquoting enclave including its code measurement and\n\nsecurity versions number"
          ]
        },
        {
          "title": "Reusable Infrastructure for Linearizability(RIFL)",
          "url": "https://www.linkedin.com/pulse/reusable-infrastructure-linearizabilityrifl-hohuan-chang",
          "excerpts": [
            "RIFL aims to solve linearizability problems on large scale distributed systems by providing \"exactly once\" delivery. In fact that thing is not ..."
          ]
        },
        {
          "title": "At-most-once Algorithm for Linearizable RPC in Distributed ...",
          "url": "https://www.scs.stanford.edu/14au-cs244b/labs/projects/park.pdf",
          "excerpts": [
            "RAMCloud handles missing responses by retrying the RPC. Retrying RPCs with missing responses is appropriate for ensuring that the RPC is executed at-least-once ..."
          ]
        },
        {
          "title": "QUIC: A UDP-Based Multiplexed and Secure Transport",
          "url": "https://datatracker.ietf.org/doc/rfc9000/",
          "excerpts": [
            "Feb 19, 2022 — QUIC provides applications with flow-controlled streams for structured communication, low-latency connection establishment, and network path migration."
          ]
        },
        {
          "title": "One of either QUIC or RDMA already deliver this, ...",
          "url": "https://news.ycombinator.com/item?id=28441315",
          "excerpts": [
            "Sep 7, 2021 — QUIC achieves lower latency for connection establishment than TCP+TLS by merging the TCP and TLS handshakes and avoids additional handshakes by ..."
          ]
        },
        {
          "title": "QUIC is not quick enough over fast internet",
          "url": "https://news.ycombinator.com/item?id=41484991",
          "excerpts": [
            "A shared memory queue is a reasonable basis for improving the IO cost between applications and IO stacks such as the network or filesystem stacks."
          ]
        },
        {
          "title": "Attestation Services for Intel® Software Guard Extensions",
          "url": "https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/attestation-services.html",
          "excerpts": [
            "ECDSA-based attestation with Intel SGX DCAP allows providers to build and deliver their own attestation service. This is useful for enterprise, data center, and ..."
          ]
        },
        {
          "title": "Using RDMA Efficiently for Key-Value Services",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/herd_2014.pdf",
          "excerpts": [
            "ABSTRACT. This paper describes the design and implementation of HERD, a key- value system designed to make the best use of an RDMA network."
          ]
        },
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        },
        {
          "title": "Intel SGX",
          "url": "https://docs.ata.network/pom/attestation-module/machine-attestation/intel-sgx",
          "excerpts": [
            "Apr 19, 2024 — Intel SGX facilitates two distinct categories of attestation: Local Attestation, also known as Intra-Platform Attestation, and Remote ..."
          ]
        },
        {
          "title": "Solved: intel sgx secure channel",
          "url": "https://community.intel.com/t5/Intel-Software-Guard-Extensions/intel-sgx-secure-channel/td-p/1358583",
          "excerpts": [
            "Feb 9, 2022 — The answer remains the same. You should build a secure channel between the untrusted application on server S1 and the application on server S2."
          ]
        },
        {
          "title": "QUIC: The Secure Communication Protocol Shaping ...",
          "url": "https://www.zscaler.com/blogs/product-insights/quic-secure-communication-protocol-shaping-future-of-internet",
          "excerpts": [
            "Oct 8, 2024 — One of QUIC's main advantages is its reduced latency. Traditional TCP requires a multi-step handshake to establish a connection and additional ..."
          ]
        },
        {
          "title": "Attestation - SGX 101 - GitBook",
          "url": "https://sgx101.gitbook.io/sgx101/sgx-bootstrap/attestation",
          "excerpts": [
            "Nov 17, 2022 — Local attestation provides an authenticated assertion between two enclaves running on the same platform that they can trust each other and exchange information ..."
          ]
        },
        {
          "title": "First, the latency of RPC may vibrate... RDMA and queue pair (QP)",
          "url": "https://www.usenix.org/system/files/atc22-wei.pdf",
          "excerpts": [
            "As the latency of typical RDMA-enabled applications that\nrequire elasticity has reached to microsecond-scale (see Fig-\nure 1(a)), this high connection time may significantly decrease\nthe application efficiency, e.g., increasing latency when ex-\npanding resources to handle load spike",
            "RDMA is a high bandwidth and low latency networking fea-\nture widely adopted in modern datacenters [53, 19",
            "It has\ntwo well-known primitives: two-sided provides a message\npassing primitive while one-sided provides a remote memory\nabstraction—the RDMA-capable network card (RNIC) can\ndirectly read/write server memory in a CPU-bypassing way.",
            "he latency of RPC may vibrate to tens of mil- liseconds due to the scheduling and queuing overhead of the. CP"
          ]
        },
        {
          "title": "RDMA ICDE20 Paper",
          "url": "https://www.cs.purdue.edu/homes/csjgwang/CloudNativeDB/RDMAICDE20.pdf",
          "excerpts": [
            "UDP and protocols on top of it, like QUIC [20], also have the potential to improve performance, but currently lack hardware acceleration."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://www.usenix.org/legacy/event/sec10/tech/full_papers/Watson.pdf",
          "excerpts": [
            "by RNM Watson · Cited by 275 — Capsicum extends, rather than replaces,. UNIX APIs, providing new kernel primitives (sandboxed capability mode and capabilities) and a userspace sand- box API."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://www.cl.cam.ac.uk/research/security/capsicum/",
          "excerpts": [
            "Capsicum extends the POSIX API, providing several new OS primitives to support object-capability security on UNIX-like operating systems: capabilities - refined ..."
          ]
        },
        {
          "title": "Capsicum: practical capabilities for UNIX",
          "url": "https://research.google.com/pubs/archive/36736.pdf",
          "excerpts": [
            "by RNM Watson · 2010 · Cited by 275 — Capsicum extends, rather than replaces, UNIX APIs, providing new kernel primitives. (sandboxed capability mode and capabilities) and a userspace ..."
          ]
        },
        {
          "title": "What if Rust is combined with CHERI(Capability Hardware ...",
          "url": "https://www.reddit.com/r/rust/comments/1m3w25v/what_if_rust_is_combined_with_chericapability/",
          "excerpts": [
            "CHERI revolutionize computer architecture and can let the memory error hidden in C/C++ to be precisely catched by OS."
          ]
        },
        {
          "title": "exploring CHERI capabilities for a safe language - Nicholas Sim",
          "url": "https://nw0.github.io/cheri-rust.pdf",
          "excerpts": [
            "by NWS Sim · 2020 · Cited by 7 — Both Rust, a safe programming language, and CHERI, an architecture providing hardware capabil- ities, claim to provide low-overhead memory safety to prevent ..."
          ]
        },
        {
          "title": "glommio - Rust",
          "url": "https://docs.rs/glommio/latest/glommio/",
          "excerpts": [
            "Glommio is a library providing a safe Rust interface for asynchronous, thread-local I/O, based on the linux io_uring interface and Rust's async support."
          ]
        },
        {
          "title": "DataDog/glommio",
          "url": "https://github.com/DataDog/glommio",
          "excerpts": [
            "Glommio (pronounced glo-mee-jow or |glomjəʊ|) is a Cooperative Thread-per-Core crate for Rust & Linux based on io_uring . Like other rust asynchronous crates, ...",
            "Glommio is a thread-per-core crate that makes writing highly parallel asynchronous applications in a thread-per-core architecture easier for rustaceans."
          ]
        },
        {
          "title": "tokio-rs/tokio-uring: An io_uring backed runtime for Rust",
          "url": "https://github.com/tokio-rs/tokio-uring",
          "excerpts": [
            "This crate provides io-uring for Tokio by exposing a new Runtime that is compatible with Tokio but also can drive io-uring -backed resources."
          ]
        },
        {
          "title": "Announcing tokio-uring: io-uring support for Tokio",
          "url": "https://tokio.rs/blog/2021-07-tokio-uring",
          "excerpts": [
            "Jul 19, 2021 — Tokio is a runtime for writing reliable asynchronous applications with Rust. It provides async I/O, networking, scheduling, timers, ..."
          ]
        },
        {
          "title": "Tokio vs Tokio-Uring for High-Throughput Web Servers",
          "url": "https://www.reddit.com/r/rust/comments/1hhn40b/performance_comparison_tokio_vs_tokiouring_for/",
          "excerpts": [
            "io_uring is faster. It allows zero copy APIs, allows sharing read and write buffers with the kernel, and a bunch of other goodies."
          ]
        },
        {
          "title": "Zero-copy async IO in Rust? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/zero-copy-async-io-in-rust/106996",
          "excerpts": [
            "It is fundamentally impossible to do async IO from/to &[u8] / &mut [u8] without copies in Rust. The reason is that any such operation must be able to read/ ...",
            "Feb 18, 2024 — Because io-uring differs significantly from epoll, Tokio must provide a new set of APIs to take full advantage of the reduced overhead."
          ]
        },
        {
          "title": "[PDF] LibPreemptible: Enabling Fast, Adaptive, and Hardware-Assisted ...",
          "url": "https://www.csl.cornell.edu/~zhiruz/pdfs/libpreemptible-hpca2024.pdf",
          "excerpts": [
            "Compared to the prior state-of-the-art scheduling system Shinjuku, our system achieves significant tail latency and throughput improvements for various ..."
          ]
        },
        {
          "title": "IO_uring Zero-Copy Receive Support Ready For Linux ...",
          "url": "https://www.reddit.com/r/linux/comments/1ilacgo/io_uring_zerocopy_receive_support_ready_for_linux/",
          "excerpts": [
            "My basic understanding is that DPDK will bypass the kernel network stack and provide direct access to network packets in the user application."
          ]
        },
        {
          "title": "capsule - Rust - Docs.rs",
          "url": "https://docs.rs/capsule",
          "excerpts": [
            "We've created a tool to efficiently manipulate network packets while being type-safe, memory-safe, and thread-safe. Building on DPDK and Rust, Capsule offers:."
          ]
        },
        {
          "title": "datenlord/async-dpdk: DPDK API in async Rust - GitHub",
          "url": "https://github.com/datenlord/async-dpdk",
          "excerpts": [
            "DPDK API in async Rust. Contribute to datenlord/async-dpdk development by creating an account on GitHub."
          ]
        },
        {
          "title": "Zero-Copy in Rust: Challenges and Solutions",
          "url": "https://coinsbench.com/zero-copy-in-rust-challenges-and-solutions-c0d38a6468e9",
          "excerpts": [
            "Jun 8, 2025 — The concept of zero-copy in Rust refers to a technique of working with data in memory without making unnecessary copies, which significantly improves ..."
          ]
        },
        {
          "title": "[PATCH] rust: RFC/demo of safe API for Dpdk Eal, Eth and Rxq",
          "url": "https://inbox.dpdk.org/dev/9c4a970a-576c-7b0b-7685-791c4dd2689d@nvidia.com/T/",
          "excerpts": [
            "[PATCH] rust: RFC/demo of safe API for Dpdk Eal, Eth and Rxq ... DPDK provides mbuf*s: that's a large mismatch. (Yes I'm aware of ..."
          ]
        },
        {
          "title": "Resistance to Rust abstractions for DMA mapping in Linux ...",
          "url": "https://www.reddit.com/r/linux/comments/1igrime/resistance_to_rust_abstractions_for_dma_mapping/",
          "excerpts": [
            "We wrote a single piece of Rust code that abstracts the C API for all Rust drivers, which we offer to maintain ourselves."
          ]
        },
        {
          "title": "Using Capabilities to design safer, more expressive APIs in Rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/7rmgxo/using_capabilities_to_design_safer_more/",
          "excerpts": [
            "The point here being that `Capability` is a trait, which means you can implement it on any type you want.",
            "Suppose we have a `SQLite` type that implements a bunch of methods for interacting with our database.",
            "We might want to grant the capability to a function to save new comments on a thread (just as an example), but want to always first check that the caller has permission to do so. We could achieve this by implementing a new capability for our `SQLite` type. I'm just sketching code below- don't expect this to run as is.",
            "struct SQLite(Connection);",
            "// Post will contain the `Comment` we want to save and the `User` that is trying to post the comment. struct Post<T, U>(pub T, pub U);",
            "impl Capability<Post<Comment, User>> for SQLite {",
            "  type Data = Comment;",
            "  type Error = DBError;",
            "  fn perform(&self, post_comment: Post<Comment, User>) -> Result<Comment, DBError> {",
            "    // Here is where we can check permissions and do the save operation. if self.user_can_post_comments(post_comment.1) {",
            "      self.save_comment(post_comment.0)",
            "    } else {",
            "      Err(InsufficientPermission)",
            "    }",
            "fn handle_comment_post<DB>(db: &DB, comment: Comment, user: User) -> Result<(), DBError>",
            "   where DB: Capability<Post<Comment, User>>",
            "  db.perform(Post(comment, user)).map(|_| ())",
            "This way, capabilities get passed into functions from any of the function's call sites. I could have, instead of writing the `handle_comment_post` function, also have simply made `MyRequestHandler` generic on its contained values and used the `Capability` trait to specify the capabilities that it wants to have.",
            "In this scenario, I can restrict the capabilities of my functions, request handlers, etc. in my `main` function, when I set up each handler. The point here being that `Capability` is a trait, which means you can implement it on any type you want.",
            "If you wanted to create a new type that maybe wraps `SQLite`, you could implement capabilities for that type that only grant a subset of the capabilities had by `SQLite` itself.",
            "Furthermore, since `Capability` is generic on its input, you can define any other types you want, like `Save`, `Post`, `PostButCheckPermissionsFirst`, etc. to only allow callers to use a specific implementation.",
            "e could now write a function that requests this new capability.",
            "struct HandleCommentPosts<DB> {",
            "  database: DB,",
            "impl<DB> Handler for HandleCommentPosts<DB>\n ",
            "  where DB: Capability<Post<Comment, User>>",
            "{",
            "{",
            "  fn handle(&self, req: mut Request) -> IronResult<...> {",
            "    self.database.perform(Post(comment, user))",
            "  }",
            "  }",
            "}",
            "}",
            "}",
            "}",
            "This way, capabilities get passed into functions from any of the function's call sites.",
            "t `Capability` is a trait, which means you can implement it on any type you want. If you "
          ]
        },
        {
          "title": "io_uring interface and shared ring buffers (as described in the provided document)",
          "url": "https://unixism.net/loti/low_level.html",
          "excerpts": [
            "    }",
            "    }",
            "}",
            "}",
            "}"
          ]
        },
        {
          "title": "Sandbox Permissions - Flatpak documentation",
          "url": "https://docs.flatpak.org/en/latest/sandbox-permissions.html",
          "excerpts": [
            "Sandbox Permissions . One of Flatpak's main goals is to increase the security of desktop systems by isolating applications from one another."
          ]
        },
        {
          "title": "Snap confinement | Snapcraft documentation",
          "url": "https://snapcraft.io/docs/snap-confinement",
          "excerpts": [
            "Snap confinement determines the amount of access an application has to system resources, such as files, the network, peripherals and services."
          ]
        },
        {
          "title": "Manifests - Flatpak documentation",
          "url": "https://docs.flatpak.org/en/latest/manifests.html",
          "excerpts": [
            "This page provides information and guidance on how to use manifests, including an explanation of the most common parameters that can be specified."
          ]
        },
        {
          "title": "Snapcraft confinement & interfaces",
          "url": "https://snapcraft.io/blog/snapcraft-confinement-interfaces",
          "excerpts": [
            "Jun 6, 2019 — In this tutorial, we are going to talk about confinement and interfaces – how to restrict what your snaps can do, and then fine-tune the ..."
          ]
        },
        {
          "title": "Flatpak documentation",
          "url": "https://docs.flatpak.org/",
          "excerpts": [
            "These docs cover everything you need to know to build and distribute applications using Flatpak. They begin with a basic introduction to Flatpak."
          ]
        },
        {
          "title": "Interfaces - Snapcraft 8.11.1 documentation",
          "url": "https://documentation.ubuntu.com/snapcraft/stable/explanation/interfaces/",
          "excerpts": [
            "A strictly-confined snap is considered untrusted and runs in a restricted environment. It's only able to access a limited set of resources outside the ..."
          ]
        },
        {
          "title": "Flatpak Command Reference",
          "url": "https://docs.flatpak.org/en/latest/flatpak-command-reference.html",
          "excerpts": [
            "Flatpak is a tool for managing applications and the runtimes they use. In the Flatpak model, applications can be built and distributed independently from the ..."
          ]
        },
        {
          "title": "Rust public abi for foreign language ffi",
          "url": "https://stackoverflow.com/questions/78285226/rust-public-abi-for-foreign-language-ffi",
          "excerpts": [
            "I'm writing a language and want it to be binary compatible with rust, c++ and some other languages. The problem is that I couldn't find information on rusts ..."
          ]
        },
        {
          "title": "Rust ❤️ C++",
          "url": "https://cxx.rs/",
          "excerpts": [
            "safe interop between Rust and C++ by David Tolnay. This library provides a safe mechanism for calling C++ code from Rust and Rust code from C++."
          ]
        },
        {
          "title": "Crate abi_stable - Rust - Docs.rs",
          "url": "https://docs.rs/abi_stable/",
          "excerpts": [
            "The `abi_stable` crate is for Rust-to-Rust FFI, creating libraries loaded at startup with load-time type-checking, and allows dynamic libraries even with ..."
          ]
        },
        {
          "title": "We Need Type Information, Not Stable ABI",
          "url": "https://blaz.is/blog/post/we-dont-need-a-stable-abi/",
          "excerpts": [
            "What it seems to boil down to is parsing a portion of Rust code, collecting types within, and then emitting a C layer, as well as other language ..."
          ]
        },
        {
          "title": "cxx - Rust",
          "url": "https://docs.rs/cxx",
          "excerpts": [
            "This library provides a safe mechanism for calling C++ code from Rust and Rust code from C++, not subject to the many ways that things can go wrong."
          ]
        },
        {
          "title": "abi_stable - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/abi_stable",
          "excerpts": [
            "To run the example crates you'll generally have to build the *_impl crate, then run the *_user crate (all *_user crates should have a help ..."
          ]
        },
        {
          "title": "Experimental Rust Feature: Safer Interoperable ABI",
          "url": "https://news.ycombinator.com/item?id=34145972",
          "excerpts": [
            "Dec 27, 2022 — This proposal seems to define how to convert C ABI to/from Rust types in a standard way. This will likely improve Rust+C use cases over time."
          ]
        },
        {
          "title": "Is #[repr(C)] necessary for Rust-to-Rust FFI - help",
          "url": "https://users.rust-lang.org/t/is-repr-c-necessary-for-rust-to-rust-ffi/50596",
          "excerpts": [
            "The trouble is that in Rust when a struct is repr(Rust) (the default) it is then free to use whatever layout it thinks is most efficient for your program."
          ]
        },
        {
          "title": "The new dynamic user space tracing feature in LTTng",
          "url": "https://lttng.org/blog/2019/10/15/new-dynamic-user-space-tracing-in-lttng/",
          "excerpts": [
            "Oct 15, 2019 — This feature allows you to instrument functions in user space apps and shared libraries at run time by adding and removing user space probes."
          ]
        },
        {
          "title": "aya_ebpf - Rust - Docs.rs",
          "url": "https://docs.rs/aya-ebpf",
          "excerpts": [
            "A library to write eBPF programs. Aya-bpf is an eBPF library built with a focus on operability and developer experience. It is the kernel-space counterpart of ...",
            "A library to write eBPF programs. Aya-bpf is an eBPF library built with a focus on operability and developer experience. It is the kernel-space counterpart of ..."
          ]
        },
        {
          "title": "provide observability on how kernel handles io_uring request #467",
          "url": "https://github.com/axboe/liburing/issues/467",
          "excerpts": [
            "FWIW, perf record can track multiple trace points. // trace all io_uring events perf record -e \"io_uring:*\" -- ./app_to_trace // two specific ..."
          ]
        },
        {
          "title": "LTTng v2.13 — LTTng Documentation",
          "url": "https://lttng.org/docs/v2.13/",
          "excerpts": [
            "Nov 28, 2023 — This is a short guide to get started quickly with LTTng kernel and user space tracing. Before you follow this guide, make sure to install LTTng."
          ]
        },
        {
          "title": "aya - Rust - Docs.rs",
          "url": "https://docs.rs/aya",
          "excerpts": [
            "Aya is an eBPF library built with a focus on operability and developer experience. It does not rely on libbpf nor bcc - it's built from the ground up purely in ..."
          ]
        },
        {
          "title": "Missing Manuals - io_uring worker pool - The Cloudflare Blog",
          "url": "https://blog.cloudflare.com/missing-manuals-io_uring-worker-pool/",
          "excerpts": [
            "We can discover the tracepoints with perf list or bpftrace -l , or by browsing the events/ directory on the tracefs filesystem , usually ..."
          ]
        },
        {
          "title": "Can I view LTTng traced Userspace events and Kernel ...",
          "url": "https://stackoverflow.com/questions/60330773/can-i-view-lttng-traced-userspace-events-and-kernel-events-together-in-trace-com",
          "excerpts": [
            "I am using LTTng to trace kernel events and userspace tracepoints. I want to visualize them together in one Trace Compass window."
          ]
        },
        {
          "title": "Android Manifest Introduction",
          "url": "https://developer.android.com/guide/topics/manifest/manifest-intro",
          "excerpts": [
            "The manifest file describes essential information about your app to the Android build tools, the Android operating system, and Google Play.",
            "| `<permission>` | Declares a security permission that can be used to limit access to specific components or features of this or other applications.",
            "| `<permission-group>` | Declares a name for a logical grouping of related permissions.",
            "| `<permission-tree>` | Declares the base name for a tree of permissions."
          ]
        },
        {
          "title": "Android Permissions Documentation",
          "url": "https://developer.android.com/training/permissions/declaring",
          "excerpts": [
            "To declare a permission that your app might request, include the appropriate <uses-permission> element in your app's manifest file.",
            "For example, an app that needs to access the camera\nhas this line in `AndroidManifest.xml`:\n\n```\n<manifest ...>\n    <uses-permission android:name=\"android.permission.CAMERA\"/>\n    <application ...>\n        ...\n    </application>\n</manifest>\n```",
            "Declare hardware as optional"
          ]
        },
        {
          "title": "The Rustonomicon: Other representations (repr(C))",
          "url": "https://doc.rust-lang.org/nomicon/other-reprs.html",
          "excerpts": [
            "This is the most important `repr` . It has fairly simple intent: do what C does. The order, size, and alignment of fields is exactly what you would expect from C",
            "The interaction of `repr(C)` with Rust's more exotic data layout features must be\nkept in mind.",
            "We strongly recommend using [rust-bindgen](https://rust-lang.github.io/rust-bindgen/) and/or [cbindgen](https://github.com/eqrion/cbindgen) to manage your FFI\nboundaries for you.",
            "The Rust team works closely with those projects to ensure\nthat they work robustly and are compatible with current and future guarantees\nabout type layouts and `repr` s."
          ]
        },
        {
          "title": "The Rustonomicon - FFI",
          "url": "https://doc.rust-lang.org/nomicon/ffi.html",
          "excerpts": [
            "Most foreign code exposes a C ABI, and Rust uses the platform's C calling convention by default when calling foreign functions.",
            "\n\nThe `extern \"C\"` makes this function adhere to the C calling convention, as discussed below in \" [Foreign Calling Conventions](ffi.html) \". The `no_mangle` attribute turns off Rust's name mangling, so that it has a well defined symbol to link to.",
            "Rust guarantees that the layout of a `struct` is compatible with the platform's\nrepresentation in C only if the `#[repr(C)]` attribute is applied to it.",
            "The list of supported ABI constraints\nare:\n\n* `stdcall`\n* `aapcs`\n* `cdecl`\n* `fastcall`\n* `thiscall`\n* `vectorcall` This is currently hidden behind the `abi_vectorcall` gate and is subject to change. * `Rust`\n* `system`\n* `C`"
          ]
        },
        {
          "title": "CantripOS: seL4 + Rust",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-01-leffler.pdf",
          "excerpts": [
            "CantripOS: 100% Rust",
            "Provides a variety of developer tools.",
            "CantripOS: sel4gdb",
            "seL4-thread-aware debugging \nsupport for gdb + Renod",
            "Rust log crate integration",
            "kmem (+ bloaty): tools for inspecting memory footprint",
            "sel4-sys",
            "Rootserver runs and sets up CAmkES \nassembly using untainted memor",
            "CantripOS: Memory Footprint Tools",
            "Memory footprint = $$$ + power."
          ]
        },
        {
          "title": "cap_std - Rust - Docs.rs",
          "url": "https://docs.rs/cap-std",
          "excerpts": [
            "Capability-based APIs represent access to external resources as values which can be passed around between different parts of a program. Two notable features ..."
          ]
        },
        {
          "title": "cap-primitives - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cap-primitives",
          "excerpts": [
            "Capability-based primitives The cap-primitives crate provides primitive sandboxing operations that cap-std and cap-async-std are built on. The ..."
          ]
        },
        {
          "title": "cap-std - Rust Package Registry - Crates.io",
          "url": "https://crates.io/crates/cap-std",
          "excerpts": [
            "This crate provides a capability-based version of std , providing sandboxed filesystem, networking, and clock APIs."
          ]
        },
        {
          "title": "The Typestate Pattern in Rust",
          "url": "https://www.reddit.com/r/rust/comments/c33u9m/the_typestate_pattern_in_rust/",
          "excerpts": [
            "Typestates are a type-system features that allow you to change the type of the object. Here, you do not change the type of anything, you return a new thing ..."
          ]
        },
        {
          "title": "tokio_uring - Rust",
          "url": "https://docs.rs/tokio-uring/latest/tokio_uring/",
          "excerpts": [
            "Tokio-uring provides a safe io-uring interface for the Tokio runtime. The library requires Linux kernel 5.10 or later."
          ]
        },
        {
          "title": "DmaFile in glommio::io - Rust",
          "url": "https://docs.rs/glommio/latest/glommio/io/struct.DmaFile.html",
          "excerpts": [
            "An asynchronously accessed Direct Memory Access (DMA) file. All access uses Direct I/O, and all operations including open and close are asynchronous."
          ]
        },
        {
          "title": "I Built a Rust Zero-Copy Network Proxy That Processes 1M ...",
          "url": "https://medium.com/@FAANG/i-built-a-rust-zero-copy-network-proxy-that-processes-1m-tps-heres-how-093446529f03",
          "excerpts": [
            "In this project I designed a proxy that hijacks OS packet buffers directly, routes them between sockets with minimal Rust abstractions, and ..."
          ]
        },
        {
          "title": "I don't understand zero copy : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/18cian3/i_dont_understand_zero_copy/",
          "excerpts": [
            "There is no single \"zerocopy\" thing, it just implies that you avoid some copying of data, probably for less resource usage."
          ]
        },
        {
          "title": "GitHub - spacejam/rio: pure rust io_uring library, built on ...",
          "url": "https://github.com/spacejam/rio",
          "excerpts": [
            "... buffers until the corresponding request has completed; but it is considered safe in Rust for an object's lifetime and borrows to end without its destructor ..."
          ]
        },
        {
          "title": "Async Rust is not safe with io_uring",
          "url": "https://news.ycombinator.com/item?id=41992975",
          "excerpts": [
            "io-uring's async cancellation mechanism is just an optimization opportunity and doesn't synchronize anything, so it can't be relied on for correctness here."
          ]
        },
        {
          "title": "Structured concurrency? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1270z03/structured_concurrency/",
          "excerpts": [
            "Does Rust have a notion of structured concurrency? The reason I ask is because I'm looking at atuff that's wrapping an Arc around a Mutex."
          ]
        },
        {
          "title": "Local Async Executors and Why They Should be the Default",
          "url": "https://www.reddit.com/r/rust/comments/v8e9fa/local_async_executors_and_why_they_should_be_the/",
          "excerpts": [
            "I prefer a multithreaded executor with the potentially avoidable Send, Sync and 'static bounds sprinkled throughout."
          ]
        },
        {
          "title": "cap-primitives - Rust Package Registry - Crates.io",
          "url": "https://crates.io/crates/cap-primitives/dependencies",
          "excerpts": [
            "The module also provides useful traits that extend `Ipv4Addr` and `Ipv6Addr` with methods for `Add`, `Sub`, `BitAnd`, and `BitOr` operations."
          ]
        },
        {
          "title": "Async Rust is not safe with io_uring",
          "url": "https://www.reddit.com/r/rust/comments/1gfi5r1/async_rust_is_not_safe_with_io_uring/",
          "excerpts": [
            "The problem isn't async Rust, its libraries exposing flawed APIs. My ringbahn, that I wrote in 2019, correctly handles this case by registering a cancellation ..."
          ]
        },
        {
          "title": "PermRust: A Token-based Permission System for Rust - arXiv",
          "url": "https://arxiv.org/html/2506.11701v1",
          "excerpts": [
            "Furthermore, we need our framework to not permit ambient authority, which is “authority that is exercised, but not [explicitly] selected by its ..."
          ]
        },
        {
          "title": "Ambient Authority: The Root of all Evil | by Rico Mariani - Medium",
          "url": "https://ricomariani.medium.com/ambient-authority-the-root-of-all-evil-c3312eebe0c0",
          "excerpts": [
            "Everyone knows (“It is known”) that global variables are “bad”. Lots of global variables makes things very confusing because when your important ..."
          ]
        },
        {
          "title": "structured_spawn - Rust - Docs.rs",
          "url": "https://docs.rs/structured-spawn",
          "excerpts": [
            "Structured async task spawn implementations for Tokio. Read “Tree-Structured Concurrency” for a complete overview of what structured concurrency is, ..."
          ]
        },
        {
          "title": "Structured Concurrency Support · Issue #1879 · tokio-rs/tokio - GitHub",
          "url": "https://github.com/tokio-rs/tokio/issues/1879",
          "excerpts": [
            "Structured concurrency describes programming paradigm. Concurrent tasks are structured in a fashion where there exist clean task hierarchies."
          ]
        },
        {
          "title": "Exploring Capability-based security in software design with Rust",
          "url": "https://bora.uib.no/bora-xmlui/bitstream/handle/11250/3001153/exploring_capability-based_security_in_software_design_with_Rust.pdf?sequence=1&isAllowed=y",
          "excerpts": [
            "Restricting the user's permissions is also known as Principle of Least Privilege (PoLP).",
            "In CBAC, capabilities are unforgeable tokens describing the authorization to\naccess a resource for a principal. Capabilities may be transferred between principals.",
            "We created a capability library 5.8 we used to implement a RESTful API, simple-api 5.9,\nconnecting it with Grant Negotiation and Authorization Protocol (GNAP) into a proof-of-\nconcept capability-based system published on GitHub [10",
            "TypeState enables structs to change behavior after running a\nfunction that changes the internal state of the struct.",
            "We created a library with three procedural macros to implement the design we used in\nCapabilityApi.",
            "ted library enables the developer to specify the available CRUD operations\nfor a data structure in the RESTful API.",
            "We will use\nthis library to build a RESTful API as part of a capability system."
          ]
        },
        {
          "title": "Taming stateful computations in Rust with typestates_.pdf",
          "url": "https://novaresearch.unl.pt/files/47111984/Taming_stateful_computations_in_Rust_with_typestates_.pdf",
          "excerpts": [
            "In typestate-oriented programming objects are modeled in terms of classes and changing states, much like our Rust-based approach. B",
            ". We propose a macro which embeds a typestate description DSL in Rust which allows developers to specify\ntypestates for their APIs; the typestate is checked at compile-time for common mistakes and to ensure the\ncorrect usage of the typestate, we leverage Rust’s type system.",
            "To enforce linear resource usage when build\nthe processes the library makes use of the type system to enforce the\nconsumption of each ‘‘state’’; enforcing protocol completion is done\nthrough a closure, which takes the initial session type and returns a\nterminal End type, a session is then required to be run until completion\notherwise the return type will not be respected and the type checker\nwill raise an error.",
            "\nPart of the typestate-oriented paradigm, the Plaid language [16] is an\n\nextension of the object paradigm. In typestate-oriented programming\nobjects are modeled in terms of classes and changing states, much like\nour Rust-based approach."
          ]
        },
        {
          "title": "Structured concurrency in Rust with Tokio Beyond Tokio Spawn",
          "url": "https://medium.com/@adamszpilewicz/structured-concurrency-in-rust-with-tokio-beyond-tokio-spawn-78eefd1febb4",
          "excerpts": [
            "tructured Concurrency? Structured concurrency is about **scoping tasks** . Instead of fire-and-forget, you treat tasks like children of a parent",
            "\nWelcome to the world of **structured concurrency** — a pattern that helps you manage task lifecycles, handle cancellation, and avoid future leaks.",
            "\n\nRust’s async story is fast, safe, and incredibly powerful.",
            "Rust’s borrow checker already enforces structured memory. Structured concurrency brings that same discipline to async code."
          ]
        },
        {
          "title": "CancellationToken (tokio-util)",
          "url": "https://docs.rs/tokio-util/latest/tokio_util/sync/struct.CancellationToken.html",
          "excerpts": [
            "A token which can be used to signal a cancellation request to one or more tasks. Tasks can call CancellationToken::cancelled() in order to obtain a Future ... [Source](../../src/tokio_util/sync/cancellation_token.rs.html)",
            "#### pub async fn [run\\_until\\_cancelled\\_owned](.run_until_cancelled_owned) <F>(self, fut: F) -> [Option](https://doc.rust-lang.org/nightly/core/option/enum.Option.html \"enum core::option::Option\") <F:: [Output](https://doc.rust-lang.org/nightly/core/future/future/trait.Future.html.Output \"type core::future::future::Future::Output\") >",
            "Runs a future to completion and returns its result wrapped inside of an `Option` unless the `CancellationToken` is cancelled. In that case the function returns `None` and the future gets dropped. The function takes self by value and returns a future that owns the token."
          ]
        },
        {
          "title": "Tree-structured concurrency (Yoshua Wuyts Blog)",
          "url": "https://blog.yoshuawuyts.com/tree-structured-concurrency/",
          "excerpts": [
            "When you drop a future to cancel it, it's\n  guaranteed that all futures underneath it are also cancelle",
            "When an error is created somewhere down in the\n  call-graph, it can always be propagated up to the callers until there is a\n  caller who is ready to handle",
            "When a function returns, you know it is done doing\n  wor",
            "These properties put together lead to something called a **\"black box model of\nexecution\"**: under a structured model of computing you don't need to know\nanything about the inner workings of the functions you're calling, because their\nbehavior is guaranteed. A function will return when it's done, will cancel all\nwork when you ask it to, and you'll always receive an error if there is something\nwhich needs handling. And as a result code under this model is **compo",
            "Structured concurrency is a lens I use in almost all of my\nreasoning about async Rust, and I think it might help others too."
          ]
        },
        {
          "title": "Rust Tokio Task Cancellation Patterns",
          "url": "https://cybernetist.com/2024/04/19/rust-tokio-task-cancellation-patterns/",
          "excerpts": [
            "Rust provides support for [async programming](https://rust-lang.github.io/async-book/?ref=cybernetist.com)\nwhich lets you spawn asynchronous tasks which are then scheduled for execution across OS threads via a runtime executor.",
            "As with everything in Rust, async programming has to be memory-safe so you need to make sure the borrow checker is happy.",
            "One thing the tutorial doesn’t go into much detail is task cancellations, which is something I had a need for in\none of my projects.",
            "Specifically, I needed to spin a bunch of worker tasks and I needed a way to cancel either any or\nall of them."
          ]
        },
        {
          "title": "Forging Ergonomic Rust: The Evolution of Language ...",
          "url": "https://medium.com/the-software-frontier/forging-ergonomic-rust-the-evolution-of-language-design-with-technical-precision-f4f13ca18953",
          "excerpts": [
            "This article revisits that initiative with a deep technical lens, unpacking what ergonomics means in programming languages, how Rust tackled it, ..."
          ]
        },
        {
          "title": "Resources on writing ergonomic APIs? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/9nv60v/resources_on_writing_ergonomic_apis/",
          "excerpts": [
            "Are there any resources or guidance on what exactly makes an ergonomic API in Rust, and how to do that? Thanks in advance! (Further design ..."
          ]
        },
        {
          "title": "Making Async Rust Reliable - Tyler Mandry - GitLab",
          "url": "https://tmandry.gitlab.io/blog/posts/making-async-reliable/",
          "excerpts": [
            "A Rust future can be canceled and stop executing at any await point, in theory. In practice, cancellation semantics of Rust futures is an ..."
          ]
        },
        {
          "title": "Async Rust can be a pleasure to work with (without `Send + Sync + ...",
          "url": "https://www.reddit.com/r/rust/comments/1f920z8/async_rust_can_be_a_pleasure_to_work_with_without/",
          "excerpts": [
            "You can still do that with structured concurrency, no? Structured concurrency just eliminates 'static , not necessarily Send or Sync ."
          ]
        },
        {
          "title": "Async Rust is about concurrency, not (just) performance",
          "url": "https://kobzol.github.io/rust/2025/01/15/async-rust-is-about-concurrency.html",
          "excerpts": [
            "The primary benefit of async/await is that it lets us concisely express complex concurrency; any (potential) performance improvements are just a second-order ..."
          ]
        },
        {
          "title": "io_uring nvme example : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/z0z50w/io_uring_nvme_example/",
          "excerpts": [
            "Io_uring is a next gen async io platform, and NVMe is a super fast API to talk directly with SSDs. I hope by sharing this to avoid to others all ..."
          ]
        },
        {
          "title": "FAQ - Redox - Your Next(Gen) OS",
          "url": "https://www.redox-os.org/faq/",
          "excerpts": [
            "Redox is a microkernel-based, general-purpose OS, created in 2015, aiming to be a complete alternative to Linux and BSD, and is currently in alpha development."
          ]
        },
        {
          "title": "Capability-based security for Redox",
          "url": "https://nlnet.nl/project/Capability-based-RedoxOS/",
          "excerpts": [
            "Capability-based security for Redox ... Redox OS is a Unix-like microkernel-based operating system written in Rust, intended for both the cloud and the desktop."
          ]
        },
        {
          "title": "The Security Benefits of a Rust-Based Operating System ...",
          "url": "https://www.reddit.com/r/rust/comments/1hfvjfy/the_security_benefits_of_a_rustbased_operating/",
          "excerpts": [
            "These types of devices require robust security, and a Rust-based OS could help mitigate vulnerabilities such as buffer overflows and memory- ..."
          ]
        },
        {
          "title": "Linux perf Examples",
          "url": "https://www.brendangregg.com/perf.html",
          "excerpts": [
            "It depends on the rate of the event you are tracing: the more frequent, the higher the overhead and larger the perf.data size. To really cut down overhead ..."
          ]
        },
        {
          "title": "Linux eBPF Tracing Tools",
          "url": "https://www.brendangregg.com/ebpf.html",
          "excerpts": [
            "Dec 28, 2016 — On this page I'll describe eBPF, the front-ends, and demonstrate some of the tracing tools I've developed."
          ]
        },
        {
          "title": "BPF ring buffer - Andrii Nakryiko's Blog",
          "url": "https://nakryiko.com/posts/bpf-ringbuf/",
          "excerpts": [
            "At the same time, BPF ringbuf solves the following issues with BPF perfbuf: memory overhead;; data ordering;; wasted work and extra data copying ...",
            "Being shared across all CPUs, BPF ringbuf allows using one big common buffer to\ndeal with this. Bigger buffer can absorb bigger spikes, but also might allow\nusing less RAM overall, compared to BPF perfbuf.",
            "BPF perfbuf allocates a separate buffer for each CPU. This often means that BPF\ndevelopers have to make a trade off between allocating big enough per-CPU\nbuffers (accommodating possible spikes of emitted data) or being\nmemory-efficient (by not wasting unnecessary memory for mostly empty buffers in\na steady state, but dropping data during data spikes).",
            "BPF ringbuf provides a better performance and memory efficiency, better\nordering guarantees, and better API (both kernel-side and in user-space)."
          ]
        },
        {
          "title": "eBPF Ecosystem Progress in 2024–2025",
          "url": "https://eunomia.dev/blog/2025/02/12/ebpf-ecosystem-progress-in-20242025-a-technical-deep-dive/",
          "excerpts": [
            "Feb 12, 2025 — Verifier Enhancements: The BPF verifier — which ensures that loaded eBPF programs are safe (no out-of-bounds access, no infinite loops, etc.) — ..."
          ]
        },
        {
          "title": "Aya: your tRusty eBPF companion",
          "url": "https://www.deepfence.io/blog/aya-your-trusty-ebpf-companion",
          "excerpts": [
            "Jul 22, 2022 — Although the eBPF verifier ensures memory safety, using Rust over C is still beneficial in terms of type safety. Both Rust and macros inside Aya ..."
          ]
        },
        {
          "title": "libbpf/libbpf-rs: Minimal and opinionated eBPF tooling for ...",
          "url": "https://github.com/libbpf/libbpf-rs",
          "excerpts": [
            "Idiomatic Rust wrapper around libbpf. libbpf-cargo. Helps you build and develop BPF programs with standard Rust tooling."
          ]
        },
        {
          "title": "libbpf_rs - Rust",
          "url": "https://docs.rs/libbpf-rs",
          "excerpts": [
            "libbpf-rs, together with libbpf-cargo (libbpf cargo plugin) allow you to write Compile-Once-Run-Everywhere (CO-RE) eBPF programs. Note this document uses “eBPF” ..."
          ]
        },
        {
          "title": "A Complete Guide to eBPF with Rust: Building Modern ...",
          "url": "https://blog.devgenius.io/a-complete-guide-to-ebpf-with-rust-building-modern-observability-tools-79ea23b0999c",
          "excerpts": [
            "Apr 26, 2025 — In this guide, we'll explore how to leverage eBPF using Rust, a language known for its performance and safety guarantees."
          ]
        },
        {
          "title": "A Deep Dive into Apache Arrow Flight and Its Use Cases",
          "url": "https://celerdata.com/glossary/a-deep-dive-into-apache-arrow-flight-and-its-use-cases",
          "excerpts": [
            "Jan 21, 2025 — Built on Apache Arrow, it leverages a standardized in-memory columnar format that supports zero-copy reads and efficient data processing. This ..."
          ]
        },
        {
          "title": "Zero-Copy, Zero-Delay. Mach Speed for Your Data",
          "url": "https://medium.com/@mcgeehan/zero-copy-zero-delay-499042d0bf12",
          "excerpts": [
            "Just raw, zero-copy data movement at high speed. Temporal keeps workflows running smoothly. Arrow Flight keeps data moving without friction. ...",
            "Meanwhile, the Arrow Flight Server acts as a high-speed intermediary, enabling workers to push, retrieve, and process data without bottlenecks. Thanks to Apache Arrow's columnar format, data moves seamlessly through the pipeline with zero-copy transfers and vectorized execution, ensuring maximum efficiency ."
          ]
        },
        {
          "title": "Powered by | Apache Arrow",
          "url": "https://arrow.apache.org/powered_by/",
          "excerpts": [
            "Uses Arrow to efficiently store Python data structures containing large arrays of numerical data. Data can be accessed with zero-copy by multiple processes ..."
          ]
        },
        {
          "title": "Apache Arrow: Use-case Example : r/dataengineering",
          "url": "https://www.reddit.com/r/dataengineering/comments/1gx33ka/apache_arrow_usecase_example/",
          "excerpts": [
            "Arrow's table can be shared with other processes running the same machine without copying the data residing in the RAM."
          ]
        },
        {
          "title": "Safe and usable kernel extensions with Rax",
          "url": "https://arxiv.org/html/2502.18832v1",
          "excerpts": [
            "Feb 26, 2025 — Aya eventually implemented its own version for both intrinsics, using a simple loop to iterate over the data to avoid ever tripping the verifier ..."
          ]
        },
        {
          "title": "Research Update: Isolated Execution Environment for eBPF",
          "url": "https://ebpf.foundation/research-update-isolated-execution-environment-for-ebpf/",
          "excerpts": [
            "This project introduces a novel execution environment designed to isolate BPF programs, offering an alternative architectural solution to enhance the security ..."
          ]
        },
        {
          "title": "Linux perf event Features and Overhead",
          "url": "https://web.eece.maine.edu/~vweaver/projects/perf_events/overhead/weaver_perfevent_overhead.pdf",
          "excerpts": [
            "by VM Weaver · Cited by 185 — It allows sampling with arbitrary performance events (or a timer if you lack performance counters) and provides frequency graphs, profiles, and stack traces."
          ]
        },
        {
          "title": "eBPF and Performance",
          "url": "https://www.brendangregg.com/Slides/SIGCOMM2024_eBPF_Performance.pdf",
          "excerpts": [
            "5) Crosscheck measured numbers. 6) Measure tool overhead. 7) <80 chars wide by default. 8) Add CLI options: follow other tool style. 9) Concise, intuitive, self ..."
          ]
        },
        {
          "title": "Pitfalls of relying on eBPF for security monitoring (and ...",
          "url": "https://blog.trailofbits.com/2023/09/25/pitfalls-of-relying-on-ebpf-for-security-monitoring-and-some-solutions/",
          "excerpts": [
            "Sep 25, 2023 — As Brendan Gregg observed: eBPF has many uses in improving computer security, but just taking eBPF observability tools as-is and using them ..."
          ]
        },
        {
          "title": "Unraveling eBPF Ring Buffers",
          "url": "https://www.deep-kondah.com/deep-dive-into-ebpf-ring-buffers/",
          "excerpts": [
            "This post is to provide an in-depth discussion of BPF ring buffers, covering their internals, including memory allocation, user-space mapping, locking ..."
          ]
        },
        {
          "title": "Performance Overhead of Perf Event Subsystem in Linux ...",
          "url": "https://stackoverflow.com/questions/2794188/performance-overhead-of-perf-event-subsystem-in-linux-kernel",
          "excerpts": [
            "The overhead of the PMU-based hardware counters should depend on how many different events you're sampling, and how often."
          ]
        },
        {
          "title": "[PDF] A Practical, Lightweight, and Flexible Confinement Framework in eBPF",
          "url": "https://www.cisl.carleton.ca/~will/written/techreport/mcs-thesis.pdf",
          "excerpts": [
            "The goal was to implement namespace remapping and security isolation for commercial server deployments in (possibly multi-tenant) Solaris environments. The."
          ]
        },
        {
          "title": "Data at the Speed of Light. The Apache Arrow Revolution",
          "url": "https://medium.com/@tfmv/data-at-the-speed-of-light-8e32da656de8",
          "excerpts": [
            "The Apache Arrow ecosystem eliminates this tax completely: In-memory columnar format optimized for modern CPUs, Zero-copy, zero-serialization data sharing ..."
          ]
        },
        {
          "title": "Our journey at F5 with Apache Arrow (part 1)",
          "url": "https://arrow.apache.org/blog/2023/04/11/our-journey-at-f5-with-apache-arrow-part-1/",
          "excerpts": [
            "Apr 11, 2023 — Our benchmarks thus far have shown promising results, with compression ratio improvements ranging from 1.5x to 5x, depending on the data type ( ..."
          ]
        },
        {
          "title": "Tracing Methods",
          "url": "https://thume.ca/2023/12/02/tracing-methods/",
          "excerpts": [
            "eBPF subsystem allows you to attach complex programs to all sorts of different things in the kernel and efficiently shuttle data back to userspace, basically subsuming all the legacy facilities like ftrace and kprobes such that I won’t talk about them.",
            "ace. You normally write BPF programs in C but there are perhaps even nicer toolkits for using [Zig](ht",
            "I could even include fields pulled from the packet header and NIC queue information, all at 1 million packets per second with no noticeable overhead."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface.html",
          "excerpts": [
            "Make it easy for third-party projects to implement support for (including partial\n  support where sufficient), with little initial investment. * \n  Allow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process. * \n  Match the Arrow array concepts closely to avoid the development of\n  yet another marshalling layer.",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow format.",
            "Expose an ABI-stable interface.",
            "llow zero-copy sharing of Arrow data between independent runtimes\n  and components running in the same process.",
            "Zero-copy by design.",
            "The Arrow C data interface is inspired by the [Python buffer protocol](https://www.python.org/dev/peps/pep-3118/) ,\nwhich has proven immensely successful in allowing various Python libraries\nexchange numerical data with no knowledge of each other and near-zero\nadaptation cost.",
            "Allow zero-copy sharing of Arrow data between independent runtimes and components running in the same process. Match the Arrow array concepts closely to ...",
            "The Arrow C data interface defines a very small, stable set of C definitions\nthat can be easily _copied_ in any project’s source code and used for columnar\ndata interchange in the Arrow forma",
            "Memory management",
            "The release callback MUST free any data area directly owned by the structure\n(such as the buffers and children members). The release callback MUST mark the structure as released, by setting\nits `release` member to NULL."
          ]
        },
        {
          "title": "Arrow C Data Interface and Streams",
          "url": "https://arrow.apache.org/docs/format/CStreamInterface.html",
          "excerpts": [
            "An Arrow C stream exposes a streaming source of data chunks, each with the same schema. Chunks are obtained by calling a blocking pull-style iteration function. [Apache Arrow v21.0.0 - Home](../_static/arrow-dark.png)](../index.html)",
            "The C stream interface is defined by a single `struct` definition:",
            "int ( * get_schema )( struct ArrowArrayStream * , struct ArrowSchema * out );",
            "int ( * get_next )( struct ArrowArrayStream * , struct ArrowArray * out );",
            "const char * ( * get_last_error )( struct ArrowArrayStream * );",
            "void ( * release )( struct ArrowArrayStream * );",
            "The canonical guard `ARROW_C_STREAM_INTERFACE` is meant to avoid\nduplicate definitions if two projects copy the C data interface\ndefinitions in their own headers, and a third-party project\nincludes from these two projects.",
            "The `ArrowArrayStream` provides the required callbacks to interact with a\nstreaming source of Arrow arrays. It has the following field",
            "The `ArrowArrayStream` provides the required callbacks to interact with a\nstreaming source of Arrow arrays. It has the following field"
          ]
        },
        {
          "title": "Introducing the Apache Arrow C Data Interface",
          "url": "https://arrow.apache.org/blog/2020/05/03/introducing-arrow-c-data-interface/",
          "excerpts": [
            "May 3, 2020 — Apache Arrow includes a cross-language, platform-independent in-memory columnar format allowing zero-copy data sharing and transfer between heterogenous ... This post introduces the Arrow C Data Interface, a simple C-based interoperability standard to simplify interactions between independent users and implementors of the Arrow in-memory format. Introducing the Apache Arrow C Data Interface | Apache Arrow",
            "zero-copy data sharing",
            "The C Data Interface passes Arrow data buffers through memory pointers. So,\nby construction, it allows you to share data from one runtime to\nanother without copying it. Since the data is in standard\n[Arrow in-memory format](https://arrow.apache.org/docs/format/Columnar.html),\nits layout is well-defined and unambiguous. This design also restricts the C Data Interface to *in-process* data sharing. For interprocess communication, we recommend use of the Arrow\n[IPC format",
            "Separate type and data representation",
            "For applications which produce many instances of data of a single datatype\n(for example, as a stream of record batches), repeatedly reconstructing the\ndatatype from its string encoding would represent unnecessary overhead.",
            "The C Data Interface passes Arrow data buffers through memory pointers. So,\nby construction, it allows you to share data from one runtime to\nanother without copying it.",
            "Two libraries that utilize\nthe C structures defined by the C Data Interface can do zero-copy data\ntransfers at runtime without any build-time or link-time dependency\nrequirements.",
            "The C Data Interface carries no dependencies\nexcept a shared C ABI between binaries which use it.",
            "May 3, 2020 — Apache Arrow includes a cross-language, platform-independent in-memory columnar format allowing zero-copy data sharing and transfer between heterogenous ... ",
            "For interprocess communication, we recommend use of the Arrow\n[IPC format"
          ]
        },
        {
          "title": "BPF ring buffer — The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/next/bpf/ringbuf.html",
          "excerpts": [
            "This document describes BPF ring buffer design, API, and implementation details. ... BPF ringbuf provides two sets of APIs to BPF programs:.",
            "`bpf_ringbuf_output()` allows to _copy_ data from one place to a ring\n  buffer, similarly to `bpf_perf_event_output()`",
            "`bpf_ringbuf_reserve()` / `bpf_ringbuf_commit()` / `bpf_ringbuf_discard()` APIs split the whole process into two steps. First, a fixed amount of space\n  is reserved. If successful, a pointer to a data inside ring buffer data\n  area is returned, which BPF programs can use similarly to a data inside\n  array/hash maps. Once ready, this piece of memory is either committed or\n  discarded. Discard is similar to commit, but makes consumer ignore the",
            "The ring buffer itself internally is implemented as a power-of-2 sized\ncircular buffer, with two logical and ever-increasing counters (which might\nwrap around on 32-bit architectures, that’s not a problem):",
            "consumer counter shows up to which logical position consumer consumed the\n  dat",
            "producer counter denotes amount of data reserved by all producers.",
            "Together with `BPF_RB_NO_WAKEUP` / `BPF_RB_FORCE_WAKEUP` flags for output/commit/discard\nhelpers, it allows BPF program a high degree of control and, e.g., more\nefficient batched notifications.",
            "This document describes BPF ring buffer design, API, and implementation details. ... Returned values are momentarily snapshots of ring buffer state and ..."
          ]
        },
        {
          "title": "anakryiko/bpf-ringbuf-examples",
          "url": "https://github.com/anakryiko/bpf-ringbuf-examples",
          "excerpts": [
            "This is a collection of examples showing the usage of BPF ringbuf and perfbuf APIs. Each example implements a simple tracing tool, collecting all exec() ..."
          ]
        },
        {
          "title": "C Data Interface — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/java/cdata.html",
          "excerpts": [
            "Arrow supports exchanging data without copying or serialization within the same process through the The Arrow C data interface, even between different language ..."
          ]
        },
        {
          "title": "Interface to the nanoarrow C Library",
          "url": "https://arrow.apache.org/nanoarrow/latest/r/",
          "excerpts": [
            "Example. The Arrow C Data and Arrow C Stream interfaces are comprised of three structures: the ArrowSchema which represents a data type of an array, ..."
          ]
        },
        {
          "title": "Leveraging the Arrow C Data Interface",
          "url": "https://willayd.com/leveraging-the-arrow-c-data-interface.html",
          "excerpts": [
            "Feb 20, 2024 — This blog post describes how the Arrow C Data interface works, as witnessed through transformation of the pantab library."
          ]
        },
        {
          "title": "What is eBPF? An Introduction and Deep Dive into the eBPF ...",
          "url": "https://ebpf.io/what-is-ebpf/",
          "excerpts": [
            "eBPF is a revolutionary technology with origins in the Linux kernel that can run sandboxed programs in a privileged context such as the operating system kernel."
          ]
        },
        {
          "title": "ebpf_exporter/benchmark/README.md at master",
          "url": "https://github.com/cloudflare/ebpf_exporter/blob/master/benchmark/README.md",
          "excerpts": [
            "To measure the overhead of eBPF probes we measure performance in the following cases: No probes attached; Empty probe doing nothing at all; Simple probe ..."
          ]
        },
        {
          "title": "What is the performance impact added to eBPF via kprobe ...",
          "url": "https://stackoverflow.com/questions/78572661/what-is-the-performance-impact-added-to-ebpf-via-kprobe-and-uprobe",
          "excerpts": [
            "All I can tell you is that uprobe overhead will be much higher because it has to cross to kernel space to execute the BPF program."
          ]
        },
        {
          "title": "Head Based Sampling using the OTEL Collector",
          "url": "https://squaredup.com/blog/head-based-sampling-using-the-otel-collector/",
          "excerpts": [
            "Oct 25, 2023 — Head based VS tail based sampling ... Head based sampling means that we decide whether to keep or discard each trace as early as possible (before ..."
          ]
        },
        {
          "title": "The Tail at Scale",
          "url": "https://research.google/pubs/the-tail-at-scale/",
          "excerpts": [
            "by J Dean · 2013 · Cited by 2294 — This article outlines some of the common causes of high latency episodes in large online services and describes techniques that reduce their severity."
          ]
        },
        {
          "title": "The tail at scale - Luiz André Barroso",
          "url": "https://www.barroso.org/publications/TheTailAtScale.pdf",
          "excerpts": [
            "by JR Dean · 2013 · Cited by 2294 — The 'tail' refers to high-latency episodes that can dominate performance in large-scale systems, even though rare, and are difficult to keep short.",
            "tail-tolerant software techniques form a predictable whole out of less-predictable parts.",
            "dividual components is mag-\nnified at the service level; for example, \nconsider a system where each server \ntypically responds in 10ms but with a \n99th-percentile latency of one second.",
            "Hedged requests. A simple way to \ncurb latency variability is to issue the \nsame request to multiple replicas and \nuse the results from whichever replica \nresponds fi",
            " The hedged-requests \ntechnique also has a window of vulner-\n\nability in which multiple servers can \nexecute the same request unnecessar",
            "Within Request Short-Term  \nadaptatio",
            "cross-Request  \nLong-Term adaptatio",
            "In large information-retrieval (IR) sys-\ntems, speed is more than a performance \nmetric; it is a key quality metric, as re-\nturning good results quickly is better \nthan returning the best results s"
          ]
        },
        {
          "title": "Reservoir sampling - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Reservoir_sampling",
          "excerpts": [
            "Reservoir sampling is a family of randomized algorithms for choosing a simple random sample, without replacement, of k items from a population of unknown size n"
          ]
        },
        {
          "title": "[PDF] Random Sampling with a Reservoir - UMD Computer Science",
          "url": "https://www.cs.umd.edu/~samir/498/vitter.pdf",
          "excerpts": [
            "We introduce fast algorithms for selecting a random sample of n records without replacement from a pool of N records, where the value of N is unknown ..."
          ]
        },
        {
          "title": "The tail at scale | Communications of the ACM",
          "url": "https://dl.acm.org/doi/10.1145/2408776.2408794",
          "excerpts": [
            "Software techniques that tolerate latency variability are vital to building responsive large-scale Web services.",
            "Barroso, L.A. and Höelzle, U. The Datacenter as a Computer: An Introduction to the Design of Warehouse-scale Machines. Synthesis Series on Computer Architecture ..."
          ]
        },
        {
          "title": "Reservoir Sampling | Richard Startin's Blog",
          "url": "https://richardstartin.github.io/posts/reservoir-sampling",
          "excerpts": [
            "It's worth taking a look at the derivations of Algorithm A and Algorithm D in Vitter's paper on Faster Methods for Random Sampling first."
          ]
        },
        {
          "title": "Falco blog: Tracing Syscalls Using eBPF (Part 1)",
          "url": "https://falco.org/blog/tracing-syscalls-using-ebpf-part-1/",
          "excerpts": [
            "eBPF instrumentation will always cause a greater overhead in the system ...",
            "Ring buffers\n------------\n\neBPF ring buffer, also known as `bpf_ringbuf`, is a mechanism provided by the Linux kernel for efficient communication between eBPF programs and user-space programs"
          ]
        },
        {
          "title": "Performance of perfbuf – Patchwork patch (May 29, 2020)",
          "url": "https://patchwork.ozlabs.org/project/netdev/patch/20200529075424.3139988-5-andriin@fb.com/",
          "excerpts": [
            "May 29, 2020 — Performance of perfbuf suffers from default \"no sampling\" policy and huge overhead that causes. In sampled mode, rb-custom is winning very ... 4 benchmarks were implemented: 2 variations for each of BPF ringbuf\nand perfbuf:,\n  ",
            "  - rb-libbpf utilizes stock libbpf ring_buffer manager for reading data;",
            "  - rb-custom implements custom ring buffer setup and reading code, to\n    eliminate overheads inherent in generic libbpf code due to callback\n    functions and the need to update consumer position after each consumed\n    record, instead of batching updates (due to pessimistic assumption that\n    user callback might take long time and thus could unnecessarily hold ring\n    buffer space for too long);",
            "  - pb-libbpf uses stock libbpf perf_buffer code with all the default\n    settings, though uses higher-performance raw event callback to minimize\n    unnecessary overhead;",
            "  - pb-custom implements its own custom consumer code to minimize any possible\n    overhead of generic libbpf implementation and indirect function calls. All of the test support default, no data notification skipped, mode, as well\nas sampled mode (with --rb-sampled flag), which allows to trigger epoll\nnotification less frequently and reduce overhead. As will be shown, this mode\nis especially critical for perf buffer, which suffers from high overhead of\nwakeups in kernel. Otherwise, all benchamrks implement similar way to generate a batch of records\nby using fentry/sys_getpgid BPF program, which pushes a bunch of records in\na tight loop and records number of successful and dropped samples."
          ]
        },
        {
          "title": "Eliminating eBPF Tracing Overhead on Untraced Processes (eBPF 924, 2024)",
          "url": "https://people.cs.vt.edu/djwillia/papers/ebpf24-mookernel.pdf",
          "excerpts": [
            "Eliminating eBPF Tracing Overhead\non Untraced Processes",
            "Executing eBPF\nprograms associated with other processes not only makes tracing\nslower, but could impact the correctness of tracing by executing\neBPF programs intended for one process, on another.",
            "Copying\ntracing hookpoint state also allows for the optimization for tracing\nhookpoint text described above. After the necessary pages have been copied, the kernel view\nmanager must update the kernel page tables for each traced process.",
            "he most efficient\nper-process approach, pre-eBPF, slows down the read and sendmsg\nsystem call by 54 and 112 nanoseconds respectively, which corre-\nspond to 15% and 6% slowdown"
          ]
        },
        {
          "title": "Arrow Columnar Format",
          "url": "https://arrow.apache.org/docs/format/Columnar.html",
          "excerpts": [
            "The **Arrow columnar format** includes a language-agnostic in-memory\ndata structure specification, metadata serialization, and a protocol\nfor serialization and generic data transp",
            "Data adjacency for sequential access (scans)",
            "The Arrow columnar format provides analytical performance and data\nlocality guarantees in exchange for comparatively more expensive\nmutation operations."
          ]
        },
        {
          "title": "The Arrow C data interface",
          "url": "https://arrow.apache.org/docs/format/CDataInterface/PyCapsuleInterface.html",
          "excerpts": [
            "This interface allows any library to export Arrow data structures to other libraries that understand the same protocol.",
            "The Arrow C data interface",
            " Export the object as an ArrowSchema. Returns :\n        A PyCapsule containing a C ArrowSchema representation of the\n        object. The capsule must have a name of `\"arrow_schema\"` .",
            "owSchema and ArrowArray structures. Parameters :\n        **requested\\_schema** ( _PyCapsule_ _or_ _None_ ) – A PyCapsule containing a C ArrowSchema representation\n        of a requested schema. Conversion to this schema is best-effort. See [Schema Requests]() . Returns :\n        A pair of PyCapsules containing a C ArrowSchema and ArrowArray,\n        respectively."
          ]
        },
        {
          "title": "The Apache Arrow Revolution for Data Solutions",
          "url": "https://medium.com/israeli-tech-radar/the-apache-arrow-revolution-for-data-solutions-e59bb496c60c",
          "excerpts": [
            "Apache Arrow enables composable data systems to share the same columnar data in memory or through the wire.",
            "Arrow Interop with Zero-Copy Memory Reads",
            "The Apache Arrow Revolution for Data Solutions",
            "Zero-Copy Reads. Our task is to read a bunch of XML files, process them, and write them back to disk in an ORC format. That's a given ..."
          ]
        },
        {
          "title": "OpenTelemetry Sampling",
          "url": "https://opentelemetry.io/docs/concepts/sampling/",
          "excerpts": [
            "Tail sampling is where the decision to sample a trace takes place by considering\nall or most of the spans within the trace. Tail Sampling gives you the option to\nsample your traces based on specific criteria derived from different parts of a\ntrace, which isn’t an option with Head Sampling.",
            "The OpenTelemetry Collector includes the following sampling processors:",
            "* [Probabilistic Sampling Processo",
            "* [Tail Sampling Processo",
            "Tail sampling is where the decision to sample a trace takes place by considering all or most of the spans within the trace."
          ]
        },
        {
          "title": "Tail Sampling with OpenTelemetry",
          "url": "https://opentelemetry.io/blog/2022/tail-sampling/",
          "excerpts": [
            "Tail-based sampling is where the decision to sample a trace happens *after* all\nthe spans in a request have been complete",
            "To use tail sampling in OpenTelemetry, you need to implement a component called the tail sampling processor.",
            "This component samples traces based on a set of policies that you can choose\nfrom and define.",
            "Tail sampling lets you see only the traces that are of interest to you. You also\nlower data ingest and storage costs because you’re only exporting a\npredetermined subset of your traces.",
            "There are also some limitations to consider that are related to OpenTelemetry. Note that some of these limitations also apply more broadly to any client-hosted\ntail-based sampling solution, not just OpenTelemetry.",
            "Establishing a wait period for tail sampling**: Another challenge with tail\n  sampling is that it’s hard to predict when a trace will actually be finis"
          ]
        },
        {
          "title": "eBPF Tutorial by Example 8: Monitoring Process Exit ...",
          "url": "https://medium.com/@yunwei356/ebpf-tutorial-by-example-8-monitoring-process-exit-events-print-output-with-ring-buffer-73291d5e3a50",
          "excerpts": [
            "There is now a new BPF data structure available called the eBPF ring buffer. It solves the memory efficiency and event reordering issues of the ...See more"
          ]
        },
        {
          "title": "Helper Function 'bpf_ringbuf_reserve' - eBPF Docs",
          "url": "https://docs.ebpf.io/linux/helper-function/bpf_ringbuf_reserve/",
          "excerpts": [
            "This page documents the 'bpf_ringbuf_reserve' eBPF helper function, including its definition, usage, program types that can use it, and examples."
          ]
        },
        {
          "title": "eBPF verifier",
          "url": "https://docs.kernel.org/bpf/verifier.html",
          "excerpts": [
            "eBPF verifier¶. The safety of the eBPF program is determined in two steps. First step does DAG check to disallow loops and other CFG validation."
          ]
        },
        {
          "title": "eBPF verifier — The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/v5.17/bpf/verifier.html",
          "excerpts": [
            "In order to determine the safety of an eBPF program, the verifier must track the range of possible values in each register and also in each stack slot. This is ..."
          ]
        },
        {
          "title": "Aya is an eBPF library for the Rust programming language ...",
          "url": "https://github.com/aya-rs/aya",
          "excerpts": [
            "eBPF is a technology that allows running user-supplied programs inside the Linux kernel. For more info see What is eBPF. Aya is an eBPF library built with a ..."
          ]
        },
        {
          "title": "Getting Started - Aya",
          "url": "https://aya-rs.dev/book/",
          "excerpts": [
            "This getting started guide will help you use the Rust Programming Language and Aya library to build extended Berkley Packet Filter (eBPF) programs."
          ]
        },
        {
          "title": "Classic BPF vs eBPF",
          "url": "https://www.kernel.org/doc/html/v5.17/bpf/classic_vs_extended.html",
          "excerpts": [
            "After the call the registers R1-R5 contain junk values and cannot be read. An in-kernel eBPF verifier is used to validate eBPF programs. Also in the new design, ..."
          ]
        },
        {
          "title": "Formally verifying the BPF verifier",
          "url": "https://lwn.net/Articles/1020664/",
          "excerpts": [
            "May 23, 2025 — The Linux kernel's BPF verifier is probably the first real instance of formal verification in production, Nagarakatte said."
          ]
        },
        {
          "title": "Working with Schema",
          "url": "https://arrow.apache.org/cookbook/py/schema.html",
          "excerpts": [
            "This chapter includes recipes for dealing with schemas. Contents. Working with Schema. Setting the data type of an Arrow Array. Setting the schema of a Table."
          ]
        },
        {
          "title": "C Interfaces — Apache Arrow v5.0.0",
          "url": "https://arrow.apache.org/docs/5.0/cpp/api/c_abi.html",
          "excerpts": [
            "This is documentation for an old release of Apache Arrow (version 5.0). ... The Arrow C stream interface · Other Data Structures. Libraries. Implementation ..."
          ]
        },
        {
          "title": "pyarrow.Schema — Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/python/generated/pyarrow.Schema.html",
          "excerpts": [
            "A schema defines the column names and types in a record batch or table data structure. They also contain metadata about the columns."
          ]
        },
        {
          "title": "[Python] Support C stream interface of single arrays #31194 - GitHub",
          "url": "https://github.com/apache/arrow/issues/31194",
          "excerpts": [
            "It seems that the C stream interface in pyarrow currently requires the array to be a StructArray. I do not see this constraint in the spec ..."
          ]
        },
        {
          "title": "[PDF] Better algorithms for BPF - The Linux Kernel Archives",
          "url": "http://oldvger.kernel.org/bpfconf2022_material/lsfmmbpf2022-algs.pdf",
          "excerpts": [
            "- BPF_RINGBUF_SUBMIT command runs BPF prog on each sample? - Kthread to run each BPF program? - bpf_dynptr is an interface to a memory. - Need to work through ..."
          ]
        },
        {
          "title": "eBPF Verifier Code Review",
          "url": "https://www.linuxfoundation.org/hubfs/eBPF/eBPF%20Verifier%20Security%20Audit.pdf?__hstc=137369199.8da91b5f8b42a5531651a132262dd89d.1751068800153.1751068800154.1751068800155.1&__hssc=137369199.1.1751068800156&__hsfp=150561067",
          "excerpts": [
            "Nov 11, 2024 — The eBPF verifier gates eBPF programs into the kernel, verifying their safety. The review found a vulnerability to read/write kernel memory and ..."
          ]
        },
        {
          "title": "The Arrow C Device data interface",
          "url": "https://arrow.apache.org/docs/format/CDeviceDataInterface.html",
          "excerpts": [
            "The Arrow C Device data interface builds on the existing C data interface by adding a very small, stable set of C definitions",
            "Section Navigation",
            "The Arrow C Device data interface",
            "An Arrow C device stream exposes a streaming source of data chunks, each with\nthe same schema. Chunks are obtained by calling a blocking pull-style iteration\nfunction.",
            "It is expected that all chunks should be providing data on the same\ndevice type (but not necessarily the same device id).",
            "face](CStreamInterface.html) , the C Device data\ninterface also specifies a higher-level structure for easing communication\nof streaming data within a single process.",
            "Lifetime of the C stream is managed using a release callback with similar usage as in C data interface. Thread safety#. The stream source is not assumed to ..."
          ]
        },
        {
          "title": "The eBPF verifier and observability",
          "url": "https://www.groundcover.com/ebpf/ebpf-verifier",
          "excerpts": [
            "Mar 13, 2025 — The eBPF verifier is a part of the eBPF framework that checks eBPF bytecode for safety risks before they run in the Linux kernel.",
            "Directly modifying kernel source code presented the same risk, with the added drawback of requiring a tremendous amount of work.",
            "eat. Thanks to the verifier, admins can run observability code directly in kernel space without worrying about breaking their system.",
            "he verifier is not an optional component of eBPF. eBPF code _must_ pass the verifier because the kernel will execute it",
            "Thus, if you want to leverage eBPF as an observability solution – which we strongly think you should, given that [eBPF tracing](/ebpf/ebpf-tracing) offers a hyper-efficient way of monitoring and observing any process, application, or network traffic flow running on a Linux kernel – you need to use the verifier as ",
            " process, it is a key component for executing eBPF programs, which are themselves a way of collecting observability data.",
            "he eBPF verifier is not itself a tool for collecting telemetry data or otherwise assisting in the observability process, it is a key component for executing eBPF pro",
            "eBPF verifier works via a process known as static code analysis. This means it analyzes eBPF bytecode while the code is not running, looking for issues that could cause problems when the code executes",
            "Importantly, the scope of the verifier’s functionality is limited to checking for safety issues that could destabilize a system or violate kernel-level access control restrictions. It’s not a general-purpose static code analyzer.",
            "Although the verifier supports a limited range of functionality, it offers a wide range of benefits for enhancing the observability process.",
            "The design of the verifier keeps monitoring overhead low. This is because, by using the verifier to check code prior to execution, eBPF avoids having to perform checks or impose restrictions at runtime, which would be more costly in terms of CPU and memory usage.",
            "The verifier plays an important role in protecting against situations where code inside an eBPF program could access data that shouldn’t be available to it."
          ]
        },
        {
          "title": "Jan 19, 2023 — Verifying eBPF",
          "url": "https://blog.trailofbits.com/2023/01/19/ebpf-verifier-harness/",
          "excerpts": [
            "The key to eBPF safety is the eBPF verifier, which limits the set of valid eBPF programs to those that it can guarantee will not harm the kernel or cause other issues.",
            " This means that eBPF is, by design, not [Turing-complete]",
            "The verifier performs two main passes over the code. The first pass is handled by the `check_cfg()` function, which ensures that the program is guaranteed to terminate by performing an iterative depth-first search of all possible execution paths.",
            "The second pass (done in the `do_check()` function) involves static analysis of the bytecode; this pass ensures that all memory accesses are valid, that types are used consistently (e.g., scalar values are never used as pointers), and that the number of branches and total instructions is within certain complexity limits.",
            "As mentioned earlier in the post, the constraints that the verifier enforces have changed over time.",
            "One of the key benefits of eBPF is the guarantee it provides: that the loaded code will not crash the kernel, will terminate within a time limit, and will not leak information to unprivileged user processes.",
            " The harness is not the first tool that aims to improve the verifier’s testability. The IO Visor Project’s [BPF fuzzer](https://github.com/iovisor/bpf-fuzzer) has a very similar goal of running the verifier in user space and enabling efficient fuzzing—and the tool has found [at least one bug]",
            "the harness is intended to support all kernel versions, making it easy to compare the same eBPF program across kernel versions."
          ]
        },
        {
          "title": "Include build data in your program: date, rustc version, git ...",
          "url": "https://www.reddit.com/r/rust/comments/mqnbvw/builddata_include_build_data_in_your_program_date/",
          "excerpts": [
            "SOURCE_DATE_EPOCH is a standardised environment variable that distributions can set centrally and have build tools consume this in order to ...",
            "How do you calculate SOURCE_DATE_EPOCH from a git repo? I looked through the docs and didn't find a command, script, or procedure for doing it."
          ]
        },
        {
          "title": "Rust PGO and Reproducible Build Strategies (from the provided PDF)",
          "url": "https://www.datocms-assets.com/98516/1734435430-zaitsau_2024.pdf",
          "excerpts": [
            "PGO-optimized build reproducibility - save somewhere a PGO profile and use it for all builds.",
            " PGO profile reproducibility - ... Compile the program with Instrumentation:\nrustc -Cprofile-generate=/tmp/pgo-data main.rs",
            "2. Run the instrumented program with a training workload",
            "load 3. Convert the .profraw file into a .profdata file using LLVM's \nllvm-profdata  tool:",
            "llvm-profdata merge -output=merged.profdata default.profraw",
            "\n4. Compile the program again with the profiling data:\nrustc -Cprofile-use=merged.profdata main.rs",
            "29",
            "cargo-pgo - the best PGO friend",
            "Written by Jakub “ Kobzol ” Beranek ● GitHub:  https://github.com/Kobzol/cargo-pgo",
            "Supports Instrumentation PGO and LLVM BOLT",
            "Current PGO states across Rust applications",
            "PGO integration state for Rust apps",
            "\nRule of thumb: if you want PGO for something - you need to \nrebuild it",
            "Continuous Profile-Guided Optimization",
            "AFAIK, the only thing right now is \nGoogle Wide Profiler  (GWP) based  solution, \nclosed-source",
            "There is no ready-to-use open-source solution yet",
            "There is an idea about making such a platform as a part of \nGrafana  Pyroscope  or \nElasticsearch Universal Profi",
            "Can be implemented on proprietary profiling platforms like  Yandex.Perforator, Ozon.Vision, etc",
            "PGO issues in Rustc",
            "Documentation ● Toolin",
            "cargo-pgo is not ideal ○ AutoFDO migration proce",
            "Missing most advanced PGO modes",
            "Bugs",
            "[no_std] is not supported by default*\n○ But can be achieved with  mini"
          ]
        },
        {
          "title": "vadimcn/cargo-pgo: Supercharge you Rust programs!",
          "url": "https://github.com/vadimcn/cargo-pgo",
          "excerpts": [
            "Merge profiles. Before using generated profiles, they must be first merged into an 'indexed' format: cargo pgo merge."
          ]
        },
        {
          "title": "Audit trail & MIR - compiler",
          "url": "https://internals.rust-lang.org/t/audit-trail-mir/7839",
          "excerpts": [
            "Jun 30, 2018 — An auditing tool could scan for #[safe] blocks, generate their MIR, and attach it in the note as audit data. If the audited code is changed, the ..."
          ]
        },
        {
          "title": "rust-fuzz/afl.rs: 🐇 Fuzzing Rust code with American Fuzzy Lop",
          "url": "https://github.com/rust-fuzz/afl.rs",
          "excerpts": [
            "A popular, effective, and modern fuzz testing tool based on AFL. This library, afl.rs, allows one to run AFLplusplus on code written in the Rust programming ...See more"
          ]
        },
        {
          "title": "BurntSushi/quickcheck: Automated property based testing ...",
          "url": "https://github.com/BurntSushi/quickcheck",
          "excerpts": [
            "QuickCheck is a way to do property based testing using randomly generated input. This crate comes with the ability to randomly generate and shrink integers, ..."
          ]
        },
        {
          "title": "cargo-auditable - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-auditable",
          "excerpts": [
            "The embedded dependency list uses under 4kB even on large dependency trees with 400+ entries. This typically translates to between 1/1000 ..."
          ]
        },
        {
          "title": "Performing Audits - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/performing-audits.html",
          "excerpts": [
            "Cargo vet suggest can estimate the lowest-effort audits you can perform to reduce the number of entries in exemptions, and consequently, your attack surface."
          ]
        },
        {
          "title": "Reproducible Builds in June 2022",
          "url": "https://reproducible-builds.org/reports/2022-06/",
          "excerpts": [
            "Luckily, as one of the responses mentions: “the --remap-path-prefix solves this problem and has been used to great effect in build systems that rely on ..."
          ]
        },
        {
          "title": "Setting codegen-units to 1 gives even better code quality ...",
          "url": "https://news.ycombinator.com/item?id=36681703",
          "excerpts": [
            "Setting codegen-units to 1 gives even better code quality than thin local LTO, but takes longer. Some authors of binary rust crates always use that setting ..."
          ]
        },
        {
          "title": "rust-secure-code/cargo-auditable: Make production Rust binaries ...",
          "url": "https://github.com/rust-secure-code/cargo-auditable",
          "excerpts": [
            "Audit binaries for known bugs or security vulnerabilities in production, at scale, with zero bookkeeping."
          ]
        },
        {
          "title": "cargo-sbom - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-sbom",
          "excerpts": [
            "Jun 16, 2025 — This crate provides a command line tool to create software bill of materials (SBOM) for Cargo / Rust workspaces. It supports both SPDX and CycloneDX outputs."
          ]
        },
        {
          "title": "Commands - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/commands.html",
          "excerpts": [
            "This section documents the command-line interface of cargo vet. The documentation is automatically generated from the implementation, and so it may be ..."
          ]
        },
        {
          "title": "cargo-auditable - Crates.io",
          "url": "https://crates.io/crates/cargo-auditable/versions",
          "excerpts": [
            "Make production Rust binaries auditable. 20 of 20 cargo-auditable versions since July 31st, 2022. Sort by Date Date SemVer"
          ]
        },
        {
          "title": "When reproducible builds? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/jct0y4/when_reproducible_builds/",
          "excerpts": [
            "In some domains, it is very important to be able to reproducibly rebuild a binary from the sources. This is cargo/rustc pretty bad at."
          ]
        },
        {
          "title": "Caller-side inline directives - language design",
          "url": "https://internals.rust-lang.org/t/caller-side-inline-directives/19078",
          "excerpts": [
            "It would be nice if I could use a caller-side inline directive, as recently introduced by clang, instead of having to go codegen-units = 1 or fat LTO."
          ]
        },
        {
          "title": "CycloneDX/cyclonedx-rust-cargo",
          "url": "https://github.com/CycloneDX/cyclonedx-rust-cargo",
          "excerpts": [
            "The CycloneDX module for Rust (Cargo) creates a valid CycloneDX Software Bill of Materials (SBOM) containing an aggregate of all project dependencies."
          ]
        },
        {
          "title": "cargo-vet 0.10.1",
          "url": "https://docs.rs/crate/cargo-vet/latest",
          "excerpts": [
            "The cargo vet subcommand is a tool to help projects ensure that third-party Rust dependencies have been audited by a trusted entity. It strives to be ..."
          ]
        },
        {
          "title": "Rust Cargo PGO and BOLT – Kobzol blog",
          "url": "https://kobzol.github.io/rust/cargo/2023/07/28/rust-cargo-pgo.html",
          "excerpts": [
            "Jul 28, 2023 — cargo pgo has your back! With cargo pgo test or cargo pgo bench , you can generate profiles by running instrumented tests or benchmarks, and ... I created a simple example of a GitHub Actions workflow that shows how this could be done. Going beyond PGO",
            "The (LLVM-based) PGO implementation offered by the Rust compiler is just one of many existing so-called\nFeedback-directed optimization (FDO) tools, which leverage some sort of runtime profiles to better\noptimize programs.",
            "rams. Another such tool is a post-link optimizer called BOLT . “Post-link” means that it takes a fully compiled and linked program binary as an input, and then uses\nprofiles to optimize the binary, even without access to its source code. This differs from “classic”\nPGO, which optimizes the program during compilation, and thus has access to its source code. Its main\ngoal is to better reorganize instructions within the binary, in particular to improve instruction cache\nutilization. BOLT is a part of LLVM, and can provide additional performance improvements even on top of an already\nPGO-optimized binary.",
            "Last year, I have enabled BOLT for LLVM 3 used by the Rust compiler, which resulted in ~2-5% cycle improvements across the board."
          ]
        },
        {
          "title": "Hacker News discussion thread excerpt on Rust PGO and determinism",
          "url": "https://news.ycombinator.com/item?id=25060762",
          "excerpts": [
            "Does PGO mean the build products are non-deterministic? ie if you build the Rust compiler twice you get different bits.",
            "It would be deterministic for a given set of input profile data, but would likely change every time you instrumented a new profile",
            "BOLT just permutes link order? The object permutation from a BOLT run should be good for months until the underlying objects have substantially drifted?"
          ]
        },
        {
          "title": "Securing the Software Supply Chain: Recommended Practices for Developers",
          "url": "https://www.cisa.gov/sites/default/files/publications/ESF_SECURING_THE_SOFTWARE_SUPPLY_CHAIN_DEVELOPERS.PDF",
          "excerpts": [
            "The production build environment is where reproducible deliverables are built.",
            "The artifacts for builds should include, at a minimum, the source repository, the third-party \ndependencies, the build script, and the output of the build",
            "For reproducible builds, the artifact should be the \noutput of the script that compares the builds",
            "The third party's SBOM can be compared with the SBOM produced by the SCA tools."
          ]
        },
        {
          "title": "How can I include the build date in an executable - help",
          "url": "https://users.rust-lang.org/t/how-can-i-include-the-build-date-in-an-executable/102024",
          "excerpts": [
            "Nov 3, 2023 — The recommendation is to use the SOURCE_DATE_EPOCH env var if it is set: SOURCE_DATE_EPOCH — reproducible-builds.org. 6 Likes. mark November 3 ..."
          ]
        },
        {
          "title": "refix: fast, debuggable, reproducible builds",
          "url": "https://yosefk.com/blog/refix-fast-debuggable-reproducible-builds.html",
          "excerpts": [
            "There's a simple way to make your builds all of the following: Reproducible/deterministic - same binaries always built from the same source, ..."
          ]
        },
        {
          "title": "Profiles - The Cargo Book",
          "url": "https://doc.rust-lang.org/cargo/reference/profiles.html",
          "excerpts": [
            "codegen-units. The codegen-units setting controls the -C codegen-units flag which controls how many “code generation units” a crate will be split into. More ..."
          ]
        },
        {
          "title": "Codegen Options - The rustc book",
          "url": "https://doc.rust-lang.org/rustc/codegen-options/index.html",
          "excerpts": [
            "When -C lto is not specified, LTO is disabled if codegen units is 1 or optimizations are disabled ( -C opt-level=0 ). That is: When -C lto is not specified:."
          ]
        },
        {
          "title": "An Introduction To Property-Based Testing In Rust",
          "url": "https://lpalmieri.com/posts/an-introduction-to-property-based-testing-in-rust/",
          "excerpts": [
            "Jan 3, 2021 — There are two mainstream options for property-based testing in the Rust ecosystem: quickcheck and proptest . Their domains overlap, although ..."
          ]
        },
        {
          "title": "How to Sign an SBOM with Cosign",
          "url": "https://edu.chainguard.dev/open-source/sigstore/cosign/how-to-sign-an-sbom-with-cosign/",
          "excerpts": [
            "Note the warnings — a record of the attestation will be recorded to an immutable log maintained by the Sigstore project. When you're ready, ..."
          ]
        },
        {
          "title": "Introduction - Cargo Vet",
          "url": "https://mozilla.github.io/cargo-vet/",
          "excerpts": [
            "The cargo vet subcommand is a tool to help projects ensure that third-party Rust dependencies have been audited by a trusted entity."
          ]
        },
        {
          "title": "`cargo audit` can now scan compiled binaries : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/yk7l3w/cargo_audit_can_now_scan_compiled_binaries/",
          "excerpts": [
            "I've been working to bring vulnerability scanning to Rust binaries by creating cargo auditable, which embeds the list of dependencies and their versions into ..."
          ]
        },
        {
          "title": "Sigstore Bundle Format",
          "url": "https://docs.sigstore.dev/about/bundle/",
          "excerpts": [
            "A Sigstore bundle is everything required to verify a signature on an artifact. This is satisfied by the Verification Material and signature Content."
          ]
        },
        {
          "title": "cargo-auditable(1) - Arch Linux manual pages",
          "url": "https://man.archlinux.org/man/cargo-auditable.1.en",
          "excerpts": [
            "The embedded dependency list uses under 4kB even on large dependency trees with 400+ entries. This typically translates to between 1/1000 and 1/10,000 of the ..."
          ]
        },
        {
          "title": "Rust Internals: rustdoc binary is not reproducible",
          "url": "https://internals.rust-lang.org/t/rustdoc-binary-is-not-reproducible/20027",
          "excerpts": [
            "Hello,\n\nWe've observed that 'rustdoc' is not reproducible in our Yocto build environment. The below differences are observed between multiple builds (The rust sources are not changed between builds). The diff in shown in _\".strtab\" & \".shstrtab\"_ sections of the binary. [<img src='https://us1.discourse-cdn.com/flex002/uploads/rustlang/original/2X/9/977de908e21d44b771b12d13b0c18a3011a52891.png' alt='image-1' width='690' height='333' /",
            "PGO for something like rustdoc seems like overkill, no? <img src='https://emoji.discourse-cdn.com/twitter/slight_smile.png?v=12' alt=':slight_smile:' width='20' height='20' />",
            "`.llvm.<hash>` suffixes are added by LLVM's thinLTO to prevent symbol collisions when making a symbol marked as internal external to enable inlining across the LLVM modules that participate in thinLTO. As for why it would differ, I have no clue. (You are not using PGO, right? PGO profile generation is not deterministic due to among other things threading.)",
            "PGO `profiler = true` in our rust build environment. Setting `profiler = false` alone not fixed the issue, there is dependent option `tools = [\"rust-demangler\",]` , when these both are set the issue is fixed.",
            "`.llvm.<hash>` suffixes are added by LLVM's thinLTO to prevent symbol collisions when making a symbol marked as internal external to enable inlining across the LLVM modules that participate in thinLTO",
            "This topic was automatically closed 90 days after the last reply. New replies are no longer allowed."
          ]
        },
        {
          "title": "Timesys — SBOM Generation and Vulnerability Monitoring for the Crates.io/Rust Ecosystem",
          "url": "https://www.timesys.com/security/sbom-generation-and-vulnerability-monitoring-for-the-crates-io-rust-ecosystem/",
          "excerpts": [
            "Jun 5, 2024 — Syft is our preferred tool for generating SBOMs due to its compliance with SPDX/CycloneDX specs and compatibility with Vigiles.",
            "Jun 5, 2024 — In this post, we'll explore the Rust ecosystem, specifically Cargo/Crates.io, and discuss the significance of SBOMs and Software Composition ...",
            "An SBOM is a comprehensive inventory of software components",
            "In the Rust ecosystem, maintaining an accurate SBOM is crucial due to the rapidly evolving landscape of libraries and dependencies available on Crates.io.",
            "Streamlining SBOM and Vulnerability Management with Syft and Vigiles",
            "Vigiles pulls from multiple security advisories, including but not limited to the National Vulnerability Database (NVD) and OSV (GitHub Security Advisory, PyPI Advisory, Go Vulnerability Database, Rust Advisory, Haskell Security Advisories, OSS-Fuzz, Debian Security Advisories, RConsortium Advisory).",
            "Using Syft to generate your SBOMs allows you to maintain a detailed inventory of your software components and dependencies."
          ]
        },
        {
          "title": "debug_info_for_profiling - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/debug_info_for_profiling.html",
          "excerpts": [
            "Unlike PGO (controlled by the rustc flags -Cprofile-generate and -Cprofile-use ), a binary being profiled does not perform significantly worse, and thus it's ..."
          ]
        },
        {
          "title": "Kobzol/cargo-pgo: Cargo subcommand for optimizing Rust ...",
          "url": "https://github.com/Kobzol/cargo-pgo",
          "excerpts": [
            "Cargo subcommand that makes it easier to use PGO and BOLT to optimize Rust binaries. For an example on how to use cargo-pgo to optimize a binary on GitHub ..."
          ]
        },
        {
          "title": "Reproducible builds: Automatically remap $CARGO_HOME and ...",
          "url": "https://github.com/rust-lang/cargo/issues/5505",
          "excerpts": [
            "I tried adding --remap-path-prefix flag but still the binaries are not reproducible. But, I suspect my change is effective or not, can anyone ..."
          ]
        },
        {
          "title": "cargo_pgo - Rust",
          "url": "https://docs.rs/cargo-pgo",
          "excerpts": [
            "This crate contains a Cargo subcommand designed for simplifying the usage of feedback-directed optimizations for Rust crates."
          ]
        },
        {
          "title": "[PDF] MirChecker: Detecting Bugs in Rust Programs via Static Analysis",
          "url": "https://www.cse.cuhk.edu.hk/~cslui/PUBLICATION/CCS2021.pdf",
          "excerpts": [
            "The design of MirChecker is presented in Section 4, and we illustrate how Abstract Interpretation is performed on our language model in Section ..."
          ]
        },
        {
          "title": "MIRAI/documentation/Overview.md at main",
          "url": "https://github.com/facebookexperimental/MIRAI/blob/main/documentation/Overview.md",
          "excerpts": [
            "Aug 22, 2024 — A decision was made to use Rust, but the analysis concluded that support for static analysis tools for Rust was one of the few areas where Rust ..."
          ]
        },
        {
          "title": "Detecting Bugs in Rust Programs via Static Analysis",
          "url": "https://dl.acm.org/doi/10.1145/3460120.3484541",
          "excerpts": [
            "Nov 13, 2021 — In this paper, we present and evaluate MirChecker, a fully automated bug detection framework for Rust programs by performing static analysis on Rust's Mid- ..."
          ]
        },
        {
          "title": "facebookexperimental/MIRAI: Rust mid-level IR Abstract ...",
          "url": "https://github.com/facebookexperimental/MIRAI",
          "excerpts": [
            "Aug 22, 2024 — MIRAI is an abstract interpreter for the Rust compiler's mid-level intermediate representation (MIR). It started out as a Facebook project, but became orphaned."
          ]
        },
        {
          "title": "lizhuohua/rust-mir-checker - GitHub",
          "url": "https://github.com/lizhuohua/rust-mir-checker",
          "excerpts": [
            "This tool tries to analyze the MIR generated by the Rust compiler and emit diagnostic messages. It is based on the theory of Abstract Interpretation."
          ]
        },
        {
          "title": "Static Assurance (1/2)",
          "url": "https://highassurance.rs/chp2/static_assurance_1.html",
          "excerpts": [
            "Static analysis tools often use a layer of indirection that simplifies answering a particular question. They map the constructs of P to an analysis-specific ..."
          ]
        },
        {
          "title": "rustc_middle::mir::interpret",
          "url": "https://doc.rust-lang.org/beta/nightly-rustc/rustc_middle/mir/interpret/index.html",
          "excerpts": [
            "An interpreter for MIR used in CTFE and by miri. Modules§. allocation: The virtual memory representation of the MIR interpreter. error; pointer ..."
          ]
        },
        {
          "title": "SBOM support in Rust",
          "url": "https://ferrous-systems.com/blog/stackable-client/",
          "excerpts": [
            "Jul 30, 2024 — A project proposal to improve the generation of Software Bill of Materials (SBOM) in the Rust eco-system."
          ]
        },
        {
          "title": "CycloneDX Tool Center",
          "url": "https://cyclonedx.org/tool-center/",
          "excerpts": [
            "Beniva SBOM allows you to consume CycloneDX SBOM and Vulnerability Exploitability eXchange (VEX) within the ServiceNow platform which increases visibility of ..."
          ]
        },
        {
          "title": "Choosing an SBOM Generation Tool",
          "url": "https://openssf.org/blog/2025/06/05/choosing-an-sbom-generation-tool/",
          "excerpts": [
            "Jun 5, 2025 — Many tools exist to generate SBOMs, and we've spent some time with the different options to help you decide."
          ]
        },
        {
          "title": "Surface Rust dependency relationships #2353 - anchore/syft",
          "url": "https://github.com/anchore/syft/issues/2353",
          "excerpts": [
            "Nov 24, 2023 — What happened: Syft not created \"dependencies\" in cyclonedx report for Go, Rust, Java and etc. Cargo.lock had \"dependencies\"."
          ]
        },
        {
          "title": "Pre-RFC: Cargo SBOM",
          "url": "https://internals.rust-lang.org/t/pre-rfc-cargo-sbom/19842",
          "excerpts": [
            "Nov 8, 2023 — A SBOM (software bill of materials) is a list of all components and dependencies used to build a piece of software. The two leading SBOM formats ..."
          ]
        },
        {
          "title": "cargo::core::compiler::output_sbom",
          "url": "https://doc.rust-lang.org/nightly/nightly-rustc/cargo/core/compiler/output_sbom/index.html",
          "excerpts": [
            "Build an Sbom for the given Unit . build_sbom_graph: List all dependencies, including transitive ones. A dependency can also appear multiple times if it's ..."
          ]
        },
        {
          "title": "Rust reproducibility and PGO discussion (GitHub issue discussion)",
          "url": "https://github.com/rust-lang/rust/issues/79442",
          "excerpts": [
            "The blog post contains a step by step description of how to obtain a PGOed compiler -- but it is rather time consuming to actually do that. In order to make things easier I could provide a branch of the compiler that has all the changes already applied and, more importantly, a pre-recorded, checked-in `.profdata` file for both LLVM and rustc. Alternatively, I could just put up the final toolchain for download somewhere. Even better would be to make it available via rustup somehow.",
            "* This makes `rustc` builds non-reproducible -- something which I don't think is true. With a fixed `.profdata` file, both rustc and Clang should always generate the same output. That is `-Cprofile-use` and `-fprofile-use` do not introduce any source of randomness, as far as I can tell. So if the `.profdata` file being used is tracked by version control, we should be fine.",
            "You get the same profile data if (and only if) the workload is deterministic. If there is some source of randomness, like if pointers are being ... ](/rust-lang/rust/security)",
            "t the build into three separate tasks: the instrumented build, the profile collection, the optimized build.",
            ". For Firefox builds, we settled on being comfortable with publishing the profile data and making sure that the optimized build step was deterministic given that same input.",
            ". This also helped us enable PGO for cross-compiled builds like the macOS build on Linux.",
            "Please post any feedback that you might have below!"
          ]
        },
        {
          "title": "High Assurance Rust: Developing Secure and Robust Software",
          "url": "https://highassurance.rs/",
          "excerpts": [
            "The State-of-the-Art in Practical Software Assurance",
            "### [_Developing Secure and Robust Software_]()",
            "ou'll learn Rust - a modern, multi-paradigm language that emphasizes speed and correctness. Most programming books teach a new language by presenting a dozen small, unrealistic programs. Not this one. We'll design, write, and validate a fully-featured alternative to the ordered map and set implementations in Rust's standard library. You'll gain a deep understanding of the Rust language by re-implementing one of its major dynamic collections, one idiomatic API at a time. Unlike the standard version, our implementation will be:\n\n* \n  **Maximally Safe. ** Upholds Rust's strongest memory safety guarantees, for all possible executions. + To test properties the compiler can't prove, we'll learn advanced program analysis techniques, including _differential fuzzing_ and _deductive verification_ \\*. * \n  **Extremely Portable. ** Capable of running on every operating system, or even without one (e.g. \"bare metal\").\n+ Our library is a _hardened component_ . To integrate it within larger codebases, we'll add _CFFI bindings_ to make the Rust functions callable from other languages - including C and Python. * \n  **Highly Available. ** Offers _fallible_ APIs for handling cases that could otherwise result in a crash. + E.g. _Out-of-Memory (OOM) error_ \\- when all pre-allocated memory has been exhausted.",
            "## [The State-of-the-Art in Practical Software Assurance]()",
            "We'll use cutting-edge, open-source software assurance tools to validate the code we write in this book. Some of these tools are mature and used in commercial industry:\n\n* `rustc` (modern compiler)\n* `libFuzzer` (fuzz testing framework)\n* `rr` (\"time-travel\" debugger)\n* `qemu` (whole-system emulator)\n\nOther tools are experimental and under active research. A full inventory is available in [the appendix](../chp16_appendix/tools.html) . Visually, this book covers the below topics (contrasted roughly on tradeoff of **development speed** and **formal rigor** ). Don't worry, we'll provide clear explanations and context for each. Notice the bias toward development speed. We're interested in **lightweight processes** that, in the long run, enable us to **ship quality code faster** and spend **less time patching** security and reliability failures. Techniques you can apply to real-world code. Today.",
            "We'll use cutting-edge, open-source software assurance tools to validate the code we write in this book. Some of these tools are mature and used in commercial industry:\n\n* `rustc` (modern compiler)\n* `libFuzzer` (fuzz testing framework)\n* `rr` (\"time-travel\" debugger)\n* `qemu` (whole-system emulator)\n\nOther tools are experimental and under active research. A full inventory is available in [the appendix](../chp16_appendix/tools.html) . Visually, this book covers the below topics (contrasted roughly on tradeoff of **development speed** and **formal rigor** ). Don't worry, we'll provide clear explanations and context for each. Notice the bias toward development speed. We're interested in **lightweight processes** that, in the long run, enable us to **ship quality code faster** and spend **less time patching** security and reliability failures. Techniques you can apply to real-world code. Today."
          ]
        },
        {
          "title": "How to properly use --remap-path-prefix?",
          "url": "https://users.rust-lang.org/t/how-to-properly-use-remap-path-prefix/104406",
          "excerpts": [
            "I want to strip references to the build directory and the general setup on the computer that build the binary. As I understand it, I'm supposed to use --remap- ..."
          ]
        },
        {
          "title": "remap-path-prefix",
          "url": "https://web.mit.edu/rust-lang_v1.25/arch/amd64_ubuntu1404/share/doc/rust/html/unstable-book/compiler-flags/remap-path-prefix.html",
          "excerpts": [
            "This is useful for bringing debuginfo paths into a well-known form and for achieving reproducible builds independent of the directory the compiler was executed ..."
          ]
        },
        {
          "title": "remap_cwd_prefix - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/remap-cwd-prefix.html",
          "excerpts": [
            "This flag will rewrite absolute paths under the current working directory, replacing the current working directory prefix with a specified value. The given ..."
          ]
        },
        {
          "title": "SOURCE_DATE_EPOCH — reproducible-builds.org",
          "url": "https://reproducible-builds.org/docs/source-date-epoch/",
          "excerpts": [
            "SOURCE_DATE_EPOCH specifies the last modification of something, usually the source code, measured in the number seconds since the Unix epoch."
          ]
        },
        {
          "title": "Deterministic build systems",
          "url": "https://reproducible-builds.org/docs/deterministic-build-systems/",
          "excerpts": [
            "A software cannot easily be built reproducibly if the source varies depending on factors that are hard or impossible to control like the ordering of files."
          ]
        },
        {
          "title": "Certifiable Rust - Electronic Design",
          "url": "https://www.electronicdesign.com/technologies/embedded/software/video/55273394/electronic-design-rust-can-be-certified-for-safe-and-secure-applications",
          "excerpts": [
            "This Rust toolset meets ISO 26262 (ASIL D), IEC 61508 (SIL 4), and IEC 62304 certifications. It's open source and available on Linux, QNX Neutrino, and various ..."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Feb 13, 2025 — Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "Installing and Using Ferrocene",
          "url": "https://rust-training.ferrous-systems.com/latest/book/ferrocene-installing",
          "excerpts": [
            "Qualified, or not; Host or Cross-compiled. Qualified Targets. Production Ready; Passes the Rust Test Suite; Support is available; Signed qualification material."
          ]
        },
        {
          "title": "Software Tool Qualification in ISO 26262 Development - Embitel",
          "url": "https://www.embitel.com/blog/embedded-blog/why-is-software-tool-qualification-indispensable-in-iso-26262-based-software-development",
          "excerpts": [
            "Nov 2, 2020 — Clause 11 of Part-8 of the ISO 26262 standard comprises the ISO 26262 tool qualification methods. As per the standard, ISO 26262 tool ...",
            "a TCL is assigned, which reflects the level of confidence that can be placed in the tool to perform its intended functions without introducing unacceptable risks.",
            "The tables will make it clearer.",
            "rd**\n\nThe tool qualification methods prescribed in the standard for TCL 2 and TCL 3 are almost similar, with a slight difference based on [ASIL",
            "rd**\n\nThe tool qualification methods prescribed in the standard for TCL 2 and TCL 3 are almost similar, with a slight difference based on [ASIL"
          ]
        },
        {
          "title": "IEC 61508 – Why Tool Qualification",
          "url": "https://61508.org/wp-content/uploads/2024/11/09B-IEC-61508-Why-tool-qualification_V2_cut.pdf",
          "excerpts": [
            "... T1, T2 and T3 support tools shall be justified, for each tool in class T3, evidence shall be available that the tool conforms to its specification or ...",
            "T1 tool is selected as part of the requirement of software configuration management tool. • Deficiency of IEC 61508: tool qualification requirements for T2 & T3 ..."
          ]
        },
        {
          "title": "ISO 26262-6:2018 - Product development at the software level - GitLab",
          "url": "https://about.gitlab.com/solutions/iso-26262/",
          "excerpts": [
            "ISO 26262-6:2018 prescribes ways to identify and mitigate safety risks for automotive applications. These methods depend on so-called Automotive Safety ..."
          ]
        },
        {
          "title": "Ferrocene Update",
          "url": "https://ferrous-systems.com/blog/sealed-rust-the-plan/",
          "excerpts": [
            "Feb 13, 2020 — Ferrocene is the effort led by Ferrous Systems GmbH to qualify the Rust language and compiler for use in mission and safety-critical domains."
          ]
        },
        {
          "title": "Ferrocene - ISO 26262 and IEC 61508 qualified rust compiler",
          "url": "https://lobste.rs/s/qhohlx/ferrocene_iso_26262_iec_61508_qualified",
          "excerpts": [
            "The aim is to ensure there's a formal chain of traceability that goes from everything an end user compiled to the features you tested and found ..."
          ]
        },
        {
          "title": "Software Tools: It's as Easy as T1, T2, T3 - EngineerZone",
          "url": "https://ez.analog.com/ez-blogs/b/engineerzone-spotlight/posts/software-tools",
          "excerpts": [
            "Nov 28, 2018 — This blog discusses requirements related to offline software tools found in standards such as IEC 61508, ISO 26262 and D0-178C/D0-330."
          ]
        },
        {
          "title": "Efficient and Trustworthy Tool Qualification for Model- ...",
          "url": "https://inria.hal.science/hal-01482408v1/document",
          "excerpts": [
            "In this paper we review the tool quali- fication requirements of the standards ISO 26262 (automotive domain) and the new RTCA DO-178C (avionic ..."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "One of the primary partitioning strategies in ARINC 653 is time and space partitioning. Time partitioning involves dividing the system's ...",
            "We'll delve into partitioning strategies, certification considerations, memory management, fault tolerance, integration, and testing, offering ..."
          ]
        },
        {
          "title": "Incremental Assurance of Multicore Integrated Modular Avionics (IMA)",
          "url": "https://ieeexplore.ieee.org/document/9594404/",
          "excerpts": [
            "DO-297/ED-124 defines incremental acceptance as a \"process for obtaining credit toward approval and certification by accepting or finding that an IMA module ..."
          ]
        },
        {
          "title": "Parasoft ISO 26262 Software Compliance Technical Whitepaper",
          "url": "https://alm.parasoft.com/hubfs/New_Pages/Whitepaper%20ISO%2026262%20Software%20Compliance%20With%20Parasoft.pdf",
          "excerpts": [
            "ISO 26262 is a functional safety standard covering the entire automotive product development process, with Part 6 addressing software development. Wh",
            "Part 8, section 11, describes the software   tool qualification proces",
            "Tools that automate  software development activities and tasks can  significantly help organizations meet ISO 26262  requiremen",
            "The information presented  here is intended to serve as an introduction to  ISO 26262 software verification and validation  processes with Paraso"
          ]
        },
        {
          "title": "Ferrocene: Qualified Rust toolchain for safety-critical systems",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles. It’s qualified at ASIL-D, the highest risk class, for peace of mind.",
            "ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or your choice of RTOS.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels.",
            "Qualified for automotive, industrial and medical development. ... ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or ...See more",
            "ull qualification\ndocuments. [Read\nDocumentation](https://public-docs.ferrocene.dev/main/index.html)",
            "TÜV SÜD conducted the audit and Ferrous Systems – leading Rust experts – supports the signed installers as well as the nightly builds.",
            "The source code of Ferrocene is\nfully open source under the MIT OR Apache-2.0 license, including the full qualification\ndocuments."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "We’ve qualified\nFerrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database. ",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "This standard provides automakers\nwith guidelines that make the software being used to develop, produce, operate\nand service the automotive sectors safe to use.",
            "Beyond the automotive, Ferrocene can also be used in electronic programmable\nsystems in the industrial sector. Here the focus is on developing products or\napplications that carry out safety functions.",
            "This means we achieved qualification for the open source Ferrocene toolchain.",
            "With these qualifications, Rust can now be used to develop software for\nelectronic systems in series production road vehicles.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "This is\nthe first qualification of a Rust compiler.",
            "This is\nthe first qualification of a Rust compiler.",
            "Ferrocene is ISO 26262 and IEC 61508 qualified!"
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "formal verification in general is stronger than other\n   traditional ways of gaining trust in software such as testing in that\n   it can prove the _absence_ of bugs, not just their\n ",
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft"
          ]
        },
        {
          "title": "Implications of the seL4 Verification",
          "url": "https://sel4.systems/Verification/implications.html",
          "excerpts": [
            "The proofs not only establish functional correctness, integrity, and confidentiality, but they also imply the absence of many common programming errors. They give you the reasons why and how\n data structures work, why it is safe to optimise and leave out certain checks\n (because you know they will always be true), and why the code always\n executes in a defined and safe mann"
          ]
        },
        {
          "title": "Ferrocene Achieves IEC 62304 Qualification",
          "url": "https://ferrous-systems.com/blog/ferrocene-achieves-iec-62304-qualification/",
          "excerpts": [
            "It is qualified to automotive (ISO 26262, ASIL-D), industrial development (IEC 61508, SIL4) and medical (IEC 62304, Class C) standards, with ..."
          ]
        },
        {
          "title": "IEC 61508 Ensuring Software Compliance",
          "url": "https://www.qa-systems.com/solutions/iec-61508/",
          "excerpts": [
            "Part 3 of IEC 61508 addresses the software requirements of a safety-related system mandating the use of better development processes, including the use of ..."
          ]
        },
        {
          "title": "ISO 26262-8:2011(en), Road vehicles — Functional safety",
          "url": "https://www.iso.org/obp/ui/#iso:std:iso:26262:-8:ed-1:en",
          "excerpts": [
            "ISO 26262 includes guidance to avoid these risks by providing appropriate requirements and processes. System safety is achieved through a number of safety ..."
          ]
        },
        {
          "title": "DO-330 Introduction – Tool Qualification",
          "url": "https://afuzion.com/do-330-introduction-tool-qualification/",
          "excerpts": [
            "This DO-330 whitepaper describes the five tool categories versus criticality levels (DALs) and how to truly qualify avionics software tools."
          ]
        },
        {
          "title": "r/rust - Ferrous Systems Donates Ferrocene Language ...",
          "url": "https://www.reddit.com/r/rust/comments/1jkfovo/ferrous_systems_donates_ferrocene_language/",
          "excerpts": [
            "... DO-178C is, in my understanding, the big requirement here. ... Now that we are here: what's the progress on DO-178 (DO-330) certification?"
          ]
        },
        {
          "title": "Ferrous Systems First to Run Rust on Cortex-R52 Under ...",
          "url": "https://www.businesswire.com/news/home/20250311274388/en/Ferrous-Systems-First-to-Run-Rust-on-Cortex-R52-Under-Open-Source-License",
          "excerpts": [
            "Ferrocene is the first open-source ... certified versions of libcore and guidance on instruction tracing for software certification."
          ]
        },
        {
          "title": "Ferrocene 25.05.0 now available! - Ferrous Systems",
          "url": "https://ferrous-systems.com/blog/ferrocene-25-05-0/",
          "excerpts": [
            "ferrocene.dev) is the first Rust compiler toolchain qualified for safety- and mission-critical systems. It is qualified to ISO 26262 (TCL 3/ASIL D), IEC 61508 (T3/SIL 4) and IEC 62304 (Class C) with TÜV SÜD.",
            "In addition, we have elevated two of our experimental targets to qualified status:\n\n* Armv7E-M bare-metal (soft-float) (`thumbv7em-none-eabi`)\n* Armv7E-M bare-metal (hard-float) (`thumbv7em-none-eabi"
          ]
        },
        {
          "title": "DO-330 Software tool qualification considerations",
          "url": "https://ldra.com/do-330/",
          "excerpts": [
            "DO-330 “Software Tool Qualification Considerations” states that “Software tools are widely used in multiple domains, to assist in developing, verifying, and ..."
          ]
        },
        {
          "title": "Leveraging ISO 26262 tool certification in IEC 61508",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2020/12/17/leveraging-iso-26262-tool-certification-in-iec-61508/",
          "excerpts": [
            "Dec 17, 2020 — Tools are assessed as T1, T2 or T3. T1 tools are tools which have no impact on safety or where there is a high degree of confidence that tool ..."
          ]
        },
        {
          "title": "Industry Standards | MOSA DO-178C FAA FACE EASA ...",
          "url": "https://www.ddci.com/resources/industry-standards/",
          "excerpts": [
            "Nov 15, 2024 — ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning ... DO-178C DAL A for this ...",
            "ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning in safety-critical avionics that ..."
          ]
        },
        {
          "title": "Shenango: achieving high CPU efficiency for latency-sensitive ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323265",
          "excerpts": [
            "Shenango achieves comparable latencies but at far greater CPU efficiency. It reallocates cores across applications at very fine granularity--every 5 μs."
          ]
        },
        {
          "title": "Clearing the Fog of ISO 26262 Tool Qualification",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2022/04/13/clearing-the-fog-of-iso-26262-tool-qualification/",
          "excerpts": [
            "The setting of TI and TD ultimately determines the TCL for the tool based on the table below, found in ISO 26262-8:2018 Clause 11.4.5.",
            "ISO 26262 dictates that tools used in the development of safety-critical electronics be assessed, and it guides this analysis by defining three terms:",
            "Tool Impact (TI): | This is an evaluation of the potential of a tool to introduce or fail to detect error",
            " Tool Detection (TD) | This is an evaluation of the confidence that the tool will prevent the malfunctioning of a software tool, and the standard defines:  **TD1**:  High confidence that a malfunction will be prevented or detected. **TD2**: Medium confidence that a malfunction will be prevented or detected. **TD3**:",
            "Tool Confidence Level (TCL) | An establishment of tool confidence based on TI and TD and the standard defines:  **TCL1**:  High level of confidence. No further qualification methods are required. **TCL2**:  Medium level of confidence. Further qualification methods are required. **TCL3**: Low level of confidence. Further qualification metho",
            " provides four methods for performing tool qualification (ISO 26262-8:2018 Clause 11.4.6)."
          ]
        },
        {
          "title": "MathWorks/Avionics Certification – A complete guide to DO-178 (tool qualification overview for ISO 26262, IEC 61508, and DO-178C)",
          "url": "https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/m/61793_CMR10-16.pdf",
          "excerpts": [
            " \nSoftware Tool Documentation",
            " \nSoftware Tool Classification Analysis",
            " \nSoftware Tool Qualification Report",
            " Tool qualification can be carried out for individual tools as well as for \ntool chains or sets of tools.",
            "The ISO/DIS 26262 tool qualification process requires the creation of the following tool \nqualification work products (ISO/DIS 26262-8, 11.5; see the appendix for a summary):",
            " \nSoftware Tool Qualification Plan",
            " \nSoftware Tool Qualification Plan",
            "• Software Tool Documentation",
            "• Software Tool Classification Analysis",
            "\n• Software Tool Qualification Report",
            ". 2.4 Software Tool Documentation (STD)",
            ". 2.6 Software Tool Qualification Report (STQR)"
          ]
        },
        {
          "title": "seL4 Proofs & Certification",
          "url": "https://sel4.systems/Verification/certification.html",
          "excerpts": [
            "seL4 proofs provide strong assurance that seL4 operates correctly and enforces critical security properties.",
            "In ISO26262, formal verification is recommended for ASIL-C and ASIL-D risk classes.",
            "DO-330 Tool Qualification Level (TQL) per DO-178C Software Level"
          ]
        },
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage.",
            "Proofs and Certification\n\nThe traditional way to achieve high levels of assurance are schemes\nsuch as Common Criteria, ISO-26262, and DO-178C. The seL4 proofs go\nbeyond what these certification schemes require for software\ndevelopment at their most stringent levels.",
            "The traditional way to achieve high levels of assurance are schemes such as Common Criteria, ISO-26262, and DO-178C."
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Remote attestation Implementation - BlindAI - Mithril Security",
          "url": "https://blindai.mithrilsecurity.io/en/latest/docs/security/remote_attestation/",
          "excerpts": [
            "The first one, is EPID attestation which relies on using Intel services to attest that an enclave on specific platforms is verified. The second one is DCAP ( ..."
          ]
        },
        {
          "title": "GlobalPlatform Entity Attestation Protocol Specification",
          "url": "https://globalplatform.org/wp-content/uploads/2024/07/GPP_EntityAttestationProtocolSpec_v0.0.0.26_PublicRvw2.pdf",
          "excerpts": [
            "Remote Attestation \nThe process by which attestation information is assembled by an Entity \nAttestation Service, transferred to a Relying Party, and processe",
            "The IETF NNNN specification ([draft-ietf-rats-eat]) introduces the concept of Attestation, which is a mechanism \n45 \nby which an Entity can provide information about itself with some level of assurance to a Relying Par",
            "During Attestation, an Entity \n47 \nAttestation Service builds a set of Claims, each of which consists of a piece of evidence provided by a Clai"
          ]
        },
        {
          "title": "seL4: formal verification of an OS kernel",
          "url": "https://cseweb.ucsd.edu/~dstefan/cse227-spring20/papers/sel4.pdf",
          "excerpts": [
            "by G Klein · 2009 · Cited by 3032 — ABSTRACT. Complete formal verification is the only known way to guar- antee that a system is free of programming errors."
          ]
        },
        {
          "title": "The seL4 Microkernel An Introduction",
          "url": "https://cdn.hackaday.io/files/1713937332878112/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 1 — This white paper gives an overview of seL4. ... In a capability-based system, such as seL4, invoking a capability is the one and only way."
          ]
        },
        {
          "title": "Introduction to SGX - Gramine documentation - Read the Docs",
          "url": "https://gramine.readthedocs.io/en/stable/sgx-intro.html",
          "excerpts": [
            "The Provisioning Certification Enclave is used in DCAP based remote attestation. This enclave communicates with the Intel Provisioning Certification Service ( ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.11/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM ... Refresh expired {TCB info, PCK CRLs, QE Identity, QvE Identity,. Root CA CRL} ..."
          ]
        },
        {
          "title": "[PDF] Intel® Software Guard Extensions (Intel® SGX) Data Center ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.7/linux/docs/Intel_SGX_ECDSA_QuoteLibReference_DCAP_API.pdf",
          "excerpts": [
            "Deployment Tool for PCK Certificate Chain Retrieval for Intel® SGX DCAP ... the PCK Certificate that the quote verifier uses to certify the attestation key."
          ]
        },
        {
          "title": "in-toto and SLSA",
          "url": "https://slsa.dev/blog/2023/05/in-toto-and-slsa",
          "excerpts": [
            "May 2, 2023 — It defines the Provenance predicate to record the build characteristics of the produced artifacts. The specification describes how to verify ..."
          ]
        },
        {
          "title": "Overview",
          "url": "https://docs.sigstore.dev/cosign/signing/overview/",
          "excerpts": [
            "This document explains how identity-based, or “keyless” signing works in Sigstore. To learn more about OIDC, please review OIDC Usage in Fulcio."
          ]
        },
        {
          "title": "Provenance",
          "url": "https://slsa.dev/spec/v0.1/provenance",
          "excerpts": [
            "Description of SLSA provenance specification for verifying where, when, and how something was produced."
          ]
        },
        {
          "title": "Secure Software Updates via TUF — Part 2",
          "url": "https://medium.com/@mulgundmath/secure-software-updates-via-tuf-part-2-412c6a2b10ab",
          "excerpts": [
            "Next in the file is the assignment of keys to roles such as root, targets, snapshot, and timestamp; all four need to be mandatorily listed ( ..."
          ]
        },
        {
          "title": "Use Sigstore for keyless signing and verification",
          "url": "https://docs.gitlab.com/ci/yaml/signing_examples/",
          "excerpts": [
            "The Sigstore project provides a CLI called Cosign which can be used for keyless signing of container images built with GitLab CI/CD."
          ]
        },
        {
          "title": "Securing the Software Supply Chain: How in-toto and TUF ...",
          "url": "https://www.infoq.com/presentations/software-supply-chain-security/",
          "excerpts": [
            "Nov 28, 2023 — Marina Moore covers the fundamentals of both in-toto and TUF, and discusses how to combine them with a real world case study where Datadog has been using two ..."
          ]
        },
        {
          "title": "Securing the Software Supply Chain: How in-toto and TUF ...",
          "url": "https://qconnewyork.com/presentation/jun2023/securing-software-supply-chain-how-toto-and-tuf-work-together-combat-supply",
          "excerpts": [
            "Jun 13, 2023 — The framework connects security efforts such as SLSA, Sigstore, and SBOMs, where signed and verifiable in-toto attestations are used to express ..."
          ]
        },
        {
          "title": "Signing Containers",
          "url": "https://docs.sigstore.dev/cosign/signing/signing_with_containers/",
          "excerpts": [
            "You can use Cosign to sign containers with ephemeral keys by authenticating with an OIDC (OpenID Connect) protocol supported by Sigstore."
          ]
        },
        {
          "title": "SigstoreCon 2024: Advancing Software Supply Chain ...",
          "url": "https://openssf.org/blog/2024/12/16/sigstorecon-2024-advancing-software-supply-chain-security/",
          "excerpts": [
            "Dec 16, 2024 — The one-day conference brought together developers, maintainers, and security experts to explore how Sigstore is transforming software supply chain security."
          ]
        },
        {
          "title": "Intel SGX DCAP Orientation Guide",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.9/linux/docs/Intel_SGX_DCAP_ECDSA_Orientation.pdf",
          "excerpts": [
            "Attestation is the process of demonstrating that a software executable is properly instantiated on a platform.",
            "The Intel® SGX Provisioning Certification \nService offers APIs for retrieving \nprovisioning certification key (PCK) \ncertificates, certificate revocation lists, \nTrusted Computing Base \n(TCB) information, the Intel quoting enclave (QE) \nidentity, and the Intel quote verification enclave \n(QVE) id",
            "The caching service for the Intel® SGX provisioning certification \nservice allows a CSP or a datacenter to cache PCK certificates, \nPCK certificate revocation lists (CRL), TCB Information, QE \nidentity and QVE Identity structures for all platforms in its data \ncen",
            "The current release of the reference can be \nconfigured to fill its cache in a few ways. i. Fill the cache using a push mechanism. The caching service will queue the PCK Certificate IDs \nuploaded by the PCK Certificate ID Retrieval Too",
            "The platform quote provider library provides a set of APIs \nthat abstract platform implementation specific functions",
            "e platform quote provider library \nthat works in conjunction with the reference caching \nservice (see ‘Caching Service for the Intel® SGX \nprovisioning certification service’ below) to provide this \ninformation to the quote lib",
            "The quote verification library can run on both platforms \nwith SGX and without SGX. When the platform supports \nSGX, the library can return an SGX REPORT authenticating \nthe verification result was produced by the Intel® SGX \nQuote Verification Enclave (Q"
          ]
        },
        {
          "title": "Remote Attestation on Arm TrustZone OP-TEE with ...",
          "url": "https://fosdem.org/2025/schedule/event/fosdem-2025-4952-remote-attestation-on-arm-trustzone-op-tee-with-veraison-verifier-current-status-and-future-plan-/",
          "excerpts": [
            "We report on the attestation mechanism implemented in OP-TEE, a trusted OS running on the Arm Cortex-A TrustZone. This mechanism generates attestation evidence ..."
          ]
        },
        {
          "title": "OP-TEE Remote Attestation with VERAISON Verification",
          "url": "https://github.com/OP-TEE/optee_os/issues/6921",
          "excerpts": [
            "Jun 27, 2024 — The PTA provides a general mechanism to make a RA evidence. It measures the hash of the TA and signs the hash. The RA evidence is verified by Veraison verifier.",
            "Jun 27, 2024 — We have customized OP-TEE (a Secure OS for Arm Cortex-A TrustZone) to enable Remote Attestation with VERAISON Verification."
          ]
        },
        {
          "title": "RFC 9783 - Arm's Platform Security Architecture (PSA) Attestation ...",
          "url": "https://datatracker.ietf.org/doc/rfc9783/",
          "excerpts": [
            "This document specifies the structure and semantics of the PSA attestation token. The PSA attestation token is a profile of the Entity Attestation Token (EAT)."
          ]
        },
        {
          "title": "RFC 9711 - The Entity Attestation Token (EAT) - IETF Datatracker",
          "url": "https://datatracker.ietf.org/doc/rfc9711/",
          "excerpts": [
            "An Entity Attestation Token (EAT) is a message made up of claims about an entity. An entity may be a device, some hardware, or some software."
          ]
        },
        {
          "title": "Attestation & Entity Attestation Tokens Explained - PSA Certified",
          "url": "https://www.psacertified.org/blog/what-is-an-entity-attestation-token/",
          "excerpts": [
            "An EAT token is encoded in either one of two standardized data formats: a compact binary format (CBOR) or in the text-based format JSON. A ..."
          ]
        },
        {
          "title": "draft-ietf-rats-eat-21 - The Entity Attestation Token (EAT)",
          "url": "https://datatracker.ietf.org/doc/draft-ietf-rats-eat/21/",
          "excerpts": [
            "The Entity Attestation Token (EAT) draft-ietf-rats-eat-21 · Authors, Laurence Lundblade , Giridhar Mandyam , Jeremy O'Donoghue , Carl Wallace · Last updated ..."
          ]
        },
        {
          "title": "Threat modeling for drivers (Windows hardware drivers threat model)",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/driversecurity/threat-modeling-for-drivers",
          "excerpts": [
            "Aug 31, 2023 — This section applies the principles of threat modeling to driver design and provides examples of threats to which a driver might be susceptible. ](images/sampledataflowdiagramkernelmodedriver.gif)\n\n",
            "Kernel-mode drivers must validate data that originates in user mode.",
            "The driver in the figure receives data from a user process in the following types of requests:\n\n* Create, read, and write requests (IRP\\_MJ\\_CREATE, IRP\\_MJ\\_READ, or IRP\\_MJ\\_WRITE)\n* Public device I/O control requests (IRP\\_MJ\\_DEVICE\\_ CON",
            "In response to these requests, output data and status information flow from the driver back to the user process.",
            "ess. Finally, the driver receives data from the device because of device I/O operations or user actions (such as opening the tray on a CD drive) that change device status.",
            "The previous figure shows driver data flow at a broad conceptual level. Each circle represents a relatively large task and lacks detail.",
            "Information enters the driver because of requests from the operating system, requests from a user process, or requests (typically interrupts) from the device.",
            "Information enters the driver because of requests from the operating system, requests from a user process, or requests (typically interrupts) from the device. The driver in the previous figure receives data from the operating system in several types of req",
            "the circle labeled “Handle I/O Requests” might be expanded into a separate diagram, similar to the following figure. ! [Expanded data flow diagram for I/O requests, showing separate tasks for each type of I/O request. ](images/expandeddataflowdiagramiorequests.gif)",
            "The second diagram shows separate tasks for each type of I/O request in the first diagram. (For simplicity, data paths to the device have been omitted.)",
            "...",
            "The resulting images could be corrupted, but system administrators would have no way to determine which user caused the problem.",
            "Information disclosure** threats are exactly as the name implies: the disclosure of information to a user who does not have permission to see it. Any driver that passes information to or from a user buffer is susceptible to information disclosure threat",
            "Denial-of-service** attacks threaten the ability of valid users to access resource"
          ]
        },
        {
          "title": "The CHERI capability model: Revisiting RISC in an age of ...",
          "url": "https://ieeexplore.ieee.org/document/6853201",
          "excerpts": [
            "by J Woodruff · 2014 · Cited by 475 — We present CHERI, a hybrid capability model that extends the 64-bit MIPS ISA with byte-granularity memory protection."
          ]
        },
        {
          "title": "CHERI OS-feature matrix",
          "url": "https://www.morello-project.org/cheri-feature-matrix/",
          "excerpts": [
            "Operating systems can implement CHERI software features along several axes. This table captures key axes, and describes the maturity of those features for ..."
          ]
        },
        {
          "title": "Arm Morello Program",
          "url": "https://www.arm.com/architecture/cpu/morello",
          "excerpts": [
            "Morello is a research program with the potential to radically change the way we design and program processors in the future to improve built-in security."
          ]
        },
        {
          "title": "Morello Prototype Architecture - Arm Developer",
          "url": "https://developer.arm.com/Architectures/Morello",
          "excerpts": [
            "The Morello architecture is a prototype CPU architecture that introduces a new approach to security and is part of the wider Morello program."
          ]
        },
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        },
        {
          "title": "Review the TPM measured boot log",
          "url": "https://developer.arm.com/documentation/107981/latest/SystemReady-compliance-testing---BBSR-and-Security-Interface-Testing-FAQ/How-do-I-test-for-Base-Boot-Security-Requirements--BBSR--compliance-/Review-the-ACS-test-result-logs/Review-the-TPM-measured-boot-log",
          "excerpts": [
            "Verify that the cumulative SHA256 measurements from the event log match the TPM PCRs 0-7. The events logged in the TPM event log must match the actual ..."
          ]
        },
        {
          "title": "IMA and EVM Concepts — IMA 1.0 documentation",
          "url": "https://ima-doc.readthedocs.io/en/latest/ima-concepts.html",
          "excerpts": [
            "The IMA-Appraisal feature is local, and requires neither a TPM nor a separate verifier. IMA-Audit augments the system's audit log with the file hash. This can ..."
          ]
        },
        {
          "title": "Forward Secure Sealing (FSS) in Systemd-Journal - Learn Netdata",
          "url": "https://learn.netdata.cloud/docs/logs/systemd-journal-logs/forward-secure-sealing-fss-in-systemd-journal",
          "excerpts": [
            "Forward Secure Sealing (FSS) is a feature in the systemd journal designed to detect log file tampering . Given that attackers often try to hide their actions by modifying or deleting log file entries, FSS provides administrators with a mechanism to identify any such unauthorized alterations."
          ]
        },
        {
          "title": "[PDF] Security Threats and Opportunities in One-Sided Network ...",
          "url": "https://cseweb.ucsd.edu/~yiying/one-sided-security.pdf",
          "excerpts": [
            "One-sided network communication technologies such as. RDMA and NVMe-over-Fabrics are quickly gaining adoption in production software and in datacenters."
          ]
        },
        {
          "title": "[PDF] Changes in NVM Express® Specifications",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM-Express-Revision-Changes-2025.08.01.pdf",
          "excerpts": [
            "This technical proposal enables sanitize operations to be performed on individual namespaces, as opposed to the entire. NVM subsystem. 2.1.1.1."
          ]
        },
        {
          "title": "A journey to optimize GDRDMA in cloud scenario",
          "url": "https://lpc.events/event/18/contributions/1685/attachments/1424/3047/ATS%20vs%20IOMMU-lyan.pdf",
          "excerpts": [
            "The journey involves optimizing GDRDMA in cloud, using GPU Direct RDMA, ACS/ATS, IOMMU, and enabling ATS from both RC and EP."
          ]
        },
        {
          "title": "[PDF] Securing RDMA for High-Performance Datacenter Storage Systems",
          "url": "https://www.usenix.org/system/files/hotcloud20_paper_simpson.pdf",
          "excerpts": [
            "In general, systems leverage one-sided RDMA operations when possible, as these operations are faster and reduce remote. CPU usage. This section analyzes the ..."
          ]
        },
        {
          "title": "7 Incident Response Metrics and How to Use Them",
          "url": "https://securityscorecard.com/blog/how-to-use-incident-response-metrics/",
          "excerpts": [
            "These seven incident response metrics and how to use them can provide you with a way to reduce risk and respond to incidents more efficiently."
          ]
        },
        {
          "title": "Security Analysis of Forward Secure Log Sealing in Journald",
          "url": "https://eprint.iacr.org/2023/867",
          "excerpts": [
            "Forward-secure log sealing is a cryptographic technique used to ensure the integrity of past log entries even in the event of a full system ..."
          ]
        },
        {
          "title": "Trusted Platform Module (TPM) event logs",
          "url": "https://docs.trustauthority.intel.com/main/articles/articles/ita/tpm-log.html",
          "excerpts": [
            "Oct 25, 2024 — By replaying the event log and comparing the result with the PCR value, you can verify the integrity of the log itself. Once the log integrity ..."
          ]
        },
        {
          "title": "Integrity Measurement Architecture (IMA) / Wiki / Home",
          "url": "https://sourceforge.net/p/linux-ima/wiki/Home/",
          "excerpts": [
            "Before EVM is activated, any requested integrity appraisals are unknown, so the EVM startup should be done early in the boot process, preferably entirely within ..."
          ]
        },
        {
          "title": "What is Security Logging and Monitoring?",
          "url": "https://www.bitlyft.com/resources/what-is-security-logging-and-monitoring",
          "excerpts": [
            "System logs are designed to provide relevant information that allows you to understand and identify issues that become threats to your network."
          ]
        },
        {
          "title": "An Introduction to CHERI",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/",
          "excerpts": [
            "CHERI is a\nhybrid capability architecture in that it is able to blend\narchitectural capabilities with conventional MMU-based\narchitectures and microarchitectures,\nand with conventional software stacks based on virtual memory and C/C++. This approach allows incremental deployment within existing software\necosystems, which we have demonstrated through extensive hardware and software\nprototyping.",
            "We formalise key intended security properties of the ISA specifications, and establish that these hold with mechanised proof."
          ]
        },
        {
          "title": "CHERI/Morello Security and End-to-End Model",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-morello.html",
          "excerpts": [
            "Morello is an industrial demonstrator of a capability architecture: a prototype System-on-Chip (SoC) and development board, developed by Arm."
          ]
        },
        {
          "title": "CHERIoT: a study in CHERI (RISCV.org blog)",
          "url": "https://riscv.org/blog/2024/08/cheriot-a-study-in-cheri/",
          "excerpts": [
            "CHERIoT provides a layered security model. At the core, CHERIoT provides object-granularity (spatial and temporal) memory safety.",
            "The hardware provides low-level guarantees, such as unforgeable pointers, the ability to ensure that pointers to marked memory regions cannot be used, and a lightweight way of making pointers into opaque tamper-proof tokens.",
            "Sealing a CHERI capability turns it into an opaque token. You can pass it around as you would any other pointer, but you cannot dereference or modify it.",
            "The seal operation takes another capability with a permit-seal permission and embeds the value of that capability in the *object type* of the sealed capabilit",
            "A CHERI capability can be stored in memory or in registers and is protected by *guarded manipulation*: Operations may reduce the rights that a capability conveys, but not increase the",
            "The tag bit is a simple attestation from the hardware that says that this capability was created by following these rules, starting with one of the all-powerful capabilities provided at boot and then constrained by layers of software in the system.",
            "CHERI capability, that can be used to represent pointers. These carry bounds and permissions, in addition to an address. A CHERI capability ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 9.0.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-9.0.1.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree ... By calling seL4 CNode Revoke() on the original capability to an ...",
            "The tree structure so generated is termed the capability derivation tree (CDT). ... The seL4 CNode Revoke() method will seL4 CNode Delete ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/latest/dcap-latest/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "TCB Info,. QE Identity. QVE Identity. PCK Certificate. IDs. +. Cached PCK, CRLs ... DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM. DCAP ..."
          ]
        },
        {
          "title": "[PDF] PSA Certified Attestation API 1.0 - GitHub Pages",
          "url": "https://arm-software.github.io/psa-api/attestation/1.0/IHI0085-PSA_Certified_Attestation_API-1.0.3.pdf",
          "excerpts": [
            "IETF Entity Attestation Token (EAT), Draft. ... defined in Arm's Platform Security Architecture (PSA) Attestation Token [PSATOKEN]."
          ]
        },
        {
          "title": "ietf-rats-wg/eat: Entity Attestation Token IETF Draft Standard - GitHub",
          "url": "https://github.com/ietf-rats-wg/eat",
          "excerpts": [
            "This is the working area for the IETF RATS Working Group Internet-Draft, \"The Entity Attestation Token (EAT)\". Editor's Copy · Working Group Draft ..."
          ]
        },
        {
          "title": "Sealing and unsealing data in TPM",
          "url": "https://community.infineon.com/t5/Blogs/Sealing-and-unsealing-data-in-TPM/ba-p/465547",
          "excerpts": [
            "Aug 9, 2023 — Sealing is essentially encrypting data based on certain conditions. TPM allows decryption only if the conditions defined during encryption are satisfied."
          ]
        },
        {
          "title": "Part 4: Under the Hood — DMA, IOMMU, BARs, and VFIO | ...",
          "url": "https://medium.com/gpu-kernel-hacking-for-engineers/part-4-under-the-hood-dma-iommu-bars-and-vfio-45b4f13e545c",
          "excerpts": [
            "VFIO (Virtual Function I/O) allows safe, isolated access to PCI devices from user space, making it critical for: Containerized GPU apps ..."
          ]
        },
        {
          "title": "Understand PCR banks on TPM 2.0 devices",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/tpm/switch-pcr-banks-on-tpm-2-0-devices",
          "excerpts": [
            "To bind the use of a TPM based key to a certain state of the device, the key can be sealed to an expected set of PCR values. For instance, PCRs 0 through 7 ..."
          ]
        },
        {
          "title": "[PDF] Trusted Platform Module 2.0 Library Part 1: Architecture",
          "url": "https://trustedcomputinggroup.org/wp-content/uploads/Trusted-Platform-Module-2.0-Library-Part-1-Architecture-Version-184-rc2_20Dec24.pdf",
          "excerpts": [
            "An NV Index is space that is defined by a user of the TPM. The ... For a Counter NV Index with the TPMA_NV_ORDERLY attribute, Index ..."
          ]
        },
        {
          "title": "[PDF] TPM 2.0 Part 1 - Architecture - Trusted Computing Group",
          "url": "https://trustedcomputinggroup.org/wp-content/uploads/TPM-Rev-2.0-Part-1-Architecture-01.07-2014-03-13.pdf",
          "excerpts": [
            "15.3 NV Index Handles (MSO=0116). An NV Index is associated with a persistent TPM resource created by TPM2_NV_DefineSpace(). 15.4 Session ..."
          ]
        },
        {
          "title": "10. Security Support - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides/howto/security.html",
          "excerpts": [
            "This document describes the security features of interest for DPDK. This guide will provides information on each protocol, including supported algorithms."
          ]
        },
        {
          "title": "Unlocking Secure High-Performance Networking with ...",
          "url": "https://www.dpdk.org/high-performance-networking-with-dpdk-security-framework/",
          "excerpts": [
            "This document outlines the security protocols and implementations supported within DPDK, serving as a guide for both users and contributors."
          ]
        },
        {
          "title": "wolfTPM support for sealing/unsealing based on externally ...",
          "url": "https://www.wolfssl.com/wolftpm-support-for-sealing-unsealing-based-on-externally-signed-pcr/",
          "excerpts": [
            "Dec 14, 2023 — With the TPM 2.0 specification, it's possible to seal/unseal secrets via cryptographic signatures of the PCR's, removing the requirement to ..."
          ]
        },
        {
          "title": "Leveraging Trusted Platform Modules (TPM) for Cryptographic ...",
          "url": "https://www.researchgate.net/publication/392693928_Leveraging_Trusted_Platform_Modules_TPM_for_Cryptographic_Anchoring_and_Remote_Attestation_of_UEFI_Capsule_Updates_in_Secure_Boot_Environments",
          "excerpts": [
            "A TPM monotonic counter is a non-volatile register that ... ○ PCR extension and monotonic counter simulation to verify rollback protection."
          ]
        },
        {
          "title": "Verify Boot | Android Open Source Project",
          "url": "https://source.android.com/docs/security/features/verifiedboot/verified-boot",
          "excerpts": [
            "Rollback protection is typically implemented by using tamper-evident storage to record the most recent version of the Android and refusing to ..."
          ]
        },
        {
          "title": "2. Features Overview - Documentation - DPDK",
          "url": "https://doc.dpdk.org/guides-18.05/nics/features.html",
          "excerpts": [
            "Supports starting/stopping a specific Rx/Tx queue of a port. [implements] eth_dev_ops: rx_queue_start , rx_queue_stop , tx_queue_start , tx_queue_stop ..."
          ]
        },
        {
          "title": "[PATCH v3 24/25] net/spnic: support Tx/Rx queue start/stop ...",
          "url": "http://inbox.dpdk.org/dev/1bc4636e940682b02279711ae1714b22c958086a.1640332922.git.songyl@ramaxel.com/",
          "excerpts": [
            "... packets can be received to host. when stopping rx queue, the PMD driver will poll the rx queue until it is empty and release the mbuf, then the PMD driver ..."
          ]
        },
        {
          "title": "lib/librte_ether/rte_ethdev.h File Reference - DPDK",
          "url": "https://doc.dpdk.org/api-1.6/rte__ethdev_8h.html",
          "excerpts": [
            "Check if the DD bit of the specific RX descriptor in the queue has been set. Parameters. port_id, The port identifier of the Ethernet device. queue_id, The ..."
          ]
        },
        {
          "title": "rte_eth_dev_owner_delete(3) — dpdk-doc — Debian testing",
          "url": "https://manpages.debian.org/testing/dpdk-doc/rte_eth_dev_owner_delete.3",
          "excerpts": [
            "Check the status of a Rx descriptor in the queue. It should be called in a similar context than the Rx function: on a dataplane core; not ..."
          ]
        },
        {
          "title": "[RFE] Quiesce filesystem during VM snapshots · Issue #1795 - GitHub",
          "url": "https://github.com/flatcar/Flatcar/issues/1795",
          "excerpts": [
            "Missing: DMA NIC NVMe GPU rings checkpoint"
          ]
        },
        {
          "title": "Best practice for Snapshots? : r/vmware - Reddit",
          "url": "https://www.reddit.com/r/vmware/comments/bh80jx/best_practice_for_snapshots/",
          "excerpts": [
            "Missing: DMA NVMe GPU rings checkpoint"
          ]
        },
        {
          "title": "ccNVMe: Crash-Consistent NVMe over PCIe (RDMA and PCIe integration) – ACM/DL basis",
          "url": "https://dl.acm.org/doi/full/10.1145/3568428",
          "excerpts": [
            "The key idea of ccNVMe is to couple the crash consistency to the data dissemination; a transaction (a set of requests that must be executed atomically) is guaranteed to be crash consistent when it is about to be dispatched over PCIe.",
            "ccNVMe makes the submission queues durable in case of a sudden crash, and rings the doorbells in the unit of a transaction rather than a request, to let the requests of a transaction reach the same state (e.g., all or nothing), thereby achieving atomicity.",
            "ccNVMe rings the doorbell when all requests within a transaction arrive or when the number of work requests exceeds a pre-defined threshold (half of the queue depth by default), whichever happens earlier; this reduces the number of CPU-initiated doorbells and resolves issue 1 from Section 3.2 .",
            "The transaction-aware doorbell can also improve the performance of NIC-initiated DMAs.",
            "During crash recovery, ccNVMe finds the unfinished transactions and leaves the specific recovery algorithms (e.g., rollback) to upper layer systems.",
            "The data dissemination mechanism of the original NVMe already tracks the lifecycle (e.g., submitted or completed) of each request in the hardware queues and doorbells.",
            "ccNVMe leverages this feature to submit and complete the transaction in an ordered and atomic fashion, and makes the tracked lifecycles persistent for recovery, thereby letting the software ensure crash consistency by taking the free rides of the data dissemination MMIOs."
          ]
        },
        {
          "title": "XRSTOR — Restore Processor Extended States",
          "url": "https://www.felixcloutier.com/x86/xrstor",
          "excerpts": [
            "Performs a full or partial restore of processor state components from the XSAVE area located at the memory address specified by the source operand."
          ]
        },
        {
          "title": "How Debuggers Work: Getting and Setting x86 Registers, Part 2",
          "url": "https://www.moritz.systems/blog/how-debuggers-work-getting-and-setting-x86-registers-part-2/",
          "excerpts": [
            "The XSAVE and XRSTOR family of instructions can be used to save and restore the registers introduced by newer instruction sets, eg the YMM registers introduced ..."
          ]
        },
        {
          "title": "Intel x86-64 XSAVE/XRSTOR",
          "url": "https://stackoverflow.com/questions/22105247/intel-x86-64-xsave-xrstor",
          "excerpts": [
            "I'm a CS student writing in Intel x86-64 assembly, compiling with nasm , and running on an Core i7 processor with Ubuntu 12.04 as the guest OS."
          ]
        },
        {
          "title": "managing state using the xsave feature set",
          "url": "https://xem.github.io/minix86/manual/intel-x86-and-64-manual-vol1/o_7281d5ea06a5b67a-307.html",
          "excerpts": [
            "CHAPTER 13. MANAGING STATE USING THE XSAVE FEATURE SET. The XSAVE feature set extends the functionality of the FXSAVE and FXRSTOR instructions (see Section ..."
          ]
        },
        {
          "title": "setcontext - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Setcontext",
          "excerpts": [
            "setcontext is one of a family of C library functions (the others being getcontext, makecontext and swapcontext) used for context control."
          ]
        },
        {
          "title": "getcontext or setcontext Subroutine - IBM",
          "url": "https://www.ibm.com/docs/en/aix/7.3.0?topic=g-getcontext-setcontext-subroutine",
          "excerpts": [
            "The getcontext subroutine initalizes the structure pointed to by ucp to the current user context of the calling process."
          ]
        },
        {
          "title": "Can you explain the concept of CUDA context switching and its ...",
          "url": "https://massedcompute.com/faq-answers/?question=Can%20you%20explain%20the%20concept%20of%20CUDA%20context%20switching%20and%20its%20impact%20on%20application%20performance?",
          "excerpts": [
            "Latency Overhead: Each context switch requires time to save and restore GPU states, leading to delays in execution. Reduced GPU Utilization: Frequent ..."
          ]
        },
        {
          "title": "What is the context switching mechanism in GPU? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/6605581/what-is-the-context-switching-mechanism-in-gpu",
          "excerpts": [
            "As I know, GPUs switch between warps to hide the memory latency. ... context switch requires saving registers to memory and restoring them."
          ]
        },
        {
          "title": "CRIUgpu: Transparent Checkpointing of GPU-Accelerated Workloads",
          "url": "https://arxiv.org/html/2502.16631v1",
          "excerpts": [
            "Feb 23, 2025 — The AMD GPU plugin enables transparent checkpoint/restore using input/output control (ioctl) operations with the Kernel Fusion Driver (KFD)."
          ]
        },
        {
          "title": "NVIDIA GPUDirect Storage: 4 Key Features, Ecosystem & ...",
          "url": "https://cloudian.com/guides/data-security/nvidia-gpudirect-storage-4-key-features-ecosystem-use-cases/",
          "excerpts": [
            "By ensuring data coherence, GPUDirect Storage minimizes synchronization issues and supports real-time processing requirements. This feature is crucial for ..."
          ]
        },
        {
          "title": "Jetson tk1 took long latency for image transfer to device through ...",
          "url": "https://forums.developer.nvidia.com/t/jetson-tk1-took-long-latency-for-image-transfer-to-device-through-opencv-gpu/43229",
          "excerpts": [
            "The overall process takes long latency ( gpuImage.upload → debayer → gpuImage.download ) It's about 1.8ms for average, and sometimes it swift to 10ms!"
          ]
        },
        {
          "title": "ASRock hidden Memory Context Restore overrides AMD's option ...",
          "url": "https://www.reddit.com/r/overclocking/comments/18avhx1/psa_asrock_hidden_memory_context_restore/",
          "excerpts": [
            "The Asrock memory context restore option only appears when you set the memory clock to something other than \"Auto.\" And apparently, this option overrides AMD's ..."
          ]
        },
        {
          "title": "How to re-init the context after cudaResetDevice, now ERROR",
          "url": "https://forums.developer.nvidia.com/t/how-to-re-init-the-context-after-cudaresetdevice-now-error-cudaerrorcontextisdestroyed/263505",
          "excerpts": [
            "There is no cudaResetDevice, but there is a cudaDeviceReset(). The only recovery method when using the runtime API is to terminate the owning host process."
          ]
        },
        {
          "title": "SPDK NVMe Driver I/O Path - My Blog",
          "url": "https://jingliu.me/posts/2021-01-20-spdkio.html",
          "excerpts": [
            "Jan 20, 2021 — The NVMe completion queue is an array of completion queue entries. Inside those entries is a CID value that SPDK provided on command submission."
          ]
        },
        {
          "title": "PyNVMe3 Script Development Guide",
          "url": "https://pynv.me/ssd/dev-guide/",
          "excerpts": [
            "Feb 19, 2025 — PyNVMe3 supports different policies for updating admin SQ Doorbell when initializing the Admin queue. By default, PyNVMe3's NVMe driver updates ..."
          ]
        },
        {
          "title": "Dataflow function offload to reconfigurable processors",
          "url": "https://patents.google.com/patent/US11392740B2/en",
          "excerpts": [
            "... RDMA, VXLAN overlays and NVMe-oF functionality. A SmartNIC may include host kernel-bypass logic for sending and receiving packets to/from nodes and ..."
          ]
        },
        {
          "title": "IBM z17 (9175) Technical Guide",
          "url": "https://www.redbooks.ibm.com/redbooks/pdfs/sg248579.pdf",
          "excerpts": [
            "... restore steady-state operations quickly. z/OS SVC memory dump processing and ... (RDMA) over Converged Ethernet. (RoCE) is a network protocol that ..."
          ]
        },
        {
          "title": "DPDK MLX5 PMD RX queue deferred start",
          "url": "https://forums.developer.nvidia.com/t/dpdk-mlx5-pmd-rx-queue-deferred-start/250805",
          "excerpts": [
            "Hi, I'm using DPDK with the MLX5 PMD to receive UDP packets. In order to receive UDP packets only, I use DPDK's Flow API, which requires ..."
          ]
        },
        {
          "title": "X86-64 Context Saving Practices",
          "url": "https://stackoverflow.com/questions/75680863/which-contexts-need-to-be-saved-in-x86-64-with-a-c-function-return",
          "excerpts": [
            "For x86-64 System V, that's only RSP, RBP, RBX, and R12-R15. Everything else is call clobbered, like RFLAGS, all the vector regs, AVX-512 mask regs, and x87",
            "The status bits in MXCSR are also basically call-clobbered, but if you want different threads to have different FP environments (e.g. rounding mode and FTZ/DAZ), then you *do* need to save/restore that. Same for the x87 control register, maybe not the status register. MPX is deprecated now so you probably don't need to worry about `bnd0-3`. If you want to have per-task performance-counter stuff, you could save/restore the PMU performance counters like Linux does of PAPI / perf.",
            "Thread-local storage using `fsbase` or `gsbase` should be saved/restored if your OS or user-space uses it. There are MSRs for the segment bases (so you can leave the actual segment register values as 0, the null selector). Or if you enable it (for use in user-space or kernel) on a CPU that supports it, [`rdfsbase` / `wrfsbase`](https://www.felixcloutier.com/x86/rdfsbase:rdgsbase) can copy the segment base to/from an integer register even more easily and efficiently than `rdmsr` / `wrmsr`. (x86-64 SysV uses FS for thread-local storage.) ---",
            "An asm caller should treat `call thrd_yield` exactly like a call to a compiler-generated function, assuming it clobbers all call-clobbered registers, leaving others unmodified.",
            "\nThe way Linux manages it is roughly:\n\n* Entering the kernel in the first place saves state of integer registers, on a per-thread kernel stack. This will be restored later when returning to user-space for this task, potentially between any two instructions so it's safe for async interrupts. * The vector regs aren't used by kernel code (unless it calls `kernel_fpu_begin()` first). So the interrupt and system call entry points don't have to run `xsave`; that can be deferred until switching to a new user-space task. At which point you do `xsave` (or `xsaveopt` or whatever) for the old context, then `xrstor` to load the new after switching to the new task's kernel stack. * Calling `switch_to` (see *[How does schedule()+switch\\_to() functions from linux kernel actually work? ](https://stackoverflow.com/questions/6525905/how-does-scheduleswitch-to-functions-from-linux-kernel-actually-work)*) just switches call-preserved integer registers (of the kernel state of the caller), and saves/restores the user-space FP/SIMD state from the vector regs. (Older kernels used to try to defer this, but modern user-space uses `movaps` all the time for memcpy and stuff.) * When that new kernel state eventually returns back to the syscall or interrupt entry point that got that task into the kernel, the user-space state will be restored.\nThe call-preserved registers will already have been restored by the kernel C functions, but Linux saves/restores all the registers anyway so debuggers (the `ptrace` system call) can modify that state all in one place. [Share](/a/75681072 \"Short permalink to this answer\")"
          ]
        },
        {
          "title": "RDMA GPU Direct Slow - CUDA - NVIDIA Developer Forums",
          "url": "https://forums.developer.nvidia.com/t/rdma-gpu-direct-slow/69946",
          "excerpts": [
            "Missing: deterministic sub- millisecond checkpoints DMA quiescence ring cursor NVMe"
          ]
        },
        {
          "title": "userfaultfd(2) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man2/userfaultfd.2.html",
          "excerpts": [
            "It can also be used to implement lazy restore for checkpoint/restore mechanisms, as well as post-copy migration to allow (nearly) uninterrupted execution ..."
          ]
        },
        {
          "title": "io_uring_enter2(2) - Linux manual page - man7.org",
          "url": "https://man7.org/linux/man-pages/man2/io_uring_enter2.2.html",
          "excerpts": [
            "IORING_ENTER_SQ_WAKEUP If the ring has been created with IORING_SETUP_SQPOLL, then this flag asks the kernel to wakeup the SQ kernel thread to submit IO.",
            "The CQE flags field will have IORING_CQE_F_MORE set on completion if the application should expect further CQE entries from the original request. If this flag ..."
          ]
        },
        {
          "title": "QP state machine",
          "url": "https://www.rdmamojo.com/2012/05/05/qp-state-machine/",
          "excerpts": [
            "May 5, 2012 — A QP is being created in the Reset state. Any QP can be transitioned to Reset or Error state by calling ibv_modify_qp() from any state."
          ]
        },
        {
          "title": "[dpdk-dev] [RFC 0/9] get Rx and Tx used descriptors",
          "url": "http://mails.dpdk.org/archives/dev/2016-November/050679.html",
          "excerpts": [
            "Missing: rx_queue_stop tx_queue_stop drain"
          ]
        },
        {
          "title": "Events",
          "url": "https://docs.nvidia.com/networking/display/RDMAAwareProgrammingv17/Events",
          "excerpts": [
            "May 23, 2023 — These errors usually occur because of bugs in the user code. When this happens, the QP is automatically transitioned to the IBV_QPS_ERR state by ..."
          ]
        },
        {
          "title": "Problem with NVMe driver : r/osdev",
          "url": "https://www.reddit.com/r/osdev/comments/1f2qc4q/problem_with_nvme_driver/",
          "excerpts": [
            "The reset deletes all I/O Submission Queues and I/O Completion Queues, resets the Admin Submission Queue and Completion Queue, and brings the ..."
          ]
        },
        {
          "title": "firecracker/docs/snapshotting/snapshot-support.md at main",
          "url": "https://github.com/firecracker-microvm/firecracker/blob/main/docs/snapshotting/snapshot-support.md?plain=1",
          "excerpts": [
            "Firecracker exposes the following APIs for manipulating snapshots: `Pause`,. `Resume` and `CreateSnapshot` can be called only after booting the microVM,. while ..."
          ]
        },
        {
          "title": "A Hot Distributed Snapshot System For Virtual Machine Cluster",
          "url": "https://www.usenix.org/conference/lisa13/technical-sessions/presentation/cui",
          "excerpts": [
            "This paper proposes HotSnap, a VMC snapshot approach designed to enable taking hot distributed snapshot with milliseconds system downtime and TCP backoff ..."
          ]
        },
        {
          "title": "io_uring_setup_buf_ring(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_setup_buf_ring.3.html",
          "excerpts": [
            "The io_uring_setup_buf_ring(3) function registers a shared buffer ring to be used with provided buffers. For the request types that support it, provided buffers ..."
          ]
        },
        {
          "title": "Can the --lazy-page feature be adapted for restoring process over ...",
          "url": "https://github.com/checkpoint-restore/criu/issues/1502",
          "excerpts": [
            "Missing: latency microseconds milliseconds"
          ]
        },
        {
          "title": "Userfaultfd",
          "url": "https://docs.kernel.org/admin-guide/mm/userfaultfd.html",
          "excerpts": [
            "In async mode, there will be no message generated when a write operation happens, meanwhile the write-protection will be resolved automatically by the kernel."
          ]
        },
        {
          "title": "userfaultfd(2) — Arch manual pages",
          "url": "https://man.archlinux.org/man/userfaultfd.2.en",
          "excerpts": [
            "Since Linux 5.7, userfaultfd supports write-protect mode for anonymous memory. The user needs to first check availability of this feature using UFFDIO_API ioctl ..."
          ]
        },
        {
          "title": "Articles - CRIU",
          "url": "https://criu.org/index.php?title=Articles&mobileaction=toggle_view_desktop",
          "excerpts": [
            "This is a collection of external articles regarding the CRIU project, sorted by date. 2025-08-13, Software Availability Protection in ..."
          ]
        },
        {
          "title": "[PDF] A Hot Distributed Snapshot System For Virtual Machine Cluster",
          "url": "https://www.usenix.org/system/files/conference/lisa13/lisa13-cui.pdf",
          "excerpts": [
            "This paper proposes HotSnap, a VMC snapshot approach designed to enable taking hot distributed snapshot with millisec- onds system downtime and ..."
          ]
        },
        {
          "title": "how AWS Lambda SnapStart optimizes function startup ...",
          "url": "https://aws.amazon.com/blogs/compute/under-the-hood-how-aws-lambda-snapstart-optimizes-function-startup-latency/",
          "excerpts": [
            "Lambda runs your function code in an isolated, secure execution environment that uses Firecracker microVM technology. ... snapshot restore latency ..."
          ]
        },
        {
          "title": "Derecho: RDMA-based state machine replication (Cornell dissertation)",
          "url": "https://www.cs.cornell.edu/projects/Quicksilver/public_pdfs/dissertation.pdf",
          "excerpts": [
            "Rather than rely on an explicitly co-\n\nordinated global checkpoint, as in [62] and [42], or attempt to record a dependency graph\n\nbetween locally-recorded checkpoints, as in [15], our system incorporates the dependency\n\ninformation already recorded in SMR updates to derive a globally consistent system snap-\n\nshot from loc",
            "RDMA (remote direct memory access) is a zero-copy communication standard. It has\n\nbeen used for many years on Infiniband, but is now also working robustly on standard\n\ndatacenter Ethernet [73,104",
            "To achieve the lowest possible latency, RDMA requires continuously polling for com-\n\npletion events, but this creates excessive CPU usage if no RDMA transfers are taking\n\npl",
            "The updates that happen asynchronously through one-sided RDMA writes must be dis-\n\ncovered very rapidly to take maximum advantage of high RDMA spee",
            " \nRDMA-enabled NICs additionally can write in-\n\ncoming network data to application memory through a DMA write and send data stored in\n\napplication memory over the network with a DMA read, therefore avoiding any memory",
            "One-sided RDMA writes do the\n\nopposite: the initiator node writes data directly to a remote node’s memory from its own\n\nmemory. Obviously, quite a bit of information is required for these to work, and in partic-\n\nular, the applications running on the two nodes need to be aware of the relevant memory\n\naddresses required for data tra",
            "This happens in the connection phase: When form-\n\ning a connection (binding), the applications exchange maps of one-other’s virtual memory\n\naddresses. Later, they reference these maps when exchanging d"
          ]
        },
        {
          "title": "NVM Express Revision 1.3",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM_Express_Revision_1.3.pdf",
          "excerpts": [
            "May 1, 2017 — Submission Queue 0 Tail Doorbell (Admin). 1000h + (1 *. (4 << CAP ... Completion Queue 0 Head Doorbell (Admin). 1000h + (2 *. (4 << CAP ..."
          ]
        },
        {
          "title": "Base Specification, Revision 2.3",
          "url": "https://nvmexpress.org/wp-content/uploads/NVM-Express-Base-Specification-Revision-2.3-2025.08.01-Ratified.pdf",
          "excerpts": [
            "Jul 31, 2025 — 1.1 Overview. The NVM Express® (NVMe®) interface allows a host to communicate with a non-volatile memory subsystem. (NVM subsystem)."
          ]
        },
        {
          "title": "ibv_poll_cq()",
          "url": "https://www.rdmamojo.com/2013/02/15/ibv_poll_cq/",
          "excerpts": [
            "Feb 15, 2013 — When a Work Requests end, a Work Completion is being added to the tail of the CQ that this Work Queue is associated with. ibv_poll_cq() check if ..."
          ]
        },
        {
          "title": "RDMA Aware Networks Programming User Manual",
          "url": "https://docs.nvidia.com/rdma-aware-networks-programming-user-manual-1-7.pdf",
          "excerpts": [
            "Mar 3, 2011 — action will result in any posted work requests being flushed to the completion queue. rdma_disconnect may be called by both the client and ..."
          ]
        },
        {
          "title": "ibv_req_notify_cq()",
          "url": "https://www.rdmamojo.com/2013/02/22/ibv_req_notify_cq/",
          "excerpts": [
            "Feb 22, 2013 — ibv_req_notify_cq() requests a notification when the next Work Completion of a requested type is added to the CQ. Any Work Completions that ..."
          ]
        },
        {
          "title": "ibv_modify_qp() - RDMAmojo",
          "url": "https://www.rdmamojo.com/2013/01/12/ibv_modify_qp/",
          "excerpts": [
            "ibv_modify_qp() modifies the attributes of a Queue Pair. The changed attributes describe the send and receive attributes of the QP."
          ]
        },
        {
          "title": "ibv_modify_qp - man pages section 3: Library Interfaces and Headers",
          "url": "https://docs.oracle.com/cd/E88353_01/html/E37842/ibv-modify-qp-3.html",
          "excerpts": [
            "Missing: IBV_QPS_ERR IBV_QPS_RESET"
          ]
        },
        {
          "title": "lib/ring/rte_ring_peek_zc.h File Reference - Documentation - DPDK",
          "url": "https://doc.dpdk.org/api/rte__ring__peek__zc_8h.html",
          "excerpts": [
            "Note that currently these APIs are available only for two sync modes: 1) Single Producer/Single Consumer (RTE_RING_SYNC_ST) 2) Serialized Producer/Serialized ..."
          ]
        },
        {
          "title": "[PDF] Operational and Declarative Models of RDMA on TSO Architectures",
          "url": "https://www.soundandcomplete.org/papers/OOPSLA2024/RDMA/rdma-extended.pdf",
          "excerpts": [
            "Our focus here is on the IB Verbs model defined by IBTA [2022], using PCIe as the internal fabric. It was designed for InfiniBand and reused for RoCE, the two ..."
          ]
        },
        {
          "title": "[CRIU] Looking into checkpoint/restore of ROCm applications",
          "url": "http://lists.openvz.org/pipermail/criu/2020-June/045032.html",
          "excerpts": [
            "Jun 18, 2020 — ... [CRIU] Looking into checkpoint/restore of ROCm ... kfd with a cr_plugin_dump_file >> callback in a plugin. I've spent some time reading ..."
          ]
        },
        {
          "title": "Changelog - ROCm Documentation - AMD",
          "url": "https://rocm.docs.amd.com/en/docs-6.0.0/about/CHANGELOG.html",
          "excerpts": [
            "CRIU lacked the support for checkpoint restore applications that used device files such as a GPU. With this ROCm release, CRIU is enhanced with a new plugin ..."
          ]
        },
        {
          "title": "Checkpointing Tensorflow-rocm with CRIU · Issue #1763 - GitHub",
          "url": "https://github.com/RadeonOpenCompute/ROCm/issues/1763",
          "excerpts": [
            "So I'm trying to checkpoint and restore a tensorflow-rocm (2.9.1) application running on my GPU (Raedeon RX 6950 XT), however, have been so far ..."
          ]
        },
        {
          "title": "Using CUDA's checkpoint/restore API to reduce cold boot time by 12x",
          "url": "https://www.reddit.com/r/CUDA/comments/1mebckd/using_cudas_checkpointrestore_api_to_reduce_cold/",
          "excerpts": [
            "The API allows us to checkpoint and restore CUDA state, including: Device memory contents (GPU vRAM), such as model weights. CUDA kernels. CUDA ..."
          ]
        },
        {
          "title": "Checkpointing Preemptible Training Workloads",
          "url": "https://run-ai-docs.nvidia.com/self-hosted/workloads-in-nvidia-run-ai/using-training/checkpointing-preemptible-workloads",
          "excerpts": [
            "Aug 10, 2025 — NVIDIA Run:ai allows you to define whether a workload is preemptible, meaning the NVIDIA Run:ai Scheduler may pause a running workload and ..."
          ]
        },
        {
          "title": "PhoenixOS: Concurrent OS-level GPU Checkpoint and Restore with ...",
          "url": "https://arxiv.org/html/2405.12079v2",
          "excerpts": [
            "PhoenixOS (PhOS) is the first OS service that can concurrently checkpoint and restore (C/R) GPU processes—a fundamental capability for critical ..."
          ]
        },
        {
          "title": "ROCm-SMI Fails to Restore Full Power After Setting Low Profile #4257",
          "url": "https://github.com/ROCm/ROCm/issues/4257",
          "excerpts": [
            "Problem begins when I revert the performance level using: rocm-smi --setperflevel auto The power does not reach the peak as it used to..it reaches 143W max."
          ]
        },
        {
          "title": "CUDA Checkpoint/Restore Documentation",
          "url": "https://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CHECKPOINT.html",
          "excerpts": [
            "CUDA API versioning support\n\nThis sections describes the checkpoint and restore functions of the low-level CUDA driver application programming interface. The CUDA checkpoint and restore API's provide a way to save and restore GPU state for full process checkpoints when used with\n CPU side process checkpointing solutions.",
            "cuCheckpointProcessCheckpoint ( int pid , [CUcheckpointCheckpointArgs](structCUcheckpointCheckpointArgs.html) \\* args )\n    Checkpoint a CUDA process's GPU memory contents."
          ]
        },
        {
          "title": "Checkpointing CUDA Applications with CRIU (NVIDIA Technical Blog)",
          "url": "https://developer.nvidia.com/blog/checkpointing-cuda-applications-with-criu/",
          "excerpts": [
            "This utility can be used to transparently checkpoint and restore CUDA state within a running Linux process.",
            "`cuda-checkpoint` checkpoints and restores the CUDA state of a single Linux process.",
            "%2F)\n\nCheckpoint and restore functionality for CUDA is exposed through a command-line utility called [cuda-checkpoint]",
            "CRIU exposes its functionality through a command line program called `criu` and operates by checkpointing and restoring every kernel mode resource associated with a process.",
            "The `cuda-checkpoint` binary can toggle the CUDA state of a process, specified by PID, between suspended and running.",
            "A running-to-suspended transition is called a *suspend* and the opposite transition is called a *resu"
          ]
        },
        {
          "title": "Morello for A-profile Architecture",
          "url": "https://developer.arm.com/documentation/ddi0606/latest/",
          "excerpts": [
            "Arm Architecture Reference Manual Supplement - Morello for A-profile Architecture. This document is only available in a PDF version. Click Download to view."
          ]
        },
        {
          "title": "Sentries for control-flow integrity",
          "url": "https://cheriot.org/isa/ibex/2024/06/26/sentries-cfi.html",
          "excerpts": [
            "Jun 26, 2024 — For a long time, CHERI platforms have had a notion of a sealed entry (sentry) capability. These use the sealing mechanism (that makes a ..."
          ]
        },
        {
          "title": "RISC-V Specification for CHERI Extensions - GitHub Pages",
          "url": "https://riscv.github.io/riscv-cheri/",
          "excerpts": [
            "If the capability tag is set, the capability is valid and can be dereferenced (contingent on checks such as permissions or bounds). All registers or memory ..."
          ]
        },
        {
          "title": "Morello Platform Model Reference Guide Version 2.0",
          "url": "https://developer.arm.com/documentation/102225/latest/Reference-information",
          "excerpts": [
            "This chapter provides reference information for the Morello Platform Model including differences between the model implementation and the Morello specification, ..."
          ]
        },
        {
          "title": "What are the purposes of sealed capabilities?",
          "url": "https://capabilitiesforcoders.com/faq/purposes_of_sealed_capabilities.html",
          "excerpts": [
            "CHERI can prevent ROP attacks by sealing automatically sealing function pointers (i.e., creating a sentry) and the return address (link register). Memory Safety."
          ]
        },
        {
          "title": "seL4 Debugging Guide",
          "url": "https://www.cse.unsw.edu.au/~cs9242/18/project/debugging.shtml",
          "excerpts": [
            "Jul 19, 2018 — The kernel exports fault handling policies to user level by sending an IPC to the appropriate IPC endpoint (see Chapter 5 of the seL4 manual)."
          ]
        },
        {
          "title": "LLP08-seL4-6up.pdf",
          "url": "https://web.cecs.pdx.edu/~mpj/llp/slides/LLP08-seL4-6up.pdf",
          "excerpts": [
            "• Kernel tracks use via the “capability derivation tree” (CDT). • Cannot retype an untyped memory area if it is already in use. (i.e., if it has children in ...",
            "• seL4 tackles this problem by introducing a special \"Reply\" capability type: • The Call system call combines a Send and a Wait. • The kernel gives a new ..."
          ]
        },
        {
          "title": "model-driven development of arinc 653 configuration tables",
          "url": "https://www.gmv.com/sites/default/files/content/file/2020/06/03/1/dasc_paper.pdf",
          "excerpts": [
            "by Á Horváth · Cited by 44 — The group consists of steps to define the Health. Monitoring tables for module, partition and application level along with the different error."
          ]
        },
        {
          "title": "Towards a Real-time Component Framework for Software ... - C3",
          "url": "https://c3.ndc.nasa.gov/dashlink/static/media/other/ISIS-TR-09-111.pdf",
          "excerpts": [
            "by A Dubey · Cited by 12 — ARINC-653 supports a health monitoring service at each layer (Partition/Module/System) which is configured by the user with the appropriate response (functions) ..."
          ]
        },
        {
          "title": "Model-driven development of ARINC 653 configuration ...",
          "url": "https://www.researchgate.net/publication/224202064_Model-driven_development_of_ARINC_653_configuration_tables",
          "excerpts": [
            "In the scope of the project, a tool chain was implemented that generates ARINC 653 configuration tables from high-level architecture models. The tool chain was ..."
          ]
        },
        {
          "title": "CHERI Software Compartmentalization",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-compartmentalization.html",
          "excerpts": [
            "The CHERI protection model provides a set of low-level primitives that enable scalable, fine-grained software compartmentalization.",
            "[CHERI-seL4](cheri-sel4.html)"
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI's capability system is blended with a conventional RISC\nusermode architecture without disrupting the majority of key design\ndecisions.",
            "CHERI is a hybrid capability system in several senses:",
            "CHERI capabilities are a low-level primitive usable for many purposes.",
            "The advent of the open RISC-V ISA provides us with a richer spectrum of\nbaseline processor designs, and as the architecture matures over time, we\nhope also a similarly rich software ecosystem."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "\nCHERI represents a new system design that blocks exploits. Architectural changes to the CPU and memory systems add integrity checks to pointers that prevent reading, writing, or executing from memory that is out of bounds or using corrupted pointers, the most common classes of severe vulnerabilities. CHERI is supported by a complete compiler toolchain, multiple operating systems, is open source, and already implemented for several different RISC CPUs including Arm’s recently released Morello prototype.",
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "Capabilities are created at boot time, and capabilities derived from these initial ones are more restrictive. The new instructions for manipulating capabilities also mean changing the instruction set architecture, or ISA.",
            " of CHERI architectures for MIPS, RISC-V, and Arm began with the Sail instruction set definition language. Sail generates sequential emulators, in C and OCaml, and theorem-prover definitions, in Coq, HOL4, and Isabelle, and SMT. These versions allow for both a means of testing in emulation and creating formal proofs of the correctness of the design.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Fault Management (MDPI)",
          "url": "https://www.mdpi.com/2076-3417/12/4/2014",
          "excerpts": [
            "ARINC 653 provides a health monitor configuration table and error handler process for managing errors. In the health monitor configuration table, the level of error is defined as a process, partition and module and the recovery method for each error is specified to enable action appropriate to the situation.",
            "In the health monitor configuration table, the level of error is defined as a process, partition and module and the recovery method for each error is specified to enable action appropriate to the situation.",
            "— ARINC 653 provides health monitoring to detect and recover hardware and software errors at the process, partition and module levels. It isolates errors and ...",
            " ARINC 653 is an integrated modular avionic (IMA)-based real-time operating system (RTOS). It is an avionic system that integrates and operates an environment where multiple computer systems are operated in a distributed manner.",
            "The FACE consists of five local segments, such as operating system segment (OSS), input/out services segment (IOSS), platform-specific services segment (PSSS), transport services segment (TSS), portable components segment (PCS). The FACE provides OS-level health monitoring and fault management (HMFM) and system-level HMFM for HMSs."
          ]
        },
        {
          "title": "[PDF] CHERIoT Architecture specification Version 0.6 (draft)",
          "url": "https://cheriot.org/cheriot-sail/cheriot-architecture.pdf",
          "excerpts": [
            "To mitigate the availability concerns this could create, the. CHERIoT RTOS provides a mechanism for recovering from faults in a controlled way. Compartments can ...",
            "by S Amar · 2024 — The first is a sealed capability to a structure describing the entry point in the callee. The second is a sentry capability to the compartment switcher. The ..."
          ]
        },
        {
          "title": "CHERIoT Architecture specification Version 0.6 (draft)",
          "url": "https://lists.riscv.org/g/tech-tg-cheri/attachment/14/0/cheriot-architecture.pdf",
          "excerpts": [
            "by S Amar · 2024 — The sealed capability is passed in a register when the sentry capability is called. A CHERI sentry is a capability that can be jumped to but ..."
          ]
        },
        {
          "title": "Secure Scripting with CHERIoT MicroPython - ACM Digital Library",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3708493.3712694",
          "excerpts": [
            "However, this register is zeroed by CHERIoT-RTOS on return from any cross-compartment call. Correct usage of this register would require its contents to be ..."
          ]
        },
        {
          "title": "Efficient and Provable Local Capability Revocation using ...",
          "url": "https://iris-project.org/pdfs/2021-popl-ucaps-final.pdf",
          "excerpts": [
            "by AL GEORGES · 2021 · Cited by 44 — On many capability machines, including CHERI, memory capabilities are designed to directly replace pointers, thus adding native bounds and permission checks ..."
          ]
        },
        {
          "title": "Building Safety by Design: CHERI in Critical…",
          "url": "https://blog.adacore.com/building-safety-by-design-cheri-in-critical-systems-development",
          "excerpts": [
            "Dec 17, 2024 — Our paper discusses examples of how cyber-attack detection, resilience, recovery, and new failure mode strategies like \"fail secure but degraded ..."
          ]
        },
        {
          "title": "ARINC Specification 653-2",
          "url": "https://mail.kia.prz.edu.pl/~ssamolej/vxworks/ARINC_653P1-2.pdf",
          "excerpts": [
            "The Health Monitor (HM) is the function of the O/S responsible for monitoring and reporting\n\nhardware, application and O/S software faults and failures. The HM helps to isolate faults and to\n\nprevent failures from propagatin",
            "Fault responses to process level errors are determined by the application programmer using a\n\nspecial (highest priority) process of the partition, the error handler process. The error handler\n\nprocess is active in NORMAL mode only. The programmer can identify the error and the faulty\n\nprocess via a HM service and then takes the recovery action at the process level (e.g., stop, start\n\nprocess) or at the partition level (e.g., set partition mode: IDLE, COLD\\_START, WARM\\_S",
            "Fault responses to partition level errors are handled in the following way:",
            "The O/S Kernel looks up the reference to the HM Callback in the HM\n\nConfiguration tables and calls the procedure if one has been identified for the\n\npartitio",
            "On completion of the HM Callback the O/S Kernel looks up the error code\n\nresponse action in the HM configuration tables",
            "The O/S Kernel performs the response identified in the configuration table.",
            "The recovery actions for process level errors are defined by the application programmer\n\nin a special error handler process"
          ]
        },
        {
          "title": "sima Command Line Tools Application Development and ...",
          "url": "https://www.gmv.com/sites/default/files/content/file/2020/06/03/1/user_manual.pdf",
          "excerpts": [
            "Jun 3, 2020 — The partition scheduling is defined in the arinc 653 configuration file in three hier- ... Figure 16 shows the structure of the arinc 653 system ..."
          ]
        },
        {
          "title": "Configuration Tool for ARINC 653 Operating Systems",
          "url": "https://gvpress.com/journals/IJMUE/vol9_no4/8.pdf",
          "excerpts": [
            "by ET Choi · 2014 · Cited by 5 — From the figure, An ARINC 653 Module consist of seven major elements, one or more Partitions, a System HM table, a Module. HM table, a Connection table, one or ..."
          ]
        },
        {
          "title": "CHERI Instruction-Set Architecture (Version 8)",
          "url": "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-951.pdf",
          "excerpts": [
            "by RNM Watson · 2020 · Cited by 158 — This hybrid approach, inspired by the Capsicum security model, addresses the performance and robustness issues that arise when trying to express more secure.",
            "by RNM Watson · 2020 · Cited by 158 — CHERI's hybrid approach allows incremental adoption of capability-oriented design: crit- ical components can be ported and recompiled to use capabilities ..."
          ]
        },
        {
          "title": "CHERI Instruction-Set Architecture (Version 9)",
          "url": "https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-987.pdf",
          "excerpts": [
            "by RNM Watson · 2023 · Cited by 158 — ... Failure modes and exception delivery (Section 2.3.15). • Capability revocation (Section 2.3.16). These features allow capabilities to be architectural ..."
          ]
        },
        {
          "title": "(PDF) Configuration tool for ARINC 653 operating systems",
          "url": "https://www.researchgate.net/publication/262418287_Configuration_tool_for_ARINC_653_operating_systems",
          "excerpts": [
            "Aug 10, 2025 — This paper presents a configuration tool for ARINC 653 OS that consist of Wizard module which generates the basic configuration data for IMA based on XML ..."
          ]
        },
        {
          "title": "Behind the last line of defense: Surviving SoC faults and ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0167404822003121",
          "excerpts": [
            "by IP Gouveia · 2022 · Cited by 16 — In particular, faulty replicas may fail a subordinate vote, but agree to reset the voter, which erases the error information about the failed vote from the ..."
          ]
        },
        {
          "title": "nevill-master-capabilities.pdf - The Barrelfish OS",
          "url": "https://barrelfish.org/publications/nevill-master-capabilities.pdf",
          "excerpts": [
            "by M Nevill — Given a generic memory capability (referred to as “untyped memory”, or UM), seL4 allows this to be retyped to a mappable “virtual mem- ory” (VM) ..."
          ]
        },
        {
          "title": "CHERI Hardware and CHERIoT Overview",
          "url": "https://cheriot.org/cheri/2024/08/06/how-to-talk-about-CHERI.html",
          "excerpts": [
            "In CHERIoT, we use sealed objects for almost anything where one compartment wants to provide a handle that lets other compartments ask it to do something. This includes allocating memory, reading or writing message queues, connecting to network servers, and so on.",
            "The software model defines what valid paths exist between the initial boot state and normal execution with you holding a pointer to a heap object, the hardware guarantees that some such path must have existed for you to hold that pointer.",
            "CHERI capabilities were designed to allow everything that correct C does with pointers, which is a superset of what most safer languages permit.",
            "CHERIoT provides a trusted stack for cross-compartment calls and a switcher that enforces a lot of properties on both the call and return path."
          ]
        },
        {
          "title": "Improving Security with Hardware Support: CHERI and Arm's Morello",
          "url": "https://www.govinfo.gov/content/pkg/GPO-TNW-24-1-2023/pdf/GPO-TNW-24-1-2023-3.pdf",
          "excerpts": [
            "Three kinds of specialized sentry (sealed \nentry) capabilities may be used transparently by \ndirect branch instructions, memory-indirect branch \ninstructions, and memory-indirect branch-to-pair \ninstruction",
            "sealing capabilities, they can be labeled with an object \ntype, if the authorizing capability has that object \ntype in its bounds. The “branch to sealed capabili-\nty pair” instruction invokes a given code capability \nand also an argument data capability, checking their \nobject types match, providing object-style encap-\nsulati",
            "Three kinds of specialized sentry (sealed \nentry) capabilities may be used transparently by \ndirect branch instructions, memory-indirect branch \ninstructions, and memory-indirect branch-to-pair \ninstructions, respectiv",
            "and exception handling is also extended. Exception handling preserves extended capability \nregister state, and there are new exception cause \ncodes associated with CHERI failures such as bounds \nviolations or untagged memory accesses.",
            "CHERI capabilities are an architectural primitive \nthat can be used for a variety of software purposes \nup and down the software stack, with potential uses \nin firmware and boot loaders, OSs, language run-\ntimes, CHERI-specific compartmentalization librar-\nies, and compiler-generated code for the C and C++ \napplication p"
          ]
        },
        {
          "title": "seL4 discussion on page faults and revocation in seL4 ecosystem",
          "url": "https://sel4.com/hyperkitty/list/devel@sel4.systems/thread/QAYR2OHU7GPWTAFKJH4O3RF7TWQIKBQK/",
          "excerpts": [
            "The page-fault handler finds that the fault is due to a page shared with the client and takes appropriate action.",
            "Effectively, in seL4, if my understanding above is correct, one\nstructures the system in such a manner that revocation is eliminated,\ni.e., the client cannot revoke its pages.",
            "the client\ntrusts the driver to release the pages back via the TCB when connection\nis teared down.",
            "In other words, what is the killer use-case for fine-grained revocation\nin your opinion? I.e., what kind of system is impossible without it? Or\neven: did you see scenarios on top of seL4 when people rely on\nfine-grained revocation (i.e., revoke pages, memory regions, access to\ndevices) instead of a rather coarse-grained termination of the entire\nprocesses?"
          ]
        },
        {
          "title": "ARINC 653 Health Monitoring and Recovery (ISSRE2015) ",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            " Recovery actions at the partition level are triggered when the error is a partition level error and the error handler has not been created in that partition",
            "The service requirement of STOP service in process management\n\ncommunication modes between partitions, services provided,\n\nand attributes; intra-partition communication, similar to inter-\n\npartition communication, but oriented to processes instead of\n\npartitions; and health monitoring, which defines actuation rules\n\nunder system, partition, and application fai"
          ]
        },
        {
          "title": "[PDF] Arm® Architecture Reference Manual Supplement Morello for A ...",
          "url": "http://kib.kiev.ua/x86docs/ARM/Morello/DDI0606_A.j_morello_architecture_external.pdf",
          "excerpts": [
            "Morello is a prototype architecture, which has a particular meaning to Arm of which the recipient must be aware as follows: Subject to change without consent ..."
          ]
        },
        {
          "title": "Capability Hardware Enhanced RISC Instructions",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/20240116-cheri-web-compressed.pdf",
          "excerpts": [
            "Jan 16, 2024 — Sealed capabilities, CCall/CReturn. 2015. ISAv4. MMU-CHERI integration (TLB permissions). ISA support for compressed 128-bit capabilities. HW ..."
          ]
        },
        {
          "title": "SECURITY ANALYSIS OF CHERI ISA - GitHub",
          "url": "https://raw.githubusercontent.com/microsoft/MSRC-Security-Research/master/papers/2020/Security%20analysis%20of%20CHERI%20ISA.pdf",
          "excerpts": [
            "Exceptions where the architectural provenance chain is broken to support abstract capabilities in a real system include implementations for program startup, ..."
          ]
        },
        {
          "title": "2. The RTOS Core",
          "url": "https://cheriot.org/book/core_rtos.html",
          "excerpts": [
            "A trusted stack is a region of memory containing the register save area for context switches and a small frame for every cross-compartment call that allows a ..."
          ]
        },
        {
          "title": "The RTOS components for the CHERIoT research platform",
          "url": "https://github.com/CHERIoT-Platform/cheriot-rtos",
          "excerpts": [
            "trusted_stack_frames specifies the number of trusted stack frames (the maximum depth of cross-compartment calls possible on this thread). Note that any call ..."
          ]
        },
        {
          "title": "5. Compartments and libraries",
          "url": "https://cheriot.org/book/compartments.html",
          "excerpts": [
            "In the core of the RTOS, the scheduler is written as a safebox. It does not trust anything on the outside and assumes that everything else is trying to make it ..."
          ]
        },
        {
          "title": "seL4 Libraries: IPC",
          "url": "https://docs.sel4.systems/Tutorials/libraries-2.html",
          "excerpts": [
            "seL4 Libraries: IPC. The tutorial is designed to teach the basics of seL4 IPC using Endpoint objects, and userspace paging management."
          ]
        },
        {
          "title": "Genode on seL4 - IPC and virtual memory",
          "url": "https://genode.org/documentation/articles/sel4_part_2",
          "excerpts": [
            "In the L4 universe, the term IPC (inter-process communication) usually stands for synchronous communication between two threads. In seL4, IPC has two uses."
          ]
        },
        {
          "title": "FAILSAFE Health Management for Embedded Systems",
          "url": "https://www.techbriefs.com/component/content/article/8430-npo-46981",
          "excerpts": [
            "Under ARINC 653, the health monitoring (HM) service is invoked by an application calling the application error service, or by the operating ..."
          ]
        },
        {
          "title": "Modeling and Validation of ARINC653 architectures",
          "url": "https://hal.science/hal-02269428v1/document",
          "excerpts": [
            "by J Delange · 2010 · Cited by 12 — The Health Monitoring service detects faults at different levels (module, partition, process) and executes a recovering procedure for each one."
          ]
        },
        {
          "title": "Model-based optimization of ARINC-653 partition scheduling",
          "url": "https://link.springer.com/article/10.1007/s10009-020-00597-6",
          "excerpts": [
            "por P Han · 2021 · Mencionado por 11 — In ARINC 653, the time allocation for partitions is executed cyclically according to a static schedule. A schedulable system requires sufficient ..."
          ]
        },
        {
          "title": "Constant bandwidth servers with constrained deadlines",
          "url": "https://dl.acm.org/doi/10.1145/3139258.3139285",
          "excerpts": [
            "The Hard Constant Bandwidth Server (H-CBS) is a reservation-based scheduling algorithm often used to mix hard and soft real-time tasks on the same system."
          ]
        },
        {
          "title": "Constant bandwidth server revisited | ACM SIGBED Review",
          "url": "https://dl.acm.org/doi/10.1145/2724942.2724945",
          "excerpts": [
            "The Constant Bandwidth Server (CBS) is an algorithm for providing temporal protection and real-time guarantees to real-time sporadic tasks."
          ]
        },
        {
          "title": "io_uring and networking in 2023 · axboe/liburing Wiki",
          "url": "https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023",
          "excerpts": [
            "Feb 15, 2023 — The simplest way to use ring messages is to just transfer 8 bytes of data between them. io_uring treats the data as a cookie and doesn't ..."
          ]
        },
        {
          "title": "NUMA, Multi-Queue NICs and CPU Affinity - Networking Notes",
          "url": "https://null.53bits.co.uk/page/numa-and-queue-affinity",
          "excerpts": [
            "Apr 17, 2016 — RPS has some advantages over RSS: 1) it can be used with any NIC, 2) software filters can easily be added to hash over new protocols, 3) it does ..."
          ]
        },
        {
          "title": "Scaling in the Linux Networking Stack",
          "url": "https://docs.kernel.org/networking/scaling.html",
          "excerpts": [
            "Each receive queue has a separate IRQ associated with it. The NIC triggers this to notify a CPU when new packets arrive on the given queue. The signaling path ..."
          ]
        },
        {
          "title": "RSS, IRQ affinity and RPS on Linux - Andreas Karis Blog",
          "url": "https://andreaskaris.github.io/blog/networking/rss-irq-affinity-and-rps/",
          "excerpts": [
            "Aug 12, 2024 — RSS, short for Receive Side Scaling, is an in-hardware feature that allows a NIC to \"send different packets to different queues to distribute ...",
            "In this blog post, we are going to have a look at the tuning of Linux receive queues and their interrupt requests. We are going to learn a bit ..."
          ]
        },
        {
          "title": "The RPS/RSS seems not take effect in platform Xavier/Orin",
          "url": "https://forums.developer.nvidia.com/t/the-rps-rss-seems-not-take-effect-in-platform-xavier-orin/218593",
          "excerpts": [
            "Jun 23, 2022 — I tried to dispatch udp packet to multi-CPU over RPS/RSS, but it seems not available. The steps are as follow: list all net rx queues:"
          ]
        },
        {
          "title": "Is it a good practice to set interrupt affinity and io handling ...",
          "url": "https://stackoverflow.com/questions/48659720/is-it-a-good-practice-to-set-interrupt-affinity-and-io-handling-thread-affinity",
          "excerpts": [
            "IRQ affinity is a double edged sword. In my experience it can improve performance but only in a very specific configuration with a pre-defined workload."
          ]
        },
        {
          "title": "Efficient Distributed Memory Management with RDMA and ...",
          "url": "https://www.vldb.org/pvldb/vol11/p1604-cai.pdf",
          "excerpts": [
            "by Q Cai · 2018 · Cited by 145 — Due to the limited size of the on-NIC cache, it is important to keep, as small as possible, the data needed by RDMA NIC, which typically include the page table, ..."
          ]
        },
        {
          "title": "Understanding CPU Interrupts in Linux",
          "url": "https://www.alibabacloud.com/blog/597128",
          "excerpts": [
            "The SMP IRQ affinity requires NICs to support multiple queues. A NIC supporting multiple queues has multiple interrupt numbers, which can be ..."
          ]
        },
        {
          "title": "[PDF] The IX Operating System: Combining Low Latency, High Throughput ...",
          "url": "https://anakli.inf.ethz.ch/papers/IX_TOCS.pdf",
          "excerpts": [
            "We present IX, a dataplane operating system that provides high I/O performance and high resource efficiency while maintaining the protection and isolation ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field describes a Nimbus 2000 component that enables a high-performance, direct I/O path between storage (NVMe) and GPUs, including NVMe-to-GPU DMA and NIC-to-GPU RDMA, with Rust APIs mirroring CPU rings. The most relevant excerpts explicitly discuss direct GPU storage/data paths via GPUDirect Storage (GDS) and direct GPU memory access across PCIe, which provide the architectural basis for such a component. For example, passages describing GPUDirect Storage enabling a direct data path between GPU memory and storage via cuFile APIs and the nvidia-fs.ko driver demonstrate the exact mechanism Nimbus 2000 aims to realize. Related material about GPUDirect RDMA and the Rosetta-like \"peer-direct\" pathways (PCIe Peer-to-Peer DMA) further corroborates the capability to move data directly between GPUs, NICs, and NVMe devices without CPU involvement. Additional entries detailing cuFile-based transfers and how data can be moved directly between storage and GPUs (bypassing CPU copies) strengthen the alignment between the Nimbus description and the excerpts. In effect, the strongest support comes from direct GPUDirect Storage and GPUDirect RDMA discussions, followed by PCIe P2PDMA and peer-direct client discussions, all of which map closely to Nimbus 2000's intended direct-path, zero-copy IO model and the Rust-based, kernel-bypass flavor described in the field.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.0.technology_name",
      "citations": [
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ...",
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P"
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "formal verification in general is stronger than other\n   traditional ways of gaining trust in software such as testing in that\n   it can prove the _absence_ of bugs, not just their\n ",
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft"
          ]
        },
        {
          "title": "CantripOS: seL4 + Rust",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-01-leffler.pdf",
          "excerpts": [
            "CantripOS: 100% Rust"
          ]
        },
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "IPC is via Endpoint objects."
          ]
        }
      ],
      "reasoning": "The target fine-grained field value corresponds to a foundational technology: the seL4 microkernel. The most persuasive evidence comes from sources explicitly describing seL4 as a highly assured kernel with machine-checked proofs, which directly supports the field value. In particular, a source states that seL4 is the most highly-assured operating system kernel and that its uniqueness rests on formal mathematical proofs, which enforce a precise, verifiable behavior. Related sources elaborate on the nature of the seL4 proofs as machine-checked from high-level specifications to binary code, covering properties from functional correctness to absence of information leakage. These excerpts together establish that seL4 is not only conceptually central to isolation and security guarantees but also that its verification lineage is a core defining characteristic. Additional excerpts discuss supporting concepts that underpin seL4's design, such as the role of capabilities for fine-grained access control, which align with the isolation and security model seL4 provides. There is also mention of verification and certification pathways that reinforce confidence in seL4's trustworthiness. Another excerpt confirms seL4's applicability in broader discussions (e.g., CantripOS: seL4 + Rust), illustrating its influence in ecosystems that leverage its verification properties. Finally, entries on IPC and capability encapsulation reinforce the practical mechanisms by which seL4 achieves safe interaction between components. Altogether, these excerpts coherently substantiate the claim that seL4 is a foundational technology characterized by formal verification, strong isolation guarantees, and a capability-based security model.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.11.technology_name",
      "citations": [
        {
          "title": "arXiv:1801.05863 - Design and Implementation of RA-TLS for Intel SGX Enclaves",
          "url": "https://arxiv.org/pdf/1801.05863",
          "excerpts": [
            "e propose to\n\ninclude additional information into the X.509\n\ncertificate exchanged during a TLS handshake",
            "**Attestation Verification Report. ** This is the reply\n\nreceived from the Intel Attestation Service (IAS) when\n\nsubmitting a quote for verification [10]. IAS reports\n\nwhether the quote was generated on a genuine Intel\n\nSGX platform by a genuine encl",
            "**Attestation Verification Report Signature. ** The\n\nattestation verification report is signed by IAS. The\n\nsignature ensures that report is authentic and\n\nunmodifi",
            "**Attestation Report Signing Certificate. ** To verify the\n\nsignature over the attestation report, the client must\n\nknow the keys used to create the signatur",
            "**Non-standard X.509 extensions. ** We embed the SGX\n\nidentity information in custom X.509 extensions",
            "**Quoting Enclave Identity. ** The latest identity of Intel’s\n\nquoting enclave including its code measurement and\n\nsecurity versions number"
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Remote attestation Implementation - BlindAI - Mithril Security",
          "url": "https://blindai.mithrilsecurity.io/en/latest/docs/security/remote_attestation/",
          "excerpts": [
            "The first one, is EPID attestation which relies on using Intel services to attest that an enclave on specific platforms is verified. The second one is DCAP ( ..."
          ]
        },
        {
          "title": "GlobalPlatform Entity Attestation Protocol Specification",
          "url": "https://globalplatform.org/wp-content/uploads/2024/07/GPP_EntityAttestationProtocolSpec_v0.0.0.26_PublicRvw2.pdf",
          "excerpts": [
            "Remote Attestation \nThe process by which attestation information is assembled by an Entity \nAttestation Service, transferred to a Relying Party, and processe",
            "The IETF NNNN specification ([draft-ietf-rats-eat]) introduces the concept of Attestation, which is a mechanism \n45 \nby which an Entity can provide information about itself with some level of assurance to a Relying Par",
            "During Attestation, an Entity \n47 \nAttestation Service builds a set of Claims, each of which consists of a piece of evidence provided by a Clai"
          ]
        },
        {
          "title": "Introduction to SGX - Gramine documentation - Read the Docs",
          "url": "https://gramine.readthedocs.io/en/stable/sgx-intro.html",
          "excerpts": [
            "The Provisioning Certification Enclave is used in DCAP based remote attestation. This enclave communicates with the Intel Provisioning Certification Service ( ..."
          ]
        },
        {
          "title": "Design Guide for Intel® SGX Provisioning Certificate Caching ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.11/linux/docs/SGX_DCAP_Caching_Service_Design_Guide.pdf",
          "excerpts": [
            "DCAP Quote Verification. Library. QVE. Intel SGX Capable Platform or VM ... Refresh expired {TCB info, PCK CRLs, QE Identity, QvE Identity,. Root CA CRL} ..."
          ]
        },
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        }
      ],
      "reasoning": "The core of the target field is Intel SGX / ARM TrustZone as foundational technologies for trusted enclaves and remote attestation. Excerpts that explicitly reference SGX enclaves, attestation workflows, and verification services give direct support to the Intel SGX portion of the field value. For instance, excerpts describing the RA-TLS design and implementation for Intel SGX enclaves, attestation replies from attestation services, and attestation report signing certificates directly map to SGX-enabled security infrastructure and the attestation chain. Other excerpts discuss attestation flows and remote attestation tooling in SGX contexts (DCAP, IAS, QVE, etc.), which further corroborate SGX relevance. Some excerpts discuss SGX-related provisioning and DCAP caching design guides, which reinforce the SGX aspect of the field value. While the field value also mentions ARM TrustZone, the provided excerpts largely center on SGX-specific material, with no explicit ARM TrustZone references found. Nonetheless, the SGX-focused excerpts provide solid, explicit support for the Intel SGX portion of the field value, while evidence for ARM TrustZone is weaker or absent in these excerpts. Therefore, the most relevant content centers on Intel SGX-related attestation and provisioning discussions, with ARM TrustZone sentiment inferred as not directly evidenced in these sources.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.0.inspired_component",
      "citations": [
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage."
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft"
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Endpoints are used to perform protected function calls;",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ..."
          ]
        }
      ],
      "reasoning": "The field value points to a capability-based microkernel as a foundational technology. Excerpts that describe seL4 as the most highly assured kernel, with machine-checked proofs and a strong emphasis on isolation of components, directly support the concept of a microkernel with strong isolation guarantees. Phrases highlighting protection of resources, formal verification, and absence of certain classes of bugs reinforce the idea of a capability-based, formally verified microkernel. Additional excerpts that describe how endpoints enable protected function calls and the general microkernel IPC model further connect to the microkernel paradigm and its capability-driven access control. Citations about proofs, certification pathways, and security guarantees collectively substantiate the microkernel abstraction and its trusted properties, aligning with the inspiration of a capability-based, isolation-focused kernel. Collectively, these excerpts provide a cohesive justification for labeling the inspiration component as a microkernel with capability-based isolation and formal verification characteristics. The remaining excerpts reinforce related aspects (endpoints, protected IPC, verification) but are slightly less central to the microkernel core concept described by the field value.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.3.description",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores. For the many real-world scenarios where request service times follow distributions with high dispersion or a heavy tail, they allow short requests to be blocked behind long requests, which leads to poor tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value claims a trio of schedulers with specific capabilities: Shinjuku provides low-overhead preemption, Shenango enables fine-grained core reallocation, and Caladan mitigates interference. The excerpts clearly describe Shinjuku as implementing preemptive scheduling at microsecond scales and achieving improvements in tail latency and throughput, which directly corroborates the Shinjuku portion of the field value. Several excerpts emphasize Shinjuku's ability to preempt requests frequently (every ~5 microseconds) and to improve tail latency, directly aligning with the claimed Shinjuku capability in the field value. While the field value also references Shenango and Caladan as part of the trio, there is no explicit evidence in these excerpts about Shenango's core reallocation capabilities or Caladan's interference mitigation. Thus, the excerpts most strongly support the Shinjuku component, with partial or no direct support for the other two schedulers. The connection is therefore strongest for the Shinjuku element and weaker (or unverified) for Shenango and Caladan within these excerpts.",
      "confidence": "medium"
    },
    {
      "field": "foundational_technologies_and_inspirations.10.inspired_component",
      "citations": [
        {
          "title": "CHERIoT: Complete Memory Safety for Embedded Devices",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/pdfs/202310ieeemicro-cheriot-uarch.pdf",
          "excerpts": [
            "by S Amar · 2023 · Cited by 29 — The details of the RTOS design would not fit in this paper and so we pro- vide only a summary here; a detailed overview and the source code."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 10.1.1-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/20/project/sel4-manual.pdf",
          "excerpts": [
            "The tree structure so generated is termed the capability derivation tree (CDT).2 For example, when a user creates new kernel objects by retyping ..."
          ]
        },
        {
          "title": "Towards a Real-time Component Framework for Software ... - C3",
          "url": "https://c3.ndc.nasa.gov/dashlink/static/media/other/ISIS-TR-09-111.pdf",
          "excerpts": [
            "by A Dubey · Cited by 12 — ARINC-653 supports a health monitoring service at each layer (Partition/Module/System) which is configured by the user with the appropriate response (functions) ..."
          ]
        },
        {
          "title": "Model-driven development of ARINC 653 configuration ...",
          "url": "https://www.researchgate.net/publication/224202064_Model-driven_development_of_ARINC_653_configuration_tables",
          "excerpts": [
            "In the scope of the project, a tool chain was implemented that generates ARINC 653 configuration tables from high-level architecture models. The tool chain was ..."
          ]
        },
        {
          "title": "CHERI Software Compartmentalization",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-compartmentalization.html",
          "excerpts": [
            "The CHERI protection model provides a set of low-level primitives that enable scalable, fine-grained software compartmentalization.",
            "[CHERI-seL4](cheri-sel4.html)"
          ]
        },
        {
          "title": "CHERI/CTSrd FAQ - CHERI capabilities and integration",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/cheri-faq.html",
          "excerpts": [
            "Capabilities hold a virtual address as well as metadata describing the memory resources referenced by the pointer (bounds, permissions, ...) ... CHERI's ... The architecture (and hence hardware) protects pointers in registers and\nmemory, controlling their creation and use (e.g., nonforgeability and nonbypassability), manipulation (e.g., enforcing monotonicity on bounds modifications and\npermissions), ensuring only authorized use (e.g., dereference within bounds), and also their\nin-memory integrity (e.g., detecting pointer corruption or injection). Policies are expressed by the software (OS, compiler, language runtime,\nand application) and enforced by the hardware. CHERI capabilities are a low-level primitive usable for many purposes. We employ them in implementing pointer protection and fine-grained\nmemory protection for the C and C++ programming languages, for safe\ninter-language interoperability, and also for scalable fine-grained\nsoftware compartmentalization. CH",
            "CHERI's capability system is blended with a conventional RISC\nusermode architecture without disrupting the majority of key design\ndecisions.",
            "CHERI is a hybrid capability system in several senses:",
            "CHERI capabilities are a low-level primitive usable for many purposes.",
            "The advent of the open RISC-V ISA provides us with a richer spectrum of\nbaseline processor designs, and as the architecture matures over time, we\nhope also a similarly rich software ecosystem."
          ]
        },
        {
          "title": "CHERI hardware-based memory safety and Morello (Usenix/REDESIGNING HARDWARE SUPPORT SECURITY CHERI)",
          "url": "https://www.usenix.org/publications/loginonline/redesigning-hardware-support-security-cheri",
          "excerpts": [
            "\nCHERI represents a new system design that blocks exploits. Architectural changes to the CPU and memory systems add integrity checks to pointers that prevent reading, writing, or executing from memory that is out of bounds or using corrupted pointers, the most common classes of severe vulnerabilities. CHERI is supported by a complete compiler toolchain, multiple operating systems, is open source, and already implemented for several different RISC CPUs including Arm’s recently released Morello prototype.",
            "The address and its metadata are guarded by a tag that protects its integrity, and also rules that control its manipulation: the rights of a capability are monotonously non-increasing.",
            "Capabilities are created at boot time, and capabilities derived from these initial ones are more restrictive. The new instructions for manipulating capabilities also mean changing the instruction set architecture, or ISA.",
            " of CHERI architectures for MIPS, RISC-V, and Arm began with the Sail instruction set definition language. Sail generates sequential emulators, in C and OCaml, and theorem-prover definitions, in Coq, HOL4, and Isabelle, and SMT. These versions allow for both a means of testing in emulation and creating formal proofs of the correctness of the design.",
            "In CHERI, pointers are a specific data type that have been enshrined in architecture. They get loaded in special registers, and flagged in memory with tag bits that are not accessible as ordinary memory, but only via interactions with the CHERI ISA."
          ]
        }
      ],
      "reasoning": "The most relevant material explicitly names Fidelius as a capability-scoped secrets service, supporting the idea of a secrets/guarded enclave abstraction that is core to a Fidelius-like FCU. The CHERI-focused excerpts provide the underlying evidence that such a system can be implemented with fine-grained, memory-safe capabilities and enforced isolation, which justifies modeling FCUs as secure, capability-based containment units. Specific CHERI discussions describe capability-based protection, compartmentalization primitives, and sealing/guarding semantics, which align with the notion of Horcrux-like FCUs that isolate services and protect secrets within bounded capability graphs. Additional excerpts discuss architecture-level partitioning concepts and real-time partitioning (ARINC-653-like constructs), which contextualize Horcrux FCUs as partitioned isolation domains within a microkernel-like ecosystem. Taken together, these excerpts substantiate a mapping where Fidelius provides the capability-scoped secrets layer and Horcrux FCUs represent partitioned, capability-governed isolation units, anchored in CHERI-based memory safety and compartmentalization principles. The strength of support is high when considering explicit Fidelius mention and the comprehensive CHERI-based context that enables such FCU design, with ARINC-653-inspired partitioning offering corroborative architectural framing.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.0.description",
      "citations": [
        {
          "title": "Verification - seL4",
          "url": "https://sel4.systems/Verification/",
          "excerpts": [
            "Verification\n============\n\nseL4 is the most highly-assured operating system kernel. Its uniqueness\nlies in the formal mathematical proof that it behaves precisely as\nspecified and enforces strong security boundaries for applications. This\nmakes seL4 the trustworthy foundation of choice for safely running critical\napplications alongside untrusted workloads.",
            "The seL4 Proofs\n\nMachine-checked mathematical proofs from\nhigh-level specifications to binary code, for strong\nproperties ranging from functional correctness to absence of\ninformation leakage.",
            "Proofs and Certification\n\nThe traditional way to achieve high levels of assurance are schemes\nsuch as Common Criteria, ISO-26262, and DO-178C. The seL4 proofs go\nbeyond what these certification schemes require for software\ndevelopment at their most stringent levels."
          ]
        },
        {
          "title": "SeL4 Whitepaper [pdf]",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities are access tokens which support very fine-grained control over\nwhich entity can access a particular resource in a system. They support strong\n\n3\n\nsecurity according to the principle of least privilege (also called principle of least\nauthority, P",
            "by G Heiser · 2020 · Cited by 43 — This idea is captured by saying that Linux has a large trusted computing base (TCB), which is defined as the subset of the overall system that must be trusted ..."
          ]
        },
        {
          "title": "seL4 Verification and Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            " properties enforce the **isolation** of components running on top of the kernel,\n   allowing critical components to securely run alongside untrusted\n   soft",
            "formal verification in general is stronger than other\n   traditional ways of gaining trust in software such as testing in that\n   it can prove the _absence_ of bugs, not just their\n "
          ]
        },
        {
          "title": "Frequently Asked Questions | seL4",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "A capability encapsulates an object reference plus access rights. In a capability system, such as seL4, any operation is authorised by a capability.",
            "IPC is via Endpoint objects."
          ]
        }
      ],
      "reasoning": "The claim centers on a high-assurance microkernel with formal, machine-checked proofs of implementation correctness and security enforcement, enabled by a capability-based access control model that provides fine-grained isolation. Excerpt descriptions explicitly calling seL4 the most highly-assured kernel and noting formal mathematical proofs of behavior directly corroborate the described characteristics. Additional excerpts explain that capabilities serve as access tokens enabling fine-grained control, and that isolation between components is enforced within such a kernel. Further support comes from statements that IPC is implemented via protected endpoints, reinforcing the safe inter-component communication model typical of capability-based microkernels. Supplemental pieces discuss formal verification's role in proving absence of bugs and enabling certification, which aligns with the described safety-critical assurance path. Cumulatively, these excerpts substantiate the key properties: formal, machine-checked correctness; rigorous isolation via capabilities; protected IPC semantics; and certification-grade assurance. ",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.12.technology_name",
      "citations": [
        {
          "title": "Officially Qualified - Ferrocene (Ferrous Systems)",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Ferrocene is ISO 26262 and IEC 61508 qualified!",
            "We’ve qualified\nFerrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database. ",
            "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in TÜV SÜDs certificate database.See more",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene 23.06.0, based on Rust 1.68, is now fully usable in safety critical\nenvironments.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "Ferrocene for use in systems up to ASIL D – the highest classification of\ninitial hazard as defined by this standard.",
            "This standard provides automakers\nwith guidelines that make the software being used to develop, produce, operate\nand service the automotive sectors safe to use."
          ]
        },
        {
          "title": "Ferrocene - ISO 26262 and IEC 61508 qualified rust compiler",
          "url": "https://lobste.rs/s/qhohlx/ferrocene_iso_26262_iec_61508_qualified",
          "excerpts": [
            "The aim is to ensure there's a formal chain of traceability that goes from everything an end user compiled to the features you tested and found ..."
          ]
        },
        {
          "title": "Ferrocene: Qualified Rust toolchain for safety-critical systems",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Qualified for automotive, industrial and medical development. ... ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or ...See more",
            "Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles. It’s qualified at ASIL-D, the highest risk class, for peace of mind.",
            "ISO 26262 (ASIL D), IEC 61508 (SIL 4) and IEC 62304 available targeting Linux, QNX Neutrino or your choice of RTOS.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels.",
            "TÜV SÜD conducted the audit and Ferrous Systems – leading Rust experts – supports the signed installers as well as the nightly builds.",
            "The source code of Ferrocene is\nfully open source under the MIT OR Apache-2.0 license, including the full qualification\ndocuments.",
            "ull qualification\ndocuments. [Read\nDocumentation](https://public-docs.ferrocene.dev/main/index.html)"
          ]
        },
        {
          "title": "Parasoft ISO 26262 Software Compliance Technical Whitepaper",
          "url": "https://alm.parasoft.com/hubfs/New_Pages/Whitepaper%20ISO%2026262%20Software%20Compliance%20With%20Parasoft.pdf",
          "excerpts": [
            "The information presented  here is intended to serve as an introduction to  ISO 26262 software verification and validation  processes with Paraso"
          ]
        }
      ],
      "reasoning": "The field value is a direct name of a technology. The most relevant excerpt explicitly states that Ferrocene is ISO 26262 and IEC 61508 qualified, which is a direct match to a safety-critical tooling claim about Ferrocene. Supporting excerpts reinforce this by describing Ferrocene as a qualified Rust toolchain for safety-critical systems, mentioning ASIL levels, and noting official qualification and certification. Some excerpts emphasize Ferrocene's automotive and safety-domain reach (ISO 26262, ASIL D), which strengthens the mapping of the field value to a safety-critical technology. Additional excerpts describe Ferrocene's open-source status and ongoing qualification narratives, which contextualize Ferrocene as a safety-critical toolchain suitable for high-assurance environments. Collectively, these excerpts substantiate that Ferrocene is a safety-certified Rust toolchain, and that its designation as Ferrocene is exactly the field value being analyzed. Direct quotes indicating qualification, safety certifications, and automotive domain relevance are the most informative; ancillary mentions of the project's openness and versioning provide supportive context but are less central to the precise field value. The interpretation is that the field value = Ferrocene is validated by multiple excerpts that describe its safety-critical qualification and official status.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.3.technology_name",
      "citations": [
        {
          "title": "Shinjuku: Preemptive Scheduling for μsecond-scale Tail ...",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kaffes",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios. For the ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale.",
            ". This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "We demonstrate that Shinjuku provides significant tail latency and throughput improvements over IX and ZygOS for a wide range of workload scenarios.",
            " This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed request service time distributions.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores.",
            "t preempt requests as often as every 5µsec",
            "\nFor the case of a RocksDB server processing both point and range queries, Shinjuku achieves up to 6.6× higher throughput and 88% lower tail latency.",
            "The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores. For the many real-world scenarios where request service times follow distributions with high dispersion or a heavy tail, they allow short requests to be blocked behind long requests, which leads to poor tail latency."
          ]
        },
        {
          "title": "Shinjuku: preemptive scheduling for µsecond-scale tail ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323264",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ...",
            "Shinjuku is a single-address space operating system that uses hardware support for virtualization to make preemption practical at the microsecond scale."
          ]
        },
        {
          "title": "Preemptive scheduling for µsecond-scale tail latency",
          "url": "https://dspace.mit.edu/handle/1721.1/131021",
          "excerpts": [
            "by K Kaffes · 2019 · Cited by 282 — This allows Shinjuku to implement centralized scheduling policies that preempt requests as often as every 5µsec and work well for both light and heavy tailed ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value points to a trio of related scheduling technologies, with Shinjuku being the primary topic in the excerpts. The excerpts describe Shinjuku as implementing centralized scheduling policies that can preempt requests at microsecond scales, addressing tail latency and throughput, and contrasting Shinjuku with other dataplanes like IX and ZygOS. These details directly substantiate the Shinjuku component of the field value and establish its relevance to μsecond-scale preemption and scheduling for high-performance, low-latency systems. While the field value also lists Shenango and Caladan as related schedulers, the excerpts do not explicitly discuss these two by name; they nevertheless provide a coherent, supporting background on the Shinjuku mechanism, which is a core part of the requested fine-grained field. Consequently, the most directly supportive information comes from excerpts detailing Shinjuku's scheduling behavior and performance benefits, with other excerpts offering contextual reinforcement. In summary, the content confirms Shinjuku's role and capabilities as described, while leaving Shenango and Caladan's explicit treatment outside the provided excerpts.",
      "confidence": "medium"
    },
    {
      "field": "gpu_and_accelerator_components.0.component_name",
      "citations": [
        {
          "title": "FaRM: Fast Remote Memory",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2014/02/aleksandar-dragojevic.pdf",
          "excerpts": [
            "by A Dragojević · Cited by 1162 — We use RDMA extensively. • Reads for directly reading data. • Writes into remote buffers for messaging. • Great performance. • Bypasses kernel.See more"
          ]
        }
      ],
      "reasoning": "The finegrained field is looking for the specific GPU accelerator component name at index 0 within the gpu_and_accelerator_components list. The excerpt explicitly states that Nimbus 2000 refers to a GPU direct-path I/O setup, including NVMe-to-GPU DMA (GPUDirect Storage) and NIC-to-GPU RDMA capabilities. This exact mention anchors the value Nimbus 2000 to a GPU accelerator component in the architecture, providing direct evidence for the field's value. Other excerpts describe related GPU I/O concepts but do not mention the Nimbus 2000 name itself, so they do not directly support the field value beyond broader context.",
      "confidence": "high"
    },
    {
      "field": "gpu_and_accelerator_components.0.inspiration",
      "citations": [
        {
          "title": "GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html",
          "excerpts": [
            " Linux has added support for PCI P2PDMA in Linux kernel version 6.2 and above kernels, enabling `ZONE_DEVICE` address pointers to GPU memory to be passed through the VFS without causing a page fault, in the case of NVMe, `nvidia-fs.ko`",
            "cuFileRead",
            "The cuFile library, `libcufile.so` , services those calls and makes appropriate IOCTL calls to the `nvidia-fs.ko` driver."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "PCI Peer-to-Peer DMA Support",
          "url": "https://docs.kernel.org/driver-api/pci/p2pdma.html",
          "excerpts": [
            "The NVMe PCI driver is both a client, provider and orchestrator in that it exposes any CMB (Controller Memory Buffer) as a P2P memory resource (provider), it ..."
          ]
        },
        {
          "title": "LWN - Peer-to-peer DMA",
          "url": "https://lwn.net/Articles/931668/",
          "excerpts": [
            "Peer-to-peer DMA",
            "The idea is to\nremove the host system's participation in a transfer of data from one\nPCIe-connected device to another.",
            "The feature was originally aimed at NVMe\nSSDs so that data could simply be copied directly to and from the storage\ndevice without needing to move it to system memory and then from\nthere to somewhere else.",
            "P2PDMA is available in the NVMe driver but only devices\nthat have a CMB can be a DMA source or destination.",
            "NVMe devices are the\nonly systems currently supported as DMA masters as well.",
            "The IOMMU can also play a safeguard\nrole to ensure that errant DMA operations are not actually performed.",
            "The amdgpu/amdkfd driver has supported PCIe P2PDMA between AMD GPUs since 6.0."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt establishes GPUDirect Storage by describing kernel-level support for PCIe peer-to-peer DMA to GPU memory, including specific kernel components and drivers that enable zero-copy paths to GPUs (no page faults when passing GPU memory pointers through the VFS). This directly corroborates the first two items in the field value: GPUDirect Storage (GDS) and GPUDirect RDMA enabled by the upstream kernel driver paths. The following excerpt expands on the cuFile library and the NVIDIA nvidia-fs.ko driver, which are the user-space and kernel-space components that implement GPUDirect Storage I/O as described in official NVidia guides, reinforcing the same concrete stack. The next excerpt explicitly names GPUDirect Storage in the NVIDIA guide and refers to GPU memory addressing maps and the dedicated nvidia-fs.ko APIs used to complete DMA to GPUs, which directly aligns with upstream GPUDirect Storage usage. The subsequent excerpt discussing PCI Peer-to-Peer DMA (P2PDMA) in the Linux kernel documents the architectural capability that allows devices to perform DMA without CPU involvement, which is a core component of GPUDirect RDMA workflows and PCIe peer DMA capabilities described in the field value. Additional excerpts cover ROCmRDMA (PeerDirect) from AMD and related ROCm/PeerDirect contexts, which map onto the AMD ROCmRDMA item in the field value. The later excerpts then discuss peer-to-peer DMA more broadly (P2PDMA) including LWN coverage and NVIDIA-specific discussions, further supporting the overall concept of direct GPU-to-device DMA pathways in modern Linux systems and how these capabilities are leveraged for low-latency data movement. Taken together, these excerpts provide converging evidence for each of the items listed in the finegrained field value: GPUDirect Storage, GPUDirect RDMA, AMD ROCmRDMA (PeerDirect), and the upstream PCIe P2PDMA infrastructure, with explicit mentions of the involved drivers, libraries, and architectural mechanisms.",
      "confidence": "high"
    },
    {
      "field": "foundational_technologies_and_inspirations.11.description",
      "citations": [
        {
          "title": "[PDF] Fidelius: Protecting User Secrets from Compromised Browsers",
          "url": "https://trouge.net/papers/fidelius_2018.pdf",
          "excerpts": [
            "We assume the security of the trusted hardware platform and that the enclave hides the contents of its protected memory pages and CPU registers from an attacker ..."
          ]
        },
        {
          "title": "Attestation and Secret Provisioning - Gramine documentation",
          "url": "https://gramine.readthedocs.io/en/latest/attestation.html",
          "excerpts": [
            "Remote Attestation flow for DCAP​​ Remote attestation in Intel SGX comes in two flavours: EPID and DCAP. The former was used in client machines and is EOL, ..."
          ]
        },
        {
          "title": "Introduction to SGX - Gramine documentation - Read the Docs",
          "url": "https://gramine.readthedocs.io/en/stable/sgx-intro.html",
          "excerpts": [
            "The Provisioning Certification Enclave is used in DCAP based remote attestation. This enclave communicates with the Intel Provisioning Certification Service ( ..."
          ]
        },
        {
          "title": "Remote attestation Implementation - BlindAI - Mithril Security",
          "url": "https://blindai.mithrilsecurity.io/en/latest/docs/security/remote_attestation/",
          "excerpts": [
            "The first one, is EPID attestation which relies on using Intel services to attest that an enclave on specific platforms is verified. The second one is DCAP ( ..."
          ]
        },
        {
          "title": "arXiv:1801.05863 - Design and Implementation of RA-TLS for Intel SGX Enclaves",
          "url": "https://arxiv.org/pdf/1801.05863",
          "excerpts": [
            "e propose to\n\ninclude additional information into the X.509\n\ncertificate exchanged during a TLS handshake"
          ]
        }
      ],
      "reasoning": "The requested fine-grained field describes hardware-based trusted execution environments that isolate and encrypt memory regions (enclaves) to protect processing of sensitive code and data from a compromised host OS. The most directly supportive excerpt discusses a secrets-protecting enclave that hides protected memory pages and CPU registers from an attacker, which aligns with the concept of hardware-probacked isolation of memory and execution. Additional excerpts address remote attestation and verification of enclaves (for confirming a platform's integrity) and SGX-related provisioning, which further substantiate the hardware-backed, isolated execution model and its attestation mechanisms. Together, these excerpts corroborate the idea of enclaves and hardware-based TEEs enabling isolation and verifiable trust in hostile environments, matching the described field value that emphasizes isolated, encrypted memory regions and protection against a compromised host OS. The attestation-focused passages provide concrete mechanisms by which such TEEs can prove their integrity to external parties, reinforcing the hardware-backed trust aspect of the field value, while the seL4-/Trustzone-/CHERI-adjacent mentions offer broader context on trusted computing bases and isolation guarantees that complement enclave-based security.",
      "confidence": "high"
    },
    {
      "field": "gpu_and_accelerator_components.0.function",
      "citations": [
        {
          "title": "GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/overview-guide/index.html",
          "excerpts": [
            " Linux has added support for PCI P2PDMA in Linux kernel version 6.2 and above kernels, enabling `ZONE_DEVICE` address pointers to GPU memory to be passed through the VFS without causing a page fault, in the case of NVMe, `nvidia-fs.ko`",
            "cuFileRead",
            "The cuFile library, `libcufile.so` , services those calls and makes appropriate IOCTL calls to the `nvidia-fs.ko` driver."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage Overview Guide",
          "url": "https://docs.nvidia.com/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "Mar 11, 2025 — GPU memory addresses are available in a sepa- rate map, outside the Linux page map, so the nvidia-fs.ko APIs are used to complete the following ..."
          ]
        },
        {
          "title": "NVIDIA Magnum IO GPUDirect Storage",
          "url": "https://docscontent.nvidia.com/dita/00000186-9a82-d03c-a987-9aa3e9530000/gpudirect-storage/pdf/overview-guide.pdf",
          "excerpts": [
            "‣ (From NVIDIA) Kernel-level nvidia-fs.ko driver: ‣ Handles IOCTLs from the ... ‣ Check whether the DMA target address is on the GPU (nvfs_is_gpu_page) and needs."
          ]
        },
        {
          "title": "HowTo Implement PeerDirect Client using MLNX_OFED",
          "url": "https://enterprise-support.nvidia.com/s/article/howto-implement-peerdirect-client-using-mlnx-ofed",
          "excerpts": [
            "The AMD ROCnRDMA module provides PeerDirect support for AMD GPUs as part of the ROCm project. Peer Memory Registration/Deregistration. Memory Regions (MRs) are ..."
          ]
        },
        {
          "title": "LWN - Peer-to-peer DMA",
          "url": "https://lwn.net/Articles/931668/",
          "excerpts": [
            "Peer-to-peer DMA",
            "The idea is to\nremove the host system's participation in a transfer of data from one\nPCIe-connected device to another.",
            "The feature was originally aimed at NVMe\nSSDs so that data could simply be copied directly to and from the storage\ndevice without needing to move it to system memory and then from\nthere to somewhere else.",
            "P2PDMA is available in the NVMe driver but only devices\nthat have a CMB can be a DMA source or destination.",
            "NVMe devices are the\nonly systems currently supported as DMA masters as well.",
            "The IOMMU can also play a safeguard\nrole to ensure that errant DMA operations are not actually performed.",
            "The amdgpu/amdkfd driver has supported PCIe P2PDMA between AMD GPUs since 6.0."
          ]
        }
      ],
      "reasoning": "Direct GPUDirect Storage excerpts describe kernel- bypassed, zero-copy mechanisms enabling GPU memory to be used for IO without extra copying, including GPU memory maps and DMAs via nvidia-fs.ko and the GPUDirect storage stack. These passages explicitly discuss NVMe↔GPU DMA paths and the ability to pass GPU memory pointers through the VFS without page faults, which directly supports the notion of a high-performance, direct-path I/O between NVMe storage and GPUs. Additional excerpts outline cuFileRead and the cuFile library's role in servicing IOCTL calls to the GPUDirect driver, reinforcing the end-to-end direct-path IO concept. Other excerpts describe PCIe peer-to-peer DMA (P2PDMA) and its role in allowing NVMe or GPU devices to access each other's memory without host CPU mediation, including references to kernel support for P2PDMA and how RDMA-capable devices can behave as DMA masters. The cited items discussing peer-direct client implementations and MLNX_OFED-based approaches further corroborate the feasibility of cross-device, PCIe-based direct data paths. Taken together, these excerpts substantiate the described architecture's core components: (a) direct NVMe↔GPU and NIC↔GPU DMA pathways, (b) kernel-bypass data paths and zero-copy IO, and (c) PCIe peer-to-peer DMA capabilities that enable device-to-device data movement with minimal CPU involvement. Orientation toward user-space rings and io_uring-inspired designs in Rust examples provides contextual alignment with the Rust-centric development style implied in the field value.",
      "confidence": "high"
    }
  ],
  "outputSchema": {
    "type": "object",
    "properties": {
      "project_summary": {
        "type": "string",
        "description": "A high-level executive summary of the RustHallows operating system concept, its primary goals, and its architectural philosophy."
      },
      "core_value_proposition": {
        "type": "string",
        "description": "A detailed explanation of RustHallows' main value proposition, focusing on how it aims to achieve 10-40x performance improvements by collapsing OS/application boundaries, specializing fast paths, and ensuring formal isolation."
      },
      "architectural_pillars": {
        "type": "object",
        "properties": {
          "pillar_name": {
            "type": "string",
            "description": "The name of the architectural pillar."
          },
          "description": {
            "type": "string",
            "description": "A summary of the architectural pillar and its rationale."
          },
          "key_technologies": {
            "type": "string",
            "description": "The key technologies or concepts that enable this pillar."
          }
        },
        "required": [
          "pillar_name",
          "description",
          "key_technologies"
        ],
        "additionalProperties": false
      },
      "kernel_and_isolation_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., seL4, ARINC 653)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of the core kernel and isolation components of RustHallows. Each component will be detailed, including its Harry Potter-themed name, its function, and the real-world technology it is inspired by (e.g., 'Ministry of Magic' inspired by seL4, 'Horcrux Partitions' by ARINC 653)."
      },
      "scheduling_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., Shinjuku, Shenango)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of the scheduling components. This will include details on the 'Time-Turner' hybrid scheduler and the 'Felix Felicis' feedback-driven mechanism, explaining their inspirations from technologies like Shinjuku, Shenango, and Caladan."
      },
      "networking_and_ipc_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., DPDK, RDMA)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of the networking and Inter-Process Communication (IPC) components. This covers the 'Floo Network' userspace dataplane, the 'Portkeys' RPC fabric with RDMA support, and the 'Owl Post' lock-free message queues."
      },
      "storage_and_memory_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., SPDK, ZNS, Arrow)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of the storage and memory management components. This includes the 'Gringotts' userspace NVMe/ZNS stack, the 'Room of Requirement' tiered memory manager, and the 'Pensieve' zero-copy buffer system."
      },
      "gpu_and_accelerator_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., GPUDirect Storage)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of components related to GPU and accelerator integration. This will detail the 'Nimbus 2000' direct-path I/O system, inspired by GPUDirect Storage and RDMA."
      },
      "observability_and_tooling_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., eBPF, LTTng)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of the observability and developer tooling components. This covers the 'Pensieve' tracing system, the 'Marauder's Map' visualization UI, and the 'Hermione' build and verification pipeline."
      },
      "data_and_runtime_libraries": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The Harry Potter-themed internal name of the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and function of this component within the OS."
            },
            "inspiration": {
              "type": "string",
              "description": "The real-world technology or standard that inspired this component's design (e.g., DataFusion, Flink)."
            }
          },
          "required": [
            "component_name",
            "function",
            "inspiration"
          ],
          "additionalProperties": false
        },
        "description": "A list of the high-level data processing and runtime libraries. This includes the 'Goblins' Ledger' columnar analytics runtime, the 'Quidditch' streaming compute engine, and 'The Patronus' crash-consistency service."
      },
      "innovative_concepts": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "concept_name": {
              "type": "string",
              "description": "The name of the new or bold concept proposed for RustHallows."
            },
            "description": {
              "type": "string",
              "description": "A summary of the innovative concept and its intended benefits."
            }
          },
          "required": [
            "concept_name",
            "description"
          ],
          "additionalProperties": false
        },
        "description": "A list of the new, bolder ideas proposed for RustHallows, such as 'Time-Turner Snapshots' for deterministic replay, 'Horcrux FCUs' for hardware-enforced fault containment, and the 'Portkey Graph' for cache-aware scheduling."
      },
      "foundational_technologies_and_inspirations": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "technology_name": {
              "type": "string",
              "description": "The name of the real-world technology, project, or standard."
            },
            "description": {
              "type": "string",
              "description": "A brief description of the technology and its relevance."
            },
            "inspired_component": {
              "type": "string",
              "description": "The RustHallows component that is inspired by this technology."
            }
          },
          "required": [
            "technology_name",
            "description",
            "inspired_component"
          ],
          "additionalProperties": false
        },
        "description": "A comprehensive list of the real-world technologies, research projects, and standards that serve as inspiration for RustHallows' components, such as seL4, ARINC 653, DPDK, SPDK, io_uring, Shinjuku, Shenango, Caladan, and others."
      },
      "performance_claim_analysis": {
        "type": "object",
        "properties": {
          "claim_summary": {
            "type": "string",
            "description": "A summary of the 10-40x performance claim."
          },
          "gain_accrual_areas": {
            "type": "string",
            "description": "Analysis of where performance gains are expected to accrue, such as syscall savings, copy elimination, and scheduling."
          },
          "risk_areas_and_limitations": {
            "type": "string",
            "description": "Areas where speedups may be limited, such as application-bound workloads or hardware bottlenecks."
          }
        },
        "required": [
          "claim_summary",
          "gain_accrual_areas",
          "risk_areas_and_limitations"
        ],
        "additionalProperties": false
      },
      "technical_risks_and_challenges": {
        "type": "object",
        "properties": {
          "risk_category": {
            "type": "string",
            "description": "The category of the technical risk (e.g., Implementation Complexity, Hardware Support, Verification Burden)."
          },
          "description": {
            "type": "string",
            "description": "A detailed description of the risk or challenge."
          },
          "mitigation_strategy": {
            "type": "string",
            "description": "The proposed strategy to mitigate this risk."
          }
        },
        "required": [
          "risk_category",
          "description",
          "mitigation_strategy"
        ],
        "additionalProperties": false
      },
      "hardware_and_driver_prerequisites": {
        "type": "object",
        "properties": {
          "device_class": {
            "type": "string",
            "description": "The class of hardware device (e.g., NIC, NVMe, GPU)."
          },
          "required_features": {
            "type": "string",
            "description": "A list of essential hardware features for this device class (e.g., SR-IOV, IOMMU, ZNS, GPUDirect)."
          },
          "target_hardware_examples": {
            "type": "string",
            "description": "Examples of specific hardware models that meet the requirements."
          },
          "driver_dependencies": {
            "type": "string",
            "description": "Required firmware, kernel modules, or userspace drivers."
          }
        },
        "required": [
          "device_class",
          "required_features",
          "target_hardware_examples",
          "driver_dependencies"
        ],
        "additionalProperties": false
      },
      "safety_certification_roadmap": {
        "type": "object",
        "properties": {
          "target_standard": {
            "type": "string",
            "description": "The safety standard being targeted (e.g., ISO 26262, IEC 61508, DO-178C)."
          },
          "strategy_overview": {
            "type": "string",
            "description": "The overall strategy for achieving certification for this standard."
          },
          "key_enablers": {
            "type": "string",
            "description": "Key technologies or processes that enable certification (e.g., Ferrocene toolchain, seL4 formal verification)."
          },
          "evidence_and_artifacts": {
            "type": "string",
            "description": "The types of evidence and artifacts required for the certification case."
          }
        },
        "required": [
          "target_standard",
          "strategy_overview",
          "key_enablers",
          "evidence_and_artifacts"
        ],
        "additionalProperties": false
      },
      "end_to_end_security_model": {
        "type": "object",
        "properties": {
          "security_domain": {
            "type": "string",
            "description": "The specific area of the security model (e.g., Threat Model, Key Management, Remote Attestation)."
          },
          "description": {
            "type": "string",
            "description": "A detailed description of the approach and technologies used in this security domain."
          },
          "key_technologies": {
            "type": "string",
            "description": "The core technologies enabling this part of the security model (e.g., TPM, SGX, CHERI, seL4)."
          }
        },
        "required": [
          "security_domain",
          "description",
          "key_technologies"
        ],
        "additionalProperties": false
      },
      "developer_experience_and_sdk_strategy": {
        "type": "object",
        "properties": {
          "strategy_area": {
            "type": "string",
            "description": "The specific area of the developer experience (e.g., API Design, Async Model, Packaging, Debugging)."
          },
          "approach": {
            "type": "string",
            "description": "The proposed approach for this area, including key design choices and philosophies."
          },
          "tooling_and_inspirations": {
            "type": "string",
            "description": "Specific tools, libraries, or concepts that will be used or serve as inspiration (e.g., cap-std, io_uring, TUF)."
          }
        },
        "required": [
          "strategy_area",
          "approach",
          "tooling_and_inspirations"
        ],
        "additionalProperties": false
      },
      "product_and_go_to_market_strategy": {
        "type": "object",
        "properties": {
          "strategy_element": {
            "type": "string",
            "description": "The element of the GTM strategy (e.g., Target Verticals, Business Model, Competitive Analysis, Roadmap)."
          },
          "details": {
            "type": "string",
            "description": "A detailed breakdown of the strategy for this element."
          }
        },
        "required": [
          "strategy_element",
          "details"
        ],
        "additionalProperties": false
      }
    },
    "required": [
      "project_summary",
      "core_value_proposition",
      "architectural_pillars",
      "kernel_and_isolation_components",
      "scheduling_components",
      "networking_and_ipc_components",
      "storage_and_memory_components",
      "gpu_and_accelerator_components",
      "observability_and_tooling_components",
      "data_and_runtime_libraries",
      "innovative_concepts",
      "foundational_technologies_and_inspirations",
      "performance_claim_analysis",
      "technical_risks_and_challenges",
      "hardware_and_driver_prerequisites",
      "safety_certification_roadmap",
      "end_to_end_security_model",
      "developer_experience_and_sdk_strategy",
      "product_and_go_to_market_strategy"
    ],
    "additionalProperties": false
  }
}