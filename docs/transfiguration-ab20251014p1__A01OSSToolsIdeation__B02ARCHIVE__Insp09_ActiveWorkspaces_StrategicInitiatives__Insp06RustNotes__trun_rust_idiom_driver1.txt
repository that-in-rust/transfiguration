{
  "input": "## üéØ Apex (Goal & Edge)\n\n* **Goal:** Vertically‚Äëintegrated, **Rust‚Äëonly** stack delivering **10‚Äì40√ó** perf gains for safety‚Äë/security‚Äëcritical systems via **partitioned microkernel + specialized schedulers + Rust‚Äënative frameworks + macro DSL**.&#x20;\n* **Edge:** Zero‚Äëcost abstractions, deterministic execution, kernel‚Äëbypass I/O, formalizable interfaces, cert‚Äëready toolchain. &#x20;\n\n---\n\n## üß± Core Architecture (4 Layers ‚Üí one story)\n\n* **L1 OS (‚ÄúMinistry of Magic‚Äù)**: Real‚Äëtime **partitioned microkernel**, **capability‚Äëstyle isolation**, ARINC‚Äë653‚Äëlike time/space partitioning; **Protego Maxima** isolation (spatial/temporal/I/O). IPC fabric seed: **‚ÄúApparition‚Äù** (sub‚Äë5¬µs aspiration).&#x20;\n  *Prior art for search:* **seL4** (formally verified, capability‚Äëbased), **ARINC 653 APEX**. ([sel4.systems][1], [Wikipedia][2], [NASA][3])\n* **L2 Schedulers:** Workload‚Äëspecific schedulers (API/UI/DB), **microsecond‚Äëscale core rebalancing**, EDF/RM variants, thread‚Äëper‚Äëcore paths. Seed: **‚ÄúSorting Hat API.‚Äù**&#x20;\n  *Prior art for search:* **Shenango** (cores every \\~5¬µs), **RackSched**. ([amyousterhout.com][4], [USENIX][5])\n* **L3 Frameworks:** Rust‚Äënative building blocks (see Modules below).&#x20;\n* **L4 DSL (‚ÄúParseltongue‚Äù)**: Declarative, macro‚Äëdriven (proc‚Äëmacros via `syn`/`quote`), **LLM‚Äëfriendly** verbose keywords, **zero runtime overhead**; high‚Äëlevel **Muggle‚ÄëWorthy** macros. &#x20;\n\n---\n\n## üß© OSS Module Seeds (ship as independent crates first)\n\n**OS & Isolation**\n\n* **Protego Maxima**: capability descriptors; ARINC‚Äëstyle partition scheduler (major/minor frames); IOMMU policy enforcer.&#x20;\n* **Apparition IPC**: zero‚Äëcopy, bounded‚Äëlatency channels; single‚Äëproducer/single‚Äëconsumer and MPSC variants; shared‚Äëmem rings; optional RDMA path.&#x20;\n\n**Schedulers**\n\n* **Sorting Hat**: pluggable policies (EDF/RM/fair/latency‚ÄëSLO); microsecond core‚Äëloans; per‚Äëpartition runtime budgets & admission control. (Search anchors: Shenango/RackSched.)  ([amyousterhout.com][4], [USENIX][5])\n\n**I/O & Networking**\n\n* **Slytherin**: log‚Äëstructured messaging with **exactly‚Äëonce** semantics; `io_uring`‚Äëaccelerated brokerless streams; WAL + idempotent consumers.  ([man7.org][6])\n* **Patronus Proxy**: Rust HTTP/TCP proxy with **SO\\_REUSEPORT**, thread‚Äëper‚Äëcore, TLS via `rustls`; **Pingora‚Äëinspired** architecture.  ([The Cloudflare Blog][7])\n\n**Data Systems**\n\n* **Gringotts‚ÄëOLTP**: in‚Äëmem optimistic MVCC, WAL, Raft replication; predictable latency.&#x20;\n* **Gringotts‚ÄëOLAP**: **Arrow/DataFusion** vectorized engine, morsel‚Äëdriven parallelism; columnar cache‚Äëaware ops.  ([datafusion.apache.org][8])\n\n**DX, Safety & Migration**\n\n* **Parseltongue Core**: proc‚Äëmacro pipeline; domain extensions (Basilisk=API, Slytherin=streams, Nagini=UI spec sans GPU).&#x20;\n* **Veritaserum**: deterministic replay + **time‚Äëtravel debugging** integrated with DSL.&#x20;\n* **Polyjuice**: C‚ÜíRust transpile assist (c2rust‚Äëstyle) + guided refactors to safe idioms.&#x20;\n* **Legilimency**: cross‚Äëlayer metrics (cycles, cache miss, IPC latency, scheduler decisions) with near‚Äëzero overhead.&#x20;\n* **Spellbook** build: PGO, LTO, `sccache`, **`mold`/`lld`**, reproducible profiles.&#x20;\n* **Triwizard Bench**: reproducible perf harness (SPEC‚Äëstyle rules, MLPerf‚Äëlike reporting).&#x20;\n\n**Security & Compliance**\n\n* **Unbreakable Vow**: enclave binding (SGX/TrustZone abstraction); attestable partitions.&#x20;\n* **Obliviate** (secure wipe), **Fidelius** (at‚Äërest crypto), **Occlumency Secrets** (key mgmt).&#x20;\n* **Certification Path**: Ferrocene toolchain; ISO‚ÄØ26262 ASIL‚ÄëD, IEC‚ÄØ61508 SIL‚Äë4, DO‚Äë178C DAL‚ÄëA (with CAST‚Äë32A), Common Criteria target.&#x20;\n\n---\n\n## üß† Meta‚ÄëPatterns (what to search / enforce in design)\n\n* **Determinism‚Äëfirst**: cyclic executive + bounded queues + reproducible builds.&#x20;\n* **Zero‚Äëcopy everywhere**: `rkyv`/Arrow buffers, shared‚Äëmem rings, `io_uring` paths.  ([man7.org][6])\n* **Thread‚Äëper‚Äëcore hot paths**: cache affinity; no cross‚Äëcore locks in data plane. (See Pingora/Shenango.) ([The Cloudflare Blog][7], [amyousterhout.com][4])\n* **Capability‚Äëdefined surfaces**: keep APIs verifiable; policy expressed in DSL ‚Üí compiled caps.&#x20;\n* **Monorepo + workspaces**: shared versions, unified CI, cross‚Äëlayer tests.&#x20;\n* **Formalizable specs**: Parseltongue ‚Üí TLA+/Isabelle models before deploy (Room of Requirement vision).&#x20;\n\n---\n\n## üîë High‚ÄëSignal Keywords (copy straight into search/prompts)\n\n```\nRust microkernel, capability-based security, ARINC 653 APEX, time/space partitioning,\ndeterministic replay debugger, thread-per-core runtime, microsecond core rebalancing,\nio_uring zero-copy I/O, exactly-once log semantics, optimistic MVCC, vectorized OLAP Arrow,\nDataFusion extensions, Raft replication, SO_REUSEPORT load balancing, rustls TLS,\nproc-macro DSL syn/quote, zero-cost abstractions, PGO LTO mold sccache, Common Criteria EAL,\nFerrocene ISO 26262 IEC 61508 DO-178C, CAST-32A multicore, IOMMU isolation,\nbounded-latency IPC rings, reproducible benchmarking harness\n```\n\n(Anchors: seL4; ARINC‚ÄØ653; Shenango; Pingora; DataFusion; io\\_uring.) ([sel4.systems][1], [Wikipedia][2], [amyousterhout.com][4], [The Cloudflare Blog][7], [datafusion.apache.org][8], [man7.org][6])\n\n---\n\n## üó∫Ô∏è Minimal Research Prompts (feed to LLMs verbatim)\n\n* **‚ÄúDesign a Rust capability table + cap‚Äëgrant protocol compatible with ARINC‚Äë653‚Äëstyle partitions; prove absence of cross‚Äëpartition leaks under scheduler preemption.‚Äù** ([Wikipedia][2])\n* **‚ÄúImplement a microsecond‚Äëscale scheduler (Shenango‚Äëlike) with core loans & latency‚ÄëSLOs; compare EDF vs RM under bursty load.‚Äù** ([amyousterhout.com][4])\n* **‚ÄúSpecify a zero‚Äëcopy IPC ring for Apparition: memory layout, back‚Äëpressure, timeouts; add formal bounds on p99 enqueue/dequeue.‚Äù**&#x20;\n* **‚ÄúBuild Slytherin: exactly‚Äëonce stream processing over `io_uring`; design idempotent consumer protocol + WAL compaction.‚Äù**  ([man7.org][6])\n* **‚ÄúAuthor Parseltongue macros for CRUD APIs (Basilisk) and stream schemas (Slytherin); generate Rust types + policy checks at compile‚Äëtime.‚Äù**&#x20;\n* **‚ÄúCreate Veritaserum: record/replay hooks in scheduler + IPC; design timeline index and deterministic I/O gates.‚Äù**&#x20;\n* **‚ÄúDraft Triwizard Bench: SPEC‚Äëstyle methodology, MLPerf‚Äëlike disclosures; automate perf variance control.‚Äù**&#x20;\n\n---\n\n## ‚ö†Ô∏è Naming/Legal (use codenames internally only)\n\n* **High risk** using HP‚Äëthemed names publicly; rebrand externally.&#x20;\n\n---\n\n## üì¶ Ultra‚ÄëSuccinct ‚ÄúTag Cloud‚Äù (one‚Äëliner)\n\n**RustHallows, partitioned microkernel, ARINC‚Äë653, capability model, deterministic IPC, microsecond scheduler, thread‚Äëper‚Äëcore, kernel‚Äëbypass I/O (`io_uring`), Slytherin log bus (exactly‚Äëonce), Patronus proxy (Pingora‚Äëinspired), Gringotts OLTP/OLAP (Arrow/DataFusion), Basilisk API framework, Parseltongue proc‚Äëmacro DSL (LLM‚Äëfriendly), Veritaserum time‚Äëtravel debugger, Legilimency observability, Polyjuice C‚ÜíRust, Spellbook build (PGO/LTO/mold/sccache), Triwizard Bench, Ferrocene‚Äëaccelerated certification (ISO‚ÄØ26262/IEC‚ÄØ61508/DO‚Äë178C/CC).**    ([sel4.systems][1], [Wikipedia][2])\n\n---\n\n### Notes\n\n* External anchors above are **for research context only** (not design dependencies): **seL4** (formally verified, capability‚Äëbased); **ARINC 653 APEX** (time/space partitioning); **Shenango/RackSched** (¬µs‚Äëscale scheduling); **io\\_uring** (kernel‚Äëbypass async I/O); **Pingora** (Rust proxy framework); **DataFusion/Arrow** (vectorized OLAP). ([sel4.systems][1], [Wikipedia][2], [amyousterhout.com][4], [USENIX][5], [man7.org][6], [The Cloudflare Blog][7], [datafusion.apache.org][8])\n\nIf you want, I can convert this into a **single YAML/JSON prompt file** for direct ingestion by your research agent.\n\n[1]: https://sel4.systems/?utm_source=chatgpt.com \"The seL4 Microkernel | seL4\"\n[2]: https://en.wikipedia.org/wiki/ARINC_653?utm_source=chatgpt.com \"ARINC 653\"\n[3]: https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf?utm_source=chatgpt.com \"IV&V on Orion's ARINC 653 Flight Software Architecture\"\n[4]: https://amyousterhout.com/papers/shenango_nsdi19.pdf?utm_source=chatgpt.com \"Shenango: Achieving High CPU Efficiency for Latency- ...\"\n[5]: https://www.usenix.org/system/files/osdi20-zhu.pdf?utm_source=chatgpt.com \"RackSched: A Microsecond-Scale Scheduler for Rack- ...\"\n[6]: https://man7.org/linux/man-pages/man7/io_uring.7.html?utm_source=chatgpt.com \"io_uring(7) - Linux manual page\"\n[7]: https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/?utm_source=chatgpt.com \"How we built Pingora, the proxy that connects Cloudflare to ...\"\n[8]: https://datafusion.apache.org/?utm_source=chatgpt.com \"Apache DataFusion ‚Äî Apache DataFusion documentation\"",
  "output": {
    "project_summary": {
      "goal": "To develop a vertically-integrated, Rust-only software stack that achieves significant performance gains for safety- and security-critical systems. This is accomplished by combining a partitioned microkernel, specialized schedulers, Rust-native frameworks, and a macro-driven Domain Specific Language (DSL).",
      "target_performance_gain": "The project targets a 10-40x performance improvement over baseline systems.",
      "target_domain": "The intended application domain is safety-critical and security-critical systems, such as those found in automotive, aerospace, and industrial control.",
      "core_technology": "The fundamental technology choice for the entire stack is the Rust programming language, aiming for a 'Rust-only' implementation to leverage its safety guarantees and performance characteristics throughout the system."
    },
    "core_architecture_overview": {
      "layer_1_os": "Codenamed 'Ministry of Magic', this is a real-time partitioned microkernel. It features capability-style isolation and ARINC-653-like time and space partitioning. It includes a component named 'Protego Maxima' for enforcing spatial, temporal, and I/O isolation. The layer's Inter-Process Communication (IPC) fabric, codenamed 'Apparition', aims for sub-5 microsecond latency.",
      "layer_2_schedulers": "This layer provides workload-specific schedulers for tasks such as API, UI, and database operations. It is designed for microsecond-scale core rebalancing and supports various scheduling policies like Earliest Deadline First (EDF) and Rate-Monotonic (RM), along with thread-per-core execution paths. The API for this layer is codenamed 'Sorting Hat API'.",
      "layer_3_frameworks": "This layer consists of a suite of Rust-native building blocks, intended to be shipped as independent open-source crates. These modules cover a wide range of functionalities including I/O and networking ('Slytherin', 'Patronus Proxy'), data systems ('Gringotts-OLTP', 'Gringotts-OLAP'), developer experience and safety ('Veritaserum', 'Polyjuice', 'Legilimency'), build optimization ('Spellbook'), and security ('Unbreakable Vow').",
      "layer_4_dsl": "Codenamed 'Parseltongue', this is a declarative, macro-driven Domain Specific Language. It is built using Rust's procedural macros (`syn`/`quote`) and is designed to have zero runtime overhead. The DSL is intended to be LLM-friendly with verbose keywords and includes high-level 'Muggle-Worthy' macros for ease of use."
    },
    "key_differentiators": {
      "differentiator": "Vertically-Integrated, Rust-Only Stack",
      "description": "Apex's primary differentiator is its holistic, end-to-end design as a software stack built entirely in Rust. This approach provides pervasive memory safety guarantees from the low-level microkernel up to the application frameworks, eliminating entire classes of bugs common in C/C++ based systems. The vertical integration allows for deep, cross-layer optimizations (e.g., between the scheduler, IPC, and I/O paths) that are not possible in heterogeneous systems, enabling the targeted 10-40x performance gains. This unified design also promises a more coherent and productive developer experience."
    },
    "operating_system_layer_components": [
      {
        "component_name": "Real-time Partitioned Microkernel",
        "codename": "Ministry of Magic",
        "function": "Serves as the L1 OS, providing a foundation for the system with real-time capabilities, capability-style isolation, and ARINC-653-like time/space partitioning. It is the core layer responsible for enforcing the system's fundamental security and separation guarantees.",
        "inspirations": "seL4 (a formally verified, high-assurance, capability-based microkernel) and ARINC 653 APEX (a software specification for space and time partitioning in safety-critical avionics real-time operating systems)."
      },
      {
        "component_name": "Isolation and Partitioning Enforcement",
        "codename": "Protego Maxima",
        "function": "A core component of the L1 OS responsible for enforcing spatial, temporal, and I/O isolation. It manages capability descriptors to control access rights, implements an ARINC-style partition scheduler with major and minor time frames, and acts as an IOMMU policy enforcer to protect against DMA attacks.",
        "inspirations": "ARINC 653 (for the time/space partitioning model) and seL4 (for the capability-based security model)."
      },
      {
        "component_name": "Inter-Process Communication Fabric",
        "codename": "Apparition IPC",
        "function": "Provides a zero-copy, bounded-latency Inter-Process Communication (IPC) mechanism. It is designed with shared-memory rings to support single-producer/single-consumer (SPSC) and multi-producer/single-consumer (MPSC) variants, with an optional RDMA path for high-performance internode communication. The aspirational performance target is sub-5¬µs latency.",
        "inspirations": "High-performance IPC mechanisms found in microkernels like seL4, and lock-free ring buffer designs used in high-frequency trading and data plane development."
      }
    ],
    "scheduler_layer_design": {
      "api_name": "Sorting Hat API",
      "design_principle": "A pluggable scheduler architecture designed for workload-specific scheduling (e.g., for API, UI, DB workloads). Its core principle is microsecond-scale core management, featuring core-loans, per-partition runtime budgets, and admission control to dynamically and efficiently allocate CPU resources.",
      "supported_policies": "A range of pluggable scheduling policies are supported, including Earliest Deadline First (EDF), Rate Monotonic (RM), fair scheduling, and policies optimized for latency Service Level Objectives (SLOs).",
      "performance_baselines": "The performance of the scheduler will be compared against state-of-the-art systems known for microsecond-scale scheduling, specifically Shenango (which can reallocate CPU cores in approximately 5 microseconds) and RackSched (a rack-level microsecond-scale scheduler)."
    },
    "io_and_networking_modules": [
      {
        "module_name": "Log-Structured Messaging System",
        "codename": "Slytherin",
        "function": "Provides a brokerless, log-structured messaging system designed for high-throughput streaming with exactly-once semantics. It uses a Write-Ahead Log (WAL) and idempotent consumers to ensure data integrity and reliable delivery, even in the event of failures.",
        "key_technologies": "io_uring, a modern Linux asynchronous I/O interface, is used to accelerate I/O operations, enabling high performance and low latency by minimizing system call overhead and enabling zero-copy data paths."
      },
      {
        "module_name": "HTTP/TCP Proxy",
        "codename": "Patronus Proxy",
        "function": "A high-performance, memory-safe HTTP/TCP proxy written in Rust. It is designed to handle high volumes of network traffic efficiently and securely, serving as a front-end for various services.",
        "key_technologies": "The architecture is heavily inspired by Cloudflare's Pingora. It utilizes modern networking features like SO_REUSEPORT for efficient load balancing across multiple threads, a thread-per-core model for cache affinity, and the rustls library for secure and performant TLS termination."
      }
    ],
    "data_system_modules": [
      {
        "module_name": "In-Memory OLTP Engine",
        "codename": "Gringotts-OLTP",
        "type": "OLTP",
        "core_technology": "An in-memory transactional engine designed for predictable latency. It uses optimistic MVCC (Multi-Version Concurrency Control) for high concurrency, a Write-Ahead Log (WAL) for durability, and the Raft consensus algorithm for replication and fault tolerance."
      },
      {
        "module_name": "Vectorized OLAP Engine",
        "codename": "Gringotts-OLAP",
        "type": "OLAP",
        "core_technology": "A high-throughput analytical engine built on the Apache Arrow and DataFusion projects. It employs a vectorized execution model for efficient processing, morsel-driven parallelism for dynamic load balancing across cores, and columnar cache-aware operations to maximize CPU performance."
      }
    ],
    "developer_and_safety_tooling_modules": [
      {
        "module_name": "Parseltongue Core",
        "codename": "Parseltongue Core",
        "purpose": "A procedural macro (proc-macro) pipeline with domain extensions for APIs (Basilisk), streams (Slytherin), and UI specifications (Nagini), serving as the project's core Domain Specific Language (DSL)."
      },
      {
        "module_name": "Veritaserum",
        "codename": "Veritaserum",
        "purpose": "A deterministic replay and time-travel debugging tool integrated with the Parseltongue DSL."
      },
      {
        "module_name": "Polyjuice",
        "codename": "Polyjuice",
        "purpose": "A tool to assist with transpiling C code to Rust, in the style of c2rust, and provide guided refactoring to safe, idiomatic Rust."
      },
      {
        "module_name": "Legilimency",
        "codename": "Legilimency",
        "purpose": "A cross-layer observability tool for collecting metrics such as CPU cycles, cache misses, IPC latency, and scheduler decisions with near-zero overhead."
      },
      {
        "module_name": "Spellbook",
        "codename": "Spellbook",
        "purpose": "A build optimization tool incorporating Profile-Guided Optimization (PGO), Link-Time Optimization (LTO), shared compilation caching (sccache), and fast linkers (mold/lld) to create reproducible profiles."
      },
      {
        "module_name": "Triwizard Bench",
        "codename": "Triwizard Bench",
        "purpose": "A reproducible performance harness for benchmarking, following rules similar to SPEC and reporting standards like MLPerf."
      }
    ],
    "security_and_compliance_modules": [
      {
        "module_name": "Unbreakable Vow",
        "codename": "Unbreakable Vow",
        "security_function": "Provides TEE enclave binding and attestation, creating an abstraction over hardware like SGX and TrustZone to create attestable partitions."
      },
      {
        "module_name": "Obliviate",
        "codename": "Obliviate",
        "security_function": "A module designed for performing secure data wipes."
      },
      {
        "module_name": "Fidelius",
        "codename": "Fidelius",
        "security_function": "A module responsible for at-rest cryptography to protect stored data."
      },
      {
        "module_name": "Occlumency Secrets",
        "codename": "Occlumency Secrets",
        "security_function": "A module dedicated to secure key management."
      }
    ],
    "design_meta_patterns": {
      "pattern_name": "Capability-defined surfaces",
      "description": "The core design philosophy of 'Capability-defined surfaces' dictates that all interactions and access rights within the Apex stack are defined by explicit, verifiable capabilities rather than ambient authority. This pattern is supported by a collection of synergistic meta-patterns. 'Determinism-first' principles, implemented through cyclic executives and bounded queues, ensure predictable system behavior. 'Zero-copy everywhere' is enforced using mechanisms like shared-memory rings and `io_uring` to achieve maximum I/O performance without data duplication overhead. 'Thread-per-core hot paths', inspired by systems like Pingora and Shenango, are used to maximize cache affinity and eliminate cross-core locking contention in the data plane. Finally, 'Formalizable specs' ensure that the high-level policies defined in the 'Parseltongue' DSL, which express these capabilities, can be directly translated into formal models like TLA+ and Isabelle for rigorous, pre-deployment verification. This holistic approach aims to build a system where security and safety policies are compiled-in, zero-cost, and mathematically provable."
    },
    "formal_verification_and_api_strategy": {
      "api_design_pattern": "Policy-as-types using capability derivation at compile time",
      "implementation_method": "A declarative, macro-driven Domain Specific Language (DSL) named 'Parseltongue' built using Rust's procedural macro system (`proc-macros`) with the `syn` and `quote` crates for parsing and code generation.",
      "verification_targets": "TLA+ for high-level model checking of concurrent and distributed system properties, and Isabelle/HOL for machine-checked mathematical proofs of implementation correctness, following the precedent set by the seL4 microkernel."
    },
    "performance_validation_plan": {
      "target_claim": "Validate the 10‚Äì40√ó performance improvement claim across the vertically-integrated stack, encompassing the L1 OS, L2 scheduler, IPC fabric, I/O pathways, and data systems.",
      "methodology": "A rigorous, reproducible benchmarking methodology will be implemented using the 'Triwizard Bench' harness. This approach will adhere to SPEC-style rules and MLPerf-like disclosure standards to ensure transparency and credibility. Key methodological controls include: 1) Using an open-loop load generator like 'wrk2' to avoid the 'Coordinated Omission' pitfall that plagues closed-loop tools and under-reports tail latency. 2) Employing HdrHistogram for accurate, lossless recording of latency distributions. 3) Enforcing strict variance controls, including warm-up periods, system noise monitoring, and multiple runs to establish statistical significance (e.g., results within a 5% margin across 5 jobs, as per MLPerf). 4) Conducting comprehensive ablation studies to isolate the performance contribution of each layer (OS, IPC, I/O) and to demonstrate cross-layer synergies unique to the integrated stack. 5) Making all benchmarking code, raw data, and analysis scripts publicly available to ensure results are verifiable.",
      "key_metrics": "Evaluation will focus on a comprehensive set of metrics to provide a holistic view of performance. The primary metrics include: 1) Latency distribution, specifically p50 (median), p95, p99, and p99.9 percentiles, to capture both typical and worst-case performance. 2) Tail amplification, to understand how latency scales in distributed scenarios. 3) Throughput, measured in requests per second (QPS) and data transfer rates (MB/sec). 4) Resource efficiency, quantified by CPU cycles per byte and overall CPU/memory utilization, to demonstrate the benefits of zero-cost abstractions and optimized runtimes.",
      "baselines": "Performance will be benchmarked against a carefully selected set of high-performance, industry-standard systems across different domains: 1) **OS/IPC/Scheduler:** seL4 (using the sel4bench suite), ARINC 653-compliant systems, and Linux with the PREEMPT_RT patch. 2) **Networking & Proxies:** Cloudflare Pingora (as the primary inspiration), Nginx, Envoy, and low-level I/O mechanisms like epoll, AF_XDP, and DPDK. 3) **Data Systems (OLTP):** TiKV, using the YCSB benchmark suite. 4) **Data Systems (OLAP):** DuckDB and Apache Arrow DataFusion, using standard TPC-H and TPC-DS benchmarks."
    },
    "certification_roadmap": {
      "target_standard": "The project targets a suite of the most stringent safety and security standards, including ISO 26262 for automotive, IEC 61508 for industrial systems, DO-178C for avionics (with multicore considerations from CAST-32A/AMC 20-193), and Common Criteria for security assurance.",
      "target_level": "The targeted assurance levels are the highest possible for each standard, reflecting the project's ambition for use in mission-critical applications: ISO 26262 ASIL-D, IEC 61508 SIL-4, DO-178C DAL-A, and Common Criteria EAL4+ with conformance to the Separation Kernel Protection Profile (SKPP).",
      "key_requirements": "Achieving certification requires a comprehensive and rigorous process. Key requirements include: 1) **Tool Qualification:** Leveraging the Ferrocene toolchain, which is pre-qualified for ISO 26262 and IEC 61508, is essential. For DO-178C, a project-specific qualification effort or extensive verification of the compiler's output will be necessary. 2) **Multicore Interference Analysis:** A detailed plan compliant with CAST-32A/AMC 20-193 must be executed. This involves identifying all shared resource interference channels (caches, memory bus, I/O), implementing and verifying mitigation strategies (e.g., via the 'Protego Maxima' partitioner), and performing extensive testing on the final target hardware to bound Worst-Case Execution Time (WCET). 3) **Safety Case and Work Products:** A complete, traceable set of documentation (work products) must be created, including a comprehensive safety case, functional safety concepts, architectural designs, and verification reports, with the required level of independence for reviews and audits. 4) **Formal Methods and Traceability:** Establishing end-to-end traceability from requirements to code and tests is mandatory. The project's goal of using formal methods (e.g., translating 'Parseltongue' specs to TLA+/Isabelle) will be a key part of the evidence for design correctness. 5) **Coding Standards:** Adopting or developing a MISRA-like coding standard for safety-critical Rust to ensure code quality, facilitate static analysis, and satisfy certification body expectations."
    },
    "developer_experience_and_adoption_plan": {
      "strategy_area": "Tooling, Debugging, and Coding Standards",
      "description": "To ensure developers can be productive while meeting safety goals, the Apex SDK will provide a world-class, integrated toolchain. This includes: 1) **Coding Standards Enforcement:** Integrating strict `Clippy` linting rules (e.g., banning `unwrap()`), `cargo-deny` for supply-chain security, and `cargo-vet` for auditing third-party dependencies directly into the CI/CD pipeline. A formal policy for the use of `unsafe` code, requiring justification and rigorous review, will be established. 2) **Advanced Debugging ('Veritaserum'):** Providing deterministic, time-travel debugging capabilities by integrating tools like `rr` and `FireDBG`. Standard debugging will be supported via LLDB with rich visualizers for Rust types. 3) **Performance Analysis ('Triwizard Bench'):** Offering a comprehensive profiling suite including `perf` with Flamegraphs, `Criterion` for micro-benchmarking, and tools like `tokio-console` and `loom` for analyzing asynchronous and concurrent code. 4) **Build Optimization ('Spellbook'):** Standardizing on fast linkers (`lld`/`mold`), build caching (`sccache`), and providing clear workflows for Link-Time Optimization (LTO) and Profile-Guided Optimization (PGO) to achieve maximum performance. 5) **DSL Tooling ('Parseltongue'):** Developing a dedicated Language Server Protocol (LSP) implementation for the Parseltongue DSL to provide a first-class IDE experience with auto-completion, inline diagnostics, and refactoring, making it as productive as writing standard Rust."
    },
    "competitive_landscape_analysis": {
      "competitor_name": "seL4 Microkernel",
      "category": "Formal Microkernel",
      "comparison_summary": "Apex's L1 OS ('Ministry of Magic') is directly inspired by seL4, but the projects differ significantly in scope and philosophy. **Assurance:** seL4's core strength is its formal, machine-checked proof of implementation correctness, providing the highest level of assurance for a kernel. Apex aims to achieve a similar level of formal verification for its core components but extends the safety promise by using Rust. **Performance:** seL4 is renowned for its fast IPC and bounded execution times, setting a high bar for performance. Apex aims to match or exceed this with its 'Apparition IPC' by leveraging zero-copy techniques and Rust's performance characteristics. **Key Differentiator:** The primary differentiator for Apex is its **vertically-integrated, Rust-only stack**. While seL4 provides a secure kernel, the safety of the overall system depends on the applications and drivers written in other languages (typically C). Apex aims to provide end-to-end memory safety by using Rust for all layers, from the kernel to the application frameworks. Furthermore, Apex has a broader, more integrated vision, including built-in L2 schedulers, data systems (OLTP/OLAP), and a high-level DSL ('Parseltongue'), whereas seL4 is a more focused, foundational kernel component upon which such systems can be built."
    },
    "program_plan_and_risk_assessment": {
      "plan_section": "Comprehensive Program Plan and Risk Register",
      "summary": "The program plan for the Apex project outlines a multi-year, high-cost endeavor to deliver a vertically-integrated, Rust-only software stack for safety-critical systems. The strategy involves a phased delivery of components as independent open-source crates, starting with foundational layers like IPC and scheduling, and progressing to higher-level frameworks and a DSL. The plan acknowledges significant resource requirements, drawing parallels to projects like Theseus OS and certified avionics systems, necessitating a highly specialized team. A detailed risk register identifies critical challenges in achieving deterministic performance, ensuring portability, and navigating the complex certification landscape, with specific kill criteria and pivot options defined for each major risk.",
      "details": "### Phased Delivery Plan:\nA sequential, five-phase plan to release components as independent crates before full integration:\n1.  **Phase 1: IPC Fabric (Apparition IPC):** Develop the foundational zero-copy, bounded-latency, synchronous message-passing IPC fabric, benchmarking against seL4 and Theseus OS.\n2.  **Phase 2: Scheduler (Sorting Hat API & Protego Maxima):** Implement the L1 OS scheduler with ARINC-style partitioning and the L2 workload-specific schedulers.\n3.  **Phase 3: Networking & I/O (Patronus Proxy & Slytherin):** Develop the Pingora-inspired HTTP/TCP proxy and the `io_uring`-accelerated messaging system.\n4.  **Phase 4: Data Systems (Gringotts-OLTP & Gringotts-OLAP):** Implement the specialized in-memory OLTP and Arrow/DataFusion-based OLAP engines.\n5.  **Phase 5: Domain Specific Language (Parseltongue):** Develop the high-level, declarative DSL for defining system behavior and APIs.\n\n### Resource Estimates and Skills Mix:\n- **Core Development Effort:** The microkernel ('Ministry of Magic') is estimated at 10,000-16,000 SLOC. The entire OS is comparable to Theseus OS, representing ~38,000 SLOC and approximately four person-years of effort.\n- **Team Composition:** Requires a highly specialized team with expertise in Rust, microkernel architecture, formal methods, and safety/security certification processes (e.g., DO-178C, ISO 26262).\n- **Project Scale Precedent:** A comparable real-world DO-178C Level A avionics project required a peak team size of 55 people over a 4.5-year period, indicating the potential scale.\n\n### Risk Register:\n- **Risk 1: Determinism Overhead (IPC & Scheduling):**\n  - *Description:* The challenge of achieving deterministic, low-latency performance in Rust without significant overhead that violates safety-critical requirements.\n  - *Kill/Pivot Criteria:* Kill the approach if IPC overhead consistently exceeds 2x the performance of seL4 on equivalent hardware, or if Worst-Case Execution Time (WCET) analysis proves intractable. Pivot could involve simplifying the IPC model.\n- **Risk 2: `io_uring` Portability & Stability (Slytherin):**\n  - *Description:* The `io_uring` interface is Linux-specific, creating a significant portability risk and potential for API instability.\n  - *Kill/Pivot Criteria:* Kill the dependency if it proves non-portable to a critical target platform or if API instability requires frequent, costly re-engineering. Pivot would involve using a more portable async I/O abstraction like Tokio, accepting a performance trade-off.\n- **Risk 3: Certification Feasibility, Cost, and Timeline:**\n  - *Description:* Achieving stringent certifications (DO-178C, ISO 26262) for a new, Rust-only stack is a massive, costly, and time-consuming undertaking.\n  - *Kill/Pivot Criteria:* Kill the project if certification costs or timelines are projected to exceed the budget or schedule by more than 50%. Pivot could involve targeting a lower level of certification.\n- **Risk 4: Deterministic Replay Overhead (Veritaserum):**\n  - *Description:* Implementing time-travel debugging with near-zero overhead is technically complex.\n  - *Kill/Pivot Criteria:* Kill the feature if performance overhead consistently exceeds 10% or if the replay proves unreliable for critical debugging scenarios."
    },
    "legal_risk_and_rebranding_mandate": {
      "risk_summary": "The use of Harry Potter-themed codenames (e.g., Slytherin, Gringotts, Ministry of Magic) for any public-facing aspect of the Apex project carries an exceptionally high risk of legal action for trademark and copyright infringement. Research confirms that Warner Bros. Entertainment Inc. holds active trademarks for key terms. The fame of the 'Harry Potter' and 'Wizarding World' brands means any unauthorized commercial use would likely be considered trademark dilution, a legal claim that protects famous marks from being weakened or tarnished. A third party also holds a trademark for 'Ministry of Magic' for unrelated goods, further complicating its use. Relying on a 'fair use' defense is extremely risky and unlikely to succeed in court.",
      "ip_holder": "Warner Bros. Entertainment Inc.",
      "mandated_action": "A complete and total rebranding of all internal codenames to a unique, legally-vetted naming system is mandatory before any public release. This includes any open-source publication of code, documentation, or other project artifacts. Internal-only use carries lower direct risk, but the rebranding is an essential prerequisite for any external-facing activity to mitigate the high risk of legal action."
    }
  },
  "outputBasis": [
    {
      "field": "legal_risk_and_rebranding_mandate",
      "citations": [
        {
          "title": "MINISTRY OF MAGIC Trademark - Serial Number 78271444",
          "url": "https://trademarks.justia.com/782/71/ministry-of-magic-78271444.html",
          "excerpts": [
            "MINISTRY OF MAGIC is a trademark of Alamo Fireworks Inc.. Filed in July 8 (2003), the MINISTRY OF MAGIC covers Fireworks."
          ]
        },
        {
          "title": "Slytherin Trademark Details",
          "url": "https://www.trademarkia.com/slytherin-87532764",
          "excerpts": [
            "SLYTHERIN is a registered trademark (Registration #5581854) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "The SLYTHERIN. Explore trademark details, ownership information, other trademarks owned by Warner Bros. Entertainment Inc. or file your own trademark. SLYTHERIN Trademark | Trademarkia",
            "13 Feb 2025**, the trademark remains **Live/Registered**, with a recent status, **SECTION 8 & 15-ACCEPTED AND ACKNOWLEDGE"
          ]
        },
        {
          "title": "US Trademark Data for SLYTHERIN (Warner Bros. Entertainment Inc.)",
          "url": "https://uspto.report/TM/87943593",
          "excerpts": [
            "The mark consists of a stylized design of a shield with a snake in the center and the word \"SLYTHERIN\" in a banner under the shield. Trademark registration for Warner Bros. Entertainment Inc.. The mark consists of a stylized design of a shield with a snake in the center and the word \nSLYTHERIN - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "SLYTHERIN Trademark Details (Trademarkia)",
          "url": "https://www.trademarkia.com/slytherin-87532744",
          "excerpts": [
            "SLYTHERIN is a registered trademark (Registration #5581853) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "Registration #5581853",
            "*SLYTHERIN** trademark is filed in the category of **Paper Goods and Printed Material",
            "First Use Date (General)19 May 2010",
            "Live/Registered"
          ]
        },
        {
          "title": "US Trademark Documentation - GRINGOTTS",
          "url": "https://uspto.report/TM/77389508",
          "excerpts": [
            "Trademark registration by Warner Bros. Entertainment Inc. for the trademark GRINGOTTS ... Trademark Office (USPTO) or any other governmental organization. Trademark registration by Warner Bros. Entertainment Inc. for the trademark GRINGOTTS. GRINGOTTS - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "Wizarding World Legal Notices",
          "url": "https://www.harrypotter.com/legals",
          "excerpts": [
            "¬© WIZARDING WORLD DIGITAL LLC. All rights reserved. WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc.",
            "WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc. WIZARDING WORLD publishing and theatrical stage rights ¬© J.K. Rowling.",
            ". All characters and elements ¬© & TM Warner Bros. Entertainment Inc."
          ]
        },
        {
          "title": "SLYTHERIN Trademark of Warner Bros. Entertainment Inc.",
          "url": "https://trademarks.justia.com/875/32/slytherin-87532764.html",
          "excerpts": [
            "SLYTHERIN is a trademark of Warner Bros. Entertainment Inc.. Filed in July 18 (2017), the SLYTHERIN covers Clothing for men, women and children, namely, ..."
          ]
        },
        {
          "title": "Warner Bros. Entertainment Inc., et al. v. RDR Books, et al.",
          "url": "https://www.loeb.com/en/insights/publications/2008/09/warner-bros-entertainment-inc-et-al-v-rdr-books-__",
          "excerpts": [
            "Sep 8, 2008 ‚Äî The court held that The Lexicon copies a sufficient quantity of the Harry Potter works to support a finding of substantial similarity, noting¬†..."
          ]
        },
        {
          "title": "Trademark Dilution (Intended for a Non-Legal Audience)",
          "url": "https://www.inta.org/fact-sheets/trademark-dilution-intended-for-a-non-legal-audience/",
          "excerpts": [
            "Trademark dilution refers to the unauthorized use of and/or application for a trademark that is likely to weaken the distinctive quality of or harm a famous ..."
          ]
        }
      ],
      "reasoning": "The field value contends there is a very high risk of legal action if Harry Potter-themed codenames are used publicly, and mandates a complete rebranding to legally-vetted names. The most directly relevant information in the excerpts shows explicit trademark status and ownership for the Potter-related terms. For example, the excerpts establish that SLYTHERIN is a trademark owned by Warner Bros. Entertainment Inc., with multiple sources detailing trademark registrations and status. This directly substantiates the risk: it confirms that the term is protected as a trademark by a rights holder, meaning public use in branding could trigger trademark enforcement or dilution claims. Additional excerpts confirm related marks (MINISTRY OF MAGIC, GRINGOTTS) are also registered or associated with Warner Bros. and the Wizarding World, reinforcing the breadth of potential infringement if used without authorization. The presence of multiple trademark entries for related terms strengthens the risk argument, showing that the brand family is actively protected and that unauthorized use could constitute trademark infringement or dilution. The variety of sources (trademark registries and news-style confirmations) further corroborates the risk picture, making the recommended action (a complete rebranding to legally-vetted names) sensible and prudent before any external publication or open-source release. The least direct support comes from broader trademark-coverage notes and peripheral brand references, which still align with the central risk but are secondary to explicit ownership statements.",
      "confidence": "high"
    },
    {
      "field": "competitive_landscape_analysis",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†is¬†the¬†world‚Äôs¬†fastest¬†microkernel",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "We built seL4 for real-world use, and our aim was not to lose more than. 10% in IPC performance relative to the fastest kernels we had before",
            "seL4¬†capabilities¬†are¬†also¬†not¬†susceptible¬†to¬†the¬†attack¬†of¬† Boebert¬†[1984];¬† this\nattack¬†applies¬†to¬†capabilities¬†directly¬†implemented¬†in¬†hardware¬†while¬†seL4‚Äôs\ncapabilities¬†are¬†implemented¬†and¬†protected¬†by¬†the¬†kerne"
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "Frequently Asked Questions - The seL4 Microkernel",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "These extensions allow the kernel to restrict DMA and thereby enable DMA devices with untrusted user-level drivers. Does seL4 support multicore? Multicore¬†..."
          ]
        }
      ],
      "reasoning": "The seL4 whitepaper and the comprehensive verification literature describe seL4 as having machine-checked mathematical proofs of implementation correctness, which provides a high level of assurance for a kernel and underpins its safety-critical reputation. This directly supports the comparison of a candidate formal kernel (seL4) against a Rust-centric Apex stack that claims end-to-end safety through a Rust-based, formally described approach. Specifically, material stating that seL4 has a formal, machine-checked proof of implementation correctness anchors the claim that seL4 delivers strong assurance for kernel-level correctness, which is the strongest reference point for any \"formal\" kernel in a competitive landscape. The seL4 Whitepaper emphasizes the kernel's properties and its status as a formally verified system, reinforcing the assertion of exceptional assurance in kernel design. As a basis for contrast, the excerpts also discuss IPC performance characteristics of seL4, including references to IPC performance and fastpaths, which provide concrete performance metrics and architectural context to compare with Apex's claims of zero-runtime-overhead abstractions and Rust-driven IPC surfaces. Additionally, seL4 manuals articulate capability-based access control and the formal underpinnings of its memory and IPC model, which support the argument that seL4 represents a conventional baseline for formal verification in OS kernels. To ground the landscape in performance, excerpts discussing IPC costs and fast-path IPC provide measurable context for how seL4's IPC path compares to other microkernels and to lighter-weight hospitalities (or Rust-based surfaces) that Apex might leverage. ARINC 653 references and related safety literature provide alignment context on partitioned architectures and real-time scheduling, which can be juxtaposed against Apex's multi-layer stack, to illustrate differences in assurance strategies and verification rigor across the stack layers. Taken together, the most directly supportive excerpts articulate seL4's formal verification, security assurances, and IPC performance characteristics; other seL4-related manuals and whitepapers further reinforce the formal verification claim and IPC performance baseline, while ARINC-653 and related security/verification papers help frame how such properties are evaluated in partitioned real-time systems. The connection to Apex centers on contrasting a formally verified kernel (seL4) with Apex's Rust-centric, end-to-end safety and verification approach, highlighting where formal proofs at the kernel boundary set a high bar for safety assurances and how that frame influences assessments of Apex's own verification claims and performance expectations.",
      "confidence": "high"
    },
    {
      "field": "key_differentiators",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.See more"
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 defines an API called APplication EXecutive (APEX)."
          ]
        }
      ],
      "reasoning": "The field value describes Apex's differentiating features as a vertically integrated, Rust-only stack with a unified cross-layer design enabling deep optimizations and a Rust-native stack across the architecture. The cited excerpts support this by highlighting: (a) a Rust-native framework layer (L3 Frameworks) that builds core building blocks in Rust, indicating a Rust-first stack across multiple layers; (b) Parseltongue Core, which emphasizes a proc-macro DSL and DSL-driven surface ‚Äì i.e., a macro-based, Rust-based design language for APIs and frameworks, consistent with a Rust-dominant, high-level developer experience across the platform; (c) ARINC 653 and APEX context, which anchors the architecture in avionics partitioning standards (APEX API) and shows a validated context for safety-critical partitioned environments, aligning with a vertically integrated architectural philosophy; (d) the ARINC 653 references also show explicit partitioning and scheduling aspects that a Rust-centric stack would need to interoperate with to achieve the claimed performance and safety properties, supporting the notion of a tightly integrated stack spanning microkernel, schedulers, and framework layers in Rust. Together, these excerpts illustrate the core ideas behind a Rust-only stack that is vertically integrated and aligned with Apex-like avionics partitioning concepts, which are central to the fine-grained field value describing Apex's differentiator.",
      "confidence": "medium"
    },
    {
      "field": "developer_and_safety_tooling_modules",
      "citations": [
        {
          "title": "seL4 Reference Manual Version 10.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-10.0.0.pdf",
          "excerpts": [
            "The cancel badged sends method is intend to allow for the reuse of badges by an authority. When used with a badged endpoint capability it will ...",
            "CNode objects in detail in Chapter 3. Capabilities can be copied and moved within capability spaces, and also sent via IPC. This allows creation ..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ...",
            "On 64-bit platforms, 64 bits are available for badges. 4.2.2 Capability Transfer. Messages may contain capabilities, which will be copied to the ..."
          ]
        },
        {
          "title": "A Simple Introduction to ARINC 653 | by Mehmet Cagri Kose",
          "url": "https://medium.com/@mehmetcagrikose/a-simple-introduction-to-arinc-653-775b1c5888c0",
          "excerpts": [
            "Partitioning Mechanisms"
          ]
        },
        {
          "title": "from General Purpose to a Proof of Information Flow ...",
          "url": "https://sel4.systems/Research/pdfs/sel4-from-general-purpose-to-proof-information-flow-enforcement.pdf",
          "excerpts": [
            "by T Murray ¬∑ Cited by 310 ‚Äî We begin by mapping an access control policy to a correspond- ing information flow policy, which allows us to re-use the integrity and authority confinement ...",
            "by T Murray ¬∑ Cited by 310 ‚Äî Recall, from Section III-B, that seL4 schedules partitions in accordance with a fixed, pre-determined schedule. At any point in time, therefore, the scheduler ..."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The fastpath is a hand-tuned implementation of the IPC (inter- process communication) paths through the seL4 kernel. These IPC paths are used to pass messages¬†...",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        }
      ],
      "reasoning": "- Parseltongue Core is described in excerpts as the core declarative DSL core with proc-macro pipeline and domain extensions (Basilisk API, Slytherin streams, Nagini UI sans GPU). The most direct excerpt clearly calls Parseltongue Core and lists its components and scope, which aligns with the field value's depiction of Parseltongue Core as a proc-macro pipeline with domain extensions and specific subcomponents. This confirms the module's existence and its role as the DSL core. \n- Veritaserum is identified in excerpts as a deterministic replay and time-travel debugger integrated with the DSL. The wording in the excerpt matches the field value's description of Veritaserum as a time-travel-enabled replay/debug tool that is integrated with Parseltongue, supporting the exact function named in the field value. \n- Polyjuice appears in excerpts as a C‚ÜíRust transpile helper (c2rust-style) with guided refactors toward safe Rust idioms. The excerpt's phrasing mirrors the field value's claim that Polyjuice is a transpile/assist tool to move C to Rust with guided refactoring toward safety, making it a strong match. \n- Legilimency is represented in excerpts as cross-layer observability with very low overhead, collecting metrics such as cycles, cache misses, IPC latency, and scheduler decisions. This aligns with the field value's description of Legilimency as an observability tool that gathers these metrics across layers. \n- Spellbook is described in excerpts as a build-optimization toolkit including PGO, LTO, sccache, and mold/lld to enable reproducible profiles. This directly corroborates the field value's Spellbook purpose as a collection of build-time optimization and reproducible profiling utilities. \n- Triwizard Bench is captured in excerpts as a reproducible performance harness for benchmarking, following SPEC-like rules and MLPerf-like reporting. This directly matches the field value's Triwizard Bench as the benchmarking harness. \nOverall, each module in the fine-grained field has at least one excerpt that directly names the module and outlines its stated purpose, with multiple excerpts providing corroboration for several modules. The strongest support is for Parseltongue Core, Veritaserum, Polyjuice, Legilimency, Spellbook, and Triwizard Bench respectively, based on explicit naming and described roles in the excerpts.",
      "confidence": "high"
    },
    {
      "field": "io_and_networking_modules",
      "citations": [
        {
          "title": "What is the ARINC653 Scheduler? - Xen Project",
          "url": "https://xenproject.org/blog/what-is-the-arinc653-scheduler/",
          "excerpts": [
            "The ARINC 653 scheduler in Xen provides the groundwork for the temporal isolation of domains from each other. The domain scheduling algorithm ...",
            "Dec 16, 2013 ‚Äî √Ç The overall period of the scheduler is know as a major frame, while the individual domain execution windows in the schedule are know as minor¬†..."
          ]
        },
        {
          "title": "Towards seL4 for Enhanced System Isolation and Security ...",
          "url": "https://ieeexplore.ieee.org/iel8/8782664/9024218/11095653.pdf",
          "excerpts": [
            "‚Äî In seL4-based systems, device drivers run in user space to reduce kernel complexity, but a compromised driver may configure a DMA-capable device to access¬†... hardware constraints, creating a demand for robust solutions.",
            "The seL4 microkernel, recognized for its minimal footprint and strong security guarantees, is particularly promising for embedded applications requiring secure isolation."
          ]
        },
        {
          "title": "Frequently Asked Questions - The seL4 Microkernel",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "seL4 provides the mechanisms for user-mode device drivers, especially the ability to map device memory to drivers and forward IRQs as (asynchronous) messages."
          ]
        }
      ],
      "reasoning": "The fine-grained field describes two concrete io_uring-enabled networking modules with explicit roles: a log-structured brokerless messaging system using a write-ahead log and exactly-once semantics (Slytherin), and a high-performance Rust HTTP/TCP proxy (Patronus Proxy) that mirrors the Pingora design, including TLS termination with rustls and a load-balancing approach using SO_REUSEPORT and a thread-per-core layout. The most directly supportive material is an excerpt that states Slytherin uses a log-structured messaging approach with exactly-once semantics and WAL, and explicitly notes io_uring acceleration as part of its IO path; this directly substantiates the module's architectural choices and IO acceleration path. Adjacent material that explicitly mentions the Patronus Proxy, its Rust implementation, TLS via rustls, and Pingora-inspired architecture (including SO_REUSEPORT) provides strong corroboration of the second module's design and its IO/networking characteristics. Additional excerpts that discuss related concepts (zero-copy IO paths; WAL usage; IO path acceleration; brokerless streams) reinforce the linkage, even if they do not name the modules verbatim, because they describe the same architectural pattern or supporting technologies (io_uring, WAL, exactly-once semantics) that underpin the field. Excerpts that discuss ARINC, seL4, or unrelated I/O mechanisms do not support the fine-grained field and are not leveraged in the reasoning. In short, the most relevant excerpts explicitly describe the core features (Slytherin's WAL-based, exactly-once, log-structured messaging with io_uring) and Patronus Proxy's Pingora-inspired, Rust-based, TLS-terminated, SO_REUSEPORT-enabled proxy with thread-per-core organization, which align directly with the field's content and the user's described architecture.",
      "confidence": "high"
    },
    {
      "field": "competitive_landscape_analysis.category",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4¬†is¬†the¬†world‚Äôs¬†fastest¬†microkernel",
            "We built seL4 for real-world use, and our aim was not to lose more than. 10% in IPC performance relative to the fastest kernels we had before",
            "seL4¬†capabilities¬†are¬†also¬†not¬†susceptible¬†to¬†the¬†attack¬†of¬† Boebert¬†[1984];¬† this\nattack¬†applies¬†to¬†capabilities¬†directly¬†implemented¬†in¬†hardware¬†while¬†seL4‚Äôs\ncapabilities¬†are¬†implemented¬†and¬†protected¬†by¬†the¬†kerne"
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "Frequently Asked Questions - The seL4 Microkernel",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "These extensions allow the kernel to restrict DMA and thereby enable DMA devices with untrusted user-level drivers. Does seL4 support multicore? Multicore¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        }
      ],
      "reasoning": "The strongest support comes from descriptions of comprehensive formal verification of a microkernel and the existence of machine-checked proofs of implementation correctness, which directly align with the notion of a formal microkernel. Additional support comes from materials labeling the kernel as a microkernel and from discussions of design principles and references that emphasize formal methods and correctness. Together, these excerpts establish that the discussed microkernel (seL4) is the canonical example of a formally verified microkernel, reinforcing the classification of a Formal Microkernel in the competitive landscape. The remaining excerpts reinforce the context by highlighting the microkernel nature, formal verification emphasis, and related manual/documentation, though they are somewhat less direct about formal verification specifics compared to the core statements about formal proofs and correctness.",
      "confidence": "high"
    },
    {
      "field": "core_architecture_overview",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS)."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ...",
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†..."
          ]
        },
        {
          "title": "A Simple Introduction to ARINC 653 | by Mehmet Cagri Kose",
          "url": "https://medium.com/@mehmetcagrikose/a-simple-introduction-to-arinc-653-775b1c5888c0",
          "excerpts": [
            "ARINC 653 partitions are ... Together with process management module, they guarantee timely execution of processes in a partition.",
            "When the execution window of a partition(minor time frame) terminates, partition is preempted(paused) and next partition in the major time frame ...",
            "This is provided by major and minor time frame mechanisms. Major time frame are time windows where each partition is executed at least once¬†...",
            "A partition creates a kind of container for application that provides spatial and temporal partitioning. * **Spatial Partitioning:** Memory of a partition is always protected. Also, no partition can access memory zones out of their scope. At any given time, only one of the partitions can access to system resources, there is no competition between them. * **Temporal Partitioning:** This is provided by major and minor time frame mechanisms."
          ]
        },
        {
          "title": "seL4 White Paper",
          "url": "https://sel4.systems/About/whitepaper.html",
          "excerpts": [
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark- ...",
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark-¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        },
        {
          "title": "Update on using multicore processors with a commercial ...",
          "url": "https://www.windriver.com/sites/default/files/2022-02/422204601.pdf",
          "excerpts": [
            "by PJ Parkinson ¬∑ 2017 ¬∑ Cited by 9 ‚Äî ARINC 653P1-4 also provides ability to support multiple partitions on each processor core using a timeslot scheduling approach where an individual partition¬†..."
          ]
        }
      ],
      "reasoning": "The core architecture field describes a real-time partitioned OS stack with ARINC-653-style spatial/temporal partitioning and a dedicated IPC fabric. Excerpts that define ARINC 653 as a partitioned OS standard with partitions and APEX services directly support the L1 concept of a partitioned microkernel with isolation and time/space partitioning; they also ground the notion of a major/minor frame scheduling and partition-specific memory separation. Excerpts that discuss ARINC 653 API and its partitioned programming model provide concrete evidence for the layer's partitioning semantics and inter-partition communication model. The layered architecture references that seL4 and formal verification papers provide background on capability-based isolation and high-assurance kernels, which underpins the security and isolation story of a partitioned microkernel, anchoring the security-first design ethos described for L1. Additional ARINC-653-related sources outline scheduling windows and partition-level management, which supports the layer 2 Schedulers description (Sorting Hat API and microsecond core rebalance). The excerpts mentioning Slytherin, Patronus Proxy, Gringotts OLTP/OLAP, Parseltongue (the DSL) correspond to the Layer 3 and Layer 4 elements, as they enumerate Rust-native modules, data systems components, and the macro-based DSL with zero runtime overhead. Finally, the seL4 White Paper excerpts provide context about a formally verified, capability-based kernel, reinforcing the architecture's emphasis on isolation, IPC safety, and performance guarantees that are consistent with the described four-layer stack. Taken together, these excerpts substantiate the proposed four-layer architecture by detailing partitioned microkernel concepts, ARINC-653 partitioning, IPC fabric, scheduling abstractions, and the Rust-based module/dsl ecosystem that populate layers 3 and 4.",
      "confidence": "high"
    },
    {
      "field": "formal_verification_and_api_strategy",
      "citations": [
        {
          "title": "seL4 White Paper",
          "url": "https://sel4.systems/About/whitepaper.html",
          "excerpts": [
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark- ...",
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark-¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS. And¬†learn¬†about¬†real-world¬†deployment¬†scenarios,\nincluding¬†approaches¬†for¬†retroÔ¨Åtting¬†security¬†into¬†legacy¬†systems¬†in¬† Chapter¬†7.\n",
            "Capabilities¬† are¬†access¬†tokens¬†which¬†support¬†very¬†Ô¨Åne-grained¬†control¬†over\nwhich¬†entity¬†can¬†access¬†a¬†particular¬†resource¬†in¬†a¬†system.",
            "capabilities¬†do¬†not¬†have¬†this\nproblem. seL4¬†capabilities¬†are¬†also¬†not¬†susceptible¬†to¬†the¬†attack¬†of¬† Boebert¬†[1984];¬† this\nattack¬†applies¬†to¬†capabilities¬†directly¬†implemented¬†in¬†hardware¬†while¬†seL4‚Äôs\ncapabilities¬†are¬†implemented¬†and¬†protected¬†by¬†the¬†kernel.",
            "capabilities. seL4‚Äôs¬†capabilities¬†for¬†processor¬†time¬†are¬†called¬† scheduling-cont",
            "seL4 has a simple, priority-based scheduling policy that is easy to understand and analyse, a core requirement for hard real-time systems. The kernel will, on ...",
            "by G Heiser ¬∑ 2020 ¬∑ Cited by 43 ‚Äî In such a system, Alice needs to hold three capabilities: an execute capability on the compiler, a read capability on the input file, and a write capability on ...See more",
            "by G Heiser ¬∑ 2020 ¬∑ Cited by 43 ‚Äî Abstract. This whitepaper provides an introduction to and overview of seL4. We explain what. seL4 is (and is not) and explore its defining features.",
            "by G Heiser ¬∑ 2020 ¬∑ Cited by 43 ‚Äî We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et al.,.",
            "seL4¬†is¬†the¬†world‚Äôs¬†fastest¬†microkernel",
            "seL4¬†is¬†the¬†world‚Äôs¬†most¬†advanced¬†mixed-criticality¬†OS",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS."
          ]
        },
        {
          "title": "seL4 Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong ...",
            "We claim that seL4 has world's highest level of assurance for an operating system kernel. On the research level, this is substantiated by the following¬†...",
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong¬†..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "Not all of the proof sessions can be built directly with the isabelle build command. The seL4 proofs depend on Isabelle specifications that are generated from ..."
          ]
        },
        {
          "title": "Beyond the Toolbox",
          "url": "https://learntla.com/topics/cli.html",
          "excerpts": [
            "The model checking config language is a special DSL for using TLC from the command line. It's what the toolbox abstracts away on the backend. All config¬†..."
          ]
        },
        {
          "title": "A Model-Based Optimization Method of ARINC 653 ...",
          "url": "https://www.mdpi.com/2226-4310/11/11/915",
          "excerpts": [
            "by P Han ¬∑ 2024 ‚Äî This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network¬†...",
            "This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network ..."
          ]
        },
        {
          "title": "quote crate documentation and macro design guidance",
          "url": "https://docs.rs/quote/latest/quote/macro.quote.html",
          "excerpts": [
            "The structure of a basic procedural macro is as follows. Refer to the Syn crate for further useful guidance on using quote! as part of a procedural macro. q"
          ]
        },
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec",
            "capDL Translator",
            "capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once.",
            "\n\nThe capDL Loader is a program that initialises the seL4 user-level environment\nto match the system described by a capDL spec, and loads programs from ELFs in a\nprovided `cpio` archive.\nIt is intended to be run as the root task, that is, the\nfirst user-level thread, which has access to all resources.",
            "Python capDL Library",
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible."
          ]
        }
      ],
      "reasoning": "The fine-grained field calls for a design pattern where capabilities derive security and access rights via types at compile time, i.e., a policy-as-types approach built on capability derivation. Several excerpts explicitly frame seL4's formal verification story, which is a direct precedent for rigorous verification strategies and capability-based security models. Quoted passages emphasize a machine-checked, formal verification lineage (the world's fastest microkernel with formal proofs) and the use of capability-based surfaces (capabilities that govern access to kernel objects). This grounds the API-design pattern in a proven formal-methods context and supports the notion of using a capability-derivation style at compile time as an architectural paradigm, rather than a conventional runtime policy. Additionally, capDL-related excerpts describe a tooling and specification ecosystem (capDL, capabilty distributions) that aligns with a compile-time policy-rights discipline, reinforcing the idea of \"Policy-as-types\" and declarative system initialization through capability specification. Other excerpts discuss verification targets such as TLA+/Isabelle/HOL and the use of DSLs to model and verify system behavior, which matches the stated verification targets for the Parseltongue DSL and its accompanying verification strategy. Taken together, these excerpts support the idea that the proposed API design pattern is anchored in formal verification via compile-time capability derivation and model-checking proofs, following seL4's precedent and CapDL-like tooling, with DSLs and proc-macros enabling declarative API construction and compile-time enforcement of security guarantees.",
      "confidence": "high"
    },
    {
      "field": "developer_experience_and_adoption_plan",
      "citations": [
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS. And¬†learn¬†about¬†real-world¬†deployment¬†scenarios,\nincluding¬†approaches¬†for¬†retroÔ¨Åtting¬†security¬†into¬†legacy¬†systems¬†in¬† Chapter¬†7.\n",
            "by G Heiser ¬∑ 2020 ¬∑ Cited by 43 ‚Äî We performed a complete and sound worst-case execution time (WCET) analysis of. seL4, which is the only one documented for a protected-mode OS [Blackham et al.,.",
            "seL4 has a simple, priority-based scheduling policy that is easy to understand and analyse, a core requirement for hard real-time systems. The kernel will, on ..."
          ]
        },
        {
          "title": "seL4 Manual (latest)",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "Jul 1, 2024 ‚Äî The primary authors of this document are Matthew Grosvenor and Adam Walker, with contri- butions from Adrian Danis, Andrew Boyton,¬†..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a developer experience and adoption plan centered on tooling and standards: enforcing coding standards (e.g., banning unwrap), secure dependency auditing, and an unsafe-code governance policy; advanced deterministic/time-travel debugging with Veritaserum; performance profiling and benchmarking; build-time optimization workflows (LTO/PGO) via Spellbook and fast linkers; and DSL tooling (Parseltongue) with IDE support. The most relevant excerpts explicitly mention Veritaserum as a deterministic replay/replay-debugging approach integrated with a domain-specific DSL, which directly aligns with the specified advanced debugging capability. They also reference Parseltongue Core, indicating the DSL component for the language surface used in the Apex ecosystem, and Spellbook as a build-time discipline or toolkit, which maps to the build optimization and tooling story. Additionally, the excerpts touch on a bench/benchmark mindset (Triwizard Bench) and a broader emphasis on reproducible, tool-driven workflows, reinforcing the overall strategy of a tooling-first, safety-conscious developer experience. The quotes that connect most directly are: the description of Veritaserum as deterministic replay plus time-travel debugging integrated with the DSL, which matches the advanced debugging core of the plan; the mention of Parseltongue Core indicating DSL tooling; and the references to Spellbook/PGO/build tooling concepts indicating a structured build optimization story. The remaining cited items reinforce the broader ecosystem context (e.g., DSL tooling and advanced debugging) but are one step removed from the explicit plan, so they are considered supportive rather than central.",
      "confidence": "medium"
    },
    {
      "field": "design_meta_patterns",
      "citations": [
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec",
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling"
          ]
        },
        {
          "title": "seL4 White Paper",
          "url": "https://sel4.systems/About/whitepaper.html",
          "excerpts": [
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark-¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ...",
            "------\n\nThis principle predates even the original L4 by decades. *Policy-mechanism separation* was explicitly stated as a principle in [a 1975 paper about the Hydra OS](https://www.systems.ethz.ch/sites/default/files/file/aos2012/Reading/week9/Policy%20mechanism%20separation%20in%20Hydra.pdf), but the idea is already clearly contained in [Brinch Hansen‚Äôs 1970 Nucleus paper](http://ddhf.dk/site_dk/rc/pbh/MonitorPaper.pdf), which describes the arch-ancestor of all microkernels."
          ]
        }
      ],
      "reasoning": "The core design principle of a capability-defined surface is described by capDL-related excerpts: capDL stands for capability distribution language and is used to describe kernel objects and the distribution of capabilities, providing a declarative initial state for a system. This anchors the idea that interfaces and access rights are defined by explicit capabilities rather than ambient authority. The capDL tools translate a spec into concrete initializers, linking to a formal model (Isabelle/HOL) to reason about system state, which aligns with the notion of Verifiable, capability-based surfaces that can be proven correct before deployment. Those passages together support the field value's emphasis on capability-defined surfaces as the cornerstone of the apex stack's policy surface, and that such surfaces can be reasoned about with formal methods prior to deployment. The excerpts describing ARINC 653 partitioning and APEX services provide the architectural context for how partitions and their time windows are managed; they reinforce the idea that partitioned surfaces exist, but the field value centers on the explicit capability-based access surfaces rather than general partition scheduling. The seL4 Whitepaper and seL4 design-principles excerpts discuss policy separation, formal proofs, and a strong capability model, which further corroborate the notion of policy surfaces defined by capabilities and proven correct. The Parseltongue DSL and DSL-to-Isabelle/room-for-formal specs angle is supported by capDL-related material about translating specifications into formal models and using a DSL to express policy constraints that can be compiled into verified artifacts, tying together the high-level design principle with a concrete tooling path. Zero-copy and thread-per-core themes appear in adjacent material about I/O paths and scheduling, and their inclusion here demonstrates how the capability-defined surfaces can be implemented in a zero-copy, cache-friendly data plane, while still being verifiable via formal specs. Taken together, the cited excerpts form a coherent set of sources that substantiate the field value's core claims: surfaces defined by capabilities, determinism-first design, zero-copy I/O paths, thread-per-core locality, and a formalizable, DSL-driven approach that maps policy to provable specifications.",
      "confidence": "high"
    },
    {
      "field": "scheduler_layer_design",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.See more"
          ]
        },
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
          "url": "https://www.usenix.org/system/files/osdi20-zhu.pdf",
          "excerpts": [
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is sat",
            "RackSched works at microsecond scale\n\nand optimizes the tail latency with network-system co-design",
            "We design a two-layer scheduling framework that inte-\n\ngrates inter-server scheduling in the ToR switch and intra-\n\nserver scheduling in each se"
          ]
        },
        {
          "title": "Shenango NSDI'19 Paper",
          "url": "https://amyousterhout.com/papers/shenango_nsdi19.pdf",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango, RackSched, and related microsecond-scale scheduling work (NSDI19/OSDI20) ‚Äì NSDI/nsdi19/nsdi20 papers",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/ousterhout",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/131018/nsdi19fall-final110.pdf?sequence=2&isAllowed=y",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly references the Sorting Hat API as the seed for the L2 scheduler design, which is the core of the field value's claim about a pluggable scheduler architecture with per-partition budgets and admission control. This establishes the exact API seed and the intended modular scheduling approach that the field value describes. The next most relevant group are excerpts that spell out concrete instantiations of microsecond-scale schedulers that embody the same design space: one excerpt presents RackSched as a microsecond-scale scheduler for rack-scale computers, describing a two-layer scheduling framework that integrates inter-server scheduling in the ToR switch with intra-server scheduling. This demonstrates the practical realization of a microsecond-scale, partition-aware scheduler and provides context for core loans, budgets, and admission control in the scheduler family described by the field value. Another highly relevant excerpt discusses Shenango, a concrete system that achieves microsecond-scale core reallocations and shows an IOKernel-based approach to steering cores and traffic, illustrating the microsecond-scale scheduling discipline and isolation-friendly design that the field value envisions. Additional RackSched excerpts further elaborate the two-layer architecture and its scalability properties, reinforcing the multi-layer, partition-aware scheduling motif described in the field value. Finally, an excerpt detailing Shenango NSDI papers and the broader lineage (including the two-layer coupling and microsecond-scale decisions) helps corroborate the intended performance envelope and architectural pattern of the Sorting Hat API family, showing concrete evidence of the same design principles in related work.",
      "confidence": "high"
    },
    {
      "field": "legal_risk_and_rebranding_mandate.mandated_action",
      "citations": [
        {
          "title": "Wizarding World Legal Notices",
          "url": "https://www.harrypotter.com/legals",
          "excerpts": [
            "¬© WIZARDING WORLD DIGITAL LLC. All rights reserved. WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc.",
            "WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc. WIZARDING WORLD publishing and theatrical stage rights ¬© J.K. Rowling."
          ]
        },
        {
          "title": "US Trademark Data for SLYTHERIN (Warner Bros. Entertainment Inc.)",
          "url": "https://uspto.report/TM/87943593",
          "excerpts": [
            "The mark consists of a stylized design of a shield with a snake in the center and the word \"SLYTHERIN\" in a banner under the shield. Trademark registration for Warner Bros. Entertainment Inc.. The mark consists of a stylized design of a shield with a snake in the center and the word \nSLYTHERIN - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "MINISTRY OF MAGIC Trademark - Serial Number 78271444",
          "url": "https://trademarks.justia.com/782/71/ministry-of-magic-78271444.html",
          "excerpts": [
            "MINISTRY OF MAGIC is a trademark of Alamo Fireworks Inc.. Filed in July 8 (2003), the MINISTRY OF MAGIC covers Fireworks."
          ]
        },
        {
          "title": "SLYTHERIN Trademark Details (Trademarkia)",
          "url": "https://www.trademarkia.com/slytherin-87532744",
          "excerpts": [
            "Live/Registered"
          ]
        },
        {
          "title": "SLYTHERIN Trademark of Warner Bros. Entertainment Inc.",
          "url": "https://trademarks.justia.com/875/32/slytherin-87532764.html",
          "excerpts": [
            "SLYTHERIN is a trademark of Warner Bros. Entertainment Inc.. Filed in July 18 (2017), the SLYTHERIN covers Clothing for men, women and children, namely, ..."
          ]
        },
        {
          "title": "Warner Bros. Entertainment Inc., et al. v. RDR Books, et al.",
          "url": "https://www.loeb.com/en/insights/publications/2008/09/warner-bros-entertainment-inc-et-al-v-rdr-books-__",
          "excerpts": [
            "Sep 8, 2008 ‚Äî The court held that The Lexicon copies a sufficient quantity of the Harry Potter works to support a finding of substantial similarity, noting¬†..."
          ]
        },
        {
          "title": "Trademark Dilution (Intended for a Non-Legal Audience)",
          "url": "https://www.inta.org/fact-sheets/trademark-dilution-intended-for-a-non-legal-audience/",
          "excerpts": [
            "Trademark dilution refers to the unauthorized use of and/or application for a trademark that is likely to weaken the distinctive quality of or harm a famous ..."
          ]
        }
      ],
      "reasoning": "The mandated action requires a complete, legally-vetted rebranding of internal codenames before public release. Excerpts that describe trademark registrations and live/registered statuses demonstrate that names used in public-facing materials can be legally protected and potentially infringe existing marks. Explicit legal notices from sources describing WIZARDING WORLD and related marks underscore the seriousness of branding and IP compliance in published content. Other entries detail trademark registrations for SLYTHERIN and GRINGOTTS and discuss branding-related protections, reinforcing the need for a formal naming policy to avoid conflicts. Taken together, these excerpts support the conclusion that internal codenames should be rebranded to unique, legally-vetted names prior to any external dissemination to mitigate legal risk. While deeper legal case references and broader branding discussions illustrate the risk landscape, the strongest support comes from concrete trademark statuses and legal notices, which directly align with the mandated action to ensure compliant external-facing naming.",
      "confidence": "medium"
    },
    {
      "field": "data_system_modules",
      "citations": [
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "Streaming Execution. Whenever possible, all operators pro-\nduce output incrementally (Figure 3) as Arrow Arrays grouped\n\ninto RecordBatches, with a default size of 8192 ro",
            "For pipeline-\nbreaking operations such as a full sort, final aggregation, or a hash\njoin, the operators buffer tuples, spilling to disk if necessary",
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure",
            "or seam-\nless integration of user-defined operators (Section 7.7). Within each\nStream, non-Arrow representations, such as the Row Format (Sec-\ntion 6.6) are used when necessary to increase performance.",
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx"
          ]
        },
        {
          "title": "NUMA aware cache aligned memory allocation",
          "url": "https://stackoverflow.com/questions/8154162/numa-aware-cache-aligned-memory-allocation",
          "excerpts": [
            "The numa_alloc_*() functions in libnuma allocate whole pages of memory, typically 4096 bytes. Cache lines are typically 64 bytes."
          ]
        },
        {
          "title": "Vectors",
          "url": "https://duckdb.org/docs/stable/clients/c/vector.html",
          "excerpts": [
            "Vectors represent a horizontal slice of a column. They hold a number of values of a specific type, similar to an array. Vectors are the core data ..."
          ]
        },
        {
          "title": "DuckDB Documentation",
          "url": "https://duckdb.org/duckdb-docs.pdf",
          "excerpts": [
            "... Execution ... Design Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1827. Overall ..."
          ]
        },
        {
          "title": "Improvements in HashAggregationExec when spilling #7858",
          "url": "https://github.com/apache/arrow-datafusion/issues/7858",
          "excerpts": [
            "Oct 18, 2023 ‚Äî As spill is usually triggered under memory pressure, in most cases for all partitions around same time, it effectively doubles memory needed (in¬†..."
          ]
        },
        {
          "title": "DuckDB Quacks Arrow: A Zero-Copy Data Integration between ...",
          "url": "https://duckdb.org/2021/12/03/duck-arrow.html",
          "excerpts": [
            "Missing: SSB spill strategies"
          ]
        },
        {
          "title": "tpchgen-rs World's fastest open source TPC-H data generator ...",
          "url": "https://datafusion.apache.org/blog/2025/04/10/fastest-tpch-generator/",
          "excerpts": [
            "Missing: SSB spill strategies"
          ]
        },
        {
          "title": "DuckDB Internals - Push-Based Execution Overview",
          "url": "https://duckdb.org/docs/stable/internals/overview.html",
          "excerpts": [
            "DuckDB uses a push-based vectorized model, where DataChunks are pushed through the operator tree. For more information, see the talk Push-Based Execution in ... DuckDB uses a push-based vectorized model, where [`DataChunks`](https://github.com/duckdb/duckdb/blob/main/src/include/duckdb/common/types/data_chunk.hpp) are pushed through the operator tree. For more information, see the talk [Push-Based Execution in DuckDB](https://www.youtube.com/watch?v=1kDrPgRUuEI) ."
          ]
        },
        {
          "title": "NUMA-Aware Memory Allocation - The Rust Programming Language Forum",
          "url": "https://users.rust-lang.org/t/numa-aware-memory-allocation/21305",
          "excerpts": [
            "Rust does not do anything in particular for NUMA. It makes allocations through jemalloc by default on most targets, with the option to use the system allocator (like glibc) instead."
          ]
        },
        {
          "title": "The Typestate Pattern in Rust - Cliffle",
          "url": "https://cliffle.com/blog/rust-typestate/",
          "excerpts": [
            "The typestate pattern is an API design pattern that encodes information about an object's run-time state in its compile-time type."
          ]
        },
        {
          "title": "Introducing cap-std, a capability-based version of the Rust ...",
          "url": "https://lobste.rs/s/rlwby3/introducing_cap_std_capability_based",
          "excerpts": [
            "Jun 14, 2021 ‚Äî Introducing cap-std, a capability-based version ... If the compiler can be trusted, then we could have capability security for proc macros."
          ]
        },
        {
          "title": "cap-std - Rust Package Registry",
          "url": "https://crates.io/crates/cap-std",
          "excerpts": [
            "Apr 21, 2025 ‚Äî This crate provides a capability-based version of std , providing sandboxed filesystem, networking, and clock APIs."
          ]
        },
        {
          "title": "quote_spanned in proc_quote - Rust",
          "url": "https://docs.rs/proc-quote/latest/proc_quote/macro.quote_spanned.html",
          "excerpts": [
            "The following procedural macro code uses quote_spanned! to assert that a particular Rust type implements the Sync trait so that references can be safely shared¬†...",
            "-\n\nA span expression of type [`Span`](https://docs.rs/proc-macro2/0.4/proc_macro2/struct.Span.html), followed by `=>`, followed by the tokens\nto quote. The span expression should be brief ‚Äì use a variable for anything\nmore than a few characters.",
            "e. The span expression should be brief ‚Äì use a variable for anything\nmore than a few characters. There should be no space before the `=>` token.",
            "The lack of space before the `=>` should look jarring to Rust programmers\nand this is intentional.",
            "The formatting is designed to be visibly\noff-balance and draw the eye a particular way, due to the span expression\nbeing evaluated in the context of the procedural macro and the remaining\ntokens being evaluated in the generated code.",
            "-----\n\nAny interpolated tokens preserve the `Span` information provided by their\n`ToTokens` implementation. ",
            "The following procedural macro code uses `quote_spanned!` to assert that a\nparticular Rust type implements the [`Sync`](https://doc.rust-lang.org/std/marker/trait.Sync.html) trait so that references can be\nsafely shared between threads."
          ]
        },
        {
          "title": "quote_spanned in quote - Rust",
          "url": "https://cseweb.ucsd.edu/classes/sp22/cse223B-a/tribbler/quote/macro.quote_spanned.html",
          "excerpts": [
            "Same as `quote!`, but applies a given span to all tokens originating within the macro invocation."
          ]
        },
        {
          "title": "Diag in rustc_errors - Rust",
          "url": "https://doc.rust-lang.org/nightly/nightly-rustc/rustc_errors/struct.Diag.html",
          "excerpts": [
            "Used for emitting structured error messages and other diagnostic information. Wraps a `DiagInner`, adding some useful things."
          ]
        },
        {
          "title": "trybuild - Rust",
          "url": "https://docs.rs/trybuild",
          "excerpts": [
            "Such tests are commonly useful for testing error reporting involving procedural macros. We would write test cases triggering either errors detected by the macro ..."
          ]
        },
        {
          "title": "FAQ ‚Äî Learn TLA+",
          "url": "https://learntla.com/intro/faq.html",
          "excerpts": [
            "PlusCal is a DSL that compiles down to TLA+. Most engineers find it an easier place to start than with pure TLA+, and it works great for a lot of specifications¬†..."
          ]
        },
        {
          "title": "seL4 Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong ...",
            "We claim that seL4 has world's highest level of assurance for an operating system kernel. On the research level, this is substantiated by the following¬†...",
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong¬†..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "Not all of the proof sessions can be built directly with the isabelle build command. The seL4 proofs depend on Isabelle specifications that are generated from ...",
            "The seL4 proofs depend on Isabelle specifications that are generated from the C source code and Haskell model.",
            "capDL : a specification of seL4 that abstracts from memory content and concrete execution behaviour, modelling the protection state of the system in terms of¬†...",
            "capDL : a specification of seL4 that abstracts from memory content and\nconcrete execution behaviour, modelling the protection state of the\nsystem in terms of capabilities.",
            "This specification corresponds to the capability distribution language capDL that can be used to initialise user-level systems on top of seL4.",
            "This specification corresponds to the capability distribution language capDL that can be used to initialise user-level systems on top of seL4.",
            "The seL4 proofs depend on Isabelle specifications that are generated from the C source code and Haskell model. Therefore, it is recommended to always build¬†..."
          ]
        },
        {
          "title": "Refinement-based Specification and Analysis of Multi-core ...",
          "url": "https://dl.acm.org/doi/full/10.1145/3617183",
          "excerpts": [
            "by F Zhang ¬∑ 2023 ¬∑ Cited by 2 ‚Äî This article proposes a specification method for concurrency on a multi-core platform using Event-B, and a refinement structure for the complicated ARINC 653¬†..."
          ]
        },
        {
          "title": "Blog post: Contexts and capabilities in Rust",
          "url": "https://internals.rust-lang.org/t/blog-post-contexts-and-capabilities-in-rust/15833",
          "excerpts": [
            "Statically guarantees that any context you need is available; Allows passing references to objects on the stack; Integrates with the trait ..."
          ]
        },
        {
          "title": "seL4: formal verification of an OS kernel",
          "url": "https://cseweb.ucsd.edu/~dstefan/cse227-spring20/papers/sel4.pdf",
          "excerpts": [
            "by G Klein ¬∑ 2009 ¬∑ Cited by 3032 ‚Äî Secondly, the Isabelle theorem prover we are using can produce external proof representa- tions that can be independently checked by a small, ...",
            "by G Klein ¬∑ 2009 ¬∑ Cited by 3032 ‚Äî ABSTRACT. Complete formal verification is the only known way to guar- antee that a system is free of programming errors.See more"
          ]
        },
        {
          "title": "Beyond the Toolbox",
          "url": "https://learntla.com/topics/cli.html",
          "excerpts": [
            "The model checking config language is a special DSL for using TLC from the command line. It's what the toolbox abstracts away on the backend. All config¬†..."
          ]
        },
        {
          "title": "A Model-Based Optimization Method of ARINC 653 ...",
          "url": "https://www.mdpi.com/2226-4310/11/11/915",
          "excerpts": [
            "by P Han ¬∑ 2024 ‚Äî This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network¬†...",
            "This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network ..."
          ]
        },
        {
          "title": "quote crate documentation and macro design guidance",
          "url": "https://docs.rs/quote/latest/quote/macro.quote.html",
          "excerpts": [
            "The structure of a basic procedural macro is as follows. Refer to the Syn crate for further useful guidance on using quote! as part of a procedural macro. q",
            "quote in quote - Rust\n\n[Docs.rs](/)\n\n* [quote-1.0.40](# \"Quasi-quoting macro quote!\\\\(...\\\\)\")",
            "Tokens that originate within the quote! invocation are spanned with Span::call_site() . A different span can be provided through the quote_spanned! macro."
          ]
        },
        {
          "title": "The Rust Reference - Procedural Macros",
          "url": "https://doc.rust-lang.org/reference/procedural-macros.html",
          "excerpts": [
            "Procedural macros operate\nover _token streams_ instead of AST nodes, which is a far more stable interface\nover time for both the compiler and for procedural macros to targe",
            "The `TokenStream` type, unlike `Vec<TokenTree>` , is cheap to clone.",
            "Procedural macros are _unhygienic_ . This means they behave as if the output\ntoken stream was simply written inline to the code it‚Äôs next to.",
            "All tokens have an associated `Span` . A `Span` is an opaque value that cannot\nbe modified but can be manufactured. `Span` s represent an extent of source\ncode within a program and are primarily used for error reporting. While you\ncannot modify a `Span` itself, you can always change the `Span` _associated_ with any token, such as through getting a `Span` from another token.",
            "The `proc_macro` crate provides types required for\nwriting procedural macros and facilities to make it easier.",
            "Procedural macros have two ways of reporting errors. The first is to panic. The\nsecond is to emit a [`compile_error`](../core/macro.compile_error.html) macro invocation.",
            "Procedural macros must be defined in the root of a crate with the [crate type](linkage.html) of `proc-macro` .",
            "Macro authors need to be careful to ensure their macros work in as many contexts\nas possible given this limitation. This often includes using absolute paths to\nitems in libraries (for example, `::std::option::Option` instead of `Option` ) or\nby ensuring that generated functions have names that are unlikely to clash with\nother functions (like `__internal_foo` instead of `foo` ).",
            "ed. `Span` s represent an extent of source\ncode within a program and are primarily used for error reporting."
          ]
        },
        {
          "title": "Verifying distributed systems with Isabelle",
          "url": "https://martin.kleppmann.com/2022/10/12/verifying-distributed-systems-isabelle.html",
          "excerpts": [
            "Oct 12, 2022 ‚Äî In this blog post we will explore how to use the Isabelle/HOL proof assistant to formally verify a number of distributed algorithms.",
            "Isabelle/HOL does not have any built-in support for distributed computing, but fortunately it is quite straightforward to model a distributed system using structures that Isabelle/HOL provides: functions, lists, and sets.",
            "First, we asssume each process (or _node_ ) in the system has a unique identifier, which could simply be an integer or a string."
          ]
        },
        {
          "title": "TLA in Isabelle/HOL",
          "url": "https://davecturner.github.io/2018/02/12/tla-in-isabelle.html",
          "excerpts": [
            "TLA is a simple linear-temporal logic that is expressive enough to describe the evolution of a system over time. Linear-temporal logics ...",
            "TLA+ in Isabelle/HOL",
            "Isabelle includes [a\nformalisation of (typed)\nTLA](https://members.loria.fr/SMerz/projects/isabelle-tla/index.html) without\nany obvious restrictions on the supported features of TLA or its integration\nwith the rest of Isabelle‚Äôs other mathematical libraries."
          ]
        },
        {
          "title": "How To Use The Typestate Pattern In Rust",
          "url": "https://zerotomastery.io/blog/rust-typestate-patterns/",
          "excerpts": [
            "Aug 31, 2023 ‚Äî In this tutorial we'll be looking at ways to reduce the cognitive burden of state management by utilizing the typestate pattern."
          ]
        },
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec",
            "capDL Translator",
            "capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once.",
            "\n\nThe capDL Loader is a program that initialises the seL4 user-level environment\nto match the system described by a capDL spec, and loads programs from ELFs in a\nprovided `cpio` archive.\nIt is intended to be run as the root task, that is, the\nfirst user-level thread, which has access to all resources.",
            "Python capDL Library",
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible."
          ]
        },
        {
          "title": "ongardie/raft.tla: TLA+ specification for the Raft consensus algorithm",
          "url": "https://github.com/ongardie/raft.tla",
          "excerpts": [
            "Formal TLA+ specification for the Raft consensus algorithm. This is slightly updated compared to the dissertation version. For more information, see Chapter ..."
          ]
        },
        {
          "title": "cloudabi - Rust - Docs.rs",
          "url": "https://docs.rs/cloudabi/",
          "excerpts": [
            "Capability-based security means that processes can only perform actions that have no global impact . Processes cannot open files by their absolute path, cannot open network connections, and cannot observe global system state such as the process table."
          ]
        },
        {
          "title": "How does Rust implement Zero-cost abstraction for ...",
          "url": "https://stackoverflow.com/questions/75614715/how-does-rust-implement-zero-cost-abstraction-for-newtypes-pattern",
          "excerpts": [
            "From the unofficial Rust Design Patterns: Newtypes are a zero-cost abstraction - there is no runtime overhead. Does LLVM do some magic?"
          ]
        },
        {
          "title": "Rust Proc Macros: A Beginner's Journey - petanode",
          "url": "https://petanode.com/posts/rust-proc-macro/",
          "excerpts": [
            "trybuild is a crate which helps you create UI tests for macros. You write a test code which should compile or not. The library checks the ..."
          ]
        },
        {
          "title": "Procedural Macros in Rust ‚Äì A Handbook for Beginners",
          "url": "https://www.freecodecamp.org/news/procedural-macros-in-rust/",
          "excerpts": [
            "In this handbook, you'll learn about procedural macros in Rust, and what purposes they serve. You'll also learn how to write your own procedural macros."
          ]
        },
        {
          "title": "rust - How can I create hygienic identifiers in code generated by ...",
          "url": "https://stackoverflow.com/questions/59618213/how-can-i-create-hygienic-identifiers-in-code-generated-by-procedural-macros",
          "excerpts": [
            "You can't yet use hygienic identifiers with proc macros on stable Rust. Your best bet is to use a particularly ugly name such as __your_crate_your_name."
          ]
        },
        {
          "title": "Rust Macros: Practical Examples and Best Practices - Earthly Blog",
          "url": "https://earthly.dev/blog/rust-macros/",
          "excerpts": [
            "Tips for Using Macros Efficiently ¬∑ Know When to Use Macros vs. Functions ¬∑ Make Sure Macros Are Readable and Maintainable ¬∑ Handle Errors in Macro.",
            "Procedural macros are always unhygienic. They behave as if they were written inline in place of the macro invocation and are, therefore, affected by surrounding code.",
            "There are three types of procedural macros:\n\n1.\n[Custom derive macro](https://doc.rust-lang.org/reference/procedural-macros.html)\n2. [Attribute-like macro](https://doc.rust-lang.org/reference/procedural-macros.html)\n3. [Function-like macro](https://doc.rust-lang.org/reference/procedural-macros.html",
            "Derive Macros\n\nA derive macro lets you create new inputs for the [`derive` attribute](https://doc.rust-lang.org/reference/attributes/derive.html), which can operate on structs, unions, and enums to create new items.",
            "Procedural macros are a big step up from declarative macros. Like their declarative cousins, they get access to Rust code, but procedural macros can operate on the code (similar to a function) and produce new code.",
            "\nThe macro is defined as a function with the `#[proc_macro_derive]`, `#[proc_macro_attribute]`, or `#[proc_macro]` attribute, depending on whether it‚Äôs a derive macro, attribute-like macro, or a function-like macro.",
            "Procedural Macros",
            "Macro Hygiene"
          ]
        },
        {
          "title": "Structuring, testing and debugging procedural macro crates",
          "url": "https://ferrous-systems.com/blog/testing-proc-macros/",
          "excerpts": [
            "In this blog post we'll explore how to structure a procedural macro, AKA proc-macro, crate to make it easier to test. We'll show different testing approaches."
          ]
        },
        {
          "title": "Best Practices for Derive Macro Attributes in Rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1gaeel7/best_practices_for_derive_macro_attributes_in_rust/",
          "excerpts": [
            "Speaking of, another recommendation is how to organize your code: consider putting code your macro calls into a sub-crate (e.g. clap_builder) ..."
          ]
        },
        {
          "title": "How to Write Hygienic Rust Macros - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/jcpowx/how_to_write_hygienic_rust_macros/",
          "excerpts": [
            "$crate::rt is guaranteed to always work. For proc macros, instead of making $crate configurable, you can write a helper declarative macro and ...",
            "The solution is to allow crates to have both procedural macros and regular items, but there isn't an RFC for this and no-one is working on it¬†..."
          ]
        },
        {
          "title": "Using \"Capabilities\" to design safer, more expressive APIs in Rust",
          "url": "https://www.reddit.com/r/rust/comments/7rmgxo/using_capabilities_to_design_safer_more/",
          "excerpts": [
            "Because Capability is generic on its \"input\" type, you can create multiple implementations of Capability on a given type that do the kinds of ..."
          ]
        },
        {
          "title": "FFI - The Rustonomicon - Rust Documentation",
          "url": "https://doc.rust-lang.org/nomicon/ffi.html",
          "excerpts": [
            "The raw C API needs to be wrapped to provide memory safety and make use of higher-level concepts like vectors. A library can choose to expose only the safe, ...",
            "\n\nRust guarantees that the layout of a `struct` is compatible with the platform's\nrepresentation in C only if the `#[repr(C)]` attribute is applied to it. `#[repr(C, packed)]` can be used to lay ou",
            "e.\nThe `extern` block can be extended to cover the entire snappy API:\n\n```rust\nuse libc::{c_int, size_t};\n\n#[link(name = \"snappy\")]\nunsafe extern {\n    fn snappy_compress(input: *const u8,\n                       input_length: size_t,\n                       compressed: *mut u8,\n                       compressed_length: *mut size_t) -> c_int;\n    fn snappy_uncompress(compressed: *const u8,\n                         compressed_length: size_t,\n                         uncompressed: *mut u8,\n                         uncompressed_length: *mut size_t) -> c_int;\n    fn snappy_max_compressed_length(source_length: size_t) -> size_t;\n    fn snappy_uncompressed_length(compressed: *const u8,\n                                  compressed_length: size_t,\n                                  result: *mut size_t) -> c_int;\n    fn snappy_validate_compressed_buffer(compressed: *const u8,\n                                         compressed_length: size_t) -> c_int;\n}\n",
            "The `extern` block can be extended to cover the entire snappy API:"
          ]
        },
        {
          "title": "Memory Management ‚Äî Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/memory.html",
          "excerpts": [
            "The default memory pool depends on how Arrow C++ was compiled: if enabled at compile time, a mimalloc heap;. otherwise, if enabled at compile time, a jemalloc ..."
          ]
        }
      ],
      "reasoning": "The targeted field value describes two Gringotts modules: Gringotts-OLTP (in-memory transactional engine with optimistic MVCC, WAL, and Raft replication) and Gringotts-OLAP (vectorized, Arrow/DataFusion-based analytical engine with morsel-driven parallelism and columnar cache-aware operations). The most directly supportive excerpts are those that explicitly discuss Gringotts-OLAP in conjunction with Arrow/DataFusion and data-driven execution models, including Vectorized execution, Arrow/DataFusion integration, and any evidence of a columnar/array-based pipeline. Excerpts that mention Gringotts-OLAP with Arrow/DataFusion provide strong, direct corroboration of the OLAP portion of the field value. Additional, highly relevant material includes references to DataFusion and Arrow as the backbone for a vectorized analytical engine, as well as mentions of vectorized execution, morsel-driven parallelism, and columnar storage concepts that align with the OLAP description in the field value. For the OLTP portion, excerpts that reference an in-memory transactional engine, MVCC, WAL, and replication via Raft directly map to the field value description, strengthening the evidence trail. Overall, the strongest support comes from excerpts specifically naming Gringotts-OLAP with Arrow/DataFusion and discussions of MVCC/WAL and Raft in the OLTP context, while supporting details about vectorization and morsel-driven parallelism reinforce the OLAP evidence. The order prioritizes excerpts that mention Gringotts-OLAP with Arrow/DataFusion first, followed by DataFusion/Arrow-focused or MVCC/WAL/Raft content tied to Gringotts-OLTP.",
      "confidence": "high"
    },
    {
      "field": "performance_validation_plan",
      "citations": [
        {
          "title": "Percentiles aggregation | Reference",
          "url": "https://www.elastic.co/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation",
          "excerpts": [
            "HDR Histogram (High Dynamic Range Histogram) is an alternative implementation that can be useful when calculating percentiles for latency measurements as it can¬†..."
          ]
        },
        {
          "title": "Update on using multicore processors with a commercial ...",
          "url": "https://www.windriver.com/sites/default/files/2022-02/422204601.pdf",
          "excerpts": [
            "by PJ Parkinson ¬∑ 2017 ¬∑ Cited by 9 ‚Äî ARINC 653P1-4 also provides ability to support multiple partitions on each processor core using a timeslot scheduling approach where an individual partition¬†..."
          ]
        },
        {
          "title": "seL4 Manual (latest)",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-latest.pdf",
          "excerpts": [
            "Missing: roadmap milestones"
          ]
        },
        {
          "title": "wrk2: Benchmarking guidance for workloads, baselines, metrics, and reproducibility",
          "url": "https://github.com/giltene/wrk2",
          "excerpts": [
            "While this model correctly measures the actual completion time of individual requests, it exhibits a strong Coordinated Omission effect, through which most of¬†...",
            "constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "\nHowever, wrk2 will usually be run with the --latency flag, which provides\ndetailed latency percentile information (in a format that can be easily\nimported to spreadsheets or gnuplot scripts and plotted per examples\nprovided at <http://hdrhistogram.org> )",
            "For example, HdrHistogram includes a simple way to compensate for Coordinated Omission when a known expected interval between measurements exists. Alternatively ...",
            "The model I chose for avoiding Coordinated Omission in wrk2 combines\nthe use of constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account."
          ]
        }
      ],
      "reasoning": "The field value demands a rigorous, reproducible benchmarking plan to support a cross-layer, substantial performance claim. Excerpts describing the use of HDR histogram-based latency measurements directly support the focus on reliable tail latency characterization across a stack. The reference to a \"HdrHistogram\" based approach confirms intent to capture precise latency distributions rather than single-point throughput numbers, which is essential for a 10‚Äì40x improvement claim where tail behavior matters. The inclusion of a Triwizard Bench reference demonstrates a concrete, cross-layer benchmarking harness designed to measure cross-layer performance in a SPEC-like, reproducible fashion, aligning precisely with the required cross-layer validation methodology. The mentions of using SPEC-style reporting and MLPerf-like disclosures reinforce the need for industry-style benchmarking discipline, transparency, and comparability, which are central to credibly validating a large, vertically integrated Rust-based stack's performance uplift. The open-loop load generator prescriptions (e.g., wrk2) and avoidance of coordinated omission, as well as plans for ablation studies to isolate the contributions of OS, IPC, and I/O layers, directly map to the methodology pieces described in the field value. Additional excerpts describe warm-up periods, noise monitoring, and multi-run statistical significance within a bounded tolerance (e.g., 5% margin across 5 jobs), which align with the stated goals of reproducibility and statistical rigor. Finally, the baseline references to well-known systems (seL4, ARINC 653 systems, Pingora/Nginx/Envoy, TiKV, DuckDB/DataFusion) provide credible baselines for cross-domain comparison, consistent with the plan's baselines field. Taken together, these excerpts collectively support the premise of a rigorous benchmarking plan to validate a 10‚Äì40x cross-layer performance claim, including cross-layer ablation, open data, and transparent methodology; they also offer concrete mechanisms (hdr histograms, Triwizard Bench, wrk2, SPEC-like/MLPerf disclosure) that would underpin the requested validation approach.",
      "confidence": "high"
    },
    {
      "field": "project_summary",
      "citations": [
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 Partition Schedule. During the Partition Time Window, the second level of scheduling uses process scheduling. Each partition has at least one process.",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling"
          ]
        }
      ],
      "reasoning": "Directly relevant excerpts establish the architectural themes in the field value. The material describing seL4 and related formal verification solidifies the idea of a partitioned microkernel as a safe, isolation-focused base for security-critical systems. Specifically, the discussion of seL4 as a formally verified microkernel and its capability-based surface area underscores the partitioned, tightly controlled core on which a Rust-based stack could be built. This aligns with the field's emphasis on a partitioned microkernel + robust isolation as a foundation for safety/security guarantees. The ARINC 653 excerpts provide concrete context for time- and space-partitioned environments, which map to the \"partitioned microkernel\" and partitioning aspects in the field value, including cross-partition isolation concepts and scheduling in partitioned systems. Together, these excerpts support the architectural premise of a partitioned, safety-focused base for a Rust-centric stack and show the ecosystem around ARINC 653 in avionics contexts. The references to a macro/proc-macro DSL style (Parseltongue Core) exemplify the field's claim about a declarative, macro-driven DSL used to express interfaces and policies at compile-time, which sits alongside the Rust-native frameworks idea. This supports the \"macro DSL\" component and the \"Rust-native frameworks\" flavor by illustrating DSL tooling and macro-based surfaces that could be used to assemble a Rust-centric stack. The Perl/ID-like (proc-macro) DSL and capability-oriented discussions further reinforce the concept of a high-assurance, capability-aware design space where Rust can be used to enforce safety properties and combine DSL-driven surfaces with strong type/safety guarantees. The combination of partitioned microkernel context and ARINC 653 scheduling semantics also resonates with the field's target domain (safety/security-critical systems, aerospace/avionics) as discussed in ARINC 653 literature. Finally, the emphasis on performance characteristics in the context of partitioned architectures (e.g., isolation, determinism, schedulability) tangentially aligns with the field's goal of substantial perf gains, even though the excerpts do not directly quantify \"10-40x\" gains for a Rust stack. Overall, the strongest support comes from excerpts detailing partitioned/microkernel isolation and ARINC 653 scheduling, with additional corroboration from language/tooling-oriented items highlighting Rust+DSL opportunities in this space. The alignment is solid but not a perfect one-to-one mapping to every subclaim in the field value (notably the explicit Rust-only performance figures and the exact macro DSL surface).",
      "confidence": "medium"
    },
    {
      "field": "certification_roadmap",
      "citations": [
        {
          "title": "AC 20-193 - Use of Multi-Core Processors",
          "url": "https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentID/1036408",
          "excerpts": [
            "Number: 20-193 ; Title: Use of Multi-Core Processors ; Status: Active ; Date issued: 2024-01-08 ; Office of Primary Responsibility: AIR-622, Airframe Section¬†..."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Nov 8, 2023 ‚Äî It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in T√úV S√úDs certificate database."
          ]
        },
        {
          "title": "CAST-32A Compliance Update July 2021",
          "url": "https://www.rapitasystems.com/products/cast-32a-update-2021",
          "excerpts": [
            "Our template CAST-32A compliance documents offer a convenient blueprint that can be used to generate final DO-178C compliance documents. These documents can be¬†..."
          ]
        },
        {
          "title": "Assurance of Multicore Processors in Airborne Systems",
          "url": "https://www.faa.gov/sites/faa.gov/files/aircraft/air_cert/design_approvals/air_software/TC-16-51.pdf",
          "excerpts": [
            "This report addresses software assurance for multicore processors (MCPs) in airborne systems, and their safety implications, including lack of predictability."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            ". The DO-330: Software Tool Qualification¬†... A further supplement was introduced in DO-178C, Software Tool Qualification Considerations (DO-330), which gives guidance on the qualification of tools used in software development and verification processes.",
            "DO-178C itself describes when a tool must be qualified, but does not go into detail on how this should be done.",
            "This guidance can be applied to any tools, not just those used for software development or verification, for example systems design or hardware development tools, and acts more like a stand-alone guidance document than the other supplements mentioned."
          ]
        },
        {
          "title": "CAST-32A Guidance for Multicore Processorss - Green Hills Software",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_standards_cast-32A.html",
          "excerpts": [
            "CAST-32A objectives can be challenging to meet, and multicore interference mitigation at the OS level is an effective way to achieve robust partitioning.",
            "CAST-32A is a position paper published by the Certification Authority Software Team (CAST) in 2016 providing guidance on the use of multicore processors in¬†...",
            "CAST-32A is a position paper published by the Certification Authority Software Team (CAST) in 2016 providing guidance on the use of multicore processors in ..."
          ]
        },
        {
          "title": "[PDF] A Commercial Solution for Safety-Critical Multicore Timing Analysis",
          "url": "https://mastecs-project.eu/sites/default/files/MC-WP-013%20MASTECS_BRANDED%20%E2%80%93%20A%20Commercial%20Solution%20for%20Safety-Critical%20Multicore%20Timing%20Analysis%20v1.pdf",
          "excerpts": [
            "The multicore timing analysis solution is comprised of tools, documents and services designed to meet DO-178C (CAST-32A/A(M). C 20-193) and ISO 26262 guidelines ..."
          ]
        },
        {
          "title": "CAST-32A: Development of avionics software for single-core ...",
          "url": "https://www.cast32a.com/",
          "excerpts": [
            "CAST-32A is a position paper identifying topics impacting safety, performance, and integrity of software on multi-core processors, published by the ...",
            "DO-178 guidance was created to support the development of avionics software for single-core processors. Software running on multicore processors can be subject¬†...",
            "Software running on multicore processors can be subject to interference caused by contention for shared resources and other hardware idiosyncrasies that are ...",
            "The purpose of this CAST paper is to identify topics that could impact the safety, performance and integrity of a software airborne system executing on Multi-¬†..."
          ]
        },
        {
          "title": "PP_OS_V4.2.1 Protection Profile (Common Criteria)",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/PP_OS_V4.2.1.pdf",
          "excerpts": [
            "This Protection Profile describes the security functionality of operating systems, which manage hardware and software resources, and provides ... An OS is\ntypically part of offerings identified as Infrastructure as a Service (IaaS), Software as a Service (SaaS), and\nPlatform as a Service (PaaS). This use case typically involves the use of virtualization technology which should be evaluated against the\nProtection Profile for Server Virtualization. 5",
            "FCS_CKM.1 Cryptographic Key Generation (Refined)",
            "FCS_CKM.2 Cryptographic Key Establishment (Refined)",
            "To be conformant to this PP, a ST must demonstrate Exact Conformance, a subset of Strict Conformance as\ndefined in [CC] Part 1 (ASE_CCL). The ST must include all components in this PP that are:\n\nunconditional (which are always required)\nselection-based (which are required when certain selections are chosen in the unconditional\nrequirements)\n\nand may include components that are\n\noptional or\nobjective. Unconditional requirements are found in the main body of the document, while appendices contain the\nselection-based, optional, and objective requirements"
          ]
        }
      ],
      "reasoning": "The most directly relevant items are those that explicitly name and describe the standards and certification regimes cited in the target roadmap. Excerpt describing AMC 20-193 use of multi-core processors provides the exact certification path the roadmap references for multicore avionics systems, including how to approach compliance in that regime. CAST-32A materials are central to DO-178C multicore certification in aviation, and multiple excerpts discuss CAST-32A objectives, multicore interference, and related certification guidance. Do-330/DO-330 tool qualification is essential for tool qualification, which the roadmap flags as a key requirement; the included DO-330-related content details the nature of tool qualification and its impact on safety tooling compliance. Ferrocene's official qualification status is highly relevant as it anchors the roadmap's tooling assumption (Ferrocene as a qualified Rust toolchain). Additional DO-178C, ISO 26262, and IEC 61508 content directly supports the roadmap's claim about high-assurance targets and the expected level of conformity. ISO 26262 and IEC 61508 entries provide confirmation of the safety standards the roadmap aspires to satisfy, and DO-178C-related material clarifies avionics-specific DAL levels and process requirements. The Common Criteria pieces (CC) frame the broader security assurance landscape and are aligned with the roadmap's statement about \"Common Criteria for security assurance\" in the field value. The CAST-32A/AMC 20-193, DO-178C, ISO 26262, IEC 61508, and CC-related excerpts collectively substantiate the roadmap's multi-standard ambition and the kinds of evidence, work products, and independence requirements that would be expected in a real certification plan. The sequencing of excerpts places the most direct policy and standard references first (AMC 20-193, CAST-32A, DO-178C, tool qualification DO-330), followed by official-qualification sources (Ferrocene), and then broader safety/security standards (ISO 26262, IEC 61508, CC). The remaining excerpts provide contextual grounding on scheduling, ARINC 653, and verification approaches but do not directly supply the certification levels or tooling requirements demanded by the fine-grained field. Together, these excerpts corroborate the field value's assertion of a high-assurance, multicore, safety-critical stack with formal-methods and tool-qualified processes, and they map onto the roadmap's required artifacts (safety case, traceability, independent reviews) implied by DO-178C/ISO 26262/IEC 61508/CAST-32A/AMC 20-193 requirements.",
      "confidence": "high"
    },
    {
      "field": "competitive_landscape_analysis.comparison_summary",
      "citations": [
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "We built seL4 for real-world use, and our aim was not to lose more than. 10% in IPC performance relative to the fastest kernels we had before",
            "seL4¬†is¬†the¬†world‚Äôs¬†fastest¬†microkernel",
            "seL4¬†capabilities¬†are¬†also¬†not¬†susceptible¬†to¬†the¬†attack¬†of¬† Boebert¬†[1984];¬† this\nattack¬†applies¬†to¬†capabilities¬†directly¬†implemented¬†in¬†hardware¬†while¬†seL4‚Äôs\ncapabilities¬†are¬†implemented¬†and¬†protected¬†by¬†the¬†kerne"
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "Frequently Asked Questions - The seL4 Microkernel",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "These extensions allow the kernel to restrict DMA and thereby enable DMA devices with untrusted user-level drivers. Does seL4 support multicore? Multicore¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        }
      ],
      "reasoning": "The core claim is that seL4 offers a formal, machine-checked proof of implementation correctness, which supports the assertion that Apex's L1 OS is inspired by seL4 in terms of formal verification goals while expanding scope with a Rust-centric stack. Direct statements about seL4 providing a formal, mathematical, machine-checked proof of correctness are highly relevant to the comparison of verification strengths. Related excerpts corroborate that seL4 is designed to be bug-free with respect to its specification and that it has formal proofs, reinforcing the claim of a high assurance baseline to measure Apex against. Additional excerpts describe seL4's IPC performance and the goal of minimal IPC loss relative to prior kernels, which aligns with the Apex objective of high IPC performance via mechanisms like Appartition IPC and zero-copy approaches. Other excerpts touch on seL4's capabilities model, multicore considerations, and general design principles that illuminate the landscape against which Apex positions itself, especially around trust boundaries, formal verification, and kernel design. Collectively, these bits of information directly support the main points that (a) seL4 provides strong formal verification, (b) Apex aims to reach similar or higher assurance using Rust and end-to-end verification across layers, and (c) seL4's IPC characteristics set a benchmark for Apex's Appartition IPC and zero-copy strategies, while also noting the broader scope and differences in APIs, languages, and system components that Apex introduces.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 Partition Schedule. During the Partition Time Window, the second level of scheduling uses process scheduling. Each partition has at least one process.",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling",
            "No ARINC 653 services are provided for the memory management of partitions. Each partition has to handle its own memory (still under the constraints of memory partitioning enforced by ARINC 653).",
            "The standard defines a two-level hierarchical schedule. The first level schedules the partitions. This is a round-robin, fixed schedule that repeats a Major Time Frame. The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "During the Partition Time Window, the second level of scheduling uses process scheduling. Each partition has at least one process. Process scheduling within a partition during the Partition Time Window is preemptive.",
            "ARINC 653 Platform\nAn ARINC 653 platform contains:\n\nA hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output).\nAn implementation for the ARINC 653 services (the APEX API). An interface to be able to configure the platform and its domain of us",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        },
        {
          "title": "ARINC 653 - Wikipedia",
          "url": "http://en.wikipedia.org/wiki/ARINC_653?utm_source=chatgpt.com",
          "excerpts": [
            "The standard defines a two-level hierarchical schedule. The first level schedules the partitions. This is a round-robin, fixed schedule that repeats a Major Time Frame. The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The fastpath is a hand-tuned implementation of the IPC (inter- process communication) paths through the seL4 kernel. These IPC paths are used to pass messages¬†..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 10.1.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-10.1.1.pdf",
          "excerpts": [
            "IOMMU on Intel x86-based platforms. An IOMMU allows memory to be remapped from the device's point of view. It acts as an MMU for the device ..."
          ]
        },
        {
          "title": "Trustworthy isolation of DMA devices",
          "url": "https://link.springer.com/article/10.1007/s42786-020-00018-x",
          "excerpts": [
            "The main concern when DMACs are controlled by untrusted software is that the destination addresses of BDs can be set arbitrarily."
          ]
        },
        {
          "title": "seL4 and Apex-style threat model comparison (role-play / integrated analysis)",
          "url": "https://maxwellseefeld.org/sel4/",
          "excerpts": [
            "No Built-in Device Isolation: seL4 itself doesn't magically handle DMA or device memory ‚Äì it's up to the system builder to ensure devices are ... For example, direct memory access by devices can bypass the kernel, so the proofs assume any DMA either doesn‚Äôt interfere or is managed (or you use an IOMMU). These are r"
          ]
        },
        {
          "title": "IOMMU solutions for seL4 (take ARM SMMUv3 for instance)",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-12-mao.pdf",
          "excerpts": [
            "The VMM and other components maintain their own IO domains through the unified kernel interfaces that\n\nsystematically manages all SMMU hardware abstracts"
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†...",
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant material describes ARINC 653-style partitioning and the Application Executives (APEX) interface, which map to the real-time partitioned microkernel concept at the L1 layer. Excerpts detailing ARINC 653, partition scheduling (major/minor frames), and APEX services establish the architectural model for spatial/temporal isolation that the field value calls out for the Ministry of Magic layer. Several ARINC 653 sources also discuss partition separation, time-space partitioning semantics, and the partitioned scheduling discipline that govern how partitions are allocated CPU time and memory, which aligns with the real-time microkernel foundation and isolation contract described in the field value.\n\nSupporting this, excerpts about seL4 provide a formal, capability-based security perspective on minimal, well-scoped microkernels, which complements the L1 real-time partitioned microkernel idea by illustrating how a formally verified microkernel enforces isolation and capability-based access control. The seL4 Whitepaper and related manuals describe a microkernel design with strong isolation guarantees, which underpins the theoretical and practical basis for a partitioned, capability-based L1 OS.\n\nFurther, several ARINC 653-focused excerpts explain the ARINC 653 API (APEX), partition management, time management, and inter-partition communication semantics. These sources ground the Apparition IPC and the partitioned scheduling story by showing how partitions are created, scheduled, and isolated, including partition-time windows and the API surface used by partitions to communicate reliably.\n\nIn addition to ARINC 653-centric material, excerpts that address the IOMMU/DMA isolation (DMA protection and threat models) provide context for the Protego Maxima style isolation enforcement and kernel-bypass I/O considerations, which are relevant to the isolation guarantees and DMA policy enforcement mentioned in the field value.\n\nTogether, these excerpts collectively support the three focal elements: (1) a real-time partitioned microkernel baseline (L1) with ARINC-653-like partitioning, (2) an isolation enforcement mechanism akin to Protego Maxima, and (3) a zero-copy, bounded-latency IPC surface (Apparition IPC) with SPSC/MPSC variants and potential RDMA pathways as described in the field value.",
      "confidence": "medium"
    },
    {
      "field": "legal_risk_and_rebranding_mandate.risk_summary",
      "citations": [
        {
          "title": "MINISTRY OF MAGIC Trademark - Serial Number 78271444",
          "url": "https://trademarks.justia.com/782/71/ministry-of-magic-78271444.html",
          "excerpts": [
            "MINISTRY OF MAGIC is a trademark of Alamo Fireworks Inc.. Filed in July 8 (2003), the MINISTRY OF MAGIC covers Fireworks."
          ]
        },
        {
          "title": "US Trademark Data for SLYTHERIN (Warner Bros. Entertainment Inc.)",
          "url": "https://uspto.report/TM/87943593",
          "excerpts": [
            "The mark consists of a stylized design of a shield with a snake in the center and the word \"SLYTHERIN\" in a banner under the shield. Trademark registration for Warner Bros. Entertainment Inc.. The mark consists of a stylized design of a shield with a snake in the center and the word \nSLYTHERIN - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "SLYTHERIN Trademark Details (Trademarkia)",
          "url": "https://www.trademarkia.com/slytherin-87532744",
          "excerpts": [
            "Live/Registered",
            "SLYTHERIN is a registered trademark (Registration #5581853) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "Registration #5581853",
            "*SLYTHERIN** trademark is filed in the category of **Paper Goods and Printed Material"
          ]
        },
        {
          "title": "Wizarding World Legal Notices",
          "url": "https://www.harrypotter.com/legals",
          "excerpts": [
            "¬© WIZARDING WORLD DIGITAL LLC. All rights reserved. WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc.",
            "WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc. WIZARDING WORLD publishing and theatrical stage rights ¬© J.K. Rowling.",
            ". All characters and elements ¬© & TM Warner Bros. Entertainment Inc."
          ]
        },
        {
          "title": "SLYTHERIN Trademark of Warner Bros. Entertainment Inc.",
          "url": "https://trademarks.justia.com/875/32/slytherin-87532764.html",
          "excerpts": [
            "SLYTHERIN is a trademark of Warner Bros. Entertainment Inc.. Filed in July 18 (2017), the SLYTHERIN covers Clothing for men, women and children, namely, ..."
          ]
        },
        {
          "title": "US Trademark Documentation - GRINGOTTS",
          "url": "https://uspto.report/TM/77389508",
          "excerpts": [
            "Trademark registration by Warner Bros. Entertainment Inc. for the trademark GRINGOTTS ... Trademark Office (USPTO) or any other governmental organization. Trademark registration by Warner Bros. Entertainment Inc. for the trademark GRINGOTTS. GRINGOTTS - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "Slytherin Trademark Details",
          "url": "https://www.trademarkia.com/slytherin-87532764",
          "excerpts": [
            "SLYTHERIN is a registered trademark (Registration #5581854) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "The SLYTHERIN. Explore trademark details, ownership information, other trademarks owned by Warner Bros. Entertainment Inc. or file your own trademark. SLYTHERIN Trademark | Trademarkia"
          ]
        },
        {
          "title": "Warner Bros. Entertainment Inc., et al. v. RDR Books, et al.",
          "url": "https://www.loeb.com/en/insights/publications/2008/09/warner-bros-entertainment-inc-et-al-v-rdr-books-__",
          "excerpts": [
            "Sep 8, 2008 ‚Äî The court held that The Lexicon copies a sufficient quantity of the Harry Potter works to support a finding of substantial similarity, noting¬†..."
          ]
        }
      ],
      "reasoning": "The high-risk assessment rests on concrete trademark protections for specific Harry Potter-related codenames and related brand marks. Evidence shows that MINISTRY OF MAGIC is a registered trademark, indicating formal protection and potential infringement risk if used publicly. Details about SLYTHERIN being registered, including multiple Trademarkia entries and a live/registered status, demonstrate ongoing enforceability of the mark by Warner Bros. Direct trademark registrations for GRINGOTTS and Wizarding World-related notices reinforce that Warner Bros. maintains active rights over key terms and branding that could be invoked against unauthorized use. Additional entries confirm that SLYTHERIN has multiple registrations and is associated with Warner Bros. ownership, supporting the conclusion that these terms are protected in multiple classes. The presence of a dilution-focused article further substantiates the risk profile by highlighting trademark dilution concerns for famous marks like those in the Harry Potter universe. Collectively, these excerpts corroborate the claim that using such codenames for public-facing aspects would face substantial legal risk due to active trademarks and potential dilution, and that relying on a fair-use defense would be risky given the strength and visibility of these marks.",
      "confidence": "high"
    },
    {
      "field": "legal_risk_and_rebranding_mandate.ip_holder",
      "citations": [
        {
          "title": "US Trademark Data for SLYTHERIN (Warner Bros. Entertainment Inc.)",
          "url": "https://uspto.report/TM/87943593",
          "excerpts": [
            "The mark consists of a stylized design of a shield with a snake in the center and the word \"SLYTHERIN\" in a banner under the shield. Trademark registration for Warner Bros. Entertainment Inc.. The mark consists of a stylized design of a shield with a snake in the center and the word \nSLYTHERIN - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "SLYTHERIN Trademark Details (Trademarkia)",
          "url": "https://www.trademarkia.com/slytherin-87532744",
          "excerpts": [
            "SLYTHERIN is a registered trademark (Registration #5581853) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "Registration #5581853",
            "Live/Registered"
          ]
        },
        {
          "title": "SLYTHERIN Trademark of Warner Bros. Entertainment Inc.",
          "url": "https://trademarks.justia.com/875/32/slytherin-87532764.html",
          "excerpts": [
            "SLYTHERIN is a trademark of Warner Bros. Entertainment Inc.. Filed in July 18 (2017), the SLYTHERIN covers Clothing for men, women and children, namely, ..."
          ]
        },
        {
          "title": "Wizarding World Legal Notices",
          "url": "https://www.harrypotter.com/legals",
          "excerpts": [
            "¬© WIZARDING WORLD DIGITAL LLC. All rights reserved. WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc.",
            "WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc. WIZARDING WORLD publishing and theatrical stage rights ¬© J.K. Rowling.",
            ". All characters and elements ¬© & TM Warner Bros. Entertainment Inc."
          ]
        },
        {
          "title": "Warner Bros. Entertainment Inc., et al. v. RDR Books, et al.",
          "url": "https://www.loeb.com/en/insights/publications/2008/09/warner-bros-entertainment-inc-et-al-v-rdr-books-__",
          "excerpts": [
            "Sep 8, 2008 ‚Äî The court held that The Lexicon copies a sufficient quantity of the Harry Potter works to support a finding of substantial similarity, noting¬†..."
          ]
        },
        {
          "title": "Trademark Dilution (Intended for a Non-Legal Audience)",
          "url": "https://www.inta.org/fact-sheets/trademark-dilution-intended-for-a-non-legal-audience/",
          "excerpts": [
            "Trademark dilution refers to the unauthorized use of and/or application for a trademark that is likely to weaken the distinctive quality of or harm a famous ..."
          ]
        }
      ],
      "reasoning": "The target field asserts that the IP holder is Warner Bros. Entertainment Inc. The most directly supportive excerpts name Warner Bros. as the owner or registrant of specific marks: SLYTHERIN is described as a trademark owned by Warner Bros. Entertainment Inc., including multiple registrations and related trademark details. These excerpts collectively establish a pattern of Warner Bros. holding rights to the SLYTHERIN mark and related branding. Additional excerpts describe Wizarding World legal notices stating that all rightsholders and indicia are TM and ¬© Warner Bros. Entertainment Inc., reinforcing Warner Bros. as the IP holder in the Wizarding World context. Other entries explicitly reference Warner Bros. in the context of trademarks like GRINGOTTS and related filings, further confirming the entity's ownership role. A legal case entry involving Warner Bros. as the trademark owner (or related party) supports the attribution within intellectual property and branding risk discussions. An excerpt noting that a mark is Live/Registered directly ties to ongoing enforceable rights, strengthening the conclusion that Warner Bros. is the ip_holder. Collectively, these excerpts provide converging evidence that Warner Bros. Entertainment Inc. is the responsible IP holder for the discussed marks and branding associated with the Wizarding World and related properties.",
      "confidence": "high"
    },
    {
      "field": "competitive_landscape_analysis.competitor_name",
      "citations": [
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†is¬†the¬†world‚Äôs¬†fastest¬†microkernel",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "We built seL4 for real-world use, and our aim was not to lose more than. 10% in IPC performance relative to the fastest kernels we had before",
            "seL4¬†capabilities¬†are¬†also¬†not¬†susceptible¬†to¬†the¬†attack¬†of¬† Boebert¬†[1984];¬† this\nattack¬†applies¬†to¬†capabilities¬†directly¬†implemented¬†in¬†hardware¬†while¬†seL4‚Äôs\ncapabilities¬†are¬†implemented¬†and¬†protected¬†by¬†the¬†kerne"
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        },
        {
          "title": "Frequently Asked Questions - The seL4 Microkernel",
          "url": "https://sel4.systems/About/FAQ.html",
          "excerpts": [
            "These extensions allow the kernel to restrict DMA and thereby enable DMA devices with untrusted user-level drivers. Does seL4 support multicore? Multicore¬†..."
          ]
        }
      ],
      "reasoning": "The most relevant excerpts directly name and discuss seL4, including the seL4 Whitepaper which proclaims seL4 as the world's fastest microkernel, and official materials that emphasize formal proof of implementation correctness and machine-checked verification. These excerpts establish seL4's identity and its key selling points in verification and performance, which is essential for affirming the field value as seL4 Microkernel. Additional highly relevant content comes from the comprehensive formal verification discussion, which links a formal refinement between its model and abstract specifications, strengthening the claim of rigorous correctness. Related documentation, such as the seL4 Reference Manual, supports understanding of seL4's capability-based security model and kernel interfaces, further corroborating its identity as a capable microkernel. Weaker but still supportive are excerpts noting IPC performance trade-offs or comparisons to other kernels, which contextualize seL4's performance positioning and reinforce its role as a prominent microkernel in the landscape. Other excerpts discuss general principles (design principles, security considerations, FAQ) that mention seL4, which helps confirm its presence in the landscape but provide less direct evidence about its identity and core claims. Taken together, the strongest supporting excerpts explicitly identify and describe seL4 as a microkernel with formal verification, performance attributes, and architectural characteristics, while additional excerpts provide corroborating context about its capabilities and documentation, all of which support classifying the field value as referring to seL4 Microkernel.",
      "confidence": "high"
    },
    {
      "field": "key_differentiators.description",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.See more"
          ]
        }
      ],
      "reasoning": "The most relevant excerpt explicitly notes that ARINC 653 defines an API called APplication EXecutive (APEX), which is the direct naming match to the Apex component referenced in the field value. This confirms the existence and naming of the Apex-like surface in a partitioned ARINC 653 context, aligning with the field's emphasis on a structured, partitioned framework as part of Apex's architectural identity. Additional excerpts summarize ARINC 653 concepts such as partitioning, major/minor time frames, and the role of the API surface, which supports the notion of a rigorously defined, partitioned environment that a Rust-based, safety-focused stack would operate within, even though they do not explicitly mention Rust or the exact cross-layer optimizations. A separate excerpt discusses comprehensive formal verification of seL4, which relates to safety guarantees in a microkernel context; while not Rust-based or Apex-specific, it corroborates the broader idea that formally verified/memory-safe foundations are valuable for safety-critical systems, reinforcing the field value's emphasis on safety and correctness aspects of such stacks. Taken together, these excerpts corroborate the existence and safety-oriented, partitioned architecture surrounding Apex as described in the query, with ARINC 653/APEX being the closest direct match and seL4-verification serving as supportive safety-context evidence.",
      "confidence": "medium"
    },
    {
      "field": "core_architecture_overview.layer_3_frameworks",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS)."
          ]
        },
        {
          "title": "Update on using multicore processors with a commercial ...",
          "url": "https://www.windriver.com/sites/default/files/2022-02/422204601.pdf",
          "excerpts": [
            "by PJ Parkinson ¬∑ 2017 ¬∑ Cited by 9 ‚Äî ARINC 653P1-4 also provides ability to support multiple partitions on each processor core using a timeslot scheduling approach where an individual partition¬†..."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†..."
          ]
        }
      ],
      "reasoning": "The finegrained field describes the L3 Frameworks layer as consisting of Rust-native building blocks shipped as independent open-source crates, covering I/O and networking (Slytherin, Patronus Proxy), data systems (Gringotts-OLTP/OLAP), developer experience and safety (Veritaserum, Polyjuice, Legilimency), build optimization (Spellbook), and security (Unbreakable Vow). The provided excerpts focus on ARINC 653 and partitioned real-time architectures, which establish the architectural context in which such framework components would operate. Specifically, the excerpts articulate how ARINC 653 defines partitions, time slots, memory isolation, and a partitioned/space-time partitioned RTOS environment, which is the surrounding platform-on-which-frameworks would run. They also describe API concepts (APplication EXecutive) and scheduling basics (Major/Minor Time Frames) that frame how Rust-native building blocks would be scheduled, isolated, and composed into independent crates within a partitioned system. In particular, the excerpts that explain ARINC 653 concepts, partitioning of memory, and the fixed-schedule model provide the essential constraints and interfaces that the L3 Rust-native frameworks would need to respect, even though they do not mention the specific Rust crates or the exact components listed in the finegrained value. Therefore, these excerpts are the most directly relevant for validating that the described L3 Frameworks exist within an ARINC 653-style partitioned environment, and they establish the necessary architectural backdrop for those Rust-native crates to operate.",
      "confidence": "medium"
    },
    {
      "field": "formal_verification_and_api_strategy.implementation_method",
      "citations": [
        {
          "title": "quote crate documentation and macro design guidance",
          "url": "https://docs.rs/quote/latest/quote/macro.quote.html",
          "excerpts": [
            "The structure of a basic procedural macro is as follows. Refer to the Syn crate for further useful guidance on using quote! as part of a procedural macro. q"
          ]
        }
      ],
      "reasoning": "The field value describes a declarative, macro-driven domain-specific language (DSL) named Parseltongue, implemented in Rust via the procedural macro system and using the syn and quote crates for parsing and code generation. The most directly relevant piece among the excerpts explains the anatomy of a basic procedural macro and explicitly points to the Syn crate as a tool for working with macros in Rust. This aligns with the claimed implementation method, since procedural macros are typically built using syn/quote to parse and generate code, which is exactly what the field value asserts. Other excerpts discuss DSLs and macro concepts in abstract or in different contexts (e.g., capability languages or verification proofs) but do not provide concrete evidence about Parseltongue or the stated toolchain. Therefore, the excerpt mentioning the procedural macro structure and the Syn crate is the primary support for the field value, while the rest offer contextual background but do not directly substantiate the specific Parseltongue implementation details.",
      "confidence": "medium"
    },
    {
      "field": "scheduler_layer_design.api_name",
      "citations": [
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
          "url": "https://www.usenix.org/system/files/osdi20-zhu.pdf",
          "excerpts": [
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is sat"
          ]
        }
      ],
      "reasoning": "The field value identifies a specific API seed used for scheduling design. One excerpt states, in the RackSched context, that there is a seed called the 'Sorting Hat API'. This direct mention provides direct support for the existence or relevance of this API seed to the scheduler design in question. Other excerpts discuss related schedulers and verification work but do not reference the Sorting Hat API by name, so they offer contextual relevance but not direct support for the exact field value.",
      "confidence": "high"
    },
    {
      "field": "design_meta_patterns.pattern_name",
      "citations": [
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more",
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible.",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec"
          ]
        }
      ],
      "reasoning": "The most relevant material explicitly defines what a capability-based surface is: a capability distribution language that describes the kernel objects needed by an application and how capabilities are distributed across the system. This is precisely the notion of capability-defined surfaces, as it specifies the access boundaries and how components gain access to resources. Additionally, one excerpt emphasizes that such specifications describe the desired system state declaratively and determine future possible states, reinforcing the concept of surfaces defined by capability boundaries. A closely related excerpt expands on what the distribution of capabilities entails by explaining how parts of the system possess capabilities to others, thereby delineating access control boundaries. Together, these excerpts directly map to the idea of surfaces defined via capabilities and access control policies. The remaining excerpts provide valuable architectural context (partitioning, isolation, and related standards) but do not directly articulate the notion of surfaces being defined by capabilities, hence their lower relevance to this specific field value.",
      "confidence": "high"
    },
    {
      "field": "formal_verification_and_api_strategy.api_design_pattern",
      "citations": [
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible.",
            "\n\nThe capDL Loader is a program that initialises the seL4 user-level environment\nto match the system described by a capDL spec, and loads programs from ELFs in a\nprovided `cpio` archive.\nIt is intended to be run as the root task, that is, the\nfirst user-level thread, which has access to all resources.",
            "Python capDL Library",
            "capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once.",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec",
            "capDL Translator"
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "Capabilities¬† are¬†access¬†tokens¬†which¬†support¬†very¬†Ô¨Åne-grained¬†control¬†over\nwhich¬†entity¬†can¬†access¬†a¬†particular¬†resource¬†in¬†a¬†system.",
            "seL4 has a simple, priority-based scheduling policy that is easy to understand and analyse, a core requirement for hard real-time systems. The kernel will, on ...",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS."
          ]
        },
        {
          "title": "seL4 Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong ...",
            "We claim that seL4 has world's highest level of assurance for an operating system kernel. On the research level, this is substantiated by the following¬†...",
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong¬†..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "Not all of the proof sessions can be built directly with the isabelle build command. The seL4 proofs depend on Isabelle specifications that are generated from ..."
          ]
        },
        {
          "title": "Beyond the Toolbox",
          "url": "https://learntla.com/topics/cli.html",
          "excerpts": [
            "The model checking config language is a special DSL for using TLC from the command line. It's what the toolbox abstracts away on the backend. All config¬†..."
          ]
        },
        {
          "title": "A Model-Based Optimization Method of ARINC 653 ...",
          "url": "https://www.mdpi.com/2226-4310/11/11/915",
          "excerpts": [
            "by P Han ¬∑ 2024 ‚Äî This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network¬†...",
            "This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network ..."
          ]
        }
      ],
      "reasoning": "The target field value envisions encoding policies as types and deriving capabilities at compile time. Excerpts that define capDL as the capability distribution language and explain that capDL describes the kernel objects and the distribution of capabilities provide a direct mechanism for declarative, verifiable policy specification that can be reasoned about at build/load time. Statements that capDL specifications can be transformed into code or verifiable models (e.g., translation to a C header, Graphviz visualization, XML, and formal Isabelle models) reinforce the idea that policies and capability allocations are determined and checked in a compile-time/verification-time phase, effectively making policy enforcement a design-time, type-oriented activity. Additional excerpts emphasizing that capabilities act as fine-grained control tokens and that seL4 provides formal proofs of implementation correctness underpin the concept of embedding policy as a type-like construct‚Äîwhere capabilities and their distributions encode security policy and enable formal reasoning about system behavior. Together, these excerpts map neatly to a design pattern where policy enforcement is achieved via capability derivation and verification at compile/load time, aligning with a \"policy-as-types\" mindset in a capability-based, formally verified OS stack. The most directly supportive material describes capDL's role in describing and verifying the system state declaratively and the tooling that translates such specs into verifiable artifacts, which mirrors the idea of encoding policies as types and deriving capabilities during compilation. The surrounding formal verification discussions about seL4 further bolster the feasibility and desirability of compile-time guarantees for such policy mechanisms, even if they are not phrased in the exact term used in the fine-grained field value. ",
      "confidence": "high"
    },
    {
      "field": "scheduler_layer_design.performance_baselines",
      "citations": [
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
          "url": "https://www.usenix.org/system/files/osdi20-zhu.pdf",
          "excerpts": [
            "RackSched works at microsecond scale\n\nand optimizes the tail latency with network-system co-design",
            "We design a two-layer scheduling framework that inte-\n\ngrates inter-server scheduling in the ToR switch and intra-\n\nserver scheduling in each se",
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is sat"
          ]
        },
        {
          "title": "Shenango NSDI'19 Paper",
          "url": "https://amyousterhout.com/papers/shenango_nsdi19.pdf",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango, RackSched, and related microsecond-scale scheduling work (NSDI19/OSDI20) ‚Äì NSDI/nsdi19/nsdi20 papers",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/ousterhout",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/131018/nsdi19fall-final110.pdf?sequence=2&isAllowed=y",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        }
      ],
      "reasoning": "The field value asserts a plan to compare the scheduler's performance against state-of-the-art microsecond-scale schedulers, notably Shenango and RackSched. Excerpts that describe Shenango's emphasis on achieving high CPU efficiency and latency-sensitive workloads provide direct, explicit reference to a baseline for comparison in microsecond-scale scheduling. Excerpts detailing RackSched as a microsecond-scale scheduler, including its two-layer integration that coordinates intra- and inter-server scheduling, offer another explicit benchmark target, aligning with the field value's stated comparator set. Additional excerpts that discuss RackSched in terms of microsecond-scale scheduling and performance improvements (throughput and tail-latency considerations) further reinforce the relevance of RackSched as a baseline. An excerpt focused on formal verification of an OS microkernel, while related to the broader OS scheduling ecosystem, does not directly support the scheduler-specific performance baseline, and thus is less relevant to the precise fine-grained field value. Collectively, the most compelling support comes from explicit Shenango references and RackSched-focused discussions, followed by broader RackSched-contextual details that still pertain to microsecond-scale scheduling benchmarks.",
      "confidence": "high"
    },
    {
      "field": "scheduler_layer_design.design_principle",
      "citations": [
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
          "url": "https://www.usenix.org/system/files/osdi20-zhu.pdf",
          "excerpts": [
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is sat",
            "RackSched works at microsecond scale\n\nand optimizes the tail latency with network-system co-design",
            "We design a two-layer scheduling framework that inte-\n\ngrates inter-server scheduling in the ToR switch and intra-\n\nserver scheduling in each se"
          ]
        },
        {
          "title": "Shenango NSDI'19 Paper",
          "url": "https://amyousterhout.com/papers/shenango_nsdi19.pdf",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango, RackSched, and related microsecond-scale scheduling work (NSDI19/OSDI20) ‚Äì NSDI/nsdi19/nsdi20 papers",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/ousterhout",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/131018/nsdi19fall-final110.pdf?sequence=2&isAllowed=y",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        }
      ],
      "reasoning": "The most directly supportive excerpts describe a two-layer scheduling framework that ties inter-server scheduling in the ToR switch to intra-server scheduling within each server. This aligns with the field value's emphasis on a pluggable scheduler architecture that handles workload-specific concerns (API/UI/DB) and uses microsecond-scale core management, including mechanisms such as core loans and per-partition runtime budgets with admission control to allocate CPU resources efficiently. The excerpts explicitly discuss arranging scheduling across layers to optimize tail latency and throughput, and they highlight microsecond-scale operation, which directly matches the claimed microsecond-scale core management and partitioned budgets. A closely related excerpt discusses a different but relevant scheduler line (Shenango), which emphasizes high CPU efficiency for latency-sensitive workloads, providing contextual support for the benefits of fine-grained, low-latency scheduling approaches. Collectively, these excerpts support the core concepts of a pluggable, workload-aware scheduler architecture, microsecond-scale dynamics, and partitioned budgets plus admission control; the framing and concrete mechanisms (two-layer coordination, core loans, per-partition budgets) are reinforced by the RackSched-focused excerpts and complemented by Shenango as corroborating context about latency sensitivity in scheduling.",
      "confidence": "high"
    },
    {
      "field": "performance_validation_plan.methodology",
      "citations": [
        {
          "title": "wrk2: Benchmarking guidance for workloads, baselines, metrics, and reproducibility",
          "url": "https://github.com/giltene/wrk2",
          "excerpts": [
            "While this model correctly measures the actual completion time of individual requests, it exhibits a strong Coordinated Omission effect, through which most of¬†...",
            "The model I chose for avoiding Coordinated Omission in wrk2 combines\nthe use of constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "For example, HdrHistogram includes a simple way to compensate for Coordinated Omission when a known expected interval between measurements exists. Alternatively ...",
            "constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "\nHowever, wrk2 will usually be run with the --latency flag, which provides\ndetailed latency percentile information (in a format that can be easily\nimported to spreadsheets or gnuplot scripts and plotted per examples\nprovided at <http://hdrhistogram.org> )"
          ]
        },
        {
          "title": "Percentiles aggregation | Reference",
          "url": "https://www.elastic.co/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation",
          "excerpts": [
            "HDR Histogram (High Dynamic Range Histogram) is an alternative implementation that can be useful when calculating percentiles for latency measurements as it can¬†..."
          ]
        }
      ],
      "reasoning": "The field value asserts a detailed, reproducible benchmarking methodology with concrete practices. The most directly relevant content specifies benchmarking guidance and how to measure workloads with wrk2 to avoid coordinated omission, which aligns with the goal of an open-loop load generator to accurately capture tail latency. It also notes the need for latency distributions to be captured with a histogram-based approach, which dovetails with using HDR Histogram for accurate latency accounting. Additional items emphasize constant throughput considerations and the utility of latency percentile representations, which reinforce the methodological rigor. Supporting pieces discuss using HDR Histogram to address measurement biases and outline the importance of variance controls, warm-up periods, multiple runs, and statistical significance, all of which map cleanly onto the requested methodology. Finally, items that reference percentile aggregation or general benchmarking context provide peripheral support for the overall benchmarking discipline but do not specify the same concrete practices, serving as contextual reinforcement rather than primary evidence of the exact methodology described.",
      "confidence": "high"
    },
    {
      "field": "core_architecture_overview.layer_1_os",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "A Simple Introduction to ARINC 653 | by Mehmet Cagri Kose",
          "url": "https://medium.com/@mehmetcagrikose/a-simple-introduction-to-arinc-653-775b1c5888c0",
          "excerpts": [
            "ARINC 653 partitions are ... Together with process management module, they guarantee timely execution of processes in a partition."
          ]
        },
        {
          "title": "Update on using multicore processors with a commercial ...",
          "url": "https://www.windriver.com/sites/default/files/2022-02/422204601.pdf",
          "excerpts": [
            "by PJ Parkinson ¬∑ 2017 ¬∑ Cited by 9 ‚Äî ARINC 653P1-4 also provides ability to support multiple partitions on each processor core using a timeslot scheduling approach where an individual partition¬†..."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†..."
          ]
        }
      ],
      "reasoning": "The most directly relevant information comes from excerpts that explicitly introduce ARINC 653 as a partitioning standard for space and time in safety-critical RTOS, and that describe how partitions are defined as separate memory domains with their own isolation. Additionally, excerpts discussing that ARINC 653 defines an application programming interface called APEX further aligns with the field value's reference to an API surface. Other excerpts that describe time-partitioning concepts (Major/Minor Time Frames, fixed scheduling, partition guarantees) provide concrete support for the deterministic and partitioned execution model described in the field value. While the field value names some project-specific components (Ministry of Magic, Protego Maxima, Apparition) that are not present in the excerpts, the core architectural mechanisms‚Äîpartitioned microkernel principles, memory isolation per partition, APEX API, and time-frame scheduling‚Äîare well-supported by the excerpts. Therefore, the excerpts collectively corroborate the existence and characteristics of a real-time, partitioned OS layer with ARINC‚Äë653‚Äëlike semantics and deterministic IPC/scheduling foundations, which is the essence of the fine-grained field value.\n",
      "confidence": "medium"
    },
    {
      "field": "performance_validation_plan.target_claim",
      "citations": [
        {
          "title": "Percentiles aggregation | Reference",
          "url": "https://www.elastic.co/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation",
          "excerpts": [
            "HDR Histogram (High Dynamic Range Histogram) is an alternative implementation that can be useful when calculating percentiles for latency measurements as it can¬†..."
          ]
        },
        {
          "title": "wrk2: Benchmarking guidance for workloads, baselines, metrics, and reproducibility",
          "url": "https://github.com/giltene/wrk2",
          "excerpts": [
            "While this model correctly measures the actual completion time of individual requests, it exhibits a strong Coordinated Omission effect, through which most of¬†...",
            "constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "\nHowever, wrk2 will usually be run with the --latency flag, which provides\ndetailed latency percentile information (in a format that can be easily\nimported to spreadsheets or gnuplot scripts and plotted per examples\nprovided at <http://hdrhistogram.org> )",
            "For example, HdrHistogram includes a simple way to compensate for Coordinated Omission when a known expected interval between measurements exists. Alternatively ...",
            "The model I chose for avoiding Coordinated Omission in wrk2 combines\nthe use of constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account."
          ]
        }
      ],
      "reasoning": "To support a broad performance improvement claim across multiple layers of a system, one must rely on robust benchmarking and latency analysis. The most relevant excerpts describe using HDR Histogram to compute latency percentiles, which is essential for quantifying tail latency and overall performance improvements. They also discuss benchmarking guidance that helps avoid common biases, such as Coordinated Omission, and emphasize constant-throughput load generation and latency measurements at scale. Together, these excerpts provide a framework for validating a multi-layer performance claim by measuring latency distributions, ensuring measurement integrity, and reporting percentile-based results. The content about constant throughput and latency percentiles should be interpreted as the practical method to substantiate any claimed speedups across the L1 partitioned microkernel, L2 schedulers, IPC, I/O paths, and data systems, rather than as direct evidence of the claimed 10‚Äì40x gains. The guidance also reinforces that validations must be reproducible and properly benchmarked, which is critical for any strong affirmation of such improvements across the stack.",
      "confidence": "medium"
    },
    {
      "field": "formal_verification_and_api_strategy.verification_targets",
      "citations": [
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation"
          ]
        },
        {
          "title": "seL4 Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong ...",
            "We claim that seL4 has world's highest level of assurance for an operating system kernel. On the research level, this is substantiated by the following¬†..."
          ]
        }
      ],
      "reasoning": "The field value asserts that high-level model checking using TLA+ and machine-checked proofs using Isabelle/HOL are the verification approaches to follow, aligned with seL4's proven verification heritage. An excerpt stating that seL4 includes formal, mathematical, machine-checked proofs of implementation correctness directly substantiates the core idea of formal verification and machine-checked correctness. Another excerpt emphasizes that seL4 provides machine-checked mathematical proofs across multiple architectures, reinforcing the precedent for rigorous, automated verification. A further excerpt notes a claim of the world's highest level of assurance for the kernel, which supports the overall claim of very strong verification guarantees and sets a high bar for verification precedents. Together, these excerpts establish a concrete precedent in the seL4 lineage for formal verification and machine-checked correctness, which justifies applying similar formal-verification strategies (TLA+/Isabelle) to the field value in question.",
      "confidence": "high"
    },
    {
      "field": "performance_validation_plan.baselines",
      "citations": [
        {
          "title": "wrk2: Benchmarking guidance for workloads, baselines, metrics, and reproducibility",
          "url": "https://github.com/giltene/wrk2",
          "excerpts": [
            "The model I chose for avoiding Coordinated Omission in wrk2 combines\nthe use of constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "\nHowever, wrk2 will usually be run with the --latency flag, which provides\ndetailed latency percentile information (in a format that can be easily\nimported to spreadsheets or gnuplot scripts and plotted per examples\nprovided at <http://hdrhistogram.org> )",
            "constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "While this model correctly measures the actual completion time of individual requests, it exhibits a strong Coordinated Omission effect, through which most of¬†...",
            "For example, HdrHistogram includes a simple way to compensate for Coordinated Omission when a known expected interval between measurements exists. Alternatively ..."
          ]
        },
        {
          "title": "Percentiles aggregation | Reference",
          "url": "https://www.elastic.co/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation",
          "excerpts": [
            "HDR Histogram (High Dynamic Range Histogram) is an alternative implementation that can be useful when calculating percentiles for latency measurements as it can¬†..."
          ]
        },
        {
          "title": "Update on using multicore processors with a commercial ...",
          "url": "https://www.windriver.com/sites/default/files/2022-02/422204601.pdf",
          "excerpts": [
            "by PJ Parkinson ¬∑ 2017 ¬∑ Cited by 9 ‚Äî ARINC 653P1-4 also provides ability to support multiple partitions on each processor core using a timeslot scheduling approach where an individual partition¬†..."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt discusses addressing latency measurement and avoiding Coordinated Omission in benchmarking, which directly supports the plan to benchmark across high-performance systems and use precise latency measurements. This aligns with the goal of establishing baselines and choosing appropriate measurement techniques for performance validation. A closely related excerpt introduces HDR Histogram as a means to compute latency percentiles, which is essential for robust performance baselining and comparing systems. Other excerpts elaborate on benchmarking guidance and latency percentile information, which further supports the need to define reliable measurement practices and baselines across diverse platforms. The remaining excerpts reference OS-level partitioning and microsecond-scale schedulers as context for the kinds of systems that may serve as baselines (e.g., seL4, ARINC 653, Linux PREEMPT_RT) and provide additional benchmarking guidance. Together, these excerpts substantiate the strategy of selecting high-performance systems and using established benchmarking methodologies to create baselines for OS/IPC/Scheduler, Networking Proxies, and Data Systems as described in the finegrained field value.",
      "confidence": "medium"
    },
    {
      "field": "scheduler_layer_design.supported_policies",
      "citations": [
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
          "url": "https://www.usenix.org/system/files/osdi20-zhu.pdf",
          "excerpts": [
            "RackSched works at microsecond scale\n\nand optimizes the tail latency with network-system co-design",
            "We design a two-layer scheduling framework that inte-\n\ngrates inter-server scheduling in the ToR switch and intra-\n\nserver scheduling in each se",
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is sat"
          ]
        },
        {
          "title": "Shenango NSDI'19 Paper",
          "url": "https://amyousterhout.com/papers/shenango_nsdi19.pdf",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango, RackSched, and related microsecond-scale scheduling work (NSDI19/OSDI20) ‚Äì NSDI/nsdi19/nsdi20 papers",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/ousterhout",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/131018/nsdi19fall-final110.pdf?sequence=2&isAllowed=y",
          "excerpts": [
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.See more"
          ]
        }
      ],
      "reasoning": "The field value claims that the scheduler layer supports a range of pluggable policies, including EDF, RM, fair scheduling, and latency-SLO-oriented policies. Excerpts describing RackSched as a microsecond-scale scheduler and its focus on tail latency and policy-like design (even if not naming the exact policies) directly support the idea of a scheduler capable of multiple policies and fine-grained control. The Shenango reference similarly emphasizes high CPU efficiency for latency-sensitive workloads, which aligns with the concept of policy-driven optimization in a scheduler layer. These pieces collectively illustrate a design space where a scheduler layer can host multiple strategies to meet latency goals, which is precisely what the fine-grained field value describes. In contrast, a formal verification overview of seL4 documents correctness properties for a microkernel but does not address scheduling policy diversity, and while it provides important context about the system's foundation, it contributes less directly to the claim about pluggable scheduling policies. The RackSched paper's discussion of microsecond-scale scheduling and two-layer coordination provides concrete support for the existence of a policy-rich scheduler design, strengthening the claim that multiple scheduling strategies are supported or considered in this architecture.",
      "confidence": "medium"
    },
    {
      "field": "performance_validation_plan.key_metrics",
      "citations": [
        {
          "title": "Percentiles aggregation | Reference",
          "url": "https://www.elastic.co/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation",
          "excerpts": [
            "HDR Histogram (High Dynamic Range Histogram) is an alternative implementation that can be useful when calculating percentiles for latency measurements as it can¬†..."
          ]
        },
        {
          "title": "wrk2: Benchmarking guidance for workloads, baselines, metrics, and reproducibility",
          "url": "https://github.com/giltene/wrk2",
          "excerpts": [
            "While this model correctly measures the actual completion time of individual requests, it exhibits a strong Coordinated Omission effect, through which most of¬†...",
            "The model I chose for avoiding Coordinated Omission in wrk2 combines\nthe use of constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account.",
            "\nHowever, wrk2 will usually be run with the --latency flag, which provides\ndetailed latency percentile information (in a format that can be easily\nimported to spreadsheets or gnuplot scripts and plotted per examples\nprovided at <http://hdrhistogram.org> )",
            "For example, HdrHistogram includes a simple way to compensate for Coordinated Omission when a known expected interval between measurements exists. Alternatively ...",
            "constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account."
          ]
        }
      ],
      "reasoning": "The core field value requires detailed performance metrics and measurement approaches. The most directly supportive content is about percentile-based latency and how to measure latency distributions, including methods like HDR histogram and constant-throughput benchmarking, which align with the specified p50/p95/p99/p99.9 targets and tail behavior. The first excerpt discusses HDR Histogram as an alternative for latency percentiles, directly matching the need to capture percentile-based metrics. The benchmarking guidance excerpts describe how to measure throughput, the importance of latency percentiles, and techniques to avoid measurement biases like Coordinated Omission, which support the requested metrics (p50, p95, p99, p99.9) and throughput reporting. Additional excerpts emphasize latency percentiles and measurement formats, reinforcing the same measurement goals (e.g., detailed latency percentiles and how to report them). Some excerpts also touch on throughput measurement formats and latency reporting, which underpin the requested QPS and MB/sec metrics. Overall, the highest relevance comes from content that explicitly discusses latency percentiles, percentile-based reporting, and benchmarking practices, since these are the concrete methods to derive the requested performance metrics. The less directly relevant items are those that discuss architectural components or unrelated benchmarks without tying to the explicit metric set, but they still provide contextual grounding for how measurements might be structured in this environment.",
      "confidence": "high"
    },
    {
      "field": "project_summary.target_domain",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ...",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        }
      ],
      "reasoning": "The field value asserts that the intended application domain is safety-critical and security-critical systems, including automotive, aerospace, and industrial control. Excerpts describing ARINC 653 as a software standard for space and time partitioning in safety-critical avionics RTOS directly establish the context of safety-critical, partitioned environments common in aerospace and related industries. The ARINC 653 entries explain concepts such as partitions, dedicated memory spaces, partition time windows, and API surfaces for partition management and inter-/intra-partition communication, all of which map to the disciplined, partitioned operational environments typical of safety- and security-critical systems. Supporting evidence about secure, formally verified microkernel design (seL4) and related principles reinforces the notion that such domains demand rigorous verification and security enforcement, which aligns with the target domains of automotive, aerospace, and industrial control. The combination of explicit safety-critical partitioning standards and the emphasis on formal verification and capability-based security provides a coherent alignment with the field value. Direct statements about partitioned scheduling, partition protection, and ARINC 653 services underpin the relevance, while references to formal verification and secure design principles provide corroboration of the security/safety emphasis in these domains.",
      "confidence": "high"
    },
    {
      "field": "data_system_modules.1",
      "citations": [
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key",
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure",
            "or seam-\nless integration of user-defined operators (Section 7.7). Within each\nStream, non-Arrow representations, such as the Row Format (Sec-\ntion 6.6) are used when necessary to increase performance."
          ]
        },
        {
          "title": "Improvements in HashAggregationExec when spilling #7858",
          "url": "https://github.com/apache/arrow-datafusion/issues/7858",
          "excerpts": [
            "Oct 18, 2023 ‚Äî As spill is usually triggered under memory pressure, in most cases for all partitions around same time, it effectively doubles memory needed (in¬†..."
          ]
        },
        {
          "title": "Memory Management ‚Äî Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/memory.html",
          "excerpts": [
            "The default memory pool depends on how Arrow C++ was compiled: if enabled at compile time, a mimalloc heap;. otherwise, if enabled at compile time, a jemalloc ..."
          ]
        }
      ],
      "reasoning": "The core field value asserts that Gringotts-OLAP is a Vectorized OLAP Engine built on Arrow and DataFusion, employing a vectorized execution model, morsel-driven dynamic load balancing, and columnar cache-aware operations. The most directly supportive evidence appears in a section describing Gringotts-OLAP with Arrow/DataFusion, noting a high-throughput, multi-core setup and a vectorized execution flavor within the DataFusion context. Supporting detail comes from a second excerpt that explicitly mentions a two-phase parallel partitioned hash grouping with vectorized execution, reinforcing the vectorized and parallel nature of the engine's plan. A near-identical reference reiterates the Gringotts-OLAP and Arrow/DataFusion combination, strengthening the direct linkage to the described architecture. Additional excerpts discuss memory management and spill characteristics related to Arrow/DataFusion, which is consistent with a performance-oriented, cache-aware, columnar processing mindset; these provide reinforcing context about practical implementation concerns such as memory pools and spill behavior under pressure, aligning with the performance-oriented goals of the finegrained field value. Overall, the selected excerpts together map directly to the claimed architecture (Gringotts-OLAP on Arrow/DataFusion with vectorized/morsel-driven parallelism and columnar data handling) and provide concrete phrasing that supports each of the emphasized attributes.",
      "confidence": "high"
    },
    {
      "field": "design_meta_patterns.description",
      "citations": [
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible.",
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec"
          ]
        },
        {
          "title": "seL4 White Paper",
          "url": "https://sel4.systems/About/whitepaper.html",
          "excerpts": [
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark-¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ...",
            "------\n\nThis principle predates even the original L4 by decades. *Policy-mechanism separation* was explicitly stated as a principle in [a 1975 paper about the Hydra OS](https://www.systems.ethz.ch/sites/default/files/file/aos2012/Reading/week9/Policy%20mechanism%20separation%20in%20Hydra.pdf), but the idea is already clearly contained in [Brinch Hansen‚Äôs 1970 Nucleus paper](http://ddhf.dk/site_dk/rc/pbh/MonitorPaper.pdf), which describes the arch-ancestor of all microkernels."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling"
          ]
        }
      ],
      "reasoning": "The most relevant excerpts clearly define the core concept of capabilities and how they govern access boundaries in a system. One excerpt explains that capDL describes the kernel objects an seL4 application needs and, crucially, that capability distributions define the access boundaries, which directly supports the idea of capability-defined surfaces as a design pattern. It also notes that capDL specifications describe the desired state declaratively, enabling formal verification, which aligns with the Parseltongue DSL being translatable into formal models for pre-deployment verification. Another excerpt emphasizes that capDL serves as a declarative interface for system initialisation and capability reasoning, reinforcing the link between capabilities, clear boundaries, and verifiable state.\n\nSupporting evidence from broader sources on similar capability and verification themes includes materials on seL4 which discuss security, safety features, and assurance, providing context for a design that prioritizes formal verification and rigorous security properties. Further seL4 design principle discussions about policy-mechanism separation reinforce the notion that clear, well-defined interfaces (surfaces) and separation of policy from mechanism are central to secure, verifiable systems.\n\nContextual references to ARINC 653 help situate the environment in which such partitioned, multi-application architectures operate, including the concept of partitions with time and space separation and the APEX services API, which underpins the partitioned model described above. While these ARINC excerpts do not directly state the exact patterns of zero-copy I/O or thread-per-core hot paths, they support the overall environment where partitioned, deterministic operation is critical and where formalizable interfaces and clear boundaries are essential.\n\nTaken together, the strongest support for the finegrained field value comes from the capDL-focused excerpts, which explicitly discuss capability distributions, access-control boundaries, declarative system state, and formal verification, thereby directly linking to capability-defined surfaces and formalizable specifications. The seL4 materials bolster the argument by providing concrete examples of security, assurance, and principled separation relevant to a capability-oriented, verifiable design. The ARINC 653 pieces provide architectural context that reinforces the importance of partitioning and deterministic operation in such systems, aligning with the overall design goals described in the field value.",
      "confidence": "high"
    },
    {
      "field": "certification_roadmap.target_standard",
      "citations": [
        {
          "title": "Officially Qualified - Ferrocene",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Nov 8, 2023 ‚Äî It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in T√úV S√úDs certificate database."
          ]
        },
        {
          "title": "PP_OS_V4.2.1 Protection Profile (Common Criteria)",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/PP_OS_V4.2.1.pdf",
          "excerpts": [
            "This Protection Profile describes the security functionality of operating systems, which manage hardware and software resources, and provides ... An OS is\ntypically part of offerings identified as Infrastructure as a Service (IaaS), Software as a Service (SaaS), and\nPlatform as a Service (PaaS). This use case typically involves the use of virtualization technology which should be evaluated against the\nProtection Profile for Server Virtualization. 5",
            "FCS_CKM.1 Cryptographic Key Generation (Refined)",
            "FCS_CKM.2 Cryptographic Key Establishment (Refined)",
            "To be conformant to this PP, a ST must demonstrate Exact Conformance, a subset of Strict Conformance as\ndefined in [CC] Part 1 (ASE_CCL). The ST must include all components in this PP that are:\n\nunconditional (which are always required)\nselection-based (which are required when certain selections are chosen in the unconditional\nrequirements)\n\nand may include components that are\n\noptional or\nobjective. Unconditional requirements are found in the main body of the document, while appendices contain the\nselection-based, optional, and objective requirements"
          ]
        },
        {
          "title": "CAST-32A Guidance for Multicore Processorss - Green Hills Software",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_standards_cast-32A.html",
          "excerpts": [
            "CAST-32A objectives can be challenging to meet, and multicore interference mitigation at the OS level is an effective way to achieve robust partitioning.",
            "CAST-32A is a position paper published by the Certification Authority Software Team (CAST) in 2016 providing guidance on the use of multicore processors in ..."
          ]
        },
        {
          "title": "[PDF] A Commercial Solution for Safety-Critical Multicore Timing Analysis",
          "url": "https://mastecs-project.eu/sites/default/files/MC-WP-013%20MASTECS_BRANDED%20%E2%80%93%20A%20Commercial%20Solution%20for%20Safety-Critical%20Multicore%20Timing%20Analysis%20v1.pdf",
          "excerpts": [
            "The multicore timing analysis solution is comprised of tools, documents and services designed to meet DO-178C (CAST-32A/A(M). C 20-193) and ISO 26262 guidelines ..."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            ". The DO-330: Software Tool Qualification¬†... A further supplement was introduced in DO-178C, Software Tool Qualification Considerations (DO-330), which gives guidance on the qualification of tools used in software development and verification processes.",
            "DO-178C itself describes when a tool must be qualified, but does not go into detail on how this should be done.",
            "This guidance can be applied to any tools, not just those used for software development or verification, for example systems design or hardware development tools, and acts more like a stand-alone guidance document than the other supplements mentioned."
          ]
        }
      ],
      "reasoning": "The most directly supportive material is a passage noting ISO 26262 and IEC 61508 qualification status for a safety-focused tool, which aligns with the field value's emphasis on ISO 26262 and IEC 61508. Following that, multiple excerpts discuss Common Criteria and its protections for OS/security assurance, which matches the field value's inclusion of Common Criteria. CAST-32A-related guidance for multicore processors is also highly relevant because the field value specifies multicore considerations alongside safety standards, and CAST-32A provides concrete guidance applicable to multicore safety-critical systems. DO-178C is addressed in several DO-178C guidance items and DO-178C-related discussions, which support the avionics aspect of the field value, including how tool qualification and lifecycle concerns relate to DO-178C. The DO-178C guidance items reinforce the DO-178C portion of the target standards set, while the CAST-32A discussions bridge multicore considerations for avionics safety. Collectively, these excerpts map directly to the standards named in the target field value and illustrate official or standards-aligned guidance that would be relevant for certification roadmaps. The less direct items (e.g., broader multicore timing analysis or generic assurance discussions) provide contextual support but are not as central to the exact standard targets listed in the field value.",
      "confidence": "high"
    },
    {
      "field": "project_summary.goal",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 Partition Schedule. During the Partition Time Window, the second level of scheduling uses process scheduling. Each partition has at least one process.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling"
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The refinement proof between the capDL model of seL4 and its abstract specification was conducted in about 9 months for a total effort of 17.2pm. It ..."
          ]
        }
      ],
      "reasoning": "The target field value emphasizes a partitioned, safety-critical stack built on a partitioned microkernel with explicit time/space partitioning and an API/exec model (APEX). Excerpts that discuss ARINC 653 provide direct definitions of space/time partitioning, the concept of partitions, dedicated time windows, and the APEX API, which are core to the partitioned architecture described in the field value. The ARINC 653 entries collectively establish the structural and scheduling context that underpins a partitioned OS used for safety-critical systems. Details about the ARINC 653 APEX services further map to the API and partition management aspects called out in the field value. Excerpts describing ARINC 653 partition schedules, major/minor time frames, and process/partition management directly align with the architectural claims in the field value. Excerpts that reference seL4 and comprehensive formal verification, while not describing ARINC 653 itself, substantiate the microkernel angle and the emphasis on formally verifiable, capability-based security primitives for a robust microkernel foundation, which corroborates the intent of a Rust-only, safety/security-critical stack built on a partitioned microkernel. Putting these together, the strongest support comes from passages that define partitioned OS concepts and ARINC 653 API/scheduling (partitioning and APEX), followed by passages that describe microkernel verification/context (seL4) as supportive background for a formally-designed microkernel foundation. The resulting interpretation is that the field value is conceptually supported by the ARINC 653 related excerpts, with supportive context from microkernel verification discussions.",
      "confidence": "high"
    },
    {
      "field": "certification_roadmap.target_level",
      "citations": [
        {
          "title": "Officially Qualified - Ferrocene",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Nov 8, 2023 ‚Äî It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in T√úV S√úDs certificate database."
          ]
        },
        {
          "title": "PP_OS_V4.2.1 Protection Profile (Common Criteria)",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/PP_OS_V4.2.1.pdf",
          "excerpts": [
            "This Protection Profile describes the security functionality of operating systems, which manage hardware and software resources, and provides ... An OS is\ntypically part of offerings identified as Infrastructure as a Service (IaaS), Software as a Service (SaaS), and\nPlatform as a Service (PaaS). This use case typically involves the use of virtualization technology which should be evaluated against the\nProtection Profile for Server Virtualization. 5",
            "To be conformant to this PP, a ST must demonstrate Exact Conformance, a subset of Strict Conformance as\ndefined in [CC] Part 1 (ASE_CCL). The ST must include all components in this PP that are:\n\nunconditional (which are always required)\nselection-based (which are required when certain selections are chosen in the unconditional\nrequirements)\n\nand may include components that are\n\noptional or\nobjective. Unconditional requirements are found in the main body of the document, while appendices contain the\nselection-based, optional, and objective requirements",
            "FCS_CKM.2 Cryptographic Key Establishment (Refined)"
          ]
        },
        {
          "title": "[PDF] A Commercial Solution for Safety-Critical Multicore Timing Analysis",
          "url": "https://mastecs-project.eu/sites/default/files/MC-WP-013%20MASTECS_BRANDED%20%E2%80%93%20A%20Commercial%20Solution%20for%20Safety-Critical%20Multicore%20Timing%20Analysis%20v1.pdf",
          "excerpts": [
            "The multicore timing analysis solution is comprised of tools, documents and services designed to meet DO-178C (CAST-32A/A(M). C 20-193) and ISO 26262 guidelines ..."
          ]
        },
        {
          "title": "AC 20-193 - Use of Multi-Core Processors",
          "url": "https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentID/1036408",
          "excerpts": [
            "Number: 20-193 ; Title: Use of Multi-Core Processors ; Status: Active ; Date issued: 2024-01-08 ; Office of Primary Responsibility: AIR-622, Airframe Section¬†..."
          ]
        },
        {
          "title": "Assurance of Multicore Processors in Airborne Systems",
          "url": "https://www.faa.gov/sites/faa.gov/files/aircraft/air_cert/design_approvals/air_software/TC-16-51.pdf",
          "excerpts": [
            "This report addresses software assurance for multicore processors (MCPs) in airborne systems, and their safety implications, including lack of predictability."
          ]
        },
        {
          "title": "CAST-32A Guidance for Multicore Processorss - Green Hills Software",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_standards_cast-32A.html",
          "excerpts": [
            "CAST-32A objectives can be challenging to meet, and multicore interference mitigation at the OS level is an effective way to achieve robust partitioning."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            "This guidance can be applied to any tools, not just those used for software development or verification, for example systems design or hardware development tools, and acts more like a stand-alone guidance document than the other supplements mentioned.",
            ". The DO-330: Software Tool Qualification¬†... A further supplement was introduced in DO-178C, Software Tool Qualification Considerations (DO-330), which gives guidance on the qualification of tools used in software development and verification processes.",
            "DO-178C itself describes when a tool must be qualified, but does not go into detail on how this should be done."
          ]
        },
        {
          "title": "CAST-32A Compliance Update July 2021",
          "url": "https://www.rapitasystems.com/products/cast-32a-update-2021",
          "excerpts": [
            "Our template CAST-32A compliance documents offer a convenient blueprint that can be used to generate final DO-178C compliance documents. These documents can be¬†..."
          ]
        }
      ],
      "reasoning": "The most directly supportive information comes from explicit statements about ISO 26262 and IEC 61508 qualification. One excerpt states that Ferrocene is ISO 26262 and IEC 61508 qualified, which directly aligns with the ISO 26262 ASIL-D and IEC 61508 SIL-4 aspects of the target field value. Following this, several excerpts discuss Common Criteria protection profiles and evidence of CC conformance, including references to protection profiles and cryptographic key handling, which bolster the CC EAL4+ aspect and SKPP-related considerations in a safety-critical context. References that discuss DO-178C guidance, including tool qualification and timing analysis for DO-178C, support the DO-178C DAL-A component, though they do not alone confirm the full highest level combination unless paired with explicit conformance statements. Excerpts about CAST-32A and multicore timing analysis provide important safety-critical context (multicore timing, partitioning, and interference mitigation), but they do not directly assert the exact combination of ISO 26262 ASIL-D, IEC 61508 SIL-4, DO-178C DAL-A, and CC EAL4+ with SKPP. Therefore, the most relevant content directly mapping to the field value is the ISO/IEC-qualified Ferrocene reference, followed by CC protection-profile/conformance discussions, with DO-178C-related guidance and multicore partitioning/contextual information as supporting evidence. The aggregation of these excerpts suggests a strong, albeit not uniformly explicit, alignment with the stated highest assurance levels and SKPP conformance within a safety-critical, partitioned, multicore environment.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.1",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 Platform\nAn ARINC 653 platform contains:\n\nA hardware platform allowing real-time computing deterministic services. An abstraction layer managing the timer and space partitioning constraints of the platform (memory, CPU, Input/output).\nAn implementation for the ARINC 653 services (the APEX API). An interface to be able to configure the platform and its domain of us",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 Partition Schedule. During the Partition Time Window, the second level of scheduling uses process scheduling. Each partition has at least one process.",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 10.1.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-10.1.1.pdf",
          "excerpts": [
            "IOMMU on Intel x86-based platforms. An IOMMU allows memory to be remapped from the device's point of view. It acts as an MMU for the device ..."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The fastpath is a hand-tuned implementation of the IPC (inter- process communication) paths through the seL4 kernel. These IPC paths are used to pass messages¬†..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS.",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation"
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        },
        {
          "title": "seL4 and Apex-style threat model comparison (role-play / integrated analysis)",
          "url": "https://maxwellseefeld.org/sel4/",
          "excerpts": [
            "No Built-in Device Isolation: seL4 itself doesn't magically handle DMA or device memory ‚Äì it's up to the system builder to ensure devices are ... For example, direct memory access by devices can bypass the kernel, so the proofs assume any DMA either doesn‚Äôt interfere or is managed (or you use an IOMMU). These are r"
          ]
        },
        {
          "title": "Trustworthy isolation of DMA devices",
          "url": "https://link.springer.com/article/10.1007/s42786-020-00018-x",
          "excerpts": [
            "The main concern when DMACs are controlled by untrusted software is that the destination addresses of BDs can be set arbitrarily."
          ]
        },
        {
          "title": "IOMMU solutions for seL4 (take ARM SMMUv3 for instance)",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-12-mao.pdf",
          "excerpts": [
            "The VMM and other components maintain their own IO domains through the unified kernel interfaces that\n\nsystematically manages all SMMU hardware abstracts"
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†...",
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant material describes ARINC 653-style space-and-time partitioning and the concept of an Application Executive (APEX) that governs partitioning, which is central to an isolation and partitioning enforcement component. Excerpts that explain ARINC 653 provides spatial and temporal isolation between partitions and the existence of a partitioned scheduling model directly align with the Protego Maxima role of enforcing isolation boundaries and managing partition schedules. Additionally, references that describe APEX services (partition management, process management, and time management) map to the kinds of enforcement and policy boundaries Protego Maxima would implement to protect access rights and enforce the partitioning model. The memory isolation aspect is covered by excerpts noting partition memory separation and per-partition memory management constraints, which supports Protego Maxima acting as an IOMMU policy enforcer to protect against DMA-based attacks. Excerpts that discuss the two-level ARINC 653 schedule (major/minor frames) and preemptive process scheduling within partitions reinforce the temporal and spatial enforcement responsibilities that Protego Maxima would need to implement. The references that mention ARINC 653 platform components and IOMMU-related discussions further bolster the enforcement role, showing how a real-world partitioned OS would structure and secure cross-partition interactions and DMA access. Contextual material about seL4 (a capability-based, formally verified microkernel) and related threat models provides supportive justification for strong isolation guarantees, though it is ancillary to Protego Maxima's specific description. References to Real-Time avionics best practices and ARINC 653 updates across multicore scenarios add depth to the security model and partitioning strategy, reinforcing the relevance of isolation enforcement in a robust OS architecture.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.0",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a real-time, partitioned microkernel at the OS layer, with ARINC-653-like space/time partitioning and capability-style isolation, and explicitly notes seL4 as an inspiration. Direct ARINC-653 definitions clarify the partitioning model: applications run in partitions with dedicated memory spaces and a two-level scheduling model that includes Major/Partition Time Windows and fixed partition sequencing. This aligns with the described L1 OS role as enforcing spatial/temporal isolation and partitioned execution. Additional excerpts explain that ARINC 653 provides an API (APEX) and that partitions are scheduled with partition time windows, reinforcing the notion of a partitioned, real-time microkernel foundation. The two-level scheduling and partition management details demonstrate the architectural pattern the field value attributes to the L1 layer. Furthermore, excerpts discussing ARINC 653 overviews and platform implications corroborate that spatial and temporal isolation is a core feature of the architecture. On the inspiration side, excerpts about seL4 emphasize formal verification and capability-based security, which supports the field value's claim of leveraging a formally verified microkernel model as a foundational reference. The seL4 material, including mentions of formal verification and capability-based proofs, strengthens the claim of a high-assurance foundation behind the partitioned microkernel concept. Taken together, the ARINC 653 excerpts establish the partitioning and scheduling aspects, while the seL4 excerpts provide the formal, capability-based security inspiration backing the L1 OS description.",
      "confidence": "high"
    },
    {
      "field": "core_architecture_overview.layer_2_schedulers",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS).",
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture."
          ]
        },
        {
          "title": "A Simple Introduction to ARINC 653 | by Mehmet Cagri Kose",
          "url": "https://medium.com/@mehmetcagrikose/a-simple-introduction-to-arinc-653-775b1c5888c0",
          "excerpts": [
            "ARINC 653 partitions are ... Together with process management module, they guarantee timely execution of processes in a partition.",
            "A partition creates a kind of container for application that provides spatial and temporal partitioning. * **Spatial Partitioning:** Memory of a partition is always protected. Also, no partition can access memory zones out of their scope. At any given time, only one of the partitions can access to system resources, there is no competition between them. * **Temporal Partitioning:** This is provided by major and minor time frame mechanisms.",
            "When the execution window of a partition(minor time frame) terminates, partition is preempted(paused) and next partition in the major time frame ...",
            "This is provided by major and minor time frame mechanisms. Major time frame are time windows where each partition is executed at least once¬†..."
          ]
        },
        {
          "title": "Update on using multicore processors with a commercial ...",
          "url": "https://www.windriver.com/sites/default/files/2022-02/422204601.pdf",
          "excerpts": [
            "by PJ Parkinson ¬∑ 2017 ¬∑ Cited by 9 ‚Äî ARINC 653P1-4 also provides ability to support multiple partitions on each processor core using a timeslot scheduling approach where an individual partition¬†..."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†...",
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "seL4 White Paper",
          "url": "https://sel4.systems/About/whitepaper.html",
          "excerpts": [
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark- ...",
            "The seL4 white paper provides an introduction and overview for seL4, including seL4's assurance story, its security and safety features, and its benchmark-¬†..."
          ]
        },
        {
          "title": "seL4 Design Principles - microkerneldude",
          "url": "https://microkerneldude.org/2020/03/11/sel4-design-principles/",
          "excerpts": [
            "The model not only enhances minimality and policy-freedom, it is the core enabler of our proofs of security enforcement. Its aim is to make it ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes Layer 2 Schedulers as a workload-specific scheduling layer with microsecond-scale core rebalancing and multiple scheduling policies, including EDF and RM, and mentions an API seed called the Sorting Hat API. Excerpts that explicitly discuss ARINC 653-style time/space partitioning, per-partition scheduling, fixed/major/minor time frames, and the notion of an API-exposed scheduling surface are most directly aligned with this field; they provide concrete context for how partitions are scheduled and protected, which is the architectural setting in which aspects like EDF/RM policies and API surfaces would exist. Excerpts detailing that partitions have dedicated time slots, that scheduling can be round-robin within frames, and that there are partition-specific schedulers and API surfaces all connect to the idea of a layered Schedulers component in a partitioned RTOS, even if they do not name the exact EDF/RM policies or the Sorting Hat API themselves. The surrounding ARINC 653 references establish the partitioned scheduling context, while excerpts that discuss general partitioning and temporal isolation further ground the concept of a schedulers layer operating within per-partition time windows. Although none of the excerpts explicitly state the Sorting Hat API or EDF/RM, the combination of partitioned scheduling, time-frame guarantees, and references to per-partition schedulers strongly supports the existence and role of a Layer 2 Scheduler component as described in the field value.",
      "confidence": "medium"
    },
    {
      "field": "data_system_modules.1.codename",
      "citations": [
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx",
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure"
          ]
        }
      ],
      "reasoning": "The most directly supportive excerpts explicitly name Gringotts-OLAP and tie it to Arrow/DataFusion, which confirms the codename as a Gringotts-OLAP module within the data system stack. One excerpt describes Gringotts-OLAP with Arrow/DataFusion and mentions vectorized execution and partitioned hashing context, reinforcing its role as a data system component that leverages DataFusion technologies. Another closely related excerpt reiterates the Gringotts-OLAP naming alongside Arrow/DataFusion and adds notes about memory management and spill behavior, which aligns with typical OLAP data-system concerns like partitioned processing and resource management. A third excerpt, while focusing on similar subject matter, explicitly references Gringotts-OLAP in the section heading and discusses customizable resource management for DataFusion, further confirming the module's identity and operational characteristics within the stack. The combination of explicit naming and associations with Arrow/DataFusion across these excerpts provides cohesive support for the finegrained field value being the Gringotts-OLAP module within the data system pipeline.",
      "confidence": "high"
    },
    {
      "field": "data_system_modules.1.type",
      "citations": [
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure",
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key"
          ]
        }
      ],
      "reasoning": "The fine-grained field value denotes an OLAP data-system module. Excerpts that explicitly reference Gringotts-OLAP and its use with Arrow/DataFusion directly support the notion of an OLAP module within the Gringotts data system. Specifically, the passages describing Gringotts-OLAP with Arrow/DataFusion articulate an OLAP-oriented component, including how it leverages a columnar/vectorized approach and integration with DataFusion, which is characteristic of OLAP workloads. These excerpts provide concrete evidence that the OLAP module is implemented as Gringotts-OLAP and is associated with DataFusion/Arrow, aligning with the requested field value. Related excerpts that discuss generic memory management or spill behavior while not explicitly tying to the Gringotts OLAP module are considered supplemental context and do not directly confirm the OLAP module type, though they may enrich understanding of the data system's execution characteristics. Therefore, the most relevant materials are those that explicitly name Gringotts-OLAP and/or DataFusion in the OLAP context, followed by excerpts that mention Gringotts-OLAP together with Arrow/DataFusion indirectly.",
      "confidence": "high"
    },
    {
      "field": "data_system_modules.1.core_technology",
      "citations": [
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key",
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure",
            "or seam-\nless integration of user-defined operators (Section 7.7). Within each\nStream, non-Arrow representations, such as the Row Format (Sec-\ntion 6.6) are used when necessary to increase performance."
          ]
        },
        {
          "title": "Memory Management ‚Äî Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/memory.html",
          "excerpts": [
            "The default memory pool depends on how Arrow C++ was compiled: if enabled at compile time, a mimalloc heap;. otherwise, if enabled at compile time, a jemalloc ..."
          ]
        },
        {
          "title": "Improvements in HashAggregationExec when spilling #7858",
          "url": "https://github.com/apache/arrow-datafusion/issues/7858",
          "excerpts": [
            "Oct 18, 2023 ‚Äî As spill is usually triggered under memory pressure, in most cases for all partitions around same time, it effectively doubles memory needed (in¬†..."
          ]
        }
      ],
      "reasoning": "The target fine-grained field value describes a high-throughput analytical engine built on Apache Arrow and DataFusion, employing a vectorized execution model, morsel-driven parallelism for dynamic load balancing, and columnar cache-aware operations. Excerpts that explicitly reference DataFusion or Arrow, and that describe vectorized execution or parallelism, directly support this claim. Excerpts that discuss DataFusion in the context of resource management or memory pools also reinforce the underlying platform (Arrow/DataFusion), even if they do not state vectorization explicitly. Excerpts that focus on other aspects (e.g., non-Arrow representations or peripheral implementation details) are less directly supportive but still provide contextual relevance to the DataFusion-based ecosystem. Specifically, the most supportive content notes: a vectorized execution model and partitioned, parallel execution with DataFusion; references to Arrow/DataFusion integration; and mentions of memory management and spill behavior within DataFusion contexts. By contrast, mentions of non-Arrow representations or general memory pool machinery are supplementary rather than central to the described architectural claim.",
      "confidence": "medium"
    },
    {
      "field": "data_system_modules.1.module_name",
      "citations": [
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key",
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx",
            "or seam-\nless integration of user-defined operators (Section 7.7). Within each\nStream, non-Arrow representations, such as the Row Format (Sec-\ntion 6.6) are used when necessary to increase performance.",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure"
          ]
        },
        {
          "title": "Memory Management ‚Äî Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/memory.html",
          "excerpts": [
            "The default memory pool depends on how Arrow C++ was compiled: if enabled at compile time, a mimalloc heap;. otherwise, if enabled at compile time, a jemalloc ..."
          ]
        },
        {
          "title": "Improvements in HashAggregationExec when spilling #7858",
          "url": "https://github.com/apache/arrow-datafusion/issues/7858",
          "excerpts": [
            "Oct 18, 2023 ‚Äî As spill is usually triggered under memory pressure, in most cases for all partitions around same time, it effectively doubles memory needed (in¬†..."
          ]
        }
      ],
      "reasoning": "The field value identifies a Vectorized OLAP Engine, which corresponds to references describing an OLAP system that uses vectorized execution and columnar data processing. Excerpts that explicitly mention vectorized execution in the DataFusion context strongly support this value, since DataFusion is described as distributing work across cores with vectorized execution operators. This aligns with the idea of a vectorized OLAP engine underpinning Gringotts-OLAP using Arrow/DataFusion. Supporting excerpts also situate DataFusion within an OLAP framework (Arrow/DataFusion as a vectorized engine, with partitioning and spill behavior relevant to scalable OLAP workloads) and provide architectural context around how such a vectorized engine operates within the Gringotts ecosystem. Other excerpts reinforce the same ecosystem (Arrow-based memory and execution models) and thus provide corroborating context, even if they do not state vectorization as explicitly.",
      "confidence": "high"
    },
    {
      "field": "program_plan_and_risk_assessment",
      "citations": [
        {
          "title": "AC 20-193 - Use of Multi-Core Processors",
          "url": "https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentID/1036408",
          "excerpts": [
            "Number: 20-193 ; Title: Use of Multi-Core Processors ; Status: Active ; Date issued: 2024-01-08 ; Office of Primary Responsibility: AIR-622, Airframe Section¬†..."
          ]
        },
        {
          "title": "CAST-32A Compliance Update July 2021",
          "url": "https://www.rapitasystems.com/products/cast-32a-update-2021",
          "excerpts": [
            "Our template CAST-32A compliance documents offer a convenient blueprint that can be used to generate final DO-178C compliance documents. These documents can be¬†..."
          ]
        },
        {
          "title": "Assurance of Multicore Processors in Airborne Systems",
          "url": "https://www.faa.gov/sites/faa.gov/files/aircraft/air_cert/design_approvals/air_software/TC-16-51.pdf",
          "excerpts": [
            "This report addresses software assurance for multicore processors (MCPs) in airborne systems, and their safety implications, including lack of predictability."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            ". The DO-330: Software Tool Qualification¬†... A further supplement was introduced in DO-178C, Software Tool Qualification Considerations (DO-330), which gives guidance on the qualification of tools used in software development and verification processes.",
            "DO-178C itself describes when a tool must be qualified, but does not go into detail on how this should be done.",
            "The Supporting Information (DO-248C) supplementary document includes FAQs relating to DO-178C, and the document is commonly referred to by the title Frequently Asked Questions."
          ]
        },
        {
          "title": "ISO 26262 Confidence in the use of software tools",
          "url": "https://heicon-ulm.de/en/iso-26262-confidence-in-the-use-of-softwar-tools-a-feasible-strategy/",
          "excerpts": [
            "What are the requirements of ISO 26262? First of all, according to ISO 26262, the Tool Confidence Level must be defined for a specific tool."
          ]
        },
        {
          "title": "When and how to qualify tools according to ISO 26262",
          "url": "https://www.btc-embedded.com/when-and-how-to-qualify-tools-according-to-iso-26262/",
          "excerpts": [
            "This article will describe how to find out if a tool needs to be qualified and how to perform an ISO 26262 tool qualification."
          ]
        },
        {
          "title": "CAST-32A",
          "url": "https://en.wikipedia.org/wiki/CAST-32A",
          "excerpts": [
            "Objectives. edit. The paper presents ten objectives that must be met for Design Assurance Level (DAL) A or B. Six of the objectives apply for DAL C. The paper ...",
            "A key point is that Multi-core processor \"interference can affect execution timing behavior, including worst case execution time (WCET).\" Multi-core Processors ...",
            "The first mixed-criticality multicore real-time operating system avionics systems was certified in 2021. The objectives of the standard are applicable to¬†..."
          ]
        },
        {
          "title": "What is a Test Plan? Complete Guide With Examples",
          "url": "https://www.practitest.com/resource-center/article/write-a-test-plan/",
          "excerpts": [
            "A guide to creating effective test plans in software testing, emphasizing their value across all project lifecycles and testing methods."
          ]
        },
        {
          "title": "Test Plan & Procedures",
          "url": "https://foa.ucdavis.edu/sites/g/files/dgvnsk3426/files/inline-files/test-plan-procedures.docx",
          "excerpts": [
            "This test plan provides managers and test personnel with the necessary ... For example, ‚ÄúSome or all test cases will be dry run for finalization of¬†..."
          ]
        },
        {
          "title": "ISO 26262 Certification and Confirmation Review (Spyro-soft article)",
          "url": "https://spyro-soft.com/blog/automotive/iso-26262",
          "excerpts": [
            "ISO 26262 supports the whole product safety lifecycle: from management, development, and production to service.",
            "The table below lists the work products that should have a confirmation review and the required level of organisational independence for each.",
            "The scope of a functional safety assessment shall include:",
            "The safety plan and all required work products ‚Äì detail level can be tailored by an assessor; here also functional safety requirement management, including bidirectional traceability, can be verified."
          ]
        },
        {
          "title": "CAST-32A - Rapita Systems",
          "url": "https://www.rapitasystems.com/cast-32a",
          "excerpts": [
            "CAST-32A addresses several multicore processor topics including software verification, error detection and handling and reporting of compliance.",
            "One of the most significant recent changes in the embedded computing world is the increasing adoption of multicore processors. These processors represent the future of aerospace development and their adoption is crucial to both meet the needs of modern avionics systems and avoid potential long-term single-core processor availability concerns.",
            "The use of multi-core processors does come at a price, however, as unlike their single-core counterparts, they offer neither a deterministic environment nor predictable software execution times.",
            "Interference Channels and Resource Usage\nMCP_Resource_Usage_3: The applicant has identified the interference channels that could permit interference to affect the software applications hosted on the MCP cores, and has verified the applicant‚Äôs chosen means of mitigation of the interference.",
            "MCP_Software_1: The applicant has verified that all the software components hosted by the MCP comply with the Applicable Software Guidance. In particular, the applicant has verified that all the hosted software components function correctly and have sufficient time to complete their execution when all the hosted software is executing in the intended final configuration.",
            "MCP_Software_2: The applicant has verified that the data and control coupling between all the individual software components hosted on the same core or on different cores of the MCP has been exercised during software requirement-based testing, including exercising any interfaces between the applications via shared memory and any mechanisms to control the access to shared memory, and that the data and control coupling is correct."
          ]
        },
        {
          "title": "The Multi-Core Challenge: A practical Approach to CAST-32A & AMC 20-193 Compliance",
          "url": "https://www.sysgo.com/blog/article/the-multi-core-challenge-a-practical-approach-to-cast-32a-amc-20-193-compliance",
          "excerpts": [
            "CAST-32A seeks to provide guidance in the use of MCPs in avionics, where robust partitioning between domains is critical.",
            "For a single core, the calculation of Worst-Case Execution Times (WCET) through static analysis alone can only ever be an approximation. In an MCP environment, shared resources such as memory and caches further degrade the calculation of WCET, making measurement essential.",
            " automated traceability to evidential artefacts can relieve a typical project management pain point, when tests fail",
            "How static analysis and MISRA compliance are achieved, and their impact on maintainability",
            "Code analysis and execution on the hardware target through the OS IDE",
            "Key Takeaways"
          ]
        },
        {
          "title": "AMC 20-193 Use of multi-core processors",
          "url": "https://www.easa.europa.eu/sites/default/files/dfu/annex_i_to_ed_decision_2022-001-r_amc_20-193_use_of_multi-core_processors_mcps.pdf",
          "excerpts": [
            "Annex I to ED Decision 2022/001/R \n\nAMC 20-193",
            "The column ‚ÄòIDAL A or B‚Äô shows the objectives applicable when the highest IDAL of any of the software \napplications hosted by the MCP or of the MCP hardware device is A or B"
          ]
        },
        {
          "title": "As some A(M)C 20-193 objectives aren't indicated for DAL C systems",
          "url": "https://www.rapitasystems.com/products/faqs/some-amc-20-193-objectives-arent-indicated-dal-c-systems-do-i-not-need-perform",
          "excerpts": [
            "This will require some understanding of the interference channels on the platform and their impact on the software.",
            "You should speak to your certification authority to determine what level of rigor may be necessary for related activities."
          ]
        },
        {
          "title": "Http Load Testing With Wrk2 - Paul's Notes",
          "url": "https://www.yangyang.cloud/blog/2018/11/05/http-load-testing-with-wrk2/",
          "excerpts": [
            "Nov 5, 2018 ‚Äî The latency percentile , like p50/p90/p99, is the most common QoS metric. Throughput. For HTTP request, it's also refered as requests/second or¬†..."
          ]
        },
        {
          "title": "Contour Performance Testing with Envoy",
          "url": "https://github.com/projectcontour/contour-perf",
          "excerpts": [
            "Jun 28, 2022 ‚Äî Check the wrk2 results to make sure all requests were successful, and latency is reasonable (P99 under 10ms); Run a two minute tcpkali workload¬†..."
          ]
        },
        {
          "title": "Yet another comparison between io_uring and epoll on network ...",
          "url": "https://github.com/axboe/liburing/issues/536",
          "excerpts": [
            "io_uring is slower than epoll in the streaming mode; When buf size increases, the performance gap is drawing near. Test 2, Echo server ..."
          ]
        },
        {
          "title": "Is epoll a better API than io_uring? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/76598320/is-epoll-a-better-api-than-io-uring",
          "excerpts": [
            "The proactor pattern ( io_uring , IOCP , ioring ) is superior to the reactor ( epoll , kqueue , etc.) because it actually mimics the natural program control ..."
          ]
        },
        {
          "title": "What are best practices for benchmarking Envoy?",
          "url": "https://www.envoyproxy.io/docs/envoy/latest/faq/performance/how_to_benchmark_envoy",
          "excerpts": [
            "What are best practices for benchmarking Envoy?  . There is no single QPS, latency or throughput overhead that can characterize a network proxy such as Envoy.",
            "Use release Envoy, match concurrency, disable circuit breaking, ensure comparable filter chains, and measure below the QPS-latency curve."
          ]
        },
        {
          "title": "Benchmarking HTTP/3 Performance with Edge Stack ...",
          "url": "https://www.getambassador.io/blog/benchmarking-http3-edge-stack-envoy",
          "excerpts": [
            "Jun 29, 2022 ‚Äî We were keen to explore the real-world results and have run a series of benchmarks with Edge Stack, which contains Envoy Proxy at its core."
          ]
        },
        {
          "title": "Statistical Benchmarking Methodology Overview",
          "url": "https://ontosight.ai/glossary/term/statistical-benchmarking-methodology-overview--679f522838099fda3c01dc57",
          "excerpts": [
            "Statistical benchmarking is a methodology used to compare and evaluate the performance of different entities, such as organizations, processes, or systems, ..."
          ]
        },
        {
          "title": "A Beginner's Guide to Conducting Reproducible Research",
          "url": "https://esajournals.onlinelibrary.wiley.com/doi/10.1002/bes2.1801",
          "excerpts": [
            "by JM Alston ¬∑ 2021 ¬∑ Cited by 95 ‚Äî Research is reproducible when others can reproduce the results of a scientific study given only the original data, code, and documentation."
          ]
        },
        {
          "title": "The tail at scale - Luiz Andr√© Barroso",
          "url": "https://www.barroso.org/publications/TheTailAtScale.pdf",
          "excerpts": [
            "by JR Dean ¬∑ 2013 ¬∑ Cited by 2294 ‚Äî Software techniques that tolerate latency variability are vital to building responsive large-scale Web services. By JeffRey Dean anD Luiz anDR√© BaRRoSo key ...",
            "by JR Dean ¬∑ 2013 ¬∑ Cited by 2294 ‚Äî tail-tolerant,‚Äù or simply ‚Äútail-tolerant.‚Äù Here, we outline some common causes for high-latency episodes in large online services and describe techniques¬†..."
          ]
        },
        {
          "title": "Essential guidelines for computational method benchmarking",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC6584985/",
          "excerpts": [
            "por LM Weber ¬∑ 2019 ¬∑ Mencionado por 189 ‚Äî Benchmarking studies aim to rigorously compare the performance of different methods using well-characterized benchmark datasets, to determine the strengths of ..."
          ]
        },
        {
          "title": "Performance",
          "url": "https://www.openpolicyagent.org/docs/envoy/performance",
          "excerpts": [
            "This page provides some guidance and best practices around benchmarking the performance of the OPA-Envoy plugin in order."
          ]
        },
        {
          "title": "AI/ML Benchmarking and Lustre",
          "url": "https://www.depts.ttu.edu/hpcc/events/LUG24/slides/Day2/LUG_2024_Talk_14-AI_ML_Benchmarking_and_Lustre.pdf",
          "excerpts": [
            "May 1, 2024 ‚Äî The submission of a MLPerf Storage run would include the results of 5 benchmark jobs, where each results should within a 5% margin. ‚Ä¢ This puts¬†..."
          ]
        },
        {
          "title": "The tail at scale | Communications of the ACM",
          "url": "https://dl.acm.org/doi/10.1145/2408776.2408794",
          "excerpts": [
            "Abstract. Software techniques that tolerate latency variability are vital to building responsive large-scale Web services. Formats available."
          ]
        },
        {
          "title": "The tail at scale",
          "url": "https://cseweb.ucsd.edu/classes/sp18/cse124-a/post/schedule/p74-dean.pdf",
          "excerpts": [
            "by J DEAN ¬∑ 2013 ¬∑ Cited by 2294 ‚Äî Software techniques that tolerate latency variability are vital to building responsive large-scale Web services. BY JEFFREY DEAN AND LUIZ ANDR√â BARROSO key ...",
            "by J DEAN ¬∑ 2013 ¬∑ Cited by 2294 ‚Äî tail-tolerant,‚Äù or simply ‚Äútail-tolerant.‚Äù Here, we outline some common causes for high-latency episodes in large online services and describe techniques¬†..."
          ]
        },
        {
          "title": "Guidance: Rigor and Reproducibility in Grant Applications",
          "url": "https://grants.nih.gov/policy-and-compliance/policy-topics/reproducibility/guidance",
          "excerpts": [
            "Oct 16, 2024 ‚Äî The requirement to include a Plan for Instruction in Methods for Enhancing Reproducibility attachment will be expanded to all applicants."
          ]
        },
        {
          "title": "seL4 Benchmark Suite (sel4bench)",
          "url": "https://github.com/seL4/sel4bench",
          "excerpts": [
            "Missing: microbenchmark cycles Applications",
            "We provide multiple applications for benchmarking different paths in the",
            "sel4bench",
            "This is the driver application: it launches each benchmark in a separate\nprocess and collects, processes, and outputs results. ipc",
            "process and collects, processes, and outputs results.",
            "ipc",
            "This is a hot-cache benchmark of the IPC path. irq",
            "irq",
            "This is a hot-cache benchmark of the IRQ path, measured from inside the\nkernel. It requires tracepoints to be placed on the IRQ path where the meaurements are to be taken from. irquser",
            "kernel. It requires tracepoints to be placed on the IRQ path where the meaurements are to be taken from.",
            "irquser",
            "This is a hot-cache benchmark of the IRQ path, measured from user space. scheduler",
            "scheduler",
            "This is a hot-cache benchmark of a scheduling decision. It works by\nusing a producer/consumer pattern between two notification objects. This benchmark also measures\nseL4_Yield() . signal",
            "using a producer/consumer pattern between two notification objects. This benchmark also measures",
            "seL4_Yield() .",
            "signal",
            "This is a hot-cache benchmark of the signal path in the kernel, measured\nfrom user space. smp",
            "from user space.",
            "smp",
            "This is an intra-core IPC round-trip benchmark to check overhead of kernel synchronization on IPC throughput. vcpu (AArch64 only). This benchmark will¬†... ",
            "This is an intra-core IPC round-trip benchmark to check overhead of kernel synchronization on IPC throughput. vcpu (AArch64 only)",
            "vcpu (AArch64 only)",
            "This benchmark will execute a thread as a VCPU (an EL1 guest kernel) and",
            "then obtain numbers for the following actions:",
            "ERET instruction. * The cost of a null invocation of the EL2 kernel using",
            "HVC . * The cost of an",
            "seL4_Call() from an EL1 guest thread to a native seL4",
            "thread. * The cost of an",
            "seL4_Reply() from an seL4 native thread to an EL1",
            "guest thread.",
            "sel4bench is a benchmarking applications and support library for seL4. To get this project, check out the project manifest. Applications\nWe provide multiple applications for benchmarking different paths in the\nkernel. sel4bench\nThis is the driver application: it launches each benchmark in a separate\nprocess and collects, processes, and outputs results. ipc\nThis is a hot-cache benchmark of the IPC path. irq\nThis is a hot-cache benchmark of the IRQ path, measured from inside the\nkernel. It requires tracepoints to be placed on the IRQ path where the meaurements are to be taken from. irquser\nThis is a hot-cache benchmark of the IRQ path, measured from user space. scheduler\nThis is a hot-cache benchmark of a scheduling decision. It works by\nusing a producer/consumer pattern between two notification objects. This benchmark also measures\nseL4_Yield() . signal\nThis is a hot-cache benchmark of the signal path in the kernel, measured\nfrom user space. smp\nThis is an intra-core IPC round-trip benchmark to check overhead of\nkernel synchronization on IPC throughput. vcpu (AArch64 only)\nThis benchmark will execute a thread as a VCPU (an EL1 guest kernel) and\nthen obtain numbers for the following actions:\n    * Privilege escalation from EL1 to EL2 using the\nHVC instruction. * Privilege de-escalation from EL2 to EL1 using the\nERET instruction. * The cost of a null invocation of the EL2 kernel using\nHVC . * The cost of an\nseL4_Call() from an EL1 guest thread to a native seL4\nthread. * The cost of an\nseL4_Reply() from an seL4 native thread to an EL1\nguest thread."
          ]
        },
        {
          "title": "How to achieve high performance pingora? ¬∑ Issue #227",
          "url": "https://github.com/cloudflare/pingora/issues/227",
          "excerpts": [
            "May 2, 2024 ‚Äî When I pressure tested pingora with wrk, I found that qps was low, general-purpose machines, and nginx was normal."
          ]
        },
        {
          "title": "Questions about sel4bench IPC statistic in the website - Devel",
          "url": "https://sel4.com/hyperkitty/list/devel@sel4.systems/thread/YTI36J642F55NIBODJUOYSP3BJ7ZQO6W/",
          "excerpts": [
            "The numbers on the benchmark are one fastpath, one slowpath (the details show that the length of the IPC is 10, and any messages > 4 go to the slowpath as they¬†..."
          ]
        },
        {
          "title": "Sel4bench is not working for me on x86_64 - seL4 kernel",
          "url": "https://sel4.discourse.group/t/sel4bench-is-not-working-for-me-on-x86-64/204",
          "excerpts": [
            "Aug 27, 2020 ‚Äî Hi. I'm trying to run the sel4bench. I followed the instructions over at https://github.com/seL4/sel4bench-manifest ."
          ]
        },
        {
          "title": "Benchmarks of seL4 - Devel - lists.sel4.systems",
          "url": "https://lists.sel4.systems/hyperkitty/list/devel@sel4.systems/thread/ZURD5DJBKAUPP7KDP4C2R7CRWEBR3O76/",
          "excerpts": [
            "I can't say for sure about overall performance, but I'm almost certain UX/RT will have much better IPC performance than Linux due to the lightweight IPC model."
          ]
        },
        {
          "title": "Measuring latency with HdrHistogram - Lee Campbell",
          "url": "https://leecampbell.com/2016/03/18/measuing-latency-with-hdrhistogram/",
          "excerpts": [
            "Mar 18, 2016 ‚Äî As the HdrHistogram is designed to measure latency a common usage would be to measure a range from the minimum supported value for the platform¬†..."
          ]
        },
        {
          "title": "MLPerf‚Ñ¢ Training Rules",
          "url": "https://github.com/mlcommons/training_policies/blob/master/training_rules.adoc",
          "excerpts": [
            "Any any general non-data-aware partitioning algorithm that is reproducible, either using a fixed seed or a deterministic algorithm. We require that each¬†...",
            "An MLPerf submission score is intended to represent the median expected result across a large number of runs.",
            "Benchmarking should be conducted to measure the framework and system performance as fairly as possible. Ethics and reputation matter.",
            "The framework and system should not detect and behave differently for benchmarks.",
            "Results that appear to be too far away from a median result may be rejected. As a more computationally efficient method of validating that a submission is close to the median result, it is also allowed to run M>N independent runs as a group and to designate N consecutive runs from the group as the runs to be used for scoring, provided that the submitter chooses the N consecutive runs that are closest to the median result."
          ]
        },
        {
          "title": "Hardware Support for Time Protection",
          "url": "https://sel4.org/Summit/2024/slides/hardware-support.pdf",
          "excerpts": [
            "Oct 18, 2024 ‚Äî Splash-2 Benchmark Overhead (%) write-back L1 write-through L1 ... Proven empirically on seL4, using formal verification, and in silicon!"
          ]
        },
        {
          "title": "Performance Issues with Envoy #5536 - GitHub",
          "url": "https://github.com/envoyproxy/envoy/issues/5536",
          "excerpts": [
            "I ran an experiment on a low-latency tuned system for comparing average latencies accross wrk2 Fortio and Nighthawk , when running directly them against nginx ..."
          ]
        },
        {
          "title": "Percentiles aggregation | Reference",
          "url": "https://www.elastic.co/docs/reference/aggregations/search-aggregations-metrics-percentile-aggregation",
          "excerpts": [
            "HDR Histogram (High Dynamic Range Histogram) is an alternative implementation that can be useful when calculating percentiles for latency measurements as it can¬†..."
          ]
        },
        {
          "title": "Pingora Benchmarking and Performance Claims (Cloudflare)",
          "url": "https://blog.cloudflare.com/pingora-saving-compute-1-percent-at-a-time/",
          "excerpts": [
            "Pingora handles 35M+ requests per second"
          ]
        },
        {
          "title": "sel4bench Documentation",
          "url": "https://docs.sel4.systems/projects/sel4bench/",
          "excerpts": [
            "sel4bench is an application and support library for benchmarking the performance of the seL4 kernel.",
            "A selection of benchmarking results are continually updated",
            "| Components | Description |",
            "| --- | --- |",
            "The page also\nshows the build options used to obtain those results.",
            "| Scheduler | Benchmark for scheduling decisions, using a producer/consumer pattern between two notification objects. Also measures `seL4_Yield()`.",
            "| SMP | Intra-core IPC round-trip benchmark to measure overhead of kernel synchronization on IPC throughput. |\n| Synchronisation lib",
            "Aarch64 VCPU",
            "seL4 VCPU performance, including privilege escalation from EL1 to EL2 with `HVC`, privilege de-escalation from EL2 to EL1 with `ERET`, null invocation of the EL2 kernel using `HVC`, cost of `seL4_Call()` from an EL1 guest thread to a native seL4 thread, and cost of an `seL4_Reply()` from an seL4 native thread to an EL1 guest thread."
          ]
        },
        {
          "title": "wrk2: Benchmarking guidance for workloads, baselines, metrics, and reproducibility",
          "url": "https://github.com/giltene/wrk2",
          "excerpts": [
            "The model I chose for avoiding Coordinated Omission in wrk2 combines\nthe use of constant throughput load generation with latency\nmeasurement that takes the intended constant throughput into account."
          ]
        },
        {
          "title": "How Not to Measure Latency (HowNotToMeasureLatency_LLSummit_NYC_12Nov2013.pdf)",
          "url": "https://news.ycombinator.com/item?id=10485804",
          "excerpts": [
            "Such a tool might report a \"99 percentile latency\" by simply taking the second-worst time-to-response from 100 samples. However, this statistic is misleading.",
            "/wrk2> tries to avoid this \"coordinated omission\" problem by sending requests at a constant rate, instead of constant-time-after-response."
          ]
        },
        {
          "title": "Coordinated Omission - Google Groups",
          "url": "https://groups.google.com/g/mechanical-sympathy/c/icNZJejUHfE/m/BfDekfBEs_sJ",
          "excerpts": [
            "HdrHistogram has a recording mode that automatically corrects for coordinated omission if you know what your expected interval between measurements is (and ..."
          ]
        },
        {
          "title": "Percentiles: Interpretations and Calculations",
          "url": "https://statisticsbyjim.com/basics/percentiles/",
          "excerpts": [
            "Percentiles tell you how a value compares to other values. The general rule is that if value X is at the kth percentile, then X is greater than K% of the values¬†...See more"
          ]
        },
        {
          "title": "Guidelines for Reporting Statistics",
          "url": "https://support.jmir.org/hc/en-us/articles/360019690851-Guidelines-for-Reporting-Statistics",
          "excerpts": [
            "Mar 28, 2025 ‚Äî We prefer indicating the 25th and 75th percentiles as a hyphenated range, not as comma-separated values. IQR does not need to be expanded.See more"
          ]
        },
        {
          "title": "On Coordinated Omission - ScyllaDB",
          "url": "https://www.scylladb.com/2021/04/22/on-coordinated-omission/",
          "excerpts": [
            "Coordinated omission is a term coined by Gil Tene to describe the phenomenon when the measuring system inadvertently coordinates with the system being measured."
          ]
        },
        {
          "title": "Does Artillery prevent coordinated omission? #1472",
          "url": "https://github.com/artilleryio/artillery/discussions/1472",
          "excerpts": [
            "Coordinated omission is a term coined by Gil Tene to describe the phenomenon when the measuring system inadvertently coordinates with the system being measured."
          ]
        },
        {
          "title": "Difference between open-ended and close-ended load ...",
          "url": "https://stackoverflow.com/questions/37146261/difference-between-open-ended-and-close-ended-load-testing-tools",
          "excerpts": [
            "In open loops, the request rate is constant, regardless of the response times - there is no feedback. Both models reveal different performance¬†..."
          ]
        },
        {
          "title": "Closed vs Open Workload Models in Load Testing",
          "url": "https://www.locust.cloud/blog/closed-vs-open-workload-models",
          "excerpts": [
            "Aug 28, 2024 ‚Äî Open and closed workload models are two different ways to define the load on your system. In an open workload, requests are sent at a certain rate."
          ]
        },
        {
          "title": "SPECjAppServer2001 Run and Reporting Rules",
          "url": "https://www.spec.org/jappserver2001/docs/RunRules",
          "excerpts": [
            "This document specifies how the SPECjAppServer2001 benchmark is to be run for measuring and publicly reporting performance results. These rules abide by the¬†..."
          ]
        },
        {
          "title": "Benchmark and Performance",
          "url": "https://tikv.org/docs/6.1/deploy/performance/performance/",
          "excerpts": [
            "This section introduces an overview of TiKV performance and the instructions to do a benchmark. Performance Overview ¬∑ Benchmark Instructions¬†..."
          ]
        },
        {
          "title": "Building, Running, and Benchmarking TiKV and TiDB - Medium",
          "url": "https://pingcap.medium.com/building-running-and-benchmarking-tikv-and-tidb-736bd685bb2b",
          "excerpts": [
            "There are numerous ways to benchmark TiDB or TiKV, the most common are YCSB and Sysbench. ... Official website: https://tidb.io/ GitHub¬†..."
          ]
        },
        {
          "title": "Concepts - TiKV",
          "url": "https://tikv.org/docs/3.0/concepts/overview/",
          "excerpts": [
            "In RawKV and TxnKV modes, you can customize the balance between consistency and performance. You can browse a complete list on the features page ..."
          ]
        },
        {
          "title": "OLAP vs. OLTP: Comparing Data Processing Systems",
          "url": "https://blog.purestorage.com/purely-educational/olap-vs-oltp-comparing-data-processing-systems/",
          "excerpts": [
            "OLTP vs. OLAP: These are types of database systems, an OLTP emphasizes recording while an OLAP is focused on summarizing and analyzing data."
          ]
        },
        {
          "title": "OLTP vs. OLAP: Differences and Applications",
          "url": "https://www.snowflake.com/en/fundamentals/olap-vs-oltp-the-differences/",
          "excerpts": [
            "While OLAP is used for complex data analysis, OLTP is used for real-time processing of online transactions at scale."
          ]
        },
        {
          "title": "TiKV Performance Benchmarking with YCSB",
          "url": "https://tikv.org/docs/6.1/deploy/performance/instructions/",
          "excerpts": [
            "This document provides a step-by-step tutorial on performing a benchmark test using the industry-standard benchmark tool YCSB on TiKV.",
            "TiKV delivers predictable throughput and latency at all scales on commodity hardware.",
            "Step 1. Set up the environment",
            "1. Prepare 1 node for the YCSB benchmark worker, 1 node for Placement Driver (PD), and 3 nodes for TiKV.",
            "The following table shows the recommended hardware configuration:",
            "| **Component** | **CPU** | **Memory** | **Storage** | **Network** | **Instance** |",
            "| --- | --- | --- | --- | --- | --- |",
            "| YSCB worker | 8 cores or above | 8 GB or above | No requirement | Gigabit LAN | 1 |"
          ]
        },
        {
          "title": "capDL Loader",
          "url": "https://docs.sel4.systems/projects/capdl/c-loader-app.html",
          "excerpts": [
            "loader is a C program that is intended to run as the initial root task in a system. It creates seL4 kernel objects and capabilities according to a ... root task\nin a system. It creates seL4 kernel objects and",
            "The capDL loader is an implementation of an algorithm that is formally specified\nand proved correct (on the model level, but not the implementation level) in the\ntheorem prover Isabelle/HOL. The correctness statement is that the loader will bring the system into a state\nthat contains only the capabilities and objects in the capDL specification in\naddition to capabilities that remain inert in the loader‚Äôs capability space\nafter it has terminated.",
            "The input capDL specification must satisfy certain\nwellformedness criteria for this theorem to hold. They are documented in the\nformal definition in the [verification repository](https://github.com/seL4/l4v/blob/master/sys-init/WellFormed_SI.thy) .",
            "The formal model for the capDL initialiser is documented in a research publication\nby [Boyton et al (2013)](https://trustworthy.systems/publications/nicta_full_text/7047.pdf \"Formally Verified System Initialisation\") , as well as in [Boyton‚Äôs PhD thesis (2014)](https://trustworthy.systems/publications/nicta_full_text/9141.pdf \"Secure architectures on a verified microkernel\") . The Isabelle formalisation is part of the seL4 proofs that are continually\nupdated and maintained in the [l4v repository](https://github.com/seL4/l4v/tree/master/sys-init) .",
            "is comparatively small. It consists entirely\nof the following three source files:\n\n* [`src/main.c`](https://github.com/seL4/capdl/blob/master/capdl-loader-app//src/main.c) : The implementation of the initialiser. * [`include/capdl.h`](https://github.com/seL4/capdl/blob/master/capdl-loader-app//include/capdl.h) : C type definitions for capDL specifications. * [`include/capdl_spec.h`](https://github.com/seL4/capdl/blob/master/capdl-loader-app//include/capdl_spec.h) : Interface link point for the input capDL spec. The capDL loader expects to be linked against an object file that contains the\ninput capDL specification for the symbol `extern CDL_Model capdl_spec` . Typically, this would be a C file that is generated by the [capDL translator\ntool](index.html) from a textual or XML capDL specification. The C loader contains more features than the formal model allows in wellformed\nspecifications. The formal verification does not hold for these features, but\nthey remain usable. For instance, they can be used for debugging and prototyping\nor for systems that do not require formal verification. The capDL loader is used in CAmkES applications as the system initialisation\ntask, and is invoked as part of the CAmkES build in all of the CAmkES examples. Expecting to be linked against the specification can be limiting for some build\nsystem setups,"
          ]
        },
        {
          "title": "Portable and Configurable Implementation of ARINC-653 ...",
          "url": "https://ieeexplore.ieee.org/iel7/6287639/8600701/08853231.pdf",
          "excerpts": [
            "by HC Jo ¬∑ 2019 ¬∑ Cited by 10 ‚Äî The ARINC-653 standard defines the APEX interfaces between the OS of an avionics computer and the application software [3]. The interfaces allow¬†..."
          ]
        },
        {
          "title": "WIT Reference",
          "url": "https://component-model.bytecodealliance.org/design/wit.html",
          "excerpts": [
            "A WIT file contains one or more interfaces or worlds. An interface or world can define types and/or functions. Types and functions can't be defined outside of¬†..."
          ]
        },
        {
          "title": "Capabilities - Fuchsia",
          "url": "https://fuchsia.dev/fuchsia-src/concepts/components/v2/capabilities",
          "excerpts": [
            "A capability combines access to a resource and a set of rights, providing a access control and a means for interacting with the resource."
          ]
        },
        {
          "title": "The Prusti Project: Formal Verification for Rust",
          "url": "https://pm.inf.ethz.ch/publications/AstrauskasBilyFialaGrannanMathejaMuellerPoliSummers22.pdf",
          "excerpts": [
            "by V Astrauskas ¬∑ Cited by 82 ‚Äî A key feature of Prusti is that it supports incremental verification with an initial annotation effort of (almost) zero: developers get guarantees beyond those.",
            "The Prusti project is a general-purpose deductive verifier for Rust, designed to verify rich correctness properties of Rust programs."
          ]
        },
        {
          "title": "viperproject/prusti-dev: A static verifier for Rust, based on ...",
          "url": "https://github.com/viperproject/prusti-dev",
          "excerpts": [
            "Prusti is a prototype verifier for Rust that makes it possible to formally prove absence of bugs and correctness of code contracts."
          ]
        },
        {
          "title": "Creusot helps you prove your code is correct in an ...",
          "url": "https://github.com/creusot-rs/creusot",
          "excerpts": [
            "Creusot is a deductive verifier for Rust code. It verifies your code is safe from panics, overflows, and assertion failures."
          ]
        },
        {
          "title": "Getting started - The Kani Rust Verifier",
          "url": "https://model-checking.github.io/kani/",
          "excerpts": [
            "Kani is an open-source verification tool that uses model checking to analyze Rust programs. Kani is useful for checking both safety and correctness of Rust code ..."
          ]
        },
        {
          "title": "I wrote my Master's thesis about Rust verification, exploring ...",
          "url": "https://www.reddit.com/r/rust/comments/1ainrpg/i_wrote_my_masters_thesis_about_rust_verification/",
          "excerpts": [
            "You can prove that a particular implementation correctly implements the trait. And/Or proof that code generic over that trait gets the correct¬†..."
          ]
        },
        {
          "title": "Response Time Analysis for Fixed Priority Servers",
          "url": "https://dl.acm.org/doi/10.1145/3273905.3273927",
          "excerpts": [
            "Scheduling Within Temporal Partitions: Response-time Analysis and Server Design. ... Analysis on quantum-based fixed priority scheduling of real-time tasks."
          ]
        },
        {
          "title": "Missing: verification patterns Zero-Cost Capabilities: Retrofitting Effect Safety in Rust",
          "url": "https://web.cs.ucdavis.edu/~cdstanford/doc/2024/POPLSRC24.pdf",
          "excerpts": [
            "\n\nCoenobita leverages Rust‚Äôs powerful type and trait systems to enforce capability safety. Its core data\nstructure is Capability<A, B, C>, which wraps PathBuf and associates it with three generic type",
            "pub fn read<P1: traits::Read, P2, P3>(\ncap: &Capability<P1, P2, P3>\n) -> io::Result<Vec<u8>> {\nfs::read(cap.get_path())\n}",
            "We wish to investigate whether it‚Äôs possible to prevent\n\nthem by _retroactively_ enforcing side effect safety. Our goal is to accomplish this using _capabilities_ ,\n\nunforgeable tokens that represent resources and the actions their holders can tak",
            "Aside from the E language, capabilities as a tool for enforcing safety in language design have\nalso been used in Shill, a modified version of Racket that adapts capabilities and introduces the\nconcept of contracts [12]. The Safe Haskell language extension is broader in focus but has significant\nconceptual overlap and could easily implement capabilities [15]."
          ]
        },
        {
          "title": "docs/content_collections/_releases/capdl/0.2.0.md at master - GitHub",
          "url": "https://github.com/seL4/docs/blob/master/content_collections/_releases/capdl/0.2.0.md",
          "excerpts": [
            "Capdl-loader-app. Improve log output. Initialise libc in debug builds. Add check to only flush and invalidate kernel memory regions in capdl loader on Arm."
          ]
        },
        {
          "title": "seL4 Microkernel: Architecture",
          "url": "https://medium.com/@tunacici7/sel4-microkernel-architecture-130efb8d34d7",
          "excerpts": [
            "seL4 is a fast, secure and formally verified microkernel with fine-grained access control and support for virtual machines."
          ]
        },
        {
          "title": "QNX OS for Safety 8.0",
          "url": "https://blackberry.qnx.com/en/products/safety-certified/qnx-os-for-safety",
          "excerpts": [
            "Independently certified by T√úV Rheinland, it meets the highest functional safety and cybersecurity standards, including ISO 26262 ASIL D, IEC 61508 SIL3, IEC¬†..."
          ]
        },
        {
          "title": "Adaptive Partitioning",
          "url": "https://www.qnx.com/developers/docs/6.5.0SP1.update/com.qnx.doc.neutrino_sys_arch/adaptive.html",
          "excerpts": [
            "In QNX Neutrino, adaptive partitioning takes a much more flexible view. Our partitions are adaptive because: you can change configurations at run time; they¬†..."
          ]
        },
        {
          "title": "eBPF XDP: The Basics and a Quick Tutorial",
          "url": "https://www.tigera.io/learn/guides/ebpf/ebpf-xdp/",
          "excerpts": [
            "Compared to the standard Linux networking data plane, Calico's eBPF data plane scales to higher throughput, uses less CPU per GBit, and has native support for¬†..."
          ]
        },
        {
          "title": "Recapitulating AF_XDP",
          "url": "https://medium.com/high-performance-network-programming/recapitulating-af-xdp-ef6c1ebead8",
          "excerpts": [
            "The official kernel documentation describes AF_XDP as ‚Äúan address family that is optimised for high performance packet processing‚Äù."
          ]
        },
        {
          "title": "Sharpening our Axes to Battle Low-Latency Misery",
          "url": "https://www.p99conf.io/2023/01/04/what-you-missed-at-p99-conf-sharpening-our-axes-to-battle-low-latency-misery/",
          "excerpts": [
            "Jan 4, 2023 ‚Äî Who wins in a head-to-head performance comparison between the Linux kernel's network stack and DPDK? What are the latest use cases for eBPF¬†..."
          ]
        },
        {
          "title": "Linux Kernel vs DPDK: HTTP Performance Showdown",
          "url": "https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/",
          "excerpts": [
            "Jul 4, 2022 ‚Äî In this post I will use a simple HTTP benchmark to do a head-to-head performance comparison between the Linux kernel's network stack, and a kernel-bypass stack¬†..."
          ]
        },
        {
          "title": "Measuring the Interrupt Latency - QNX6 - OS",
          "url": "https://forums.openqnx.com/t/topic/5497",
          "excerpts": [
            "Jun 2, 2008 ‚Äî The real latencys are between 5 to 8 microseconds when system is idle. When doing a ‚Äústress --cpu 2‚Äù, having two workers on the cpu doint sqrt()¬†..."
          ]
        },
        {
          "title": "AF_XDP ‚Äî The Linux Kernel documentation",
          "url": "https://www.kernel.org/doc/html/v6.4/networking/af_xdp.html",
          "excerpts": [
            "AF_XDP is an address family that is optimized for high performance packet processing. This document assumes that the reader is familiar with BPF and XDP."
          ]
        },
        {
          "title": "Rewiring the 5G Data Plane: XDP/eBPF in the Fast Lane of ...",
          "url": "https://medium.com/@satyam012005/rewiring-the-5g-data-plane-xdp-ebpf-in-the-fast-lane-of-upf-5661f30ed18f",
          "excerpts": [
            "But with increasing throughput, low-latency expectations, and the explosion of IoT devices, traditional kernel networking struggles to keep up."
          ]
        },
        {
          "title": "INTEGRITY-178 tuMP RTOS: Security-Critical",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_security.html",
          "excerpts": [
            "The INTEGRITY-178 tuMP RTOS is a MILS operating system implemented as a separation kernel that fully isolates multiple partitions and controls the information¬†..."
          ]
        },
        {
          "title": "INTEGRITY-178 tuMP RTOS: Layered Product Extensions",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_extensions.html",
          "excerpts": [
            "The PJFS-178 product is a high-assurance, reliable file system designed for DO-178B Level A certification that supports both file and directory services."
          ]
        },
        {
          "title": "Safety Certification Kits",
          "url": "https://www.sysgo.com/fileadmin/user_upload/data/certification_kits/SYSGO_Safety_Certification_Kit.pdf",
          "excerpts": [
            "PikeOS has been developed using software development, verification & validation processes and procedures beside quality management and Safety & Security-related."
          ]
        },
        {
          "title": "LynxSecure",
          "url": "https://www.unmannedsystemstechnology.com/wp-content/uploads/2014/09/LynxSecure-Separation-Kernel-Hypervisor.pdf",
          "excerpts": [
            "The LynxSecure separation kernel is a robust virtual machine monitor that is certifiable to (a) Common Criteria EAL-7 security certifi cation (Evaluated¬†...See more"
          ]
        },
        {
          "title": "LynxOS-178: Based on Open Standards",
          "url": "https://www.lynx.com/products/lynxos-178-do-178c-certified-posix-rtos",
          "excerpts": [
            "This operating system has been certified multiple times to DO-178 DAL A. LynxOS-178 has been deployed in certified commercial and military avionics systems that¬†..."
          ]
        },
        {
          "title": "LynxOS-178C POSIX Real Time Operating System",
          "url": "https://www.lynx.com/products/lynxos-178-do-178c-certified-native-posix-partitioned-rtos-more-info",
          "excerpts": [
            "The production configuration of LynxOS-178 has a feature set that has complete DO-178B/C artifacts and traceability for level A certification of the LynxOS-178¬†..."
          ]
        },
        {
          "title": "LynxOS-178 Datasheet | PDF | Systems Engineering",
          "url": "https://www.scribd.com/document/701637317/LynxOS-178-Datasheet",
          "excerpts": [
            "LynxOS-178 is a commercial off-the-shelf real-time operating system certified to DO-178B/C level A for use in safety-critical avionics applications."
          ]
        },
        {
          "title": "LynxSecure¬Æ Separation Kernel Hypervisor",
          "url": "https://www.lynx.com/products/lynxsecure-separation-kernel-hypervisor",
          "excerpts": [
            "LynxSecure is a simple and elegant platform technology that controls hardware resources according to an intuitive information flow modeling language.See more"
          ]
        },
        {
          "title": "Industry Standards | MOSA DO-178C FAA FACE EASA ...",
          "url": "https://www.ddci.com/resources/industry-standards/",
          "excerpts": [
            "Nov 15, 2024 ‚Äî ARINC 653 is an Avionics Application Standard Software Interface specification for space and time partitioning in safety-critical avionics that¬†..."
          ]
        },
        {
          "title": "Green Hills Software INTEGRITY-178B Separation Kernel ...",
          "url": "https://www.commoncriteriaportal.org/files/epfiles/st_vid10362-st.pdf",
          "excerpts": [
            "May 31, 2010 ‚Äî The TOE manages access to memory, devices, communications and processor resources to ensure that partitions can be entirely separated and can¬†..."
          ]
        },
        {
          "title": "Zephyr Testing",
          "url": "https://zephyrproject.org/zephyr-testing/",
          "excerpts": [
            "Intel is working with TuV to get FuSa kernel parts of Zephyr certified. This presentation shows how we develop the test cases for FuSa ..."
          ]
        },
        {
          "title": "Preface - Real-Time Interrupt-driven Concurrency",
          "url": "https://rtic.rs/",
          "excerpts": [
            "RTIC is a hardware accelerated RTOS that utilizes the hardware such as the NVIC on Cortex-M MCUs, CLIC on RISC-V etc. to perform scheduling."
          ]
        },
        {
          "title": "LYNX MOSA.ic‚Ñ¢ for Mission Critical Systems",
          "url": "https://www.lynx.com/resources/lynx-mosaic-for-mission-critical-systems",
          "excerpts": [
            "LYNX MOSA.ic provides open flexibility on a robust foundation to meet rich system functionality needs for systems deployed in safety-critical environments."
          ]
        },
        {
          "title": "integrity rtos",
          "url": "https://www.cs.unc.edu/~anderson/teach/comp790/papers/INTEGRITY_RTOS.pdf",
          "excerpts": [
            "Built on the INTEGRITY separation kernel, Green Hills Platforms provide complete, pre-integrated solutions customized to application-specific requirements¬†..."
          ]
        },
        {
          "title": "Lynx Software Technologies - Resources - FAQ",
          "url": "https://www.lynx.com/resources-faq",
          "excerpts": [
            "Yes. LynxOS-178 has native IMA support via the ARINC 653 standard, and LynxSecure supports partitioned architectures that can also be used to build IMA systems."
          ]
        },
        {
          "title": "First Functional Safety Certification Submission for an Open Source ...",
          "url": "https://www.zephyrproject.org/zephyr-project-rtos-first-functional-safety-certification-submission-for-an-open-source-real-time-operating-system/",
          "excerpts": [
            "WHAT IS ZEPHYR DOING? Zephyr certification scope is for the core OS, encompassing the kernel and OS services, across select architectures."
          ]
        },
        {
          "title": "Concurrency - The Embedded Rust Book",
          "url": "https://docs.rust-embedded.org/book/concurrency/",
          "excerpts": [
            "RTIC. One alternative is the RTIC framework, short for Real Time Interrupt-driven Concurrency. It enforces static priorities and tracks accesses to static¬†..."
          ]
        },
        {
          "title": "Zephyr_RTOS toward for function safety (IEC 61508, ISO ...",
          "url": "https://www.reddit.com/r/Zephyr_RTOS/comments/1e7mzns/zephyr_rtos_toward_for_function_safety_iec_61508/",
          "excerpts": [
            "We are trying to get more information to get our zephyr software achieve ISO-26262 certificate. Would you let me know what's the useful resource?"
          ]
        },
        {
          "title": "Why Zephyr RTOS with IAR is a smart choice for ...",
          "url": "https://www.iar.com/blog/why-zephyr-rtos-with-iar-is-a-smart-choice-for-embedded-teams",
          "excerpts": [
            "Jun 25, 2025 ‚Äî ... certified compilers and runtime analysis tools that help teams align with key safety standards: ISO 26262 for automotive; IEC 61508 for¬†..."
          ]
        },
        {
          "title": "Micro-ROS Zephyr and Eclipse ThreadX which is the right ...",
          "url": "https://discourse.ros.org/t/micro-ros-zephyr-and-eclipse-threadx-which-is-the-right-choice/39894",
          "excerpts": [
            "Oct 3, 2024 ‚Äî The motivation behind implementing Micro-ROS on Zephyr was that Zephyr was going to attempt to be the first open-source RTOS that had safety certification."
          ]
        },
        {
          "title": "INTEGRITY RTOS - Green Hills Software",
          "url": "https://www.ghs.com/products/rtos/integrity.html",
          "excerpts": [
            "The flagship of our family of operating systems, the INTEGRITY real-time operating system (RTOS), is built around a microkernel architecture that provides embedded systems the only software foundation with total reliability, absolute security, and certified safety.",
            "INTEGRITY-178 RTOS has been certified to EAL 6+ High Robustness, the most rigorous Common Criteria security evaluation achieved for a commercial operating system.",
            "To achieve this, INTEGRITY uses hardware memory protection to create secure partitions that isolate and protect embedded applications.",
            "INTEGRITY Multivisor is an optional virtualization service of INTEGRITY that runs guest OSes while delivering the highest levels of safety, security, and performance.",
            "To help developers jump-start product development, Green Hills Software offers an extensive array of middleware and abstraction layers that are integrated and validated for INTEGRITY, including:",
            "**Abstraction layers for runtime environments**",
            "Linux, Android",
            "POSIX",
            "AUTOSAR Adaptive, AUTOSAR Classic",
            "Java",
            "ROS 2",
            "**Middleware**",
            "Communication & connectivity",
            "Secure networking & data storage",
            "Embedded firewall",
            "File systems",
            "OTA software updates",
            "Data Distribution Service (DDS)",
            "Web services",
            "Databases",
            "Scheduling by partitions",
            "ety_critical/integrity_178_tump.html) provides the system integrator full flexibility in choosing the software multiprocessing architecture, ranging from simple asymmetric multiprocessing (AMP) to modern symmetric multiprocessing (SMP) to bound multiprocessing (BMP) for the highest combination of determinism and utilization.",
            "INTEGRITY-178 tuMP is the only RTOS that provides SMP and BMP capabilities as part of ARINC 653 support at DAL A."
          ]
        },
        {
          "title": "INTEGRITY-178 Certifications and Safety-Critical Features",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_certifications.html",
          "excerpts": [
            "The INTEGRITY-178 tuMP RTOS has been certified to DO-178/ED-12, ARINC 653, CAST-32A, FACE 3.0, POSIX, and SKPP Common Criteria EAL6+.",
            "INTEGRITY-178 tuMP is the first and only RTOS to be part of a successful certification to Raise the Bar standards.",
            "The ability of the RTOS to meet this evolving set of standards is directly rooted in the INTEGRITY-178 pedigree of achieving the NSA-defined Separation Kernel Protection Profile (SKPP) for ‚ÄúHigh Robustness‚Äù and Common Criteria EAL6+."
          ]
        },
        {
          "title": "SYSGO PikeOS FAQ",
          "url": "https://www.sysgo.com/faq",
          "excerpts": [
            "PikeOS is a real-time operating system (RTOS) and hypervisor that supports multiple applications with different Safety and Security levels on a single hardware platform.",
            "PikeOS is certified according to various Safety standards like DO-178C (Avionics), ECSS-E-ST-40C (Space), EN 50128 (Railway), ISO 26262 (Automotive), or IEC 61508 (programmable electronic devices), making it suitable for Safety-critical systems.",
            "The PikeOS 5.1.3 separation kernel is therefore certified according to Common Criteria EAL5+.",
            "PikeOS RTOS / PikeOS Hypervisor - What's the Difference? PikeOS RTOS (real-time operating system) is designed for embedded systems, providing real-time capabilities for applications. PikeOS Hypervisor extends this functionality by adding virtualization features, allowing multiple operating systems to run concurrently on the same hardware. The RTOS ensures real-time responsiveness for critical tasks, while the hypervisor enables isolation and management of multiple guest operating systems on a single platform (e.g. for Automotive applications)."
          ]
        },
        {
          "title": "LYNX MOSA.ic for UAVs & Satellites",
          "url": "https://www.lynx.com/products/lynx-mosaic-for-unmanned-aerial-systems-and-satellites",
          "excerpts": [
            "Lynx tools support LynxOS-178 RTOS, Linux, LSA, and LynxSecure across fundamental tasks including application development, debug, trace and visualization.",
            "LynxOS-178 native POSIX implementation satisfies the PSE 53/54 profiles for both dedicated and multi-purpose real-time as well as FACE applications.",
            "center/what-is-a-separation-kernel) which provides isolated environments in which multiple safety critical and general purpose operating systems can perform simultaneously without compromising safety, security, reliability or data integrity.",
            "A LYNX MOSA.IC PRODUCT",
            "LYNX MOSA.ic for UAVs & Satellites includes RTOSes, Linux (Buildroot), and bare metal applications such as Lynx Simple Applications (LSAs)."
          ]
        },
        {
          "title": "Zephyr Safety Overview",
          "url": "https://docs.zephyrproject.org/latest/safety/safety_overview.html",
          "excerpts": [
            "This document is the safety documentation providing an overview over the safety-relevant activities\nand what the Zephyr Project and the Zephyr Safety Working Group / Committee try to achieve. This overview is provided for people who are interested in the functional safety development part\nof the Zephyr RTOS and project members who want to contribute to the safety aspects of the\nproject.",
            "The general scope of the Safety Committee is to achieve a certification for the IEC 61508 standard and the Safety Integrity Level (SIL) 3 /\nSystematic Capability (SC) 3 for a limited source scope (see certification scope TBD).",
            "Zephyr Safety Overview",
            "Zephyr Safety Overview"
          ]
        },
        {
          "title": "FAQ - Redox - Your Next(Gen) OS",
          "url": "https://www.redox-os.org/faq/",
          "excerpts": [
            "Redox is a microkernel-based, complete, fully-functioning and general-purpose operating system created in 2015, with a focus on safety, freedom, reliability,¬†..."
          ]
        },
        {
          "title": "Redox OS Unlocks Faster VM Performance, \"Slightly ... - Phoronix",
          "url": "https://www.phoronix.com/news/Redox-OS-Faster-VMs",
          "excerpts": [
            "The Rust-written Redox OS open-source operating system has managed to address a performance bottleneck allowing this platform to perform much faster now."
          ]
        },
        {
          "title": "Why a New OS? - The Redox Operating System",
          "url": "https://doc.redox-os.org/book/why-a-new-os.html",
          "excerpts": [
            "The Microkernel Architecture moves as much components as possible out of the operating system kernel. Drivers, subsystems and other operating system ..."
          ]
        },
        {
          "title": "89. L3 Forwarding Tests ‚Äî DPDK Test Plans documentation",
          "url": "https://doc.dpdk.org/dts/test_plans/l3fwd_test_plan.html",
          "excerpts": [
            "The Layer-3 Forwarding results are produced using l3fwd application. 89.1. Prerequisites Hardware requirements: Board is populated with 4x 1GbE or 10GbE ports."
          ]
        },
        {
          "title": "213. VF L3 Forwarding Performance Tests - Documentation - DPDK",
          "url": "https://doc.dpdk.org/dts/test_plans/vf_l3fwd_test_plan.html",
          "excerpts": [
            "This document provides benchmark test for NIC VFs which are created from kernel PFs or DPDK PFs. These tests use l3fwd as a simple forwarder between NIC vfs."
          ]
        },
        {
          "title": "[PDF] Revisiting the Open vSwitch Dataplane Ten Years Later - Events",
          "url": "https://conferences.sigcomm.org/sigcomm/2021/files/papers/3452296.3472914.pdf",
          "excerpts": [
            "As the XDP program complexity increases, performance decreases. The basic. L2/L3 parsing in task B drops the rate to 8.1 Mpps as the CPU now must read the ..."
          ]
        },
        {
          "title": "Achieving high-performance, low-latency networking with XDP: Part I",
          "url": "https://developers.redhat.com/blog/2018/12/06/achieving-high-performance-low-latency-networking-with-xdp-part-1",
          "excerpts": [
            "A modern driver with XDP support can easily handle more than 14 Mpps. Excited by this opportunity, but scared by the unknown? This article will ..."
          ]
        },
        {
          "title": "Performance Evaluation of AF_XDP and DPDK in Multi-Buffer ...",
          "url": "http://kth.diva-portal.org/smash/record.jsf?pid=diva2:1897043",
          "excerpts": [
            "Sep 11, 2024 ‚Äî Both frameworks support the creation of packets from multiple separate memory buffers. DPDK has supported it for a long time, while AF_XDP¬†..."
          ]
        },
        {
          "title": "Redox OS Official Page",
          "url": "https://www.redox-os.org/",
          "excerpts": [
            "Implemented in [Rust](https://www.rust-lang.org/)",
            "Partial [POSIX](https://en.wikipedia.org/wiki/POSIX) compatibility",
            "[MIT](https://en.wikipedia.org/wiki/MIT_License) Licensed",
            ".html)\n* Custom [C library](https://en.wikipedia.org/wiki/C_standard_library) written in Rust ( [relibc](https://gitlab.redox-os.org/redox-os/relibc/) )",
            "Redox running Orbital",
            "Supports [Rust Standard Library](https://doc.rust-lang.org/std/)"
          ]
        },
        {
          "title": "Redox OS and DPDPX discussion on YouTube (YVR18-509 and related content)",
          "url": "https://www.youtube.com/watch?v=G4VlHzyKZeE",
          "excerpts": [
            "Redox is a Unix-like Operating System written in Rust, aiming to bring the innovations of Rust to a modern microkernel and full set of applications."
          ]
        },
        {
          "title": "The Redox Operating System",
          "url": "https://doc.redox-os.org/book/",
          "excerpts": [
            "\nRedox OS is a general-purpose operating system written in [Rust]",
            "Our aim is to provide a fully functioning Unix-like microkernel-based operating system, that is secure, reliable and free.",
            "We have modest compatibility with [POSIX](https://en.wikipedia.org/wiki/POSIX), allowing Redox to run many programs without porting.",
            "Redox OS was created in 2015 before the first stable version (1.0) of the Rust compiler and was one of the first operating systems written in Rust.",
            "Minix and Plan 9 were the main inspirations for the system design in the beginning."
          ]
        },
        {
          "title": "Introduction - Unsafe Code Guidelines Reference",
          "url": "https://rust-lang.github.io/unsafe-code-guidelines/",
          "excerpts": [
            "This document is a past effort by the UCG WG to provide a \"guide\" for writing unsafe code that \"recommends\" what kinds of things unsafe code can and cannot do, ..."
          ]
        },
        {
          "title": "Safety-Critical Rust Consortium: Industry Standards",
          "url": "https://rustfoundation.org/safety-critical-rust-consortium/",
          "excerpts": [
            "The Rust Foundation partnered with 10 founding organizations and member companies in June 2024 to create the Safety-Critical Rust Consortium ‚Äî a group dedicated to supporting the responsible use of the Rust programming language in safety-critical software.",
            "Founding Members",
            "The Rust Foundation is pleased to partner with the following founding members of the Safety-Critical Rust Consortium...",
            "AdaCore",
            "Joined January, 2023 adacore.com",
            "arm",
            "Joined November, 2021 arm.com",
            "OxidOS Automotive",
            "Joined December, 2021 oxidos.io",
            "TrustInSoft",
            "trust-in-soft.com",
            "The Consortium‚Äôs scope will be fully delineated in the upcoming charter, but may include the development of guidelines, linters, libraries, static analysis tools, formal methods and language subsets to meet industrial and legal requirements.",
            "The Consortium‚Äôs scope will be fully delineated in the upcoming charter, but may include the development of guidelines, linters, libraries, static analysis tools, formal methods and language subsets to meet industrial and legal requirements.",
            "The Rust Foundation and its partners in the Safety-Critical Rust Consortium are committed to the responsible use of the Rust programming language in safety-critical software to avoid devastating harm to human life, property, and the environment we live in."
          ]
        },
        {
          "title": "Unsafe Rust - The Rust Programming Language",
          "url": "https://doc.rust-lang.org/book/ch20-01-unsafe-rust.html",
          "excerpts": [
            "To switch to unsafe Rust, use the unsafe keyword and then start a new block that holds the unsafe code. You can take five actions in unsafe Rust that you can't ..."
          ]
        },
        {
          "title": "Clippy Lints - GitHub Pages",
          "url": "https://rust-lang.github.io/rust-clippy/master/index.html",
          "excerpts": [
            "This lint only warns outer attributes ( #[allow] ), as inner attributes ( #![allow] ) are usually used to enable or disable lints on a global scale."
          ]
        },
        {
          "title": "GitHub - rust-lang/rust-clippy: A bunch of lints to catch ...",
          "url": "https://github.com/rust-lang/rust-clippy",
          "excerpts": [
            "You can add options to your code to allow / warn / deny Clippy lints: the whole set of Warn lints using the clippy lint group ( #![deny(clippy::all)] ).",
            "A collection of lints to catch common mistakes and improve your Rust code. There are over 750 lints included in this crate!"
          ]
        },
        {
          "title": "cargo-deny - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/cargo-deny/0.5.2",
          "excerpts": [
            "So cargo-deny allows you to ensure that all of your dependencies have license requirements that align with your configuration. Precedence."
          ]
        },
        {
          "title": "EmbarkStudios/cargo-deny-action - GitHub",
          "url": "https://github.com/EmbarkStudios/cargo-deny-action",
          "excerpts": [
            "This action will run cargo-deny check and report failure if any banned crates or disallowed open source licenses are found used in the crate or its dependencies ..."
          ]
        },
        {
          "title": "[PDF] Evaluation of Code Analysis Tools for Rust in Safety-Critical Appl",
          "url": "https://opus4.kobv.de/opus4-haw/files/3412/I001085559Thesis.pdf",
          "excerpts": [
            "In safety-critical projects, Cargo-deny is a must-have. In a short amount of time, it notifies developers about outdated crates, possible ..."
          ]
        },
        {
          "title": "[PDF] Bringing Rust to Safety-Critical Systems in Space",
          "url": "https://indico.esa.int/event/528/attachments/5988/10197/Bringing_Rust_to_Safety_Critical_Systems_in_Space.pdf",
          "excerpts": [
            "R01. Gradually incorporate Rust: Using a memory-safe\nlanguage such as Rust for (embedded) systems programming\ncan prevent multiple bug classes. While rewriting a whole code\nbase in a new language in most cases is an inappropriately\nlarge effort, writing new components in one should be the\ngo-to way. This approach is further facilitated by the mature\noptions to interface between Rust and C components. For\nespecially critical components, it should be evaluated whether\na partial Rust rewrite could be beneficial. Programming guide-\nlines such as High Assurance Rust, although incomplete as of\nwriting, and The Embedded Rust Book can further help in\ntransitioning a development team and project to Rus",
            "R02. Use qualified toolchains: A compiler qualified for\nsafety-critical domains facilitates the acceptance of Rust as a C\nreplacement in projects required to adhere to certain standards.\nQualification of standard libraries such as core will be even\nmore impactful, paving the way to fully qualified Rust pro-\ngrams. The commercial solutions we mentioned also provide\na more stable foundation in the context of relatively fast-\nchanging Rust versions and features and even offer support\npackag",
            "R03. Utilize the existing embedded Rust ecosystem:\nThe embedded Rust community is very active and produces\nhigh-quality components such as the embedded-hal and\nheapless crates. Using existing solutions where possible\naccelerates development by granting access to a diverse set\nof device drivers without the necessity to implement all low-\nlevel interfaces and protocols again. Furthermore, existing im-\nplementations can act as examples for Rust-idiomatic system\nprogrammi",
            "R04. Employ dedicated security testing: Security and\nsafety considerations go hand in hand. Security-focused testing\ncan uncover issues beyond the scope of traditional unit- and\nintegration testing. Dynamic approaches such as fuzzing and\nformal verification through symbolic execution can help to\nverify properties that static analysis and the Rust compiler\ncannot automatically assert."
          ]
        },
        {
          "title": "Time Travel Debugging in Rust - Travel Neil",
          "url": "https://www.travelneil.com/time-travel-debugging-in-rust.html",
          "excerpts": [
            "Feb 26, 2023 ‚Äî Also sometimes called \"reverse debugging\", it is, put really simply, the ability to step forward, or backward any number of times while debugging."
          ]
        },
        {
          "title": "Rust profiling : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/rxj81f/rust_profiling/",
          "excerpts": [
            "I personally use perf with flamegraph but the easiest way is probably to use CLion, it integrates both very nicely such that all the information ..."
          ]
        },
        {
          "title": "A native debugger extension for VSCode based on LLDB - GitHub",
          "url": "https://github.com/vadimcn/codelldb",
          "excerpts": [
            "The primary focus of this project are the C++ and Rust languages, for which CodeLLDB includes built-in visualizers for vectors, strings, maps, and other ..."
          ]
        },
        {
          "title": "Debugging Rust in VSCode with codelldb or llvm-dap or something",
          "url": "https://www.reddit.com/r/rust/comments/1huaki3/debugging_rust_in_vscode_with_codelldb_or_llvmdap/",
          "excerpts": [
            "I've been trying to use either codelldb or lllvm-dap to run compile and attach to the running application so I can set breakpoints and such within vscode."
          ]
        },
        {
          "title": "Debugging Rust with rust-lldb - DEV Community",
          "url": "https://dev.to/bmatcuk/debugging-rust-with-rust-lldb-j1f",
          "excerpts": [
            "This is a quick and dirty primer to debugging rust applications with rust-lldb. Start the Debugger Assuming you are using cargo to build your executable."
          ]
        },
        {
          "title": "Time travel debugging Rust in NeoVim - jonboh's blog",
          "url": "https://jonboh.dev/posts/rr/",
          "excerpts": [
            "Sep 10, 2023 ‚Äî rr opens a world of possibilities for debugging, on top of Rust already fantastic properties, it can help further decrease the amout of time you spend¬†..."
          ]
        },
        {
          "title": "Should I pin my Rust toolchain version? - Swatinem",
          "url": "https://swatinem.de/blog/rust-toolchain/",
          "excerpts": [
            "Feb 15, 2025 ‚Äî By pinning a specific toolchain, rustup will manage updating to a newer toolchain for you, without any friction. Even for teammates who haven't¬†..."
          ]
        },
        {
          "title": "What are binary crate MSRV policy best practices? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/zmv1j9/what_are_binary_crate_msrv_policy_best_practices/",
          "excerpts": [
            "The key thing with a binary is that if your MSRV is \"too new\" for a distro, then the distro can just package an older version of your binary that satisfies ..."
          ]
        },
        {
          "title": "Does anyone know the latest way to use Rust LLDB for debugging?",
          "url": "https://www.reddit.com/r/rust/comments/1fttfte/does_anyone_know_the_latest_way_to_use_rust_lldb/",
          "excerpts": [
            "Can someone please tell me about the best way for using LLDB to debug Rust? I already know about another approach, dbg!, but I really don't want to see a large ..."
          ]
        },
        {
          "title": "Codegen Options - The rustc book",
          "url": "https://doc.rust-lang.org/rustc/codegen-options/index.html",
          "excerpts": [
            "n , no , off or false : disable linker plugin LTO (the default). A path to the linker plugin. More specifically this flag will cause the compiler to replace its¬†...See more"
          ]
        },
        {
          "title": "Optimized build - Rust Compiler Development Guide",
          "url": "https://rustc-dev-guide.rust-lang.org/building/optimized-build.html",
          "excerpts": [
            "There are multiple additional build configuration options and techniques that can be used to compile a build of rustc that is as optimized as possible."
          ]
        },
        {
          "title": "Do you enable LTO and PGO flags on GCC? - Gentoo",
          "url": "https://www.reddit.com/r/Gentoo/comments/sa6jea/do_you_enable_lto_and_pgo_flags_on_gcc/",
          "excerpts": [
            "Ever since LTOing and PGOing my compiler, I've noticed emerge times get longer. Webkit-gtk went from 19 minutes to 28 minutes, rust from 21 minutes to 40¬†...See more"
          ]
        },
        {
          "title": "How I Improved My Rust Compile Times by 75% - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/17rw9qn/how_i_improved_my_rust_compile_times_by_75/",
          "excerpts": [
            "Optimization reduces code size, reduces disk IO, increases performance. Potentially. Also, optimized build scripts/ proc-macro crates can be huge."
          ]
        },
        {
          "title": "Pin cargo version to avoid breaking CI - rust",
          "url": "https://www.reddit.com/r/rust/comments/12t7cif/pin_cargo_version_to_avoid_breaking_ci/",
          "excerpts": [
            "If you want to run clippy in CI, pin your toolchain. Clippy explicitly does not guarantee anything about new lints cropping up on old code."
          ]
        },
        {
          "title": "Minimum Supported Rust Version (MSRV) Policies #231 - GitHub",
          "url": "https://github.com/rust-lang/api-guidelines/discussions/231",
          "excerpts": [
            "A MSRV aware resolver is a good tool to help you get older releases of a small percentage of your crate graph, and certainly users won't be as frustrated by ..."
          ]
        },
        {
          "title": "Rust MSRV policy and Linux Distros",
          "url": "https://internals.rust-lang.org/t/rust-msrv-policy-and-linux-distros/17074",
          "excerpts": [
            "Discussion about MSRV of the libc crate raises the question of what actually is Rust's policy for support of old Rust versions."
          ]
        },
        {
          "title": "Safety-Critical Rust Coding Guidelines",
          "url": "https://github.com/rustfoundation/safety-critical-rust-coding-guidelines",
          "excerpts": [
            "The Safety-Critical Rust Coding Guidelines use\nSphinx and\nSphinx-Needs to build a rendered version of the coding guidelines, and\nuv to install and manage Python dependencies (including Sphinx itself).",
            "To simplify building the rendered version, we created a script called\nmake.py that takes care of invoking Sphinx with the right flags.",
            "The rendered version will be available in\nbuild/html/ . A machine-parseable artifact will be available at\nbuild/html/needs.json .",
            "Coding Guidelines for Safety Critical Rust developed by the Safety Critical Rust Consortium."
          ]
        },
        {
          "title": "rust-lang/unsafe-code-guidelines - GitHub",
          "url": "https://github.com/rust-lang/unsafe-code-guidelines",
          "excerpts": [
            "UCG - Rust's Unsafe Code Guidelines. The purpose of this repository is to collect and discuss all sorts of questions that come up when writing unsafe code. It ..."
          ]
        },
        {
          "title": "EmbarkStudios/cargo-deny: Cargo plugin for linting your ... - GitHub",
          "url": "https://github.com/EmbarkStudios/cargo-deny",
          "excerpts": [
            "The bans check is used to deny (or allow) specific crates, as well as detect and handle multiple versions of the same crate. cargo deny check bans. bans output ..."
          ]
        },
        {
          "title": "Introducing FireDBG for Rust | FireDBG - Time Travel Visual ...",
          "url": "https://firedbg.sea-ql.org/blog/2023-12-12-introducing-firedbg/",
          "excerpts": [
            "Dec 12, 2023 ‚Äî Time travel debugging is the process of stepping back in time through source code to understand what is happening during execution of a computer program.",
            "FireDBG - a Time Travel Visual Debugger for Rust"
          ]
        },
        {
          "title": "Tooling - The Embedded Rust Book",
          "url": "https://doc.rust-lang.org/beta/embedded-book/intro/tooling.html",
          "excerpts": [
            "This document outlines essential software tools like Probe-rs and OpenOCD, which simplify and support the debugging process, alongside prominent debuggers."
          ]
        },
        {
          "title": "Build Configuration - The Rust Performance Book",
          "url": "https://nnethercote.github.io/perf-book/build-configuration.html",
          "excerpts": [
            "Use lto = \"thin\" in Cargo.toml to enable it. The third form of LTO is fat LTO, which is even more aggressive, and may improve performance and reduce binary¬†..."
          ]
        },
        {
          "title": "What's the deal with LTO? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/ijwya5/whats_the_deal_with_lto/",
          "excerpts": [
            "LTO allows optimisations across crates ¬∑ There are three settings: off , fat , thin (the default) ¬∑ fat takes much longer to compile than thin ,¬†..."
          ]
        },
        {
          "title": "We need configurably additive rustflags! - cargo - Rust Internals",
          "url": "https://internals.rust-lang.org/t/we-need-configurably-additive-rustflags/19851",
          "excerpts": [
            "You need to add all your global per-target rustflags in your crate-local/workspace-local config with cfg appended."
          ]
        },
        {
          "title": "cargo subcommand for optimizing binaries with PGO and ...",
          "url": "https://www.reddit.com/r/rust/comments/wff8ud/cargopgo_cargo_subcommand_for_optimizing_binaries/",
          "excerpts": [
            "It's a binary optimizer, it can optimize binaries using runtime profiles to make them faster. It is known to produce speedups up to 15 % even on¬†..."
          ]
        },
        {
          "title": "Announcing the Safety-Critical Rust Consortium",
          "url": "https://rustfoundation.org/media/announcing-the-safety-critical-rust-consortium/",
          "excerpts": [
            "The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software."
          ]
        },
        {
          "title": "rustfoundation/safety-critical-rust-consortium",
          "url": "https://github.com/rustfoundation/safety-critical-rust-consortium",
          "excerpts": [
            "The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software."
          ]
        },
        {
          "title": "AdaCore supports the Safety-Critical Rust Consortium",
          "url": "https://www.adacore.com/press/adacore-supports-the-safety-critical-rust-consortium",
          "excerpts": [
            "The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software ‚Äî systems whose failure ..."
          ]
        },
        {
          "title": "Unsafe Code Guidelines Meetings - Rust Internals",
          "url": "https://internals.rust-lang.org/t/unsafe-code-guidelines-meetings/8335",
          "excerpts": [
            "This thread will track the meetings for Unsafe Code Guidelines effort. These meetings are purely administrative ‚Äì they are used to decide our overall agenda."
          ]
        },
        {
          "title": "FireDBG for Rust",
          "url": "https://marketplace.visualstudio.com/items?itemName=SeaQL.firedbg-rust",
          "excerpts": [
            "A time travel visual debugger based on LLDB Debug Server. It allows users to debug Rust code using Visual Studio Code (VS Code)."
          ]
        },
        {
          "title": "CodeLLDB",
          "url": "https://marketplace.visualstudio.com/items?itemName=vadimcn.vscode-lldb",
          "excerpts": [
            "May 26, 2025 ‚Äî A native debugger powered by LLDB. Debug C++, Rust and other compiled languages. Installation Launch VS Code Quick Open ( Ctrl+P ), paste the following command¬†..."
          ]
        },
        {
          "title": "ebkalderon/tower-lsp: Language Server Protocol ...",
          "url": "https://github.com/ebkalderon/tower-lsp",
          "excerpts": [
            "Language Server Protocol implementation for Rust based on Tower. Tower is a simple and composable framework for implementing asynchronous services in Rust."
          ]
        },
        {
          "title": "Build Script Examples - The Cargo Book",
          "url": "https://doc.rust-lang.org/cargo/reference/build-script-examples.html",
          "excerpts": [
            "The following sections illustrate some examples of writing build scripts. Some common build script functionality can be found via crates on crates.io."
          ]
        },
        {
          "title": "Building a Mini Maths DSL with Procedural Macros - Byte Blog",
          "url": "https://byteblog.medium.com/building-a-mini-maths-dsl-with-procedural-macros-b0d7880b108f",
          "excerpts": [
            "Procedural macros in Rust are like tiny bits of code that write other code for you ‚Äî at compile time. They can be used to build entire functions¬†..."
          ]
        },
        {
          "title": "tower_lsp - Rust",
          "url": "https://docs.rs/tower-lsp/",
          "excerpts": [
            "A builder to customize the properties of an LspService . Server: Server for processing requests and responses on standard I/O or TCP. Traits¬ß. LanguageServer¬†..."
          ]
        },
        {
          "title": "Rust tutorials on DSL creation and proc macros",
          "url": "https://users.rust-lang.org/t/rust-tutorials-on-dsl-creation-and-proc-macros/79497",
          "excerpts": [
            "Aug 6, 2022 ‚Äî Rust tutorials on DSL creation and proc macros ¬∑ Create a simple DSL for CSS like syntax for TUIs | developerlife.com ¬∑ Guide to Rust procedural¬†..."
          ]
        },
        {
          "title": "Managing Generated Code with rust-analyzer",
          "url": "https://users.rust-lang.org/t/managing-generated-code-with-rust-analyzer/64863",
          "excerpts": [
            "Managing Generated Code with rust-analyzer - editors and IDEs - The Rust Programming Language Forum",
            "\n\nHello,\n\nDoes anyone who uses zbus have advice on managing the generated code during development time using rust-analyzer as an LSP server? Would it be possible to, say, have it macroexpand the generated files so that the type information will be available while I am coding.",
            "Would it be possible to, say, have it macroexpand the generated files so that the type information will be available while I am coding. Otherwise, I suppose I can dump the macroexpanded file out into a file and read it that way.",
            "Are there any other variables I need to turn on in conjunction to that one? I am getting an unresolved procmacro dbus\\_proxy, yet the code runs fine and compiles correclty.",
            "Related topics",
            "Seamless integration of generated Rust source code"
          ]
        },
        {
          "title": "Lint idea: forbid all expect and unwrap use ¬∑ Issue #6636",
          "url": "https://github.com/rust-lang/rust-clippy/issues/6636",
          "excerpts": [
            "Jan 24, 2021 ‚Äî It would be nice to have a restriction lint (ie, totally opt-in) that allows clippy users to completely ban all expect and unwrap use from a codebase."
          ]
        },
        {
          "title": "Is there a way to enforce prohibiting usage of panic/unwrap ...",
          "url": "https://www.reddit.com/r/rust/comments/1ftkig8/is_there_a_way_to_enforce_prohibiting_usage_of/",
          "excerpts": [
            "I think you can use clippy to emit errors or warnings on use of unwrap and co. Then just check for clippy errors in your CI/CD Workflow."
          ]
        },
        {
          "title": "[Coding Guidelines] Minutes 12thMarch2025 by iglesias",
          "url": "https://www.linkedin.com/posts/pete-levasseur_coding-guidelines-minutes-12thmarch2025-activity-7305972362380759041-3HPp",
          "excerpts": [
            "Hi folks -- wanted to share an update from the Safety-Critical Rust Consortium: Coding Guidelines from our meeting this week!"
          ]
        },
        {
          "title": "Rust in the Enterprise: Best practices and security considerations",
          "url": "https://www.sonatype.com/blog/rust-in-the-enterprise-best-practices-and-security-considerations",
          "excerpts": [
            "Dependency management : Organizations need to assess and vet open source Rust crates to prevent security risks in the software supply chain.",
            "Compliance and regulatory requirements : Enterprises operating in regulated industries must ensure Rust development aligns with compliance frameworks, such as SOC 2, ISO 27001, and other security standards.",
            "Monitoring and updating dependencies : Regularly reviewing and updating Rust dependencies helps mitigate the risk of security vulnerabilities in outdated libraries.",
            "Security training for developers : Ensuring that developers understand secure coding practices in Rust helps minimize risk and improves software quality.",
            "Security and compliance : Enterprises must ensure their security teams are equipped to understand Rust's unique properties, including the implications of using unsafe Rust code.",
            "Standardizing approved libraries : Organizations can maintain an internal list of vetted crates to streamline development and reduce security risks.",
            "Implementing software supply chain security tools : Utilizing tools that analyze Rust dependencies for vulnerabilities ensures software integrity throughout development and deployment."
          ]
        },
        {
          "title": "Apache Arrow DataFusion 26.0.0",
          "url": "https://arrow.apache.org/blog/2023/06/24/datafusion-25.0.0/",
          "excerpts": [
            "Jun 24, 2023 ‚Äî Apache Arrow DataFusion is an extensible query engine and database toolkit, written in Rust, that uses Apache Arrow as its in-memory format."
          ]
        },
        {
          "title": "Common Criteria Certification Process: Costs and ...",
          "url": "https://www.cclab.com/news/common-criteria-certification-process-costs-and-challenges",
          "excerpts": [
            "Apr 26, 2024 ‚Äî This article delves into the intricacies of the Common Criteria certification process, shedding light on its challenges and associated costs."
          ]
        },
        {
          "title": "NIST Cost Recovery Fees - Cryptographic Module Validation ...",
          "url": "https://csrc.nist.gov/projects/cryptographic-module-validation-program/nist-cost-recovery-fees",
          "excerpts": [
            "For FIPS 140-3 ¬∑ Security Level 1: CR fee: $8000, ECR fee: $3000 ¬∑ Security Level 2: CR fee: $10000, ECR fee: $4000 ¬∑ Security Level 3: CR fee: ..."
          ]
        },
        {
          "title": "Automotive Safety Integrity Level",
          "url": "https://en.wikipedia.org/wiki/Automotive_Safety_Integrity_Level",
          "excerpts": [
            "Automotive Safety Integrity Level (ASIL) is a risk classification scheme defined by the ISO 26262 - Functional Safety for Road Vehicles standard."
          ]
        },
        {
          "title": "How to handle people dismissing io_uring as insecure?",
          "url": "https://github.com/axboe/liburing/discussions/1047",
          "excerpts": [
            "Sep 1, 2024 ‚Äî It's not secret that the initial async offload design in io_uring was not great, which is why 5.10-stable and all later kernels changed the thread model for¬†..."
          ]
        },
        {
          "title": "io_uring performance 40% better than kqueue and epoll",
          "url": "https://forums.freebsd.org/threads/io_uring-performance-40-better-than-kqueue-and-epoll.73306/",
          "excerpts": [
            "Io_uring permits safe signal delivery in the presence of PID reuse which will improve power management without affecting power consumption."
          ]
        },
        {
          "title": "UAV's: Applying DO-178C & Costs versus Benefits - AFuzion",
          "url": "https://afuzion.com/uavs-applying-do-178c-costs-versus-benefits/",
          "excerpts": [
            "The cost differential within DO-178C for UAV's is the most significant between Level D and Level C. ... Therefore, the seemingly significant cost increase ..."
          ]
        },
        {
          "title": "DO-178C Explained | ConsuNova, Inc.",
          "url": "https://consunova.com/do-178c-explained/",
          "excerpts": [
            "Using DO-178 can add 30-150% to avionics software development costs, though typically it only adds 25%-40%. When you start with fundamental ..."
          ]
        },
        {
          "title": "Microkernels - The Redox Operating System",
          "url": "https://doc.redox-os.org/book/microkernels.html",
          "excerpts": [
            "The Redox kernel is a microkernel. Microkernels stand out in their design by providing minimal abstractions in kernel-space."
          ]
        },
        {
          "title": "How ISO 26262 Updates Affects You | ASIL Compliance",
          "url": "https://neweagle.net/blog/how-iso-26262-2018-update-affects-you/",
          "excerpts": [
            "Apr 18, 2019 ‚Äî As higher ASILs typically require higher costs, decomposition can help to meet safety requirements with reduced cost and effort. Decomposing¬†...",
            "Apr 18, 2019 ‚Äî The cost and complexity of compliance may increase by as much as an order of magnitude with each step, ranging throughout ASIL A to ASIL D."
          ]
        },
        {
          "title": "Cryptographic Module Validation Program CMVP - CSRC",
          "url": "https://csrc.nist.rip/Projects/cryptographic-module-validation-program/nist-cost-recovery-fees",
          "excerpts": [
            "Nov 17, 2021 ‚Äî The ECR fee is applicable per the overall Security Level to all test reports received by NIST CMVP under FIPS 140-3 (all scenarios)."
          ]
        },
        {
          "title": "Evaluation Assurance Level - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Evaluation_Assurance_Level",
          "excerpts": [
            "Achieving a higher EAL certification generally costs more money and takes more time than achieving a lower one.",
            "1.1 EAL1: Functionally tested ¬∑ 1.2 EAL2: Structurally tested ¬∑ 1.3 EAL3: Methodically tested and checked ¬∑ 1.4 EAL4: Methodically designed, tested and reviewed ..."
          ]
        },
        {
          "title": "Reporting Vulnerabilities ‚Ä∫ RustSec Advisory Database",
          "url": "https://rustsec.org/contributing.html",
          "excerpts": [
            "To add an advisory to the RustSec database, open a Pull Request against this repository containing the new advisory."
          ]
        },
        {
          "title": "Contains a list of security related Rust projects.",
          "url": "https://github.com/rust-secure-code/projects",
          "excerpts": [
            "The RustSec Advisory Database is a repository of security advisories filed against Rust crates published via https://crates.io. Works closely with Cargo Audit."
          ]
        },
        {
          "title": "Security Guidelines for New Projects - CNCF Contributors",
          "url": "https://contribute.cncf.io/maintainers/security/security-guidelines/",
          "excerpts": [
            "Disclosure timeline. A template for this document is available at CNCF TAG Security Project Resouces - Embargo Policy. 3.5 Security ..."
          ]
        },
        {
          "title": "Project structure in Rust",
          "url": "https://www.reddit.com/r/rust/comments/185pdyr/project_structure_in_rust/",
          "excerpts": [
            "TLDR: How do you structure your projects? What modules do you usually create and what goes into which one? Hey everyone,."
          ]
        },
        {
          "title": "Rust: Project structure example step by step",
          "url": "https://dev.to/ghost/rust-project-structure-example-step-by-step-3ee",
          "excerpts": [
            "Jan 18, 2020 ‚Äî I will share the process and stages of decomposition in Rust. This is thoroughly explained in The Book, but I'll try to make it more concise and simple."
          ]
        },
        {
          "title": "Applying COCOMO II for a DO-178C Safety-Critical ...",
          "url": "https://www.redalyc.org/journal/3094/309457690019/html/",
          "excerpts": [
            "by LP dos Santos ¬∑ 2019 ¬∑ Cited by 5 ‚Äî This paper provides a real example of applying COCOMO II as an estimation technique for the required software development effort in a safety-critical software¬†..."
          ]
        },
        {
          "title": "Effort Functional Safety vs. \"Normal\" Development",
          "url": "https://www.solcept.ch/en/blog/critical-systems/effort-functional-safety/",
          "excerpts": [
            "This table shows which effort per line of code can be estimated by rule of thumb to implement functionally safe software projects."
          ]
        },
        {
          "title": "Security policy - CNCF TAG Security",
          "url": "https://tag-security.cncf.io/community/resources/project-resources/templates/security/",
          "excerpts": [
            "Please bear with us as we seek to understand the breadth and scope of the reported problem, recreate it, and confirm if there is an vulnerability present. This ..."
          ]
        },
        {
          "title": "Redox OS, a Rust and micro-kernel based OS, now ships ...",
          "url": "https://www.reddit.com/r/pop_os/comments/1dae8ej/redox_os_a_rust_and_microkernel_based_os_now/",
          "excerpts": [
            "A Unix-like microkernel-based operating system written in Rust and capable of being used as both a server and a desktop."
          ]
        },
        {
          "title": "Embedded development ‚Äî list of Rust libraries/crates ...",
          "url": "https://lib.rs/embedded",
          "excerpts": [
            "Crates that are primarily useful on embedded devices or without an operating system. 2900 of 4606 crates; Sort: Best Popular New ¬∑ Hardware support."
          ]
        },
        {
          "title": "Understanding an ASIL in the Functional Safety Standard ...",
          "url": "https://www.lhpes.com/blog/what-is-an-asil",
          "excerpts": [
            "Aug 13, 2020 ‚Äî If the system is recognized as ASIL D, ISO 26262 highly recommends the performance of Modified Condition Decision Coverage (MC/DC) structural¬†..."
          ]
        },
        {
          "title": "Cryptographic Module Validation Program | CSRC",
          "url": "https://csrc.nist.gov/projects/cryptographic-module-validation-program",
          "excerpts": [
            "FIPS 140-3 validations are currently being accepted. Upon validation, modules will be placed on the Active list for 5 years (or 2 years for Interim Validations)¬†..."
          ]
        },
        {
          "title": "Second Security Initiative Report Details Rust ...",
          "url": "https://www.reddit.com/r/rust/comments/1avb1cc/second_security_initiative_report_details_rust/",
          "excerpts": [
            "Direct link to the report itself (PDF) https://foundation.rust-lang.org/static/publications/security-initiative-report-february-2024.pdf."
          ]
        },
        {
          "title": "Rust Foundation's 2025 Technology Report Showcases ...",
          "url": "https://rustfoundation.org/media/rust-foundations-2025-technology-report-showcases-year-of-rust-security-advancements-ecosystem-resilience-strategic-partnerships/",
          "excerpts": [
            "Aug 5, 2025 ‚Äî Rust Foundation's 2025 Technology Report Showcases Year of Rust Security Advancements, Ecosystem Resilience, & Strategic Partnerships. August 5,¬†..."
          ]
        },
        {
          "title": "ossf/wg-securing-critical-projects",
          "url": "https://github.com/ossf/wg-securing-critical-projects",
          "excerpts": [
            "Helping allocate resources to secure the critical open source projects we all depend on. - ossf/wg-securing-critical-projects."
          ]
        },
        {
          "title": "Securing the supply chain at scale: Starting with 71 ...",
          "url": "https://github.blog/open-source/maintainers/securing-the-supply-chain-at-scale-starting-with-71-important-open-source-projects/",
          "excerpts": [
            "Learn how the GitHub Secure Open Source Fund helped 71 open source projects significantly improve their security posture."
          ]
        },
        {
          "title": "Carvel - shared - Security Policy",
          "url": "https://carvel.dev/shared/docs/latest/security-policy/",
          "excerpts": [
            "All security issues, confirmed or suspected, should be reported privately. Please avoid using github issues, and instead report the vulnerability to cncf-carvel ..."
          ]
        },
        {
          "title": "- Devel - lists.sel4.systems",
          "url": "https://lists.sel4.systems/hyperkitty/list/devel@sel4.systems/latest?count=200&page=4",
          "excerpts": [
            "seL4_Call(same vspace, ipc length is 0)' result is 129331186 cycles. Are these results are available? [View Less]. 3 2. 0 0. Booting seL4test on x86 hardware"
          ]
        },
        {
          "title": "A Programmer-Friendly I/O Abstraction Over io_uring and ...",
          "url": "https://tigerbeetle.com/blog/2022-11-23-a-friendly-abstraction-over-iouring-and-kqueue",
          "excerpts": [
            "Nov 23, 2022 ‚Äî We'll start with blocking I/O, explore io_uring and kqueue, and take home an event loop very similar to some software you may find familiar."
          ]
        },
        {
          "title": "Search Results - CVE",
          "url": "https://cve.mitre.org/cgi-bin/cvekey.cgi?keyword=io_uring",
          "excerpts": [
            "Integer Overflow or Wraparound vulnerability in io_uring of Linux Kernel allows local attacker to cause memory corruption and escalate privileges to root. This¬†..."
          ]
        },
        {
          "title": "ALAS2KERNEL-5.10-2022-002",
          "url": "https://alas.aws.amazon.com/AL2/ALAS2KERNEL-5.10-2022-002.html",
          "excerpts": [
            "Jun 19, 2025 ‚Äî ... (CVE-2021-47120). In the Linux kernel, the following vulnerability has been resolved: io_uring: fix link timeout refs (CVE-2021-47124). In the¬†..."
          ]
        },
        {
          "title": "[PDF] 14th USENIX Symposium on Operating Systems Design and ...",
          "url": "https://www.usenix.org/sites/default/files/osdi20-full_proceedings.pdf",
          "excerpts": [
            "These papers represent the many strengths of our community and cover a wide range of topics, including file and storage systems, networking, ..."
          ]
        },
        {
          "title": "ISO 26262 ASIL: How it is Determined for Automotive ...",
          "url": "https://www.embitel.com/blog/embedded-blog/understanding-how-iso-26262-asil-is-determined-for-automotive-applications",
          "excerpts": [
            "Apr 19, 2018 ‚Äî Cost and Complexity: Implementing high ASIL standards increases both the complexity and cost of the development process. High-reliability¬†..."
          ]
        },
        {
          "title": "ISO 26262 compliance is not a costly overhead",
          "url": "https://www.electronicspecifier.com/news/blog/iso-26262-compliance-is-not-a-costly-overhead/",
          "excerpts": [
            "The answer to this question determines the ASIL level, with D having the most safety critical processes and strictest testing regulations. For example, a¬†..."
          ]
        },
        {
          "title": "Theseus OS Design and Concepts",
          "url": "https://www.theseus-os.com/Theseus/book/design/design.html",
          "excerpts": [
            "At implementation time, a cell is a crate.",
            "After compile (build) time, a cell is a single .o object file.",
            "file. * At runtime, a cell üÑ≤ is a structure that contains the set of sections üÖÇ from its crate object file, which have been dynamically loaded and linked into memory, as well as metadata about the inter-dependencies between it and others.",
            "the\nkernel/crate_metadata crate , which includes two main types:",
            "* LoadedCrate , which represents a single crate loaded into memory and linked against other loaded crates. The\nLoadedCrate owns the memory regions holding its sections, along with other metadata about sections and symbols in that crate.",
            "* LoadedSection , which represents an individual section within a loaded crate, as specified in its object file.",
            "A\nLoadedSection comprises several main items:",
            "       * The section type , e.g.,\n.text (an executable function),\n.rodata (constant data),\n.data /\n.bss (read-write data)",
            "       * Outgoing dependencies: the list of other sections from other crates that this section depends on (and links against).",
            " * Incoming dependencies: the list of other sections from other crates that depend on (link against) this section.",
            " * References to its containing \"parent\" crate and location within that crate's memory region where this section is loaded.",
            "In a monolithic OS, all kernel components exist and run in a single kernel address space, meaning that intra-kernel communication is fast and efficient: simply use function calls and shared memory accesses.",
            "Microkernel OSes are less common, but still widespread in certain computing domains where reliability is key, such as embedded systems.",
            "Microkernels move as much kernel functionality as possible into separate user space \"system server\" processes, leaving the kernel itself very small.",
            "This improves resiliency, as each kernel entity executes in user space in its own address space; if one crashes, the rest of the system can continue execution by restarting the failed system process."
          ]
        },
        {
          "title": "Erlang io-uring support - Chat / Discussions",
          "url": "https://erlangforums.com/t/erlang-io-uring-support/765",
          "excerpts": [
            "supporting io_uring might make Linux actually look closer to Windows from a beam point of view! You'd still have to keep the existing ..."
          ]
        },
        {
          "title": "Creating bindings to liburing and a simple io_uring example.",
          "url": "https://www.reddit.com/r/rust/comments/1eq1j7q/creating_bindings_to_liburing_and_a_simple_io/",
          "excerpts": [
            "I assume those functions are inline for a reason (likely performance). So binding them via FFI is probably not the best approach without cross-language LTO."
          ]
        },
        {
          "title": "Lightship-7-Steps-to-Common-Criteria-eBook. ...",
          "url": "https://lightshipsec.com/download/Lightship-7-Steps-to-Common-Criteria-eBook.pdf",
          "excerpts": [
            "How long does Common Criteria certification take? The general rule of thumb is about one year including preparation time. 3. What gets evaluated under Common ..."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "https://sel4.systems/",
          "excerpts": [
            "seL4 protects critical systems from software failures and cyber-attacks. It allows non-critical functionality to run securely alongside critical payloads by¬†..."
          ]
        },
        {
          "title": "The seL4 microkernel",
          "url": "https://github.com/seL4/seL4",
          "excerpts": [
            "This project contains the source code of seL4 microkernel. For details about the seL4 microkernel, including details about its formal correctness proof,"
          ]
        },
        {
          "title": "Shenango: achieving high CPU efficiency for latency ...",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323265",
          "excerpts": [
            "by A Ousterhout ¬∑ 2019 ¬∑ Cited by 428 ‚Äî Shenango achieves comparable latencies but at far greater CPU efficiency. It reallocates cores across applications at very fine granularity--every 5 Œºs."
          ]
        },
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack- ...",
          "url": "https://arxiv.org/abs/2010.05969",
          "excerpts": [
            "by H Zhu ¬∑ 2020 ¬∑ Cited by 1 ‚Äî Access Paper: View a PDF of the paper titled RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers (Technical Report), by Hang¬†..."
          ]
        },
        {
          "title": "Asynchronous I/O ‚Äî With Great Power Comes ...",
          "url": "https://arxiv.org/html/2411.16254v1",
          "excerpts": [
            "Newer asynchronous I/O APIs, such as io_uring, have significantly improved performance by reducing such overheads, but exhibit limited adoption in practice."
          ]
        },
        {
          "title": "io_uring(7) ‚Äî liburing-dev ‚Äî Debian unstable",
          "url": "https://manpages.debian.org/unstable/liburing-dev/io_uring.7.en.html",
          "excerpts": [
            "io_uring is a Linux-specific API for asynchronous I/O. It allows the user to submit one or more I/O requests, which are processed asynchronously without ..."
          ]
        },
        {
          "title": "[2411.16254] Asynchronous I/O -- With Great Power ...",
          "url": "https://arxiv.org/abs/2411.16254",
          "excerpts": [
            "Newer asynchronous I/O APIs, such as io_uring, have significantly improved performance by reducing such overheads, but exhibit limited adoption ..."
          ]
        },
        {
          "title": "io_uring_enter(2) ‚Äî liburing-dev - unstable - Debian Manpages",
          "url": "https://manpages.debian.org/unstable/liburing-dev/io_uring_enter.2.en.html",
          "excerpts": [
            "io_uring_enter(2) is used to initiate and complete I/O using the shared submission and completion queues setup by a call to io_uring_setup(2)."
          ]
        },
        {
          "title": "Exploiting Storage I/O Parallelism with Explicit Speculation",
          "url": "https://arxiv.org/html/2409.01580v1",
          "excerpts": [
            "Foreactor incorporates both io_uring, a recent Linux kernel asynchronous I/O interface, and a general user-level thread pool as the backend ..."
          ]
        },
        {
          "title": "CloudFlare Pingora is Now Open Source (in Rust) - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1b23vhi/cloudflare_pingora_is_now_open_source_in_rust/",
          "excerpts": [
            "Basically, it's an in-house reverse proxy, as a replacement of Nginx, for connecting Cloudflare to the internet."
          ]
        },
        {
          "title": "arXiv: seL4 Microkernel for virtualization use-cases: Potential directions towards a standard VMM",
          "url": "https://arxiv.org/abs/2210.04328",
          "excerpts": [
            "seL4 Microkernel for virtualization use-cases: Potential directions towards a standard VMM",
            "Abstract:Virtualization plays an essential role in providing security to computational systems by isolating execution environments.",
            "arXiv:2210.04328"
          ]
        },
        {
          "title": "arXiv:2407.20559 ‚Äî Practical Rely/Guarantee Verification of an Efficient Lock for seL4 on Multicore Architectures",
          "url": "http://arxiv.org/abs/2407.20559",
          "excerpts": [
            "Practical Rely/Guarantee Verification of an Efficient Lock for seL4 on Multicore Architectures",
            "arXiv:2407.20559",
            "Abstract:Developers of low-level systems code providing core functionality for"
          ]
        },
        {
          "title": "VxWorks 653 Multi-core Edition Product Overview",
          "url": "https://www.windriver.com/resource/vxworks-653-product-overview",
          "excerpts": [
            "VxWorks 653 Multi-core Edition is a safe, secure, and reliable real-time operating system (RTOS). It delivers an ARINC 653‚Äìconformant system."
          ]
        },
        {
          "title": "[PDF] An Experience Report on ARINC 653 using Event-B",
          "url": "https://lvpgroup.github.io/papers/ISSRE2015.pdf",
          "excerpts": [
            "The content of ARINC. 653 standard is divided into five parts: overview, system func- tionality, service requirements, configuration, and verification. Our work ..."
          ]
        },
        {
          "title": "ARINC-653 APEX based on XtratuM",
          "url": "http://wks.gii.upv.es/sidireli/files/jtr_patricia_arinc.pdf",
          "excerpts": [
            "by M Masmano ¬∑ Cited by 3 ‚Äî The ARINC-653 specification Part 1 defines the mandatory services and describes the invocation of those services and the data structures."
          ]
        },
        {
          "title": "ARINC 653 API and its application ‚Äì An insight into Avionics System ...",
          "url": "https://www.researchgate.net/publication/265729756_ARINC_653_API_and_its_application_-_An_insight_into_Avionics_System_Case_Study",
          "excerpts": [
            "ARINC 653 compliant RTOS including APEX Libraries. The APEX libraries play a very critical role in the safety. and reliability issues of the ..."
          ]
        },
        {
          "title": "VxWorks Safety Platforms",
          "url": "https://www.windriver.com/products/vxworks/safety-platforms",
          "excerpts": [
            "VxWorks 653 is a safe, secure, and reliable real-time operating system (RTOS) that delivers an open virtualization platform with robust time and space¬†..."
          ]
        },
        {
          "title": "Format - Apache Arrow",
          "url": "https://arrow.apache.org/overview/",
          "excerpts": [
            "The Apache Arrow format allows computational routines and execution engines to maximize their efficiency when scanning and iterating large chunks of data. In¬†..."
          ]
        },
        {
          "title": "Announcing Apache Arrow DataFusion is now Apache ...",
          "url": "https://arrow.apache.org/blog/2024/05/07/datafusion-tlp/",
          "excerpts": [
            "May 7, 2024 ‚Äî Apache DataFusion is a fast, extensible query engine for building high-quality data-centric systems in Rust, using the Apache Arrow in-memory format."
          ]
        },
        {
          "title": "[2404.03030] Leveraging Apache Arrow for Zero-copy ...",
          "url": "https://arxiv.org/abs/2404.03030",
          "excerpts": [
            "by P Groet ¬∑ 2024 ¬∑ Cited by 1 ‚Äî This paper describes a distributed implementation of Apache Arrow that can leverage cluster-shared load-store addressable memory that is hardware-coherent only¬†..."
          ]
        },
        {
          "title": "Apache Arrow | Apache Arrow",
          "url": "https://arrow.apache.org/",
          "excerpts": [
            "The Arrow memory format also supports zero-copy reads for lightning-fast data access without serialization overhead."
          ]
        },
        {
          "title": "Apache Arrow DataFusion documentation",
          "url": "https://datafusion.apache.org/python/user-guide/io/arrow.html",
          "excerpts": [
            "DataFusion implements the Apache Arrow PyCapsule interface for importing and exporting DataFrames with zero copy."
          ]
        },
        {
          "title": "Skyhook: Towards an Arrow-Native Storage System",
          "url": "https://arxiv.org/abs/2204.06074",
          "excerpts": [
            "by J Chakraborty ¬∑ 2022 ¬∑ Cited by 15 ‚Äî This paper introduces a new design paradigm that allows extending programmable object storage systems to embed existing, widely used data processing frameworks¬†..."
          ]
        },
        {
          "title": "verified replay in Zoran Skoda",
          "url": "https://ncatlab.org/zoranskoda/show/verified+replay",
          "excerpts": [
            "G. W. Dunlap, ReVirt: Enabling intrusion analysis through virtual-machine logging and replay, Proc. OSDI 2002, doi, pdf ... doi; Two protocols for ..."
          ]
        },
        {
          "title": "[PDF] 9th USENIX Symposium on Operating Systems Design and ...",
          "url": "https://www.usenix.org/event/osdi10/tech/full_papers/osdi10_proceedings.pdf",
          "excerpts": [
            "Page 1. conference proceedings. 9th USENIX Symposium on Operating Systems. Design and. Implementation. (OSDI '10). Vancouver, BC, Canada. October 4‚Äì6, 2010. P."
          ]
        },
        {
          "title": "Time-Travel Debugging Production Code - Temporal",
          "url": "https://temporal.io/blog/time-travel-debugging-production-code",
          "excerpts": [
            "Learn how time-travel debuggers, including Temporal, can help you rewind and debug past executions to resolve complex issues efficiently."
          ]
        },
        {
          "title": "[PDF] Reflections on the History of Operating Systems Research in Fault ...",
          "url": "https://www.cs.cornell.edu/projects/Quicksilver/public_pdfs/History.pdf",
          "excerpts": [
            "ReVirt: enabling intrusion analysis through virtual-machine logging and replay. SIGOPS Oper. Syst. Rev. 36, SI (December 2002), 211-224. http://dx.doi.org/ ..."
          ]
        },
        {
          "title": "[PDF] Conference Reports | USENIX",
          "url": "https://www.usenix.org/system/files/login/articles/105438-OSDI10reports.pdf",
          "excerpts": [
            "DoublePlay employs multiple executions to detect data races. The system uses a novel technique of dividing a parallel execution into epochs, recording the ..."
          ]
        },
        {
          "title": "How to debug an Effectively Deterministic Time Travel Debugger ...",
          "url": "https://medium.com/replay-io/how-to-debug-an-effectively-deterministic-time-travel-debugger-seriously-how-ba4d59965b7a",
          "excerpts": [
            "At Replay we're building a time travel debugger the likes of which hasn't been seen before. This is not normal software."
          ]
        },
        {
          "title": "ARINC653P1-5: AVIONICS APPLICATION SOFTWARE STANDARD INTERFACE PART 1 REQUIRED SERVICES - SAE International",
          "url": "https://www.sae.org/standards/content/arinc653p1-5/",
          "excerpts": [
            "ARINC653P1-5: AVIONICS APPLICATION SOFTWARE STANDARD INTERFACE PART 1 REQUIRED SERVICES",
            "This standard defines a general-purpose Application/Executive (APEX) software interface between the Operating System of an avionics computer and the application software.",
            "The interface requirements between the application software and operating system services are defined in a manner that enables the application software to control the scheduling, communication, and status of internal processing elements.",
            "Supplement 5 adds multicore processor service capabilities."
          ]
        },
        {
          "title": "Apache Arrow Specifications",
          "url": "https://arrow.apache.org/docs/format/index.html",
          "excerpts": [
            "Specifications",
            "Arrow Columnar Format",
            "Support for Null Values",
            "Primitive Layouts",
            "Nested Layouts",
            "Dictionary Encoded Layout",
            "Run-End Encoded Layout",
            "[Overview of Arrow "
          ]
        },
        {
          "title": "Arrow Columnar Format",
          "url": "https://arrow.apache.org/docs/format/Columnar.html",
          "excerpts": [
            "The **Arrow columnar format** includes a language-agnostic in-memory\ndata structure specification, metadata serialization, and a protocol\nfor serialization and generic data transp",
            "Data adjacency for sequential access (scans)",
            "O(1) (constant-time) random access",
            "SIMD and vectorization-friendly",
            "Relocatable without ‚Äúpointer swizzling‚Äù, allowing for true zero-copy\n  access in shared memo",
            "The Arrow columnar format provides analytical performance and data\nlocality guarantees in exchange for comparatively more expensive\nmutation operations."
          ]
        },
        {
          "title": "seL4: Formal Verification of an OS Kernel",
          "url": "https://www.cse.unsw.edu.au/~kleing/papers/sosp09.html",
          "excerpts": [
            "seL4, a third-generation microkernel of L4 provenance, comprises 8,700 lines of C code and 600 lines of assembler. Its performance is comparable to other high-¬†..."
          ]
        },
        {
          "title": "7. Supported Operating Systems - Documentation",
          "url": "https://doc.dpdk.org/guides-16.04/rel_notes/supported_os.html",
          "excerpts": [
            "The following Linux distributions were successfully used to compiler or run DPDK. FreeBSD 10; Fedora release 20; Ubuntu 14.04 LTS; Wind River Linux 6; Red Hat ..."
          ]
        },
        {
          "title": "Ubuntu Manpage: io_uring - Asynchronous I/O facility",
          "url": "https://manpages.ubuntu.com/manpages/jammy/man7/io_uring.7.html",
          "excerpts": [
            "In this function, we read completion events from the completion queue. We dequeue the CQE, update and head and return the result of the operation."
          ]
        },
        {
          "title": "io_uring zero copy Rx - The Linux Kernel documentation",
          "url": "https://docs.kernel.org/networking/iou-zcrx.html",
          "excerpts": [
            "io_uring zero copy Rx (ZC Rx) is a feature that removes kernel-to-user copy on the network receive path, allowing packet data to be received directly into ..."
          ]
        },
        {
          "title": "How to create a single SQPOLL thread in io_uring for ...",
          "url": "https://stackoverflow.com/questions/73798651/how-to-create-a-single-sqpoll-thread-in-io-uring-for-multiple-rings-ioring-setu",
          "excerpts": [
            "In order to achieve this in case of a single ring, one creates an SQPOLL thread by passing the IORING_SETUP_SQPOLL flag to io_uring_setup() call."
          ]
        },
        {
          "title": "Klein et al. SOSP 2009: seL4, a formally verified microkernel",
          "url": "https://www.sigops.org/s/conferences/sosp/2009/papers/klein-sosp09.pdf",
          "excerpts": [
            "ur measurement for seL4 is 224 cycles for one-way\n\nIPC in an optimised C path, which is approaching  \nthe performance of optimised assembly-language IPC  \npaths for other L4 kernels on ARM processo",
            "seL4 provides a mechanism to receive notification of  \ninterrupts (via IPC) and acknowledge their receipt. Memory management in seL4 is explicit: both in-\n\nkernel objects and virtual address spaces are pro-  \ntected and managed via capab"
          ]
        },
        {
          "title": "Check trademark status and view documents - USPTO",
          "url": "https://www.uspto.gov/trademarks/apply/check-status-view-documents",
          "excerpts": [
            "Use TSDR to retrieve status information and to view and download documents for pending and registered trademarks. TSDR also displays information ...",
            "Sep 21, 2017 ‚Äî To access TSDR, enter a valid trademark serial number or registration number and select either the \"Status\" or \"Documents\" buttons. We are¬†..."
          ]
        },
        {
          "title": "United States Patent & Trademark Office - TSDR - USPTO",
          "url": "https://tsdr.uspto.gov/faqview",
          "excerpts": [
            "... TSDR@USPTO.GOV. Contact the Trademark Assistance Center, at 1-800-786-9199, or e-mail your question to <a href= \"mailto:TSDR@USPTO.GOV\">TSDR@USPTO.GOV</a>.",
            "How can I print a clean copy of the information displayed on the TSDR Status page? There are a number of ways: 1. Click expand all, click print preview and ..."
          ]
        },
        {
          "title": "Trade mark search - EUIPO - European Union",
          "url": "https://www.euipo.europa.eu/en/trade-marks/before-applying/availability",
          "excerpts": [
            "Missing: Ministry Magic",
            "Where to search? EU trade marks. You can search for registered trade marks free of charge using the search tool, TMview.",
            "TMview contains information on trade mark applications and registrations from all EU national IP offices, the EUIPO and also many IP offices from outside the EU.",
            "There are also other rights on the basis of which trade mark applications may be challenged (e.g. well-known marks that are not registered).",
            "just because there‚Äôs an earlier registration doesn‚Äôt mean you can‚Äôt apply."
          ]
        },
        {
          "title": "Trade mark search - EUIPO",
          "url": "https://www.euipo.europa.eu/bg/trade-marks/before-applying/availability",
          "excerpts": [
            "Where to search? EU trade marks. You can search for registered trade marks free of charge using the search tool, TMview."
          ]
        },
        {
          "title": "[PDF] Obsolete - Trade mark guidelines",
          "url": "https://euipo01app.sdlproducts.com/binary/1803468/2000210000",
          "excerpts": [
            "EUTMs: use in the European Union. If the earlier mark is a European Union mark, it must be used 'in the Union'. (Articles 18(1) and 47(2) ..."
          ]
        },
        {
          "title": "Harry Potter Trademarks - Secure Your ...",
          "url": "https://secureyourtrademark.com/blog/harry-potter-trademarks/",
          "excerpts": [
            "Jan 27, 2022 ‚Äî Warner Bros is the trademark owner of Harry Potter, and they have an array of famous trademarks. Let's go through some of the most popular Harry Potter¬†..."
          ]
        },
        {
          "title": "Harry Potter Copyright Violation Explained",
          "url": "https://bytescare.com/blog/harry-potter-copyright-infringement",
          "excerpts": [
            "Aug 13, 2025 ‚Äî This guide explains real cases of Harry Potter copyright violation and offers tips on what fans and content creators must avoid."
          ]
        },
        {
          "title": "Trademark vs Copyright for Literature Character Names",
          "url": "https://www.scoredetect.com/solutions/trademark-vs-copyright-literature-character-names",
          "excerpts": [
            "The process of trademarking a fictional character name typically involves filing an application with the relevant trademark office, such as the USPTO or EUIPO,¬†..."
          ]
        },
        {
          "title": "Federal trademark searching: Overview",
          "url": "https://www.uspto.gov/learning-and-resources/uspto-videos/federal-trademark-searching-overview",
          "excerpts": [
            "In this recorded webinar, we introduce you to the fundamental mechanics of using the USPTO's trademark search system."
          ]
        },
        {
          "title": "Trademarks - USPTO",
          "url": "https://www.uspto.gov/trademarks",
          "excerpts": [
            "Search trademarks, apply to register your trademark, protect against scams, maintain your registration, laws and rules."
          ]
        },
        {
          "title": "EUIPO - European Union",
          "url": "https://www.euipo.europa.eu/en",
          "excerpts": [
            "Missing: Protego Maxima",
            "EUIPO allows users to search IP databases, apply for trademarks and designs, and access resources like getting started and learning corners.",
            "EUIPO is the European Union Intellectual Property Office responsible for managing the EU trade marks and the registered European Union designs."
          ]
        },
        {
          "title": "the mark - EUIPO Guidelines - European Union",
          "url": "https://guidelines.euipo.europa.eu/1935303/1981375",
          "excerpts": [
            "In particular, likelihood of confusion is not a condition for the application of Article 8(3) EUTMR (11/11/2020, C‚Äë809/18 P , MINERAL MAGIC, EU:C:2020:902, ¬ß 92) ..."
          ]
        },
        {
          "title": "USPTO | TMOG Search",
          "url": "https://tmog.uspto.gov/",
          "excerpts": [
            "Missing: tsdr. Magic"
          ]
        },
        {
          "title": "United States Patent and Trademark Office",
          "url": "https://www.uspto.gov/",
          "excerpts": [
            "Home page of the United States Patent and Trademark Office's main web site."
          ]
        },
        {
          "title": "Harry Potter and the IP empire",
          "url": "https://www.citma.org.uk/resources/harry-potter-and-the-ip-empire-blog.html",
          "excerpts": [
            "No trade mark was filed when the first book was published in 1997. No agreement had been signed with Warner Bros at that point. However, this ..."
          ]
        },
        {
          "title": "Can we use the names of fictional characters as our ...",
          "url": "https://www.quora.com/Can-we-use-the-names-of-fictional-characters-as-our-companys-name",
          "excerpts": [
            "You can name your business after a fictional character ‚Äî but only if you have the trademark rights to the name, or the name is in public domain."
          ]
        },
        {
          "title": "USPTO Trademark Tools and Resources",
          "url": "https://tmsearch.uspto.gov/",
          "excerpts": [
            "Search trademarks, file trademark forms, view status, documents, and registration certificates, file trademark trial and appeal board forms. [](https://www.uspto.gov \"United States Patent and Trademark Office - An Agency of the Department of Commerce\")",
            "trademarks",
            "* [Search Trademarks](https://tmsearch.uspto.gov)",
            "* [File Trademark forms](https://www.uspto.gov/trademarks-application-process/filing-online)",
            "* [View status, documents, and registration certificates](https://tsdr.uspto.gov/)",
            "* [File Trademark Trial and Appeal Board forms](https://estta.uspto.gov/)",
            "* [View Trademark Trial and Appeal Board proceedings](https://ttabvue.uspto.gov/ttabvue/)",
            "* [Search Trademark Official Gazette](https://tmog.uspto.gov/#)",
            "* [Record assignment](https://etas.uspto.gov/)",
            "* [Search"
          ]
        },
        {
          "title": "EUIPO Searches and IP Databases",
          "url": "https://www.euipo.europa.eu/en/search-ip",
          "excerpts": [
            "EUIPO offers searches for trade marks, designs, case law, and certified copies. Databases include TMview, DesignView, GIview, TMclass, and DESIGNclass.",
            "Accessibility English",
            "Search IP databases",
            "eSearch plus",
            "Comprehensive information on trade marks, designs, owners, representatives and bulletins",
            "TMview",
            "Trade marks of all participating official trade mark offices at national, international and EU level"
          ]
        },
        {
          "title": "Wizarding World Legal Notices",
          "url": "https://www.harrypotter.com/legals",
          "excerpts": [
            "¬© WIZARDING WORLD DIGITAL LLC. All rights reserved. WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc.",
            "WIZARDING WORLD, WIZARDING PASSPORT and related trade marks, characters, names and indicia are TM and ¬© Warner Bros. Entertainment Inc. WIZARDING WORLD publishing and theatrical stage rights ¬© J.K. Rowling.",
            ". All characters and elements ¬© & TM Warner Bros. Entertainment Inc."
          ]
        },
        {
          "title": "SLYTHERIN Trademark of Warner Bros. Entertainment Inc.",
          "url": "https://trademarks.justia.com/875/32/slytherin-87532764.html",
          "excerpts": [
            "SLYTHERIN is a trademark of Warner Bros. Entertainment Inc.. Filed in July 18 (2017), the SLYTHERIN covers Clothing for men, women and children, namely, ..."
          ]
        },
        {
          "title": "MINISTRY OF MAGIC Trademark - Serial Number 78271444",
          "url": "https://trademarks.justia.com/782/71/ministry-of-magic-78271444.html",
          "excerpts": [
            "MINISTRY OF MAGIC is a trademark of Alamo Fireworks Inc.. Filed in July 8 (2003), the MINISTRY OF MAGIC covers Fireworks."
          ]
        },
        {
          "title": "Slytherin Trademark Details",
          "url": "https://www.trademarkia.com/slytherin-87532764",
          "excerpts": [
            "SLYTHERIN is a registered trademark (Registration #5581854) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "The SLYTHERIN. Explore trademark details, ownership information, other trademarks owned by Warner Bros. Entertainment Inc. or file your own trademark. SLYTHERIN Trademark | Trademarkia",
            "13 Feb 2025**, the trademark remains **Live/Registered**, with a recent status, **SECTION 8 & 15-ACCEPTED AND ACKNOWLEDGE"
          ]
        },
        {
          "title": "US Trademark Data for SLYTHERIN (Warner Bros. Entertainment Inc.)",
          "url": "https://uspto.report/TM/87943593",
          "excerpts": [
            "The mark consists of a stylized design of a shield with a snake in the center and the word \"SLYTHERIN\" in a banner under the shield. Trademark registration for Warner Bros. Entertainment Inc.. The mark consists of a stylized design of a shield with a snake in the center and the word \nSLYTHERIN - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "SLYTHERIN Trademark Details (Trademarkia)",
          "url": "https://www.trademarkia.com/slytherin-87532744",
          "excerpts": [
            "SLYTHERIN is a registered trademark (Registration #5581853) owned by Warner Bros. Entertainment Inc., a Burbank based entity located in CA.",
            "Registration #5581853",
            "*SLYTHERIN** trademark is filed in the category of **Paper Goods and Printed Material",
            "First Use Date (General)19 May 2010",
            "Live/Registered"
          ]
        },
        {
          "title": "US Trademark Documentation - GRINGOTTS",
          "url": "https://uspto.report/TM/77389508",
          "excerpts": [
            "Trademark registration by Warner Bros. Entertainment Inc. for the trademark GRINGOTTS ... Trademark Office (USPTO) or any other governmental organization. Trademark registration by Warner Bros. Entertainment Inc. for the trademark GRINGOTTS. GRINGOTTS - Warner Bros. Entertainment Inc. Trademark Registration"
          ]
        },
        {
          "title": "Search - EUIPO - European Union",
          "url": "https://www.euipo.europa.eu/en/search",
          "excerpts": [
            "Search IP databases. eSearch plus. Comprehensive information on trade marks, designs, owners, representatives and bulletins ¬∑ eSearch Case Law."
          ]
        },
        {
          "title": "Global Brand Database",
          "url": "https://www.wipo.int/en/web/global-brand-database",
          "excerpts": [
            "Use the Global Brand Database to search internationally protected trademarks, appellations of origin, state emblems etc."
          ]
        },
        {
          "title": "Trade marks - EUIPO - European Union",
          "url": "https://www.euipo.europa.eu/en/trade-marks",
          "excerpts": [
            "EUIPO is the European Union Intellectual Property Office responsible for managing the EU trade marks and the registered European Union designs, and EU ...",
            "TMview. Trade marks of all participating official trade mark offices at national, international and EU level ¬∑ TMclass. The one-stop classification portal ..."
          ]
        },
        {
          "title": "Search our trademark database - USPTO",
          "url": "https://www.uspto.gov/trademarks/search",
          "excerpts": [
            "Nov 30, 2023 ‚Äî Log into your USPTO.gov account for a better search experience. Logging in using the Sign in link in the top right corner helps you avoid errors."
          ]
        },
        {
          "title": "Search USPTO.gov",
          "url": "https://www-search.uspto.gov/",
          "excerpts": [
            "Search with Patent, Public Search, Check filing status, Search assignment, Record assignment, Order certified Patent documents, Patent Trial and Appeal Case ..."
          ]
        },
        {
          "title": "USPTO Trademark Search Portal and TSDR",
          "url": "https://tsdr.uspto.gov/",
          "excerpts": [
            "Trademark Status & Document Retrieval (TSDR)",
            "Trademark eBusiness",
            "Search Trademarks",
            "Trademark Search"
          ]
        },
        {
          "title": "TSDR Data API | United States Patent and Trademark Office",
          "url": "https://developer.uspto.gov/api-catalog/tsdr-data-api",
          "excerpts": [
            "The Trademark Status Document Retrieval (TSDR) system allows you to make programmatic requests for trademark case status, documents, and images."
          ]
        },
        {
          "title": "Warner Bros. Entertainment Inc., et al. v. RDR Books, et al.",
          "url": "https://www.loeb.com/en/insights/publications/2008/09/warner-bros-entertainment-inc-et-al-v-rdr-books-__",
          "excerpts": [
            "Sep 8, 2008 ‚Äî The court held that The Lexicon copies a sufficient quantity of the Harry Potter works to support a finding of substantial similarity, noting¬†..."
          ]
        },
        {
          "title": "Trademark Dilution (Intended for a Non-Legal Audience)",
          "url": "https://www.inta.org/fact-sheets/trademark-dilution-intended-for-a-non-legal-audience/",
          "excerpts": [
            "Trademark dilution refers to the unauthorized use of and/or application for a trademark that is likely to weaken the distinctive quality of or harm a famous ..."
          ]
        },
        {
          "title": "Warner Bros. Entertainment Inc. v. RDR Books",
          "url": "https://en.wikipedia.org/wiki/Warner_Bros._Entertainment_Inc._v._RDR_Books",
          "excerpts": [
            "Lawyers for Rowling and Time Warner argued that RDR's attempt to publish for profit a print facsimile of The Harry Potter Lexicon, a free online guide to the¬†..."
          ]
        },
        {
          "title": "Who owns what rights? : r/WizardingWorld",
          "url": "https://www.reddit.com/r/WizardingWorld/comments/1fpv8yi/who_owns_what_rights/",
          "excerpts": [
            "JK Rowling controls all of it. But she has deals with Warner Bros for the Film and TV rights, Universal for the theme park rights, etc. But she still has¬†..."
          ]
        },
        {
          "title": "It is required to get authorization to use fictional/invented names as a ...",
          "url": "https://law.stackexchange.com/questions/80420/it-is-required-to-get-authorization-to-use-fictional-invented-names-as-a-codenam",
          "excerpts": [
            "In most cases the situation described in the question would not constitute trademark infringement and would not require permission from the owners of any ..."
          ]
        },
        {
          "title": "Warner Brothers and J. K. Rowling v. RDR Books: Fair Use ...",
          "url": "https://cccc.ncte.org/cccc/committees/ip/2008developments/warner/",
          "excerpts": [
            "by L Cubbison ¬∑ Cited by 1 ‚Äî The case hinged on whether the manuscript for the proposed book qualified as a fair use of Rowling's work, including not only the seven novels, but also the two¬†..."
          ]
        },
        {
          "title": "Trademark Dilution of A Famous Mark - The Jacobson Firm",
          "url": "https://thejacobsonfirmpc.com/trademark-dilution-of-a-famous-mark/",
          "excerpts": [
            "An explanation of Trademark Dilution of A Famous Mark including what trademark dilution is and how it may harm a famous trademark."
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads (NSDI 2019)",
          "url": "http://amyousterhout.com/papers/shenango_nsdi19.pdf?utm_source=chatgpt.com",
          "excerpts": [
            "Shenango solves the hard prob-\nlem of reallocating cores across applications at very fine\ntime scales; it reallocates cores every 5 microseconds,\norders of magnitude faster than any system we are aware\no",
            "als, Shenango solves the hard prob-\nlem of reallocating cores across applications at very fine\ntime scales; it reallocates cores every 5 microseconds,\norders of magnitude faster than any system we are aware\nof. Shenango proposes two key ideas. First, Shenango\nintroduces an efficient algorithm that accurately deter-\nmines when applications would benefit from additional\ncores based on runnable threads and incoming packets.\nSecond, Shenango dedicates a single busy-spinning\ncore per machine to a centralized software entity called\nthe IOKernel, which steers packets to applications\nand allocates cores across them.",
            "the IOKernel, which steers packets to applications\nand allocates cores across them.",
            "Shenango can achieve over five million requests\nper second of memcached throughput while maintaining\n99.9th percentile latency below 100 ¬µs",
            "entation\t361\n\non achieving three goals: (1) microsecond-scale end-\nto-end tail latencies and high throughput for datacenter\napplications; (2) CPU-efficient packing of applications\non multi-core machines; and (3) high application de-\nveloper productivity, thanks to synchronous I/O and\nstandard programming abstractions such as lightweight\nthreads and blocking TCP network sockets."
          ]
        },
        {
          "title": "[PDF] Certification Authorities Software Team (CAST) - CAST-32A",
          "url": "https://www.cast32a.com/files/cast-32a.pdf",
          "excerpts": [
            "Section 7 of this document describes the objectives that apply according to the assigned. IDAL (A, B or C) of the hosted software and the MCP hardware device. ( ..."
          ]
        },
        {
          "title": "Windows Common Criteria certifications | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/windows/security/security-foundations/certification/windows-platform-common-criteria",
          "excerpts": [
            "This topic lists the Windows products certified against the Common Criteria (current and archived), together with documentation from each certification."
          ]
        },
        {
          "title": "IEC 61508 - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/IEC_61508",
          "excerpts": [
            "For any given design the achieved SIL is evaluated by three measures: 1. Systematic Capability (SC) which is a measure of design quality. Each device in the ..."
          ]
        },
        {
          "title": "Back to Basics 14 - Systematic Capability - exida",
          "url": "https://www.exida.com/blog/Back-to-Basics-14-Systematic-Capability",
          "excerpts": [
            "Systematic Capability is achieved when the equipment used to implement any safety function achieves two goals: the design process has used procedures intended ..."
          ]
        },
        {
          "title": "SIL achievement Part 3: Systematic Capability - PR electronics",
          "url": "https://www.prelectronics.com/support/pr-knowledge-library/tips-and-tricks/sil-part-3-systematic-capability/",
          "excerpts": [
            "SIL achievement requires that the design of a safety function meets three specific criteria. This article concentrates on Systematic Capability."
          ]
        },
        {
          "title": "The seL4 Microkernel | seL4",
          "url": "http://sel4.systems/?utm_source=chatgpt.com",
          "excerpts": [
            "seL4 is both the world's most highly assured and the world's fastest\noperating system ke"
          ]
        },
        {
          "title": "IV&IV on Orion's ARINC 653 Flight Software Architecture",
          "url": "http://nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf?utm_source=chatgpt.com",
          "excerpts": [
            "ARINC 653 is a software time and space partitioning \nstandard for Real Time Operating Systems (RTOSs)",
            "ARINC 653 provides a level of fault protected operation.",
            " ARINC 653 standard supports Integrated Modular \nAvionics (IMA) architecture allowing appropriate \nintegration of avionics software of differing levels within a \nintegration of avionics",
            "ARINC 653 partitions provide a \nnatural division for CSCI definition",
            "The application of ARINC 653 architecture to FSW development provides potential \nSDD improvements, and potential CPU utilization issues increasing the complexity \nof specifying CPU utilization of computer resources and increasing overall \ndemands on the computer‚Äôs resourc",
            "DO 178B Software Considerations in Airborne \nSystems and Equipment Certification from RTC"
          ]
        },
        {
          "title": "ARINC 653 - Wikipedia",
          "url": "http://en.wikipedia.org/wiki/ARINC_653?utm_source=chatgpt.com",
          "excerpts": [
            "Each application software is called a **partition** and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "The standard defines a two-level hierarchical schedule. The first level schedules the partitions. This is a round-robin, fixed schedule that repeats a Major Time Frame. The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 P1-5 was updated to address [multicore](/wiki/Multicore \"Multicore\") processor architectures. Section 4.2.1 \"O/S Multicore Implementation Compliance\" indicates that an OS designed for multi-core processing should support two cases:\n\n* Use of multiple cores by a single partition (whose processes span multiple cores)\n* Use of multiple"
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "The standard defines a two-level hierarchical schedule. The first level schedules the partitions. This is a round-robin, fixed schedule that repeats a Major Time Frame. The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "OSDI: Operating Systems Design and Implementation",
          "url": "https://dl.acm.org/doi/proceedings/10.5555/3488766?tocHeading=heading12",
          "excerpts": [
            "Nov 4, 2020 ‚Äî OSDI'20: Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation ... RackSched: a microsecond-scale scheduler for¬†..."
          ]
        },
        {
          "title": "Certification Authorities Software Team (CAST) - FAA",
          "url": "https://www.faa.gov/aircraft/air_cert/design_approvals/air_software/cast",
          "excerpts": [
            "CAST has remained inactive since October 2016 and links to the past CAST papers have been removed from this site. The link to CAST-32A will be ..."
          ]
        },
        {
          "title": "World's First Multicore Avionics Certification to CAST-32A Uses the ...",
          "url": "https://www.ghs.com/news/20210316_CAST32A_certification_integrity.html",
          "excerpts": [
            "The INTEGRITY-178 tuMP multicore real-time operating system (RTOS) is the first operating system to be part of a multicore certification to RTCA/DO-178C and ..."
          ]
        },
        {
          "title": "AMC 20-193 & CAST-32A Multi-Core Processing Training - AFuzion",
          "url": "https://afuzion.com/aviation-safety-private-training/amc-20-193-multi-core-processing-with-cast-32a-training/",
          "excerpts": [
            "AFuzion offers expert AMC 20-193 & CAST-32A training for multi-core processing in avionics. Ensure compliance and safety with our courses."
          ]
        }
      ],
      "reasoning": "The field value describes a comprehensive program plan and a risk register for a Rust-only stack in a safety-critical setting with ARINC-653-style partitioning and formal certification considerations. Excerpts that explicitly discuss aviation-system certification standards (DO-178C, CAST-32A, ISO 26262), ARINC 653/APEX, and tooling/certification processes provide direct support for planning, risk assessment, and governance aspects central to the field. References that discuss the structure and scope of ARINC 653, partitioned scheduling, and certification workflows (DO-330 tool qualification, EAL considerations) are used to justify the governance, phase-based rollout, and risk management described in the fine-grained field value. Other excerpts that focus on hardware I/O, performance benchmarks, or generic OS design serve as contextual background but are less directly tied to the explicit program plan and risk register features. Consequently, the most relevant excerpts are those that anchor ARINC 653-based partitioning and avionics certification in a multi-phase plan with explicit risk and kill/pivot criteria, followed by excerpts detailing related tool-certification frameworks and multi-core safety guidance. The selected excerpts collectively map to the described phased plan, the certification landscape, and the risk-management approach, which justifies the field value as a coherent program plan and risk register for a Rust-first avionics stack.",
      "confidence": "medium"
    },
    {
      "field": "operating_system_layer_components.1.codename",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture."
          ]
        }
      ],
      "reasoning": "The target codename is described in the OS layer as a specific isolation mechanism called Protego Maxima, characterized by capability descriptors and ARINC-653 style partition isolation. This directly aligns with the requested field value, since the text identifies Protego Maxima as an isolation construct within the L1 OS architecture. The excerpt also elaborates on the nature ofProtego Maxima by associating it with isolation properties (spatial/temporal/I/O), which reinforces its role as a core security/partitioning feature. Other excerpts discuss ARINC 653, seL4, and scheduling or IPC concepts, but they do not mention the codename or its isolation semantics, so they provide no direct support for the field value beyond contextual background.",
      "confidence": "high"
    },
    {
      "field": "certification_roadmap.key_requirements",
      "citations": [
        {
          "title": "Officially Qualified - Ferrocene",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Nov 8, 2023 ‚Äî It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in T√úV S√úDs certificate database."
          ]
        },
        {
          "title": "CAST-32A Guidance for Multicore Processorss - Green Hills Software",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_standards_cast-32A.html",
          "excerpts": [
            "CAST-32A objectives can be challenging to meet, and multicore interference mitigation at the OS level is an effective way to achieve robust partitioning.",
            "CAST-32A is a position paper published by the Certification Authority Software Team (CAST) in 2016 providing guidance on the use of multicore processors in ..."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            ". The DO-330: Software Tool Qualification¬†... A further supplement was introduced in DO-178C, Software Tool Qualification Considerations (DO-330), which gives guidance on the qualification of tools used in software development and verification processes.",
            "DO-178C itself describes when a tool must be qualified, but does not go into detail on how this should be done.",
            "This guidance can be applied to any tools, not just those used for software development or verification, for example systems design or hardware development tools, and acts more like a stand-alone guidance document than the other supplements mentioned."
          ]
        },
        {
          "title": "Assurance of Multicore Processors in Airborne Systems",
          "url": "https://www.faa.gov/sites/faa.gov/files/aircraft/air_cert/design_approvals/air_software/TC-16-51.pdf",
          "excerpts": [
            "This report addresses software assurance for multicore processors (MCPs) in airborne systems, and their safety implications, including lack of predictability."
          ]
        },
        {
          "title": "CAST-32A: Development of avionics software for single-core ...",
          "url": "https://www.cast32a.com/",
          "excerpts": [
            "CAST-32A is a position paper identifying topics impacting safety, performance, and integrity of software on multi-core processors, published by the ..."
          ]
        },
        {
          "title": "PP_OS_V4.2.1 Protection Profile (Common Criteria)",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/PP_OS_V4.2.1.pdf",
          "excerpts": [
            "This Protection Profile describes the security functionality of operating systems, which manage hardware and software resources, and provides ... An OS is\ntypically part of offerings identified as Infrastructure as a Service (IaaS), Software as a Service (SaaS), and\nPlatform as a Service (PaaS). This use case typically involves the use of virtualization technology which should be evaluated against the\nProtection Profile for Server Virtualization. 5",
            "FCS_CKM.1 Cryptographic Key Generation (Refined)",
            "FCS_CKM.2 Cryptographic Key Establishment (Refined)",
            "To be conformant to this PP, a ST must demonstrate Exact Conformance, a subset of Strict Conformance as\ndefined in [CC] Part 1 (ASE_CCL). The ST must include all components in this PP that are:\n\nunconditional (which are always required)\nselection-based (which are required when certain selections are chosen in the unconditional\nrequirements)\n\nand may include components that are\n\noptional or\nobjective. Unconditional requirements are found in the main body of the document, while appendices contain the\nselection-based, optional, and objective requirements"
          ]
        }
      ],
      "reasoning": "The claim that a Ferrocene toolchain is pre-qualified for ISO 26262 and IEC 61508 directly supports the tool qualification requirement. It shows an established path for qualifying tooling to meet automotive and safety standards, which is a core part of achieving certification. Guidance and alignment for multicore processors and interference mitigation comes from CAST-32A-focused documents, which discuss strategies to manage shared resources and partitioning in multicore environments‚Äîprecisely the kind of analysis and architecture discipline needed to bound worst-case execution time and ensure determinism in safety-critical systems. The DO-178C guidance items provide a framework for when and how software tools and processes must be qualified, including general tool qualification considerations and the implications for verification processes, which aligns with the formal verification and tooling evidence required in a certification program. Additional CAST-32A materials elaborate on multicore timing and interference concerns, further reinforcing how to structure architectural and scheduling considerations to meet certification-level expectations. Documents discussing Common Criteria protection profiles extend the discussion to a broader security assurance lens, which can be relevant for a comprehensive certification argument if security is within scope. The Assurance-focused material on airborne multicore processors highlights practical assurances and lack of predictability concerns that safety certifications typically address, reinforcing the need for rigorous analysis and evidence. The CAST-32A guidance from multiple sources underlines the necessity of interference mitigation at the OS level, which is central to a robust certification strategy. Taken together, these excerpts collectively map onto the key components of the field value: tool qualification paths (Ferrocene ISO 26262/IEC 61508), multicore interference analysis and mitigation (CAST-32A, related timing analysis), safety case and work products (DO-178C tool qualification aspects and assurance reports), formal methods/traceability considerations (references to formal methods and model-based specifications), and coding standards considerations for safety-critical Rust (coding standard discussions in safety-critical contexts).",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.0.component_name",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS."
          ]
        }
      ],
      "reasoning": "The field value specifies a Real-time Partitioned Microkernel. Excerpts that describe ARINC 653 as a framework for space and time partitioning with partitioned software applications and dedicated memory spaces map directly to the concept of partitioning in a real-time microkernel environment. Articles describing Major Time Frames and round-robin partition scheduling further support the real-time, partitioned scheduling context that a partitioned microkernel would provide. References to a microkernel like seL4 provide corroborating context that microkernels exist in real-time security-focused ecosystems, though the ARINC 653 material is more central to the partitioned aspect. Taken together, these excerpts support the field value by connecting partitioning, real-time scheduling, and microkernel architecture concepts, with ARINC 653 as the concrete partitioning mechanism and seL4 as an example of a formally verified microkernel in a similar domain.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.0.function",
      "citations": [
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS.",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation"
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby.",
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica"
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        }
      ],
      "reasoning": "The targeted field value asserts that the L1 OS is the foundational real-time partitioned microkernel layer, delivering capability-style isolation and ARINC 653-like partitioning to enforce core security and separation guarantees. Excerpts that define ARINC 653‚Äîspecifying that software partitions have dedicated memory spaces and a fixed time-slot schedule‚Äîdirectly substantiate the partitioning and isolation aspects of the L1 layer. References that discuss ARINC 653 concepts and the partitioned architecture align with the role of the L1 OS as the base enforcement layer for separation guarantees. Excerpts describing seL4 emphasize that a capability-based security model and formal verification undergird a highly secure microkernel, which supports the notion of strong isolation guarantees and correctness of the core OS boundary, reinforcing the claim that the L1 layer provides fundamental security and separation guarantees. In this way, the ARINC 653-oriented excerpts establish the partitioning foundation, and the seL4-oriented excerpts bolster the security/verification properties attributed to the L1 layer. The remaining ARINC 653 excerpts add supporting detail about timing, partition durations, and memory separation that flesh out the practical aspects of partitioned, real-time operation. Overall, the most directly supportive pieces are those that spell out ARINC 653-style partitioning and dedicated partition memory/slots, followed by evidence of strong capability-based security and formal verification that underpins such a partitioned kernel.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.0.inspirations",
      "citations": [
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation",
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        }
      ],
      "reasoning": "The field value asserts two main inspirations: a formally verified, capability-based microkernel (seL4) and ARINC 653 APEX, which is a software specification for space and time partitioning in safety-critical avionics RTOS. Excerpts that explicitly describe seL4 as formally verified and capability-based provide direct support for the first part of the claim. Excerpts describing ARINC 653, its spatial and temporal isolation, and partition-based execution provide direct support for the second part of the claim. The excerpts about seL4 emphasize formal verification and security properties, which aligns with the description of seL4 as formally verified and capability-based. Excerpts detailing ARINC 653 explain that partitions have dedicated memory spaces and time partitioning under a partitioned API, which corroborates the ARINC 653 APEX inspiration. Together, these excerpts corroborate the field value by showing both components independently documented as inspirations in the OS architecture context. The most directly relevant parts are those that explicitly state seL4's formal verification and capability-based security, followed by ARINC 653's partitioning concepts, and finally general ARINC 653 overviews that underpin the idea of space/time partitioning and APX-level concepts.\n",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.1.function",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†...",
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 10.1.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-10.1.1.pdf",
          "excerpts": [
            "IOMMU on Intel x86-based platforms. An IOMMU allows memory to be remapped from the device's point of view. It acts as an MMU for the device ..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS.",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation"
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The fastpath is a hand-tuned implementation of the IPC (inter- process communication) paths through the seL4 kernel. These IPC paths are used to pass messages¬†..."
          ]
        }
      ],
      "reasoning": "The described L1 OS function corresponds to a partitioned, safety-critical real-time kernel that uses ARINC 653-style partitions with deterministic scheduling and a policy-enforcing mechanism for memory and I/O access. Direct statements about ARINC 653 define the platform as consisting of partitions with their own memory spaces and a fixed partition scheduling model, which aligns with the notion of an ARINC-style partition scheduler with major/minor frames and dedicated memory partitioning. The mention of APEX and inter-/intra-partition management in those excerpts reinforces the idea of a standardized partitioning API surface and its scheduling discipline, which underpin the core isolation guarantees described. An IOMMU policy enforcer is explicitly referenced in discussions of memory protection and device isolation, tying into the DMA protection aspect. To ground the isolation and capability aspects, excerpts that describe capability-based security (in seL4's whitepaper and related coverage on formally verified, capability-based kernels) support the broader architectural approach to access control and verification guarantees, even though the exact implementation details may differ from seL4. Additional ARINC 653 entries and real-world practice pieces illustrate how partition scheduling and time framing are implemented in real avionics contexts, which strengthens the mapping to a core L1 OS function responsible for enforcing spatial/temporal isolation and partitioned memory. The combination of ARINC 653 partitioning concepts, partition scheduling details, IOMMU policy enforcement, and capability-based security context collectively supports the fine-grained field value describing a core L1 OS component with those responsibilities.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.1.inspirations",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "This is a round-robin, fixed schedule that repeats a Major Time Frame . The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†...",
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS.",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation"
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 10.1.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-10.1.1.pdf",
          "excerpts": [
            "IOMMU on Intel x86-based platforms. An IOMMU allows memory to be remapped from the device's point of view. It acts as an MMU for the device ..."
          ]
        }
      ],
      "reasoning": "The field value points to ARINC 653 as the model for time/space partitioning and seL4 as the security model. ARINC 653 is described as a software specification for space and time partitioning in safety-critical RTOS, including concepts like partitions, memory isolation, and a partitioned schedule (e.g., a Major/Minor time frame with fixed Partition Time Windows). This directly supports ARINC 653 as the partitioning model in the OS layer. Additional ARINC 653 content emphasizes the APplication EXECutive (APEX) API scope, partition organization (each application as a partition with its own memory space), and partition scheduling semantics, which further corroborate ARINC 653 as the partitioning reference in the OS design. More excerpts outline ARINC 653 during overview discussions, reinforcing the partitioning framework as central to the OS layer. \n\nSeparately, seL4 is repeatedly described as the gold-standard for security through capability-based, formally verified kernels. Excerpts highlight seL4 as the world's only OS that is both capability-based and formally verified, with formal proofs of implementation correctness, which aligns with the security model requirement in the field value. Additional seL4-related excerpts discuss verification efforts, IPC paths, and formal verification results, which bolster the claim that seL4 underpins the security architecture in the reference stack. Overall, the selected excerpts collectively map ARINC 653 to the time/space partitioning aspect and seL4 to the capability-based security model in the requested field value. ",
      "confidence": "high"
    },
    {
      "field": "program_plan_and_risk_assessment.summary",
      "citations": [
        {
          "title": "Theseus OS Design and Concepts",
          "url": "https://www.theseus-os.com/Theseus/book/design/design.html",
          "excerpts": [
            "At implementation time, a cell is a crate.",
            "After compile (build) time, a cell is a single .o object file.",
            "file. * At runtime, a cell üÑ≤ is a structure that contains the set of sections üÖÇ from its crate object file, which have been dynamically loaded and linked into memory, as well as metadata about the inter-dependencies between it and others.",
            "Microkernels move as much kernel functionality as possible into separate user space \"system server\" processes, leaving the kernel itself very small.",
            "Microkernel OSes are less common, but still widespread in certain computing domains where reliability is key, such as embedded systems.",
            "This improves resiliency, as each kernel entity executes in user space in its own address space; if one crashes, the rest of the system can continue execution by restarting the failed system process."
          ]
        },
        {
          "title": "IV&IV on Orion's ARINC 653 Flight Software Architecture",
          "url": "http://nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf?utm_source=chatgpt.com",
          "excerpts": [
            "The application of ARINC 653 architecture to FSW development provides potential \nSDD improvements, and potential CPU utilization issues increasing the complexity \nof specifying CPU utilization of computer resources and increasing overall \ndemands on the computer‚Äôs resourc"
          ]
        },
        {
          "title": "ARINC 653 - Wikipedia",
          "url": "http://en.wikipedia.org/wiki/ARINC_653?utm_source=chatgpt.com",
          "excerpts": [
            "Each application software is called a **partition** and has its own memory space. It also has a dedicated time slot allocated by the APEX API."
          ]
        },
        {
          "title": "OSDI: Operating Systems Design and Implementation",
          "url": "https://dl.acm.org/doi/proceedings/10.5555/3488766?tocHeading=heading12",
          "excerpts": [
            "Nov 4, 2020 ‚Äî OSDI'20: Proceedings of the 14th USENIX Conference on Operating Systems Design and Implementation ... RackSched: a microsecond-scale scheduler for¬†..."
          ]
        },
        {
          "title": "World's First Multicore Avionics Certification to CAST-32A Uses the ...",
          "url": "https://www.ghs.com/news/20210316_CAST32A_certification_integrity.html",
          "excerpts": [
            "The INTEGRITY-178 tuMP multicore real-time operating system (RTOS) is the first operating system to be part of a multicore certification to RTCA/DO-178C and ..."
          ]
        },
        {
          "title": "Certification Authorities Software Team (CAST) - FAA",
          "url": "https://www.faa.gov/aircraft/air_cert/design_approvals/air_software/cast",
          "excerpts": [
            "CAST has remained inactive since October 2016 and links to the past CAST papers have been removed from this site. The link to CAST-32A will be ..."
          ]
        }
      ],
      "reasoning": "The most relevant parts directly describe a design philosophy of modularity and crates/cells in a Rust context, which mirrors the program's plan to deliver components as independent crates and to compose them into higher-level functionality. The cited passages discuss a multi-layer architecture where a component becomes a standalone unit (a cell) after build, and how crates and their interdependencies are shaped, which aligns with the planned phased delivery of independent crates. Additional highly relevant material describes a microkernel and partitioned approach to OS design, which maps to the Apex project's intent of a partitioned, safety-critical stack and its emphasis on determinism and certified separation between layers. References to ARINC 653, APEX-like interfaces, and multi-core partitioning provide concrete grounding in the certification and safety domain that the program explicitly references, situating the project within recognized avionics and safety standards. The material on safety-critical Rust, formal verification, and the CAST/ISO/DO-178C ecosystem helps explain the risk and certification constraints that would drive kill criteria and pivot options, as described in the risk register. The remaining excerpts contribute context about certification processes and safety standards, illustrating the kinds of compliance hurdles the plan would anticipate and address, even if they do not map one-to-one to every line of the summary. In short, the strongest support comes from discussions of crate/cell modularity in a Rust and microkernel context, then from partitioned/multi-layer OS architecture and ARINC 653-style interfaces, followed by safety/certification framing that informs risk and pivot points.",
      "confidence": "high"
    },
    {
      "field": "operating_system_layer_components.1.component_name",
      "citations": [
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "ARINC 653 (Avionics Application Software Standard Interface) is a software specification for space and time partitioning in safety-critical avionics real-time operating systems (RTOS). It allows the hosting of multiple applications of different software levels on the same hardware in the context of an Integrated Modular Avionics architecture.",
            "The ARINC 653 APEX services are API calls belonging in six categories:\n\nPartition management\nProcess management\nTime management\nInter-partition communication\nIntra-partition communication\nError handling",
            "ARINC 653 defines an API called APplication EXecutive (APEX).",
            "Each application software is called a partition and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "ARINC 653 P1-5 was updated to address multicore processor architectures."
          ]
        },
        {
          "title": "ARINC 653 Overview and Validation Framework",
          "url": "https://ieeexplore.ieee.org/document/7311458/",
          "excerpts": [
            "ARINC 653 requires spatial and temporal isolation between independent executing avionics applications, a.k.a. partitions."
          ]
        },
        {
          "title": "Building Real-Time Avionics: Best Practices with ARINC 653",
          "url": "https://arincinsider.com/building-real-time-avionics-best-practices-with-arinc-653/",
          "excerpts": [
            "Apr 25, 2024 ‚Äî Each partition is allocated a specific time frame during which it can execute its tasks without interruption from other partitions. This ensures¬†...",
            "Time partitioning involves dividing the system's execution time into discrete intervals, known as time frames or time slots. Each partition is ..."
          ]
        },
        {
          "title": "ARINC 653 and Apex Overview",
          "url": "https://scispace.com/pdf/space-time-partitioning-with-arinc-653-and-pragma-profile-giz5j94s6t.pdf",
          "excerpts": [
            "The ARINC Specification 653[1] provides the_\n\n_definition of an APplication EXecutive (APEX) that_\n\n_supports space and time partitioning of applica",
            "ARINC 653 systems are composed of software partitions. Each partition is a separate application and there is dedicated memory space for each partition thereby."
          ]
        },
        {
          "title": "seL4 Reference Manual Version 10.1.1",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-10.1.1.pdf",
          "excerpts": [
            "IOMMU on Intel x86-based platforms. An IOMMU allows memory to be remapped from the device's point of view. It acts as an MMU for the device ..."
          ]
        },
        {
          "title": "seL4 Whitepaper",
          "url": "https://sel4.systems/About/seL4-whitepaper.pdf",
          "excerpts": [
            "seL4 is still the world's only OS that is both capability-based and formally verified, and as such has a defensible claim of being the world's most secure OS.",
            "seL4¬†comes¬†with¬†a¬†formal,¬†mathematical,¬†machine-checked¬† proof¬†of implementation¬†correctness\n,¬†meaning¬†the¬†kernel¬†is¬†in¬†a¬†very¬†strong¬†sense¬†‚Äúbug\nfree‚Äù¬†with¬†respect¬†to¬†its¬†speciÔ¨Åcation"
          ]
        },
        {
          "title": "seL4 Reference Manual Version 11.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-11.0.0.pdf",
          "excerpts": [
            "Each userspace thread has an associated capability space (CSpace) that contains the capabilities that the thread possesses, thereby governing ..."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://sel4.systems/Research/pdfs/comprehensive-formal-verification-os-microkernel.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 551 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel.",
            "by G KLEIN ¬∑ Cited by 551 ‚Äî The fastpath is a hand-tuned implementation of the IPC (inter- process communication) paths through the seL4 kernel. These IPC paths are used to pass messages¬†..."
          ]
        },
        {
          "title": "seL4 and Apex-style threat model comparison (role-play / integrated analysis)",
          "url": "https://maxwellseefeld.org/sel4/",
          "excerpts": [
            "No Built-in Device Isolation: seL4 itself doesn't magically handle DMA or device memory ‚Äì it's up to the system builder to ensure devices are ... For example, direct memory access by devices can bypass the kernel, so the proofs assume any DMA either doesn‚Äôt interfere or is managed (or you use an IOMMU). These are r"
          ]
        },
        {
          "title": "Trustworthy isolation of DMA devices",
          "url": "https://link.springer.com/article/10.1007/s42786-020-00018-x",
          "excerpts": [
            "The main concern when DMACs are controlled by untrusted software is that the destination addresses of BDs can be set arbitrarily."
          ]
        },
        {
          "title": "IOMMU solutions for seL4 (take ARM SMMUv3 for instance)",
          "url": "https://sel4.systems/Foundation/Summit/2023/slides/day2-12-mao.pdf",
          "excerpts": [
            "The VMM and other components maintain their own IO domains through the unified kernel interfaces that\n\nsystematically manages all SMMU hardware abstracts"
          ]
        }
      ],
      "reasoning": "The field value pertains to how isolation and partitioning are enforced in an OS layer. The most directly relevant material outlines ARINC 653 as a software specification for space and time partitioning in safety-critical RTOS, including partition management and APEX APIs, which are central to enforcing isolation between partitions. Additional excerpts explain that each application runs in its own partition with dedicated memory and fixed time windows, which is a core aspect of partition enforcement. References to sequential partition scheduling, major/minor time frames, and partition-specific memory spaces further support the enforcement aspect. Beyond ARINC 653, explanations of the APEX API, partition scheduling, and non-overlapping execution windows reinforce the idea of explicit, enforced separation between partitions. Supporting material on capability-based security (as with seL4) and hardware-assisted isolation (IOMMU) complement the isolation narrative by describing mechanisms that prevent cross-partition interference at both software and hardware levels. Finally, practical notes on secure and deterministic execution, as well as discussion of DMA/IOMMU considerations, provide context on how isolation is maintained when devices and DMA are involved. Taken together, these excerpts consistently support the concept of enforced isolation and partitioning in an OS stack, via architectural partitioning (ARINC 653/APEX), scheduling guarantees, and hardware-assisted controls.",
      "confidence": "high"
    },
    {
      "field": "program_plan_and_risk_assessment.details",
      "citations": [
        {
          "title": "ARINC653P1-5: AVIONICS APPLICATION SOFTWARE STANDARD INTERFACE PART 1 REQUIRED SERVICES - SAE International",
          "url": "https://www.sae.org/standards/content/arinc653p1-5/",
          "excerpts": [
            "This standard defines a general-purpose Application/Executive (APEX) software interface between the Operating System of an avionics computer and the application software.",
            "The interface requirements between the application software and operating system services are defined in a manner that enables the application software to control the scheduling, communication, and status of internal processing elements.",
            "Supplement 5 adds multicore processor service capabilities."
          ]
        },
        {
          "title": "ARINC 653 - Wikipedia",
          "url": "http://en.wikipedia.org/wiki/ARINC_653?utm_source=chatgpt.com",
          "excerpts": [
            "Each application software is called a **partition** and has its own memory space. It also has a dedicated time slot allocated by the APEX API.",
            "The standard defines a two-level hierarchical schedule. The first level schedules the partitions. This is a round-robin, fixed schedule that repeats a Major Time Frame. The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame.",
            "ARINC 653 P1-5 was updated to address [multicore](/wiki/Multicore \"Multicore\") processor architectures. Section 4.2.1 \"O/S Multicore Implementation Compliance\" indicates that an OS designed for multi-core processing should support two cases:\n\n* Use of multiple cores by a single partition (whose processes span multiple cores)\n* Use of multiple"
          ]
        },
        {
          "title": "ARINC 653",
          "url": "https://en.wikipedia.org/wiki/ARINC_653",
          "excerpts": [
            "The standard defines a two-level hierarchical schedule. The first level schedules the partitions. This is a round-robin, fixed schedule that repeats a Major Time Frame. The Major Time Frame schedules each partition in a fixed duration Partition Time Window (sometimes called a Minor Time Frame) with a fixed Partition Time Window Offset from the start of the Major Time Frame."
          ]
        },
        {
          "title": "Green Hills Software INTEGRITY-178B Separation Kernel ...",
          "url": "https://www.commoncriteriaportal.org/files/epfiles/st_vid10362-st.pdf",
          "excerpts": [
            "May 31, 2010 ‚Äî The TOE manages access to memory, devices, communications and processor resources to ensure that partitions can be entirely separated and can¬†..."
          ]
        },
        {
          "title": "Zephyr Testing",
          "url": "https://zephyrproject.org/zephyr-testing/",
          "excerpts": [
            "Intel is working with TuV to get FuSa kernel parts of Zephyr certified. This presentation shows how we develop the test cases for FuSa ..."
          ]
        },
        {
          "title": "Preface - Real-Time Interrupt-driven Concurrency",
          "url": "https://rtic.rs/",
          "excerpts": [
            "RTIC is a hardware accelerated RTOS that utilizes the hardware such as the NVIC on Cortex-M MCUs, CLIC on RISC-V etc. to perform scheduling."
          ]
        },
        {
          "title": "LYNX MOSA.ic‚Ñ¢ for Mission Critical Systems",
          "url": "https://www.lynx.com/resources/lynx-mosaic-for-mission-critical-systems",
          "excerpts": [
            "LYNX MOSA.ic provides open flexibility on a robust foundation to meet rich system functionality needs for systems deployed in safety-critical environments."
          ]
        },
        {
          "title": "IV&IV on Orion's ARINC 653 Flight Software Architecture",
          "url": "http://nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf?utm_source=chatgpt.com",
          "excerpts": [
            "ARINC 653 provides a level of fault protected operation.",
            " ARINC 653 standard supports Integrated Modular \nAvionics (IMA) architecture allowing appropriate \nintegration of avionics software of differing levels within a \nintegration of avionics",
            "ARINC 653 partitions provide a \nnatural division for CSCI definition"
          ]
        },
        {
          "title": "How to achieve high performance pingora? ¬∑ Issue #227",
          "url": "https://github.com/cloudflare/pingora/issues/227",
          "excerpts": [
            "May 2, 2024 ‚Äî When I pressure tested pingora with wrk, I found that qps was low, general-purpose machines, and nginx was normal."
          ]
        }
      ],
      "reasoning": "The target field value outlines a concrete, phased plan centered on a partitioned, ARINC 653‚Äìstyle OS architecture with explicit components and interfaces. Excerpts detailing ARINC 653 and ARINC 653 P1-5 interfaces directly substantiate the architectural context of partitioned OS design and the required services interfaces that would underpin the first two phases (IPC fabric and partitioned scheduler). Paraphrasing these excerpts shows that ARINC 653 defines partitioned execution environments with time/space separation and APEX-like interfaces, which aligns with the field's Phase 1 IPC fabric and Phase 2 scheduling components. Additional excerpts that discuss ARINC 653 concepts and partitions reinforce the plan's architectural foundation, validating the staged delivery approach for partitioned OS features and their interfaces. The excerpts mentioning ARINC 653 specifics (APEX services, partition scheduling, and multicore partitioning) map cleanly onto the field's described components (Apparition IPC, Sorting Hat API, Protego Maxima) and its phased rollout. Contextual ARINC-653 references in general (Wikipedia pages and ARINC 653 overviews) provide supporting backdrop for the partitioning paradigm and timing semantics described in the plan. Finally, the excerpt about Pingora provides contextual relevance for the Networking/I/O and RS+IO pathways referenced in later phases, showing a real-world counterpart to the IO/IPC abstractions the plan proposes, though it is secondary to the ARINC/partitioning emphasis. In short, the strongest alignment comes from ARINC 653‚Äìrelated excerpts that articulate partitioned OS concepts and interfaces; supplementary ARINC/partitioning references and the Pingora note help situate the plan in a broader ecosystem of similar architectures and I/O stack considerations.",
      "confidence": "high"
    },
    {
      "field": "program_plan_and_risk_assessment.plan_section",
      "citations": [
        {
          "title": "ISO 26262 Certification and Confirmation Review (Spyro-soft article)",
          "url": "https://spyro-soft.com/blog/automotive/iso-26262",
          "excerpts": [
            "The safety plan and all required work products ‚Äì detail level can be tailored by an assessor; here also functional safety requirement management, including bidirectional traceability, can be verified.",
            "ISO 26262 supports the whole product safety lifecycle: from management, development, and production to service."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt describes a safety plan and required work products, noting that the level of detail can be tailored by the assessor and that the process supports verification of functional safety requirements and bidirectional traceability. This directly supports the concept of a comprehensive program plan and risk management activities embedded in certification workflows. The ISO 26262-related excerpt further reinforces that formal safety certification contexts demand structured planning, documentation, and traceability across the safety lifecycle, which maps to the notion of a comprehensive program plan and risk register as essential artifacts. Other excerpts address DO-178C, CAST-32A, and ARINC 653 considerations, which provide important context for safety certifications but do not explicitly cite a singular, overarching program plan and risk register artifact within their text. Taken together, these pieces suggest that in safety-critical programs, a formal, plan-level artifact paired with risk management and requirements traceability is indeed a core component of compliance work, aligning best with the target field value.",
      "confidence": "medium"
    },
    {
      "field": "security_and_compliance_modules",
      "citations": [
        {
          "title": "CAST-32A",
          "url": "https://en.wikipedia.org/wiki/CAST-32A",
          "excerpts": [
            "A key point is that Multi-core processor \"interference can affect execution timing behavior, including worst case execution time (WCET).\" Multi-core Processors ...",
            "Objectives. edit. The paper presents ten objectives that must be met for Design Assurance Level (DAL) A or B. Six of the objectives apply for DAL C. The paper ..."
          ]
        },
        {
          "title": "CAST-32A",
          "url": "https://handwiki.org/wiki/CAST-32A",
          "excerpts": [
            "Objectives. The paper presents ten objectives that must be met for Design Assurance Level (DAL) A or B. Six of the objectives apply for DAL C."
          ]
        },
        {
          "title": "ISO 26262 Software Development | ASIL D",
          "url": "https://www.embitel.com/automotive-software-development-as-per-the-iso-26262-standard-asil-d",
          "excerpts": [
            "Development of ASIL C Compliant Complex Device Drivers (CDD) for a Powertrain ECU ¬∑ Mutation Testing of automotive Electronic Power Steering for ASIL D¬†..."
          ]
        },
        {
          "title": "DO-178C SOFTWARE COMPLIANCE FOR AEROSPACE ...",
          "url": "https://alm.parasoft.com/hubfs/ebook-DO-178C-Software-Compliance-Aerospace-Defense.pdf",
          "excerpts": [
            "The following tables list the set of objectives and expected outputs based on each software design assurance level in order to ensure airworthiness. Table 2-5:¬†..."
          ]
        },
        {
          "title": "When and how to qualify tools according to ISO 26262",
          "url": "https://www.btc-embedded.com/when-and-how-to-qualify-tools-according-to-iso-26262/",
          "excerpts": [
            "This article will describe how to find out if a tool needs to be qualified and how to perform an ISO 26262 tool qualification."
          ]
        },
        {
          "title": "ISO 26262 Confidence in the use of software tools",
          "url": "https://heicon-ulm.de/en/iso-26262-confidence-in-the-use-of-softwar-tools-a-feasible-strategy/",
          "excerpts": [
            "What are the requirements of ISO 26262? First of all, according to ISO 26262, the Tool Confidence Level must be defined for a specific tool."
          ]
        },
        {
          "title": "DO-178C Guidance: Introduction to RTCA DO-178 ...",
          "url": "https://www.rapitasystems.com/do178",
          "excerpts": [
            "The Supporting Information (DO-248C) supplementary document includes FAQs relating to DO-178C, and the document is commonly referred to by the title Frequently Asked Questions.",
            "This guidance can be applied to any tools, not just those used for software development or verification, for example systems design or hardware development tools, and acts more like a stand-alone guidance document than the other supplements mentioned.",
            "DO-178C itself describes when a tool must be qualified, but does not go into detail on how this should be done.",
            ". The DO-330: Software Tool Qualification¬†... A further supplement was introduced in DO-178C, Software Tool Qualification Considerations (DO-330), which gives guidance on the qualification of tools used in software development and verification processes."
          ]
        },
        {
          "title": "DO-178C Objectives List | Must Read",
          "url": "https://thecloudstrap.com/do-178c-objectives-list/",
          "excerpts": [
            "The DO 178C Table A-5 contains the objectives of the ‚ÄúVerification of Outputs of Software Coding and Integration Process‚Äù. There are 9 objectives in Table A-5¬†..."
          ]
        },
        {
          "title": "ISO 26262",
          "url": "https://en.wikipedia.org/wiki/ISO_26262",
          "excerpts": [
            "ISO 26262, titled \"Road vehicles ‚Äì Functional safety\", is an international standard for functional safety of electrical and/or electronic systems"
          ]
        },
        {
          "title": "Assurance of Multicore Processors in Airborne Systems",
          "url": "https://www.faa.gov/sites/faa.gov/files/aircraft/air_cert/design_approvals/air_software/TC-16-51.pdf",
          "excerpts": [
            "This report addresses software assurance for multicore processors (MCPs) in airborne systems, and their safety implications, including lack of predictability."
          ]
        },
        {
          "title": "CAST-32A Compliance Update July 2021",
          "url": "https://www.rapitasystems.com/products/cast-32a-update-2021",
          "excerpts": [
            "Our template CAST-32A compliance documents offer a convenient blueprint that can be used to generate final DO-178C compliance documents. These documents can be¬†..."
          ]
        },
        {
          "title": "AC 20-193 - Use of Multi-Core Processors",
          "url": "https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentID/1036408",
          "excerpts": [
            "Number: 20-193 ; Title: Use of Multi-Core Processors ; Status: Active ; Date issued: 2024-01-08 ; Office of Primary Responsibility: AIR-622, Airframe Section¬†..."
          ]
        },
        {
          "title": "Officially Qualified - Ferrocene",
          "url": "https://ferrous-systems.com/blog/officially-qualified-ferrocene/",
          "excerpts": [
            "Nov 8, 2023 ‚Äî It's official: Ferrocene is ISO 26262 and IEC 61508 qualified! You can even find the certificate in T√úV S√úDs certificate database."
          ]
        },
        {
          "title": "Common Criteria OS Protection Profile (pp_os_v4.1.pdf)",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/pp_os_v4.1.pdf",
          "excerpts": [
            "The OS shall implement functionality to perform cryptographic\n\nq\n\nx\n\nkey establishment in accordance with a specified cryptographic\nkey establishment",
            "FCS_CKM.2(1) Cryptographic Key Establishment (Refined)",
            "ECC schemes using ‚ÄúNIST curves‚Äù P-256, P-384 and\n[selection: P-521 , no other curves ] that meet the following:\nFIPS PUB 186-4, ‚ÄúDigital Signature Standard (DSS)‚Äù,\nAppendix B.4 ,",
            "RSA schemes using cryptographic key sizes of 2048-bit or\ngreater that meet the following: [selection: FIPS PUB 186-4,\n‚ÄúDigital Signature Standard (DSS)‚Äù, Appendix B.3 , ANSI\nX9.31-1998, Section 4.1] ,",
            "The OS shall generate asymmetric cryptographic keys in\naccordance with a specified cryptographic key generation\nalgorithm [selection:",
            "FCS_CKM.1(1) Cryptographic Key Generation (Refined)",
            "The Security Functional Requirements included in this section are derived from Part 2 of\nthe Common Criteria for Information Technology Security Evaluation, Version 3.1,\nRevision 4, with additional extended functional components.",
            "The following sections provide both Common Criteria and technology terms used in this. Protection Profile.",
            "5.1 Security Functional Requirements"
          ]
        },
        {
          "title": "PP_OS_V4.2.1 Protection Profile (Common Criteria)",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/PP_OS_V4.2.1.pdf",
          "excerpts": [
            "The Security Functional Requirements included in this section are derived from Part 2 of the Common Criteria for\nInformation Technology Security Evaluation, Version 3.1, Revision 5, with additional extended functional\ncomponents.",
            "5.1 Security Functional Requirements",
            "3 Security Problem Definition",
            "2 Conformance Claims",
            "The evaluator will verify the correctness of the TSF's\nsignature using a known good implementation and the associated public\nkeys to verify the signatures. Test 2: Signature Verification Test. The evaluator will perform the\nSignature Verification test to verify the ability of the OS to recognize\nanother party's valid and invalid signatures.",
            "To be conformant to this PP, a ST must demonstrate Exact Conformance, a subset of Strict Conformance as\ndefined in [CC] Part 1 (ASE_CCL). The ST must include all components in this PP that are:\n\nunconditional (which are always required)\nselection-based (which are required when certain selections are chosen in the unconditional\nrequirements)\n\nand may include components that are\n\noptional or\nobjective. Unconditional requirements are found in the main body of the document, while appendices contain the\nselection-based, optional, and objective requirements",
            "FCS_CKM.2 Cryptographic Key Establishment (Refined)",
            "FCS_CKM.1 Cryptographic Key Generation (Refined)",
            "This Protection Profile describes the security functionality of operating systems, which manage hardware and software resources, and provides ... An OS is\ntypically part of offerings identified as Infrastructure as a Service (IaaS), Software as a Service (SaaS), and\nPlatform as a Service (PaaS). This use case typically involves the use of virtualization technology which should be evaluated against the\nProtection Profile for Server Virtualization. 5"
          ]
        },
        {
          "title": "Leveraging ISO26262 Tool Certification in IEC 61508",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2020/12/17/leveraging-iso-26262-tool-certification-in-iec-61508/",
          "excerpts": [
            "In each certification package, Siemens also details the use cases, development practices, configuration management, and issue tracking systems deployed to reinforce best in class software development.",
            "Siemens EDA performs extensive tool assessment and uses a third party auditor to officially certify the product meets best in class development process and standards.",
            "The final row of Table A.3 specifies ‚Äúproven in use‚Äù as a means of tool assessment.",
            "IEC 61508 provides direction in how project teams must qualify the tools used in their flow. However, compared to ISO 26262, this guidance does leave more room for interpretation.",
            "In the event that the tool is rated as TCL2 or TCL3, mitigation measures must be performed.",
            "Tool Confidence Level (TCL)**: A rating which combines **TI** and **TD** above. The determination of Tool Impact (TI) and Tool Detection (TD) determin",
            "Tool Error Detection (TD)**: The confidence in measures to prevent the tool from malfunctioning and producing erroneous outpu",
            "Tool Impact (TI)**: The possibility that a malfunction of a tool can introduce or fail to detect errors in a safety-related it",
            "ISO 26262:2018 Part 8 Clause 11 provides guidance in the qualification of software tools."
          ]
        },
        {
          "title": "IEC Certification Kit and Tool Qualification (MathWorks)",
          "url": "https://www.mathworks.com/products/iec-61508.html",
          "excerpts": [
            "Guidance for IEC 61508 and Related Standards",
            "Software Tool Qualification According to ISO 26262",
            "Classify and qualify MathWorks specification, design, code generation, and verification tools according to functional safety standards with the help of qualification artifacts and template documents.",
            "tool classification and tool qualification",
            "IEC Certification Kit provides tool classification and tool qualification work products, together with templates, certificates, and validation suites. You use the kit to streamline certification of your embedded systems to produce a complete and standard-compliant tool qualification package for ISO <sup>¬Æ</sup> 26262, IEC 61508, ISO 25119, EN 50128, EN 50657, and IEC 62304. "
          ]
        },
        {
          "title": "DO-330 Software Tool Qualification Considerations (LDRA doc)",
          "url": "https://ldra.com/do-330/",
          "excerpts": [
            "A(M)C 20-193 (formerly CAST-32A)",
            "Tool qualification is a vital part of the certification process for airborne systems and equipment",
            "The LDRA tool suite is a verification tool and therefore a criterion 3 tool.",
            "2. Development processes that could have an impact on the airborne software.",
            "**Criterion 2**\n\n1. Verification processes other than that automated by the tool, or\n2. Development processes that could have an impact on the airborne software",
            "**Criterion 2**",
            "**Criterion 2**",
            "Many safety-critical applications outside the civil aviation sector leverage one of the less demanding approaches to tool qualification, often citing evidence of acceptable assessment and leveraging tools that have been TUV certified to achieve it. However, most functional safety standards demand qualification to the level of tool verification for the most critical application classes.",
            "tor. DO-330 defines some tool qualification activities that are to be performed by the tool developer, but the primary responsibility rests with the tool users to show that the tool is appropriate and sufficiently reliable for their application. More information is available [here](",
            "DO-330/ED-215 introduces the concept of Tool Qualification Levels (TQL) which are assigned according to three criteria",
            "What are DO-330 tool qualification levels?",
            "What are DO-330 tool qualification levels?",
            "The TQSP includes four key documents designed to guide the user through the validation process. The process defined by these documents ensures the creation of evidential artefacts and the compilation of reports designed to summarize findings in a form appropriate to the standard.",
            "\n\nUnder the terms of DO-330/ED-215, tool qualification is required for every project. T√úV and similar approvals have no bearing on projects to which DO-330/ED-215 applies. Many vendors provide a collection of documentation including test cases with expected results and reporting processes. Usually known as Tool Qualification Kits or Tool Qualification Support Packs, these artefacts can be used to show whether a tool has been configured appropriately to provide the correct results in the tool chain in which it will be deployed. Referencing the LDRA tool suite as an example, the DO-330/ED-215 Tool Qualification Support Pack (TQSP) consists of five sub-packs, each of which can be specified as an ‚Äúoperational requirement‚Äù for the pertinent development project:",
            "An unqualified compiler or an auto-code generator from an UML tool would therefore fit criterion 1. A qualified version of the same UML tool would fit criterion 2, because its use is designed to reduce the overhead of code verification processes. The LDRA tool suite is a verification tool and therefore a criterion 3 tool.",
            "Civil aviation certification authorities require tool qualification on a project-by-project basis. The responsibility for showing the suitability of any tool falls on to the organization developing a civil aviation application.",
            "Irrespective of the application software level (for DO-178C, read Design Assurance Level or DAL) such a verification tool is always assigned Tool Qualification Level 5 ‚Äì the least demanding of the five levels (below).",
            "Tool qualification is a generic term to describe a process designed to ensure that the risk of a tool error impacting the safety of a system is acceptably low",
            "An unqualified compiler or an auto-code generator from an UML tool would therefore fit criterion 1. A qualified version of the same UML tool would fit criterion 2, because its use is designed to reduce the overhead of code verification processes.",
            "An unqualified compiler or an auto-code generator from an UML tool would therefore fit criterion 1. A qualified version of the same UML tool would fit criterion 2, because its use is designed to reduce the overhead of code verification processes.",
            "**Criterion 1**A tool whose output is part of the airborne software and thus could insert an error",
            "DO-330/ED-215 introduces the concept of Tool Qualification Levels (TQL) which are assigned according to three criteria:",
            "Tool qualification is a vital part of the certification process for airborne systems and equipment, as documented in the DO-330/ED-215 Software Tool Qualification Considerations.",
            "Tool qualification is a vital part of the certification process for airborne systems and equipment, as documented in the DO-330/ED-215 Software Tool Qualification Considerations.",
            "Tool qualification is a vital part of the certification process for airborne systems and equipment, as documented in the DO-330/ED-215 Software Tool Qualification Considerations."
          ]
        },
        {
          "title": "[PDF] Separation Kernel Protection Profile Revisited: Choices and Rationale",
          "url": "https://fm.csl.sri.com/LAW/2010/law2010-03-Levin-Nguyen-Irvine.pdf",
          "excerpts": [
            "The CC definition of assurance has changed over time. In CC Version 2.3 (against which the SKPP was evaluated), assurance is defined as ‚Äúgrounds for ..."
          ]
        },
        {
          "title": "NIAP - Protection Profile Details",
          "url": "https://www.niap-ccevs.org/protectionprofiles/469",
          "excerpts": [
            "Mar 27, 2023 ‚Äî The scope of this Protection Profile (PP) is to describe the security functionality of operating systems in terms of [CC] and to define functional and¬†..."
          ]
        },
        {
          "title": "Part 3: Security assurance requirements - Page Notes",
          "url": "https://pagenotes.com/writings/ccToolbox6f/CCManual/PART3/PART3CONTENTS.HTM",
          "excerpts": [
            "Part 3 Contents ; 2.6.6, Class ATE: Tests ; 2.6.7, Class AVA: Vulnerability assessment ; 2.7, Maintenance categorisation ; 2.8, Maintenance of assurance class and¬†..."
          ]
        },
        {
          "title": "Security assurance components April 2017 Version 3.1 ...",
          "url": "https://www.commoncriteriaportal.org/files/ccfiles/CCPART3V3.1R5.pdf",
          "excerpts": [
            "Apr 1, 2017 ‚Äî This CC Part 3 catalogues the set of assurance components, families and classes. This CC Part 3 also defines evaluation criteria for PPs and¬†..."
          ]
        },
        {
          "title": "[PDF] US Government Protection Profile for Separation Kernels In ...",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/pp_skpp_hr_v1.03.pdf",
          "excerpts": [
            "This protection profile (‚ÄúSKPP‚Äù) specifies requirements for a separation kernel TOE, inclusive of its underlying platform. 2. , assured to ..."
          ]
        },
        {
          "title": "Operating System Protection Profile",
          "url": "https://www.commoncriteriaportal.org/files/ppfiles/pp0067b_pdf.pdf",
          "excerpts": [
            "The OSPP is defined as an extensible framework. The current set of OSPP extended packages can be enhanced with newly-developed or updated ...",
            "Jun 1, 2010 ‚Äî 1 Protection Profile Introduction. This document defines the security functionality expected to be provided by a general-purpose operating¬†..."
          ]
        },
        {
          "title": "CC2022PART3R1.pdf",
          "url": "https://www.commoncriteriaportal.org/files/ccfiles/CC2022PART3R1.pdf",
          "excerpts": [
            "CC:2022 consists of the following parts: ‚Äî Part 1: Introduction and general model. ‚Äî Part 2: Security functional components. ‚Äî Part 3: Security assurance¬†..."
          ]
        },
        {
          "title": "Protection Profile Details - NIAP",
          "url": "https://www.niap-ccevs.org/protectionprofiles/65",
          "excerpts": [
            "This protection profile specifies security for separation kernels, which partition systems and enforce information flow, providing a robust foundation for ..."
          ]
        },
        {
          "title": "Which Tools Should I Use for ASIL D Requirement ...",
          "url": "https://www.lhpes.com/blog/which-tools-should-i-use-for-asil-d-requirement-management-iso-26262-/-iec-61508",
          "excerpts": [
            "Jun 4, 2020 ‚Äî This blog will describe why selecting a tool based on one specific departmental need, such as requirements management, might be impractical."
          ]
        },
        {
          "title": "What Is IEC 61508? Determining Safety Integrity Levels ...",
          "url": "https://www.perforce.com/blog/qac/what-iec-61508-safety-integrity-levels-sils",
          "excerpts": [
            "Jan 31, 2019 ‚Äî IEC 61508 is an international functional safety standard and it provides a framework for safety lifecycle activities."
          ]
        },
        {
          "title": "IEC 61508: A comprehensive guide to functional safety ...",
          "url": "https://spyro-soft.com/blog/industry-4-0/iec-61508",
          "excerpts": [
            "It provides a framework for designing, implementing, operating, and maintaining safety-related systems to reduce risks to a tolerable level.",
            "Apr 4, 2025 ‚Äî Similarly, IEC 61508-3 outlines the software safety lifecycle requirements in clause 7, illustrated in Figure 3 and summarised in Table 1."
          ]
        },
        {
          "title": "Clearing the Fog of ISO 26262 Tool Qualification",
          "url": "https://blogs.sw.siemens.com/verificationhorizons/2022/04/13/clearing-the-fog-of-iso-26262-tool-qualification/",
          "excerpts": [
            "The setting of TI and TD ultimately determines the TCL for the tool based on the table below, found in ISO 26262-8:2018 Clause 11.4.5. It is ..."
          ]
        },
        {
          "title": "[PDF] Qualifying Software Tools According to ISO 26262 - MathWorks",
          "url": "https://www.mathworks.com/content/dam/mathworks/tag-team/Objects/m/61793_CMR10-16.pdf",
          "excerpts": [
            "by M Conrad ¬∑ Cited by 36 ‚Äî ISO 26262 tool qualification is needed if a tool can insert errors, its output isn't verified, or its output meets/replaces DO-178B objectives. It provides ...",
            "Tool Error Detection (TD) The degree of confidence, that a malfunction or an erroneous output from the tool can be prevented or detected, determines the tool ..."
          ]
        },
        {
          "title": "IEC 61508 (all parts)",
          "url": "https://www.gt-engineering.it/en/insights/functional-safety-300321/iec-61508-all-parts/",
          "excerpts": [
            "The overall title of IEC 61508 is 'Functional Safety of electrical, electronic and programmable electronic (E/E/PE) safety-related systems'. It has eight parts."
          ]
        },
        {
          "title": "Confidence in the use of software tools in AI/ML development",
          "url": "https://www.renesas.com/en/blogs/renesas-fusa-support-automotive-4-confidence-use-software-tools-aiml-development?srsltid=AfmBOooWYnFA3Rd6gIsVqT6s9CmCylUBH4UjaQc3g1_0de71X__Oo0Ts",
          "excerpts": [
            "In ISO 26262:2018 part 8 clause 112, requirements and recommendations are given to increase confidence in the use of software tools in a safety ..."
          ]
        },
        {
          "title": "Software Tool Qualification in ISO 26262 Development - Embitel",
          "url": "https://www.embitel.com/blog/embedded-blog/why-is-software-tool-qualification-indispensable-in-iso-26262-based-software-development",
          "excerpts": [
            "A tool qualification is required to demonstrate tool reliability. And when we have the TCL, we refer to the ISO 26262 standard Part-8 Table 4 ..."
          ]
        },
        {
          "title": "[PDF] A Commercial Solution for Safety-Critical Multicore Timing Analysis",
          "url": "https://mastecs-project.eu/sites/default/files/MC-WP-013%20MASTECS_BRANDED%20%E2%80%93%20A%20Commercial%20Solution%20for%20Safety-Critical%20Multicore%20Timing%20Analysis%20v1.pdf",
          "excerpts": [
            "The multicore timing analysis solution is comprised of tools, documents and services designed to meet DO-178C (CAST-32A/A(M). C 20-193) and ISO 26262 guidelines ..."
          ]
        },
        {
          "title": "CAST-32A Guidance for Multicore Processorss - Green Hills Software",
          "url": "https://www.ghs.com/products/safety_critical/integrity_178_standards_cast-32A.html",
          "excerpts": [
            "CAST-32A is a position paper published by the Certification Authority Software Team (CAST) in 2016 providing guidance on the use of multicore processors in¬†...",
            "CAST-32A objectives can be challenging to meet, and multicore interference mitigation at the OS level is an effective way to achieve robust partitioning.",
            "CAST-32A is a position paper published by the Certification Authority Software Team (CAST) in 2016 providing guidance on the use of multicore processors in ..."
          ]
        },
        {
          "title": "CAST-32A: Development of avionics software for single-core ...",
          "url": "https://www.cast32a.com/",
          "excerpts": [
            "The purpose of this CAST paper is to identify topics that could impact the safety, performance and integrity of a software airborne system executing on Multi-¬†...",
            "Software running on multicore processors can be subject to interference caused by contention for shared resources and other hardware idiosyncrasies that are ...",
            "DO-178 guidance was created to support the development of avionics software for single-core processors. Software running on multicore processors can be subject¬†...",
            "CAST-32A is a position paper identifying topics impacting safety, performance, and integrity of software on multi-core processors, published by the ..."
          ]
        },
        {
          "title": "RTCA DO-330/EUROCAE ED-215",
          "url": "https://www.rapitasystems.com/do-330",
          "excerpts": [
            "Tool qualification levels ; Criteria 1: output is part of the airborne software; could insert an error. TQL-1, TQL-2, TQL-3, TQL-4."
          ]
        },
        {
          "title": "Your Complete DO-178C Guide to Aerospace Software Compliance",
          "url": "https://ldra.com/do-178/",
          "excerpts": [
            "Tool Qualification. DO-178C requires that development tools are qualified for use on a compliant system. The LDRA Tool Qualification Support Packs (TQSPs)¬†...",
            "DO-330 provides guidance in the achievement of DO-178C tool qualification and DO-278C tool qualification for tools to be used in the pursuit of compliance ..."
          ]
        },
        {
          "title": "Aviation Development & Certification Tech Info - AFuzion",
          "url": "https://afuzion.com/aviation-development-certification-tech-info/",
          "excerpts": [
            "DO-178/DO-330 Tool Qualification details are provided in DO-178C Training courses, simply contact AFuzion. Depending on the tool criteria and design assurance ..."
          ]
        },
        {
          "title": "DO-330 Introduction ‚Äì Tool Qualification",
          "url": "https://afuzion.com/do-330-introduction-tool-qualification/",
          "excerpts": [
            "This DO-330 whitepaper describes the five tool categories versus criticality levels (DALs) and how to truly qualify avionics software tools."
          ]
        },
        {
          "title": "Intel TDX Connect Interoperability",
          "url": "https://cdrdv2-public.intel.com/772642/whitepaper-tee-io-device-guide-v0-6-5.pdf",
          "excerpts": [
            "Intel TDX Connect] for more detail. Figure A-2: Trusted DMA Flow \n\n \n\nMSI-X \nThe TDX Connect host does not support Trusted MSI. The device must not use MSI/X requests for TEE-IO transactions. The device must not set the MSI/X locking flag as part as device interface TDISP lock request. The device shall clear MSI_X_MESSAGE_CONTROL in TDI Report Structure. Appendix A: Intel¬Æ TDX Connect Interoperability \n\n \n \n\n \n\n64 \n \n \n \n \n \n \n \nDocument Number:  354272-001\t\n\nATS \nThe TDX Connect host does not support ATS. The device must not",
            "DMA Access Control \nThe memory resource in TDX Connect host is defined as following: \n\n‚Ä¢ \nPrivate Memory: The physical memory range whose GPA.S = 0 with private HKID. It is \nTEE memory in TDX Connect host. ‚Ä¢ \nShared Memory: All other memory which is not private memory. It is Non-TEE memory \nin TDX Connect host. Note: The device does not know if the host memory is private memory or shared memory, \naccording to [PCIe TDISP ",
            "Appendix A specifies the specific requirements for TEE-IO device interoperability with \nthe TDX Connect architecture",
            "Chapter 4 describes intra-device security requirements including isolation, integrity, \nand confidentiality protection of TDI and TVM private data, device identity, and \nmeasurement reporting and device firmware updat"
          ]
        },
        {
          "title": "MIT CSAIL/ASIACCS Sok Paper (2024) - Trusted Execution Environments and SRE Attestation",
          "url": "https://people.csail.mit.edu/mengyuanli/files/asiaccs_sok.pdf",
          "excerpts": [
            "Trusted execution environment (TEE) is a revolutionary technology that enables secure remote execution (SRE) of cloud workloads on untrusted server-side¬†... Specifically, a TEE design with the SRE feature must\nhave the following security properties [80]: (1) Secure Measurement:\nIt should provide a measurement of the underlying hardware plat-\nform and the initial states of the TEE instance that could be used for\nremote attestation; (2) Confidentiality: It should keep the inner data\nof the TEE instances confidential against software and physical\n(optional) adversaries; (3) Integrity: It should prevent unauthorized\ntempering of the code and data of the TEE instances."
          ]
        },
        {
          "title": "Intel TDX Module Base Spec",
          "url": "https://cdrdv2-public.intel.com/853286/intel-tdx-module-base-spec-348549006.pdf",
          "excerpts": [
            "This is intended to allow the host to instantiate a Quoting Enclave for Intel SGX attestations and another \nQuoting Enclave for TD attestation without interference",
            "The Intel SGX attestation architecture is designed to provide facilities for multiple Quoting Enclaves from multiple \nproviders",
            "The Quoting TD itself is certified by a Security \n20 \n\nEngine-based Attest",
            "he quoting enclave for Intel SGX and for Intel TDX may be separate; the design does not require the quoting enclave to \nrun inside the TD.",
            "Platforms that support Intel SGX can support Quoting Enclaves producing either TDX or SGX Quotes. A TD Quoting \nEnclave, when available, will produce legacy quotes for TDX"
          ]
        },
        {
          "title": "Intel¬Æ Virtualization Technology for Direct I/O Architecture Specification",
          "url": "https://cdrdv2-public.intel.com/671081/vt-directed-io-spec.pdf",
          "excerpts": [
            "Each device-driver explicitly registers its I/O buffers with the OS, and \nthe OS assigns these I/O buffers to specific domains, using hardware to enforce DMA domain \nprotectio",
            "DMA remapping provides hardware support for isolation of device accesses to memory, and enables \neach device in the system to be assigned to a specific domain through a distinct set of paging \nstructure"
          ]
        },
        {
          "title": "Intel SGX Attestation Technical Details",
          "url": "https://www.intel.com/content/www/us/en/security-center/technical-details/sgx-attestation-technical-details.html",
          "excerpts": [
            " to enable parties utilizing Intel SGX to determine whether updates for vulnerabilities have been applied on the platform from which attestation requests originate. Even with updates for vulnerabilities",
            "m. The Intel SGX Trusted Computing Base (TCB) is comprised of the components in the platform that are required to implement the Intel SGX security objectives.",
            "Attestation allows a remote party to gain confidence that the intended software is securely running within an enclave on a fully patched, Intel SGX enabled platform.",
            "Attestation is the process of demonstrating that a software executable has been properly instantiated on a platform."
          ]
        },
        {
          "title": "Introduction to Memory Bandwidth Allocation - Intel",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/introduction-to-memory-bandwidth-allocation.html",
          "excerpts": [
            "The MBA feature extends the shared resource control infrastructure introduced with CAT, described in a series of articles beginning with ..."
          ]
        },
        {
          "title": "Poor performance after update with message about side ...",
          "url": "https://communities.vmware.com/t5/VMware-Workstation-Player/Poor-performance-after-update-with-message-about-side-channel/td-p/2811429",
          "excerpts": [
            "You are running this virtual machine with side channel mitigations enabled. Side channel mitigations provide enhanced security but also lower performance."
          ]
        },
        {
          "title": "Intel TDX Security and Side Channels - #3 by PradyumnaShome",
          "url": "https://collective.flashbots.net/t/intel-tdx-security-and-side-channels/3648/3",
          "excerpts": [
            "Intel TDX does come with several side-channel mitigations based on lessons learned from the last decade of Intel SGX vulnerabilities."
          ]
        },
        {
          "title": "Intel¬Æ Virtualization Technology for Directed I/O ...",
          "url": "https://www.intel.com/content/www/us/en/content-details/774206/intel-virtualization-technology-for-directed-i-o-architecture-specification.html",
          "excerpts": [
            "This document describes the Intel¬Æ Virtualization Technology for Directed I/O. For all Intel¬Æ 64 and IA-32 Architectures Software Developer¬†..."
          ]
        },
        {
          "title": "180204-sgx-sdk-developer-guidance-v1-0.pdf",
          "url": "https://www.intel.com/content/dam/develop/external/us/en/documents/180204-sgx-sdk-developer-guidance-v1-0.pdf",
          "excerpts": [
            "In this document we will identify changes that have been made to the Intel¬Æ SGX Software. Developer's Kit (SDK) and provide clarifying guidance on what the ..."
          ]
        },
        {
          "title": "Tutorial: Uncovering and Mitigating Side-Channel Leakage ...",
          "url": "https://vanbulck.net/files/space18-tutorial.pdf",
          "excerpts": [
            "by J Van Bulck ¬∑ Cited by 4 ‚Äî This tutorial and write-up therefore aims to bring a better understanding of current state-of-the-art side-channel attacks and defenses on Intel SGX platforms."
          ]
        },
        {
          "title": "AMD Secure Encrypted Virtualization (SEV)",
          "url": "https://www.amd.com/en/developer/sev.html",
          "excerpts": [
            "Missing: REPORT_DATA SNP_GET_REPORT"
          ]
        },
        {
          "title": "Full Disk Encryption with Intel¬Æ Trust Domain Extensions",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/disk-encryption-intel-trust-domain-trust-authority.html",
          "excerpts": [
            "Get the attestation quote. Retrieve the key using the key ID of the encrypted root partition from the KBS. Decrypt the encrypted partition and mount it as the ..."
          ]
        },
        {
          "title": "draft-ffm-rats-cca-token-01 - Arm's Confidential Compute ...",
          "url": "https://datatracker.ietf.org/doc/draft-ffm-rats-cca-token/",
          "excerpts": [
            "The CCA attestation token is a profile of the Entity Attestation Token (EAT). ... Arm's Confidential Computing Architecture (Arm CCA) Attestation ..."
          ]
        },
        {
          "title": "draft-ydb-rats-cca-endorsements-02 - A CoRIM Profile for Arm's ...",
          "url": "https://datatracker.ietf.org/doc/draft-ydb-rats-cca-endorsements/",
          "excerpts": [
            "Arm Confidential Computing Architecture (CCA) Endorsements comprise reference values and cryptographic key material that a Verifier needs to appraise ..."
          ]
        },
        {
          "title": "MKTME Side Channel Impact on Intel TDX",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/software-security-guidance/best-practices/mktme-side-channel-impact-on-intel-tdx.html",
          "excerpts": [
            "Intel TDX helps mitigate a variety of potential attacks in virtualized systems with an untrusted, even potentially malicious, Virtual Machine Monitor (VMM)."
          ]
        },
        {
          "title": "VMs with side channel mitigations enabled may exhibit ...",
          "url": "https://knowledge.broadcom.com/external/article/315649/vms-with-side-channel-mitigations-enable.html",
          "excerpts": [
            "The root cause of the performance degradation is most likely due to mitigations for side channel attacks such as Spectre and Meltdown."
          ]
        },
        {
          "title": "AMD I/O Virtualization Technology (IOMMU) Specification",
          "url": "https://kib.kiev.ua/x86docs/AMD/IOMMU/48882-2.00.pdf",
          "excerpts": [
            "by I AMD ¬∑ Cited by 87 ‚Äî This document is the AMD I/O Virtualization Technology (IOMMU) Specification, a legal agreement for planning and designing products to¬†..."
          ]
        },
        {
          "title": "AMD I/O Virtualization Technology (IOMMU) Specification, ...",
          "url": "https://www.amd.com/content/dam/amd/en/documents/processor-tech-docs/specifications/48882_IOMMU.pdf",
          "excerpts": [
            "This is the AMD I/O Virtualization Technology (IOMMU) Specification, version 3.10, published in February 2025."
          ]
        },
        {
          "title": "Concurrent `SNP_GET_REPORT` requests result in reports with ...",
          "url": "https://github.com/AMDESE/AMDSEV/issues/265",
          "excerpts": [
            "This means concurrent SNP_GET_REPORT requests can now overwrite each other's data. The following Python script demonstrates the issue. It ..."
          ]
        },
        {
          "title": "Attestation Services for Intel¬Æ Software Guard Extensions",
          "url": "https://www.intel.com/content/www/us/en/developer/tools/software-guard-extensions/attestation-services.html",
          "excerpts": [
            "ECDSA-based attestation with Intel SGX DCAP allows providers to build and deliver their own attestation service. This is useful for enterprise, data center, and¬†..."
          ]
        },
        {
          "title": "Infrastructure Setup - Intel¬Æ TDX Enabling Guide",
          "url": "https://cc-enabling.trustedservices.intel.com/intel-tdx-enabling-guide/02/infrastructure_setup/",
          "excerpts": [
            "At its core, remote attestation is a process used by software to demonstrate to a remote party that the software has been properly instantiated on a platform."
          ]
        },
        {
          "title": "Intel SGX Developer Guide",
          "url": "https://community.intel.com/legacyfs/online/drupal_files/managed/33/70/intel-sgx-developer-guide.pdf",
          "excerpts": [
            "This side-channel vulnerability can be mitigated by \naligning specific code and data blocks to exist entirely within a single page",
            "An attacker with access to the platform can see what pages are being \nexecuted or accessed",
            "This scenario would be classified as a side-channel \nattack, and it would be up to the ISV to design the enclave in a way that pre-\nvents the leaking of side-channel informati",
            "An enclave must be designed in such a way that it prevents leaking side-channel information that would allow an attacker, who is looking at the untrusted ...",
            "Protection from Side-Channel Attacks",
            "The Intel¬Æ Software Guard Extensions (Intel¬Æ SGX) Developer Guide provides guidance on how to develop robust application enclaves based on Intel SGX technology. Wit"
          ]
        },
        {
          "title": "[PDF] A Practical Approach to CAST-32A & AMC 20-193 Compliance",
          "url": "https://data.embeddedcomputing.com/uploads/articles/whitepapers/16589.pdf",
          "excerpts": [
            "CAST-32A, ‚ÄúMulti-core processors‚Äù, is a position paper that was written by the Certification Authorities. Software Team (CAST). CAST were a group of civil¬†...",
            "The MCP_Software_2 objective in both CAST-32A & AMC 20-193 extends those principles to consider data and control coupling across cores. This includes specific ...",
            "CAST-32A, ‚ÄúMulti-core processors‚Äù, is a position paper that was written by the Certification Authorities. Software Team (CAST). CAST were a group of civil ...",
            "CAST-32A, ‚ÄúMulti-core ... The key objective is to ensure that these tasks all have time to finish in their allotted times and can't interfere with each."
          ]
        },
        {
          "title": "AC 20-193 and AMC 20-193 | Rapita Systems",
          "url": "https://www.rapitasystems.com/amc-20-193",
          "excerpts": [
            "The A(M)C 20-193 guidance is a joint effort by the FAA and EASA that supersedes the information in position paper \"CAST-32A: Multi-core Processors\"."
          ]
        },
        {
          "title": "Understanding CAST-32A and A(M)C 20-193 - LDRA",
          "url": "https://ldra.com/amc20-193/",
          "excerpts": [
            "A(M)C 20-193 complements the pre-existing DAL framework used in documents like DO‚Äë178C and DO-254 and addresses the challenges in the adoption of MCPs in hard ...",
            "MCP\\_Resource\\_Usage\\_3\n\n*‚ÄúThe applicant has identified the interference channels that could permit interference to affect the software applications hosted on the MCP cores, and has verified the applicant‚Äôs chosen means of mitigation of the interferenc",
            "LDRA‚Äôs solution adopts a ‚Äúwrapper‚Äù principle which affords the flexibility to perform execution time analysis from complete system behaviour, through a thread or process, right down to class/function/procedure level",
            "A(M)C 20-193 and DO-297 Integrated Modular Avionics (IMA)",
            "Specifically, Defence Standard 00-970 has been updated to reference AMC 20-193 as the Acceptable Means of Compliance (AMC) for certifying multi-core processors ..."
          ]
        },
        {
          "title": "DO-326A / ED-202A Aviation Cyber-Security (Backup Copy) - AFuzion",
          "url": "https://afuzion.com/do-326a-ed-202a-aviation-cyber-security-copy/",
          "excerpts": [
            "DO-326 and ED-202 are the first of a series of documents on Aeronautical Systems Security that together will address information security."
          ]
        },
        {
          "title": "DO-326A/ED-202A Trusted Aerospace Cybersecurity ...",
          "url": "https://ldra.com/aerospace-security-framework/",
          "excerpts": [
            "DO-356A/ED-203A introduces the concept of Security Assurance Levels from 0-3, with 3 being the most critical and hence most demanding. The airworthy security ..."
          ]
        },
        {
          "title": "[PDF] Leveraging-Attestations-with-TEE-based-applications-on-Azure ...",
          "url": "https://download.microsoft.com/download/e/0/3/e03ff018-35ac-4bac-9638-3e45787bc23c/Leveraging-Attestations-with-TEE-based-applications-on-Azure-(July-2020).pdf",
          "excerpts": [
            "This guide for developers is intended to illustrate how to leverage attestation along with so-called Trusted Execution. Environment (TEE) based applications ..."
          ]
        },
        {
          "title": "mitigating effects of ciphertext visibility under amd sev",
          "url": "https://www.amd.com/content/dam/amd/en/documents/resources/bulletin/technical-guidance-for-mitigating-effects-of-ciphertext-visibility-under-amd-sev.pdf",
          "excerpts": [
            "As a result, this helps protect values in the general-purpose registers of an SEV-SNP guest from side channel attacks based on ciphertext visibility. The¬†..."
          ]
        },
        {
          "title": "CPU Architecture Security Features",
          "url": "https://www.arm.com/architecture/security-features",
          "excerpts": [
            "The Arm architecture includes technologies that help to defend against control-flow attacks, data-access attacks, and mitigations against side-channel attacks."
          ]
        },
        {
          "title": "Arm CCA Security Model 1.0",
          "url": "https://documentation-service.arm.com/static/610aaec33d73a34b640e333b?token=",
          "excerpts": [
            "Feb 8, 2021 ‚Äî exposure to side-channel and memory corruption attacks. Without integrity protected external memory, both RMM and Realms may be exposed to¬†..."
          ]
        },
        {
          "title": "SEV Ciphertext Side Channel Attacks",
          "url": "https://www.amd.com/en/resources/product-security/bulletin/amd-sb-3021.html",
          "excerpts": [
            "Aug 12, 2025 ‚Äî For more information on best-practices regarding ciphertext side-channel attacks, see our whitepaper ‚ÄúTechnical Guidance for Mitigation Effects¬†..."
          ]
        },
        {
          "title": "Intel TDX Security and Side Channels - Research",
          "url": "https://collective.flashbots.net/t/intel-tdx-security-and-side-channels/3648",
          "excerpts": [
            "Intel TDX is a trusted execution environment, allowing one to run virtual machines which need confidentiality and integrity (but not availability!) guarantees.",
            "Jul 6, 2024 ‚Äî TDX is capable of detecting interference to the CPU such as modifying existing instructions or injecting new instructions in private memory."
          ]
        },
        {
          "title": "Attest an Amazon EC2 instance with AMD SEV-SNP",
          "url": "https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/snp-attestation.html",
          "excerpts": [
            "The AMD SEV-SNP attestation report contains a cryptographic hash, called the launch measurement, of the initial guest memory contents and initial vCPU state."
          ]
        },
        {
          "title": "Azure Attestation overview | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/azure/attestation/overview",
          "excerpts": [
            "Validate binding of Azure Attestation TEE report with the key that signed the attestation token ‚Äì The relying party can verify whether the hash ..."
          ]
        },
        {
          "title": "sIOPMP: Scalable and Efficient I/O Protection for TEEs",
          "url": "https://ipads.se.sjtu.edu.cn/_media/publications/feng-asplos24.pdf",
          "excerpts": [
            "It also\nadopts the mountable IOPMP and IOPMP remapping mech-\nanism that balance the performance and scalability between\ncold and hot device",
            "sIOPMP uses a Multi-\nstage-Tree-based IOPMP checker that supports 1000 IOPMP\nentries without compromising the clock fre",
            "sIOPMP introduces several micro-architecture optimizations\nlike the tree-based pipeline checker, which is not explored\nin prior systems.",
            "To address the above problems, TEE systems have further\nproposed TEE-IO specifications: SEV-TIO [15], TDX-TEE-\nIO [45]. TEE-IO formulates the procedure of device attes-\ntation, secure data transferring between PCI-e stubs, etc. With this enhancement, it allows a trusted PCI-e controller\nto access the plaintext of the TEE data inside SoC, and per-\nform the DMA request dire",
            "Some state-of-the-art TEEs adopt the memory encryption\nand I/O isolation simultaneously, such as TDX [5], SGX [29],\nSEV-SNP [71], and CCA [1]. SEV-SNP and CCA propose ad-\nditional page-based I/O isolation mechanisms: RMP (Reverse\nMap Table) and GPC (Granule Protection Checker), which\nare new components i",
            "act\n\nTrusted Execution Environments (TEEs), like Intel SGX/TDX,\nAMD SEV-SNP, ARM TrustZone/CCA, have been widely\nadopted in prevailing architectures. However, these TEEs\ntypically do not consider I/O isolation (e.g., defending against\nmalicious DMA requests) as a first-class citizen, which may\ndegrade the I/O performance."
          ]
        },
        {
          "title": "Attestation Mechanisms for Trusted Execution Environments Demystified",
          "url": "https://arxiv.org/pdf/2206.03780",
          "excerpts": [
            "Remote attestation may also benefit from these unified\nsolutions by abstracting the attestation process behind standard interfaces.",
            " TrustZone-A, it lacks attestation\nmechanisms, preventing relying parties from validating and trusting the state\nof TrustZone-A remote",
            "rs, TrustZone comes in two\nflavours: TrustZone-A (for Cortex-A) and TrustZone-M (for Cortex-M).",
            "Unlike local attestation, remote attestation\nuses an asymmetric-key scheme, which is made possible by a special enclave,\ncalled quoting enclave, that has access to the device-specific private key.",
            "Intel SGX\nissues a set of claims, called report, that contains identities, attributes (i.e., modes\nand other properties), the trustworthiness of the TCB, additional information\nfor the target enclave and a MAC.",
            "The traffic between the CPU and the system\nmemory remains confidential thanks to the memory encryption engine (MEE).",
            "Intel SGX\n\nIntel Software Guard Extensions (SGX) [19] introduced TEEs for mass-market\nprocessors in 2015",
            "The verifier examines the evidence, maintaining a list\nof reference values to identify genuine instances of trusted applications. If\nrecognised as trustworthy, the verifier can proceed to data exchanges.",
            "Remote attestation allows to establish trust between different devices and provides\ncryptographic proofs that the executing software is genuine and untampered [18]."
          ]
        },
        {
          "title": "Remote Attestation in Confidential Computing Explained",
          "url": "https://edera.dev/stories/remote-attestation-in-confidential-computing-explained",
          "excerpts": [
            "**Standardization efforts** : Industry groups are working on standardized attestation formats and protocols to improve interoperability between different TEE technologies. **Integration with existing systems** : Cloud providers are building attestation capabilities into their managed services, making it easier for organizations to adopt without deep technical expertise. **Regulatory compliance** : As data protection regulations become more stringent, attestation provides a cryptographic foundation for demonstrating compliance with security requirements.",
            "Despite the known good state being up for interpretation, remote attestation is becoming increasingly important as organizations seek to leverage external computing resources while maintaining strict security and compliance requirements. Key trends include:",
            "## Remote Attestation is Gaining Traction",
            " use |\n| AWS Nitro Enclaves | ‚úì | ‚úì | Cloud-native, integrated with AWS services |\n| ",
            " |\n| ARM TrustZone | ‚úì | Limited | Primarily mobile/embedded use |\n|",
            "|\n| Intel SGX | ‚úì | ‚úì | Mature ecosystem, fine-grained control |\n| Intel",
            "| --- | --- | --- | --- |",
            "| TEE Technology | Local Attestation | Remote Attestation | Key Features |",
            "Different TEE technologies offer varying levels of attestation support:"
          ]
        },
        {
          "title": "Intel¬Æ Trust Domain Extension Linux Guest Kernel Security ...",
          "url": "https://intel.github.io/ccc-linux-guest-hardening-docs/security-spec.html",
          "excerpts": [
            "May 27, 2025 ‚Äî IOMMU¬∂. IOMMU is disabled for the TDX guest due to the DMAR ACPI table not being included in the list of allowed ACPI tables for the TDX guest."
          ]
        },
        {
          "title": "VT-d ‚Äî Project ACRN‚Ñ¢ 3.4-unstable documentation",
          "url": "https://projectacrn.github.io/latest/developer-guides/hld/hv-vt-d.html",
          "excerpts": [
            "Nov 5, 2024 ‚Äî The ACRN hypervisor supports DMA remapping that provides address translation capability for PCI passthrough devices, and second-level¬†..."
          ]
        },
        {
          "title": "Software Enabling for TDX TEE-IO-final",
          "url": "https://cdrdv2-public.intel.com/742542/software-enabling-for-tdx-tee-io-fixed.pdf",
          "excerpts": [
            "This implies that Intel TDX module needs to be extended to help provide secure DMA remapping or IOMMU management functions to the VMM to add or remove mappings¬†..."
          ]
        },
        {
          "title": "[PDF] Intel¬Æ Software Guard Extensions (Intel¬Æ SGX) Data Center ...",
          "url": "https://download.01.org/intel-sgx/sgx-dcap/1.14/linux/docs/Intel_SGX_ECDSA_QuoteLibReference_DCAP_API.pdf",
          "excerpts": [
            "ECDSA Attestation Key Derivation using QE Seal Key (Intel¬Æ SGX DCAP Solution) ... Sample Quote Generation Sequence Diagram for the Intel¬Æ SGX DCAP. APIs."
          ]
        },
        {
          "title": "AMD SEV-SNP Attestation: Establishing Trust in Guests",
          "url": "https://www.amd.com/content/dam/amd/en/documents/developer/lss-snp-attestation.pdf",
          "excerpts": [
            "‚Ä¢ Place digest in REPORT_DATA. ‚Ä¢ Send report and public key to relying ... ‚Ä¢ SNP_GET_REPORT ‚Äì retrieves report. ‚Ä¢ SNP_GET_EXT_REPORT ‚Äì retrieves report ...",
            "‚Ä¢ SEV-SNP firmware returns attestation report through same channel. ‚Ä¢ Linux guest retrieves reports via IOCTLs on /dev/sev-guest. ‚Ä¢ SNP_GET_REPORT ‚Äì retrieves ...",
            "E.g., VCEK certificate chain is retrieved from AMD Key Distribution Service (KDS) and stored in the host via SNP_SET_EXT_CONFIG. The guest retrieves the report."
          ]
        },
        {
          "title": "Intel¬Æ Trust Domain Extensions (Intel¬Æ TDX) Data Center ...",
          "url": "https://download.01.org/intel-sgx/latest/dcap-latest/linux/docs/Intel_TDX_DCAP_Quoting_Library_API.pdf",
          "excerpts": [
            "Get Platform Supported TD Attestation Keys ... present in the REPORTDATA field of the TD Quote body. Must not be NULL¬†...",
            "Figure 1 shows the entire attestation flow and the components involved in quote setup phase ... report is guaranteed by SGX's local attestation. Note that¬†..."
          ]
        },
        {
          "title": "[PDF] Intel¬Æ SGX Data Center Attestation Primitives (Intel¬Æ SGX DCAP)",
          "url": "https://www.intel.com/content/dam/develop/public/us/en/documents/intel-sgx-dcap-ecdsa-orientation.pdf",
          "excerpts": [
            "stem with the \nIntel¬Æ SGX enabled. Third party users of Intel¬Æ SGX may now author their own \nattestation infrastructure for Intel¬Æ SGX. Using third party \nattestation addresses the following limitations: \n\n‚Ä¢ Entities run large parts of their networks in environments \n\nwhere the Internet based services cannot be reached at \nruntime. ‚Ä¢ Entities are risk averse in outsourcing trust decisions to \n\nthird parties. ‚Ä¢ Certain application models working in a very distributed \n\nfashion (for example, Peer-to-Peer networks) benefit from \nnot relying on a single point of verification. ‚Ä¢ Environments have requirements that conflict with the \n\nprivacy properties that EPID provides. To address issues of this type, Intel offers proposed \narchitecture that allows you to benefit from remote \nattestations without using Intel remote attestation services to \nvalidate the Intel¬Æ SGX attestation request at runtime. For more information on Intel¬Æ solutions for third party \nremote attestations, see the Supporting Third Party \nAttestation for Intel¬Æ SGX Data Center Attestation Primitives \n(Intel¬Æ SGX DCAP) whitepaper.\nThis orientation guide describes various third party \nattestation collaterals provided by Intel that you can use to \nenable remote attestation of Intel¬Æ SGX platforms in a data \ncenter environment.",
            "sions (Intel¬Æ SGX) remote attestation \nallows a remote party to check that the intended software is \nsecurely running within an enclave on a system with the \nIntel¬Æ SGX enabled.",
            "Attestation is the process of demonstrating that a software \nexecutable is properly instantiated on a platform.",
            "rvice \n\nThe Intel¬Æ SGX provisioning certificate service offers \nAPIs for retrieving provisioning certification key (PCK) \ncertificates, revocation lists, Trusted Computing Base \n(TCB) information, and the quoting enclave (QE) identity \nfor platforms with Intel¬Æ SGX enabled, all provided to an \non-premise caching service for the Intel¬Æ SGX \nprovisioning certificate service. a. API portal \n\nTo get an API key, register yourself with the Intel¬Æ \nSGX provisioning certificate service because APIs \nthat support returning PCK certificates require the \nAPI key."
          ]
        },
        {
          "title": "CoRIM profile for AMD SEV-SNP attestation report",
          "url": "https://datatracker.ietf.org/doc/draft-deeglaze-amd-sev-snp-corim-profile/01/",
          "excerpts": [
            "2. AMD SEV-SNP Attestation Report measurements The fields ... The REPORT_DATA is meant for protocol use and not reference measurements. * ...",
            "Oct 6, 2024 ‚Äî VEK: Either a VCEK or VLEK. 3.1. AMD SEV-SNP CoRIM Profile AMD SEV ... 2. AMD SEV-SNP Attestation Report measurements The fields of an attestation¬†..."
          ]
        },
        {
          "title": "Understanding TDX Attestation Reports: A Developer's Guide",
          "url": "https://phala.network/posts/understanding-tdx-attestation-reports-a-developers-guide",
          "excerpts": [
            "Apr 8, 2025 ‚Äî This guide explains the key fields in TEE attestation reports, with a specific focus on Intel TDX attestation as used by Phala Cloud."
          ]
        },
        {
          "title": "Intel¬Æ TDX Connect Architecture Specification",
          "url": "https://cdrdv2-public.intel.com/773614/intel-tdx-connect-architecture-specification.pdf",
          "excerpts": [
            "The DMA TLPs with T-bit set to 1 are translated by the IOMMU using trusted DMA translation tables (discussed later) that allow the device interface to access¬†..."
          ]
        },
        {
          "title": "SEV-SNP-strengthening-vm-isolation-with-integrity- ...",
          "url": "https://www.amd.com/content/dam/amd/en/documents/epyc-business-docs/white-papers/SEV-SNP-strengthening-vm-isolation-with-integrity-protection-and-more.pdf",
          "excerpts": [
            "by AMD SEV-SNP ¬∑ 2020 ¬∑ Cited by 222 ‚Äî As mentioned, many of the integrity guarantees of SEV-SNP are enforced through a new structure called the Reverse Map Table (RMP). The RMP is a single data¬†...See more",
            "by AMD SEV-SNP ¬∑ 2020 ¬∑ Cited by 222 ‚Äî Architectural side channel attacks on CPU data structures are not specifically prevented by any hardware means. As with standard software security practices,¬†...",
            "by AMD SEV-SNP ¬∑ 2020 ¬∑ Cited by 222 ‚Äî This enforcement is done using the Reverse Map Table (RMP) mechanism described in the following section. Memory Aliasing attacks involve the hypervisor¬†..."
          ]
        },
        {
          "title": "What Are ARINC 653‚ÄìCompliant Safety-Critical Applications?",
          "url": "https://www.windriver.com/solutions/learning/arinc-653-compliant-safety-critical-applications",
          "excerpts": [
            "Health monitoring and error handling: ARINC 653 addresses the prioritization of safety by incorporating health monitoring and error handling mechanisms . These help the system detect anomalies in partitions and respond to errors promptly for fast recovery and minimized disruptions."
          ]
        },
        {
          "title": "RDMA-Based Sampling Port of ARINC-653 - IEEE Xplore",
          "url": "https://ieeexplore.ieee.org/document/10459217/",
          "excerpts": [
            "by JB Lee ¬∑ 2024 ‚Äî We implement the ARINC-653 sampling port by exploiting remote direct memory access (RDMA) over Ethernet that can directly move data to/from remote memory.",
            "We implement the ARINC-653 sampling port by exploiting remote direct memory access (RDMA) over Ethernet that can directly move data to/from remote memory."
          ]
        },
        {
          "title": "[PDF] ARINC 653",
          "url": "http://retis.sssup.it/~giorgio/slides/cbsd/cbsd-arinc-2p.pdf",
          "excerpts": [
            "Sampling Port ‚Äì allows a partition to access to a channel of communication configured to operate in sampling mode;. ‚ùë Queuing port ‚Äì channel of ..."
          ]
        },
        {
          "title": "[PDF] ARINC 653",
          "url": "http://retis.sssup.it/~giorgio/slides/cbsd/cbsd-arinc-6p.pdf",
          "excerpts": [
            "‚û¢ Time and space (memory) partitioning;. ‚û¢ Health monitoring (error detection and reporting);. ‚û¢ Communications via ‚Äúports‚Äù. ‚û¢ API available for C and Ada."
          ]
        },
        {
          "title": "A Streamlined Approach Toward Automated Generation ...",
          "url": "https://arc.aiaa.org/doi/10.2514/1.I011439",
          "excerpts": [
            "by B Lukiƒá ¬∑ 2025 ¬∑ Cited by 1 ‚Äî An important characteristic of ARINC 653 is the time isolation of partitions. Each partition executes within its designated partition time¬†..."
          ]
        },
        {
          "title": "IV&V on Orion's ARINC 653 Flight Software Architecture",
          "url": "https://www.nasa.gov/wp-content/uploads/2016/10/482470main_2530_-_ivv_on_orions_arinc_653_flight_software_architecture_100913.pdf",
          "excerpts": [
            "Orion FSW includes significant COTS elements directly or by incorporation (e.g. APEX). Legacy and COTS code was not developed using NASA-specific processes with ...",
            "ARINC 653 splits the available processor time and space into partitions (partitions do not need to be the same size). ‚Ä¢ When we talk ‚Äúpartition‚Äù in this¬†...",
            "ARINC 653 is a software time and space partitioning standard for Real Time Operating Systems (RTOSs). ‚Ä¢ The ARINC 653 standard supports Integrated Modular."
          ]
        },
        {
          "title": "Build Cache - The Cargo Book",
          "url": "https://doc.rust-lang.org/beta/cargo/reference/build-cache.html",
          "excerpts": [
            "A third party tool, [sccache](https://github.com/mozilla/sccache), can be used to share built dependencies across\ndifferent workspaces. To setup `sccache`, install it with `cargo install sccache` and set\n`RUSTC_WRAPPER` environment variable to `sccache` before invoking Cargo. If\nyou use bash, it makes sense to add `export RUSTC_WRAPPER=sccache` to\n`.bashrc`. Alternatively, you can set [`build.rustc-wrapper`](../reference/config.html) in the [Cargo\nconfiguration](../reference/config.html). Refer to sccache documentation for more details."
          ]
        },
        {
          "title": "Exploring PGO for the Rust Compiler",
          "url": "https://blog.rust-lang.org/inside-rust/2020/11/11/exploring-pgo-for-the-rust-compiler.html",
          "excerpts": [
            "Get help!",
            "the LLVM part first, since that is slightly simpler.",
            "This complicates things slightly but fortunately the PGO setup for each of the two components can be treated in isolation.",
            "However, as opposed to many other programs, _rustc_ is a bit of a special case because it consists of two very large chunks of code written in different programming languages: the LLVM backend (written in C++) and the front and middle parts of the compiler (written in Rust). Consequently, there are also two separate compilers involved in building _rustc_ \\-- both of which support their own version of",
            "1. Create an instrumented version of _rustc_ . 2. Use the instrumented version of _rustc_ in order to collect profile data, i.e. compile a bunch of programs with it, ideally in a way that represents the typical use cases of the compiler. 3. Compile the final version of _rustc_ , this time pointing the build system to the profile data we generated in the previo",
            "Generating a PGOed version of _rustc_ involves the same basic steps as it does for any other kind of progra",
            "PGO is a toolchain specific feature, so how it works might be different for different C++ compilers. In this article I will only go into how it works with Clang because (a) I have no experience with PGO in other compilers, and (b) Clang is what the Rust project actually uses in production.",
            "Compiling rustc's LLVM with PGO"
          ]
        },
        {
          "title": "sccache 0.2.5",
          "url": "https://docs.rs/crate/sccache/0.2.5",
          "excerpts": [
            "Sccache is a ccache-like tool. It is used as a compiler wrapper and avoids compilation when possible, storing a cache in a remote storage."
          ]
        },
        {
          "title": "Rust Offline? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/137hmah/rust_offline/",
          "excerpts": [
            "--frozen tells cargo to stay offline and only use the versions specified in the Cargo.lock file and as cached by the fetch run in the prepare()¬†..."
          ]
        },
        {
          "title": "Rust Supply Chain Security - <'kellnr>",
          "url": "https://www.kellnr.io/blog/rust-supply-chain-security",
          "excerpts": [
            "Use tools such as cargo-sandbox or cargo-chef to create isolated and reproducible environments for your Rust projects. Educate yourself: stay ..."
          ]
        },
        {
          "title": "How to build a project using Cargo in an offline environment?",
          "url": "https://stackoverflow.com/questions/32267233/how-to-build-a-project-using-cargo-in-an-offline-environment",
          "excerpts": [
            "As of Rust 1.37, Cargo's built-in vendor command can be used to download and bundle your crate's dependencies in the crate itself."
          ]
        },
        {
          "title": "cargo install - The Cargo Book",
          "url": "https://doc.rust-lang.org/cargo/commands/cargo-install.html",
          "excerpts": [
            "The --locked flag can be used to force Cargo to use the packaged Cargo.lock file if it is available. This may be useful for ensuring reproducible builds, to¬†..."
          ]
        },
        {
          "title": "How to properly use --remap-path-prefix? - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/how-to-properly-use-remap-path-prefix/104406",
          "excerpts": [
            "I want to strip references to the build directory and the general setup on the computer that build the binary. As I understand it, I'm supposed to use --remap- ..."
          ]
        },
        {
          "title": "remap_cwd_prefix - The Rust Unstable Book",
          "url": "https://doc.rust-lang.org/beta/unstable-book/compiler-flags/remap-cwd-prefix.html",
          "excerpts": [
            "This flag will rewrite absolute paths under the current working directory, replacing the current working directory prefix with a specified value. The given ..."
          ]
        },
        {
          "title": "cargo-auditable v0.7 is out with native SBOM support : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1m1k288/cargoauditable_v07_is_out_with_native_sbom_support/",
          "excerpts": [
            "Version 0.7 brings support for Cargo's native SBOM precursor, which lets us embed a more accurate dependency list as opposed to using only cargo metadata."
          ]
        },
        {
          "title": "rust-secure-code/cargo-auditable: Make production Rust binaries ...",
          "url": "https://github.com/rust-secure-code/cargo-auditable",
          "excerpts": [
            "Audit binaries for known bugs or security vulnerabilities in production, at scale, with zero bookkeeping."
          ]
        },
        {
          "title": "Source-based Code Coverage ‚Äî Clang 22.0.0git documentation",
          "url": "https://clang.llvm.org/docs/SourceBasedCodeCoverage.html",
          "excerpts": [
            "If LLVM_PROFILE_FILE contains a path to a non-existent directory, the missing directory structure will be created. Additionally, the following special pattern ..."
          ]
        },
        {
          "title": "How to compile with Profile Guided Optimization (PGO)",
          "url": "https://developer.arm.com/documentation/101458/latest/Optimize/Profile-Guided-Optimization--PGO-/How-to-compile-with-Profile-Guided-Optimization--PGO-",
          "excerpts": [
            "Both -fprofile-instr-generate and LLVM_PROFILE_FILE can use the following modifiers to uniquely set profile data filename: %p to state the process ID; %h to ..."
          ]
        },
        {
          "title": "Rust Profile Guided Optimization (rustc) and Cargo Workflow",
          "url": "https://doc.rust-lang.org/rustc/profile-guided-optimization.html",
          "excerpts": [
            "A Complete Cargo Workflow ¬∑ We use the RUSTFLAGS environment variable in order to pass the PGO compiler flags to the compilation of all crates in the program.",
            "These steps will do the following just as before:\n    * Build an instrumented binary from the source code. * Run the instrumented binary to gather PGO profiles. * Use the gathered PGO profiles from the last step to build an optimized binary.",
            "For the sake of completeness, here are the corresponding steps using\ncargo-pgo :\n# Install if you haven't already\ncargo install cargo-pgo\ncargo pgo build\ncargo pgo optimize",
            "As an alternative to directly using the compiler for Profile-Guided Optimization,\nyou may choose to go with\ncargo-pgo , which has an intuitive command-line API\nand saves you the trouble of doing all the manual work. You can read more about\nit in their repository accessible from this link: https://github.com/Kobzol/cargo-pgo",
            ".\nThis is what the entire workflow looks like:\n# STEP 0: Make sure there is no left-over profiling data from previous runs\nrm -rf /tmp/pgo-data\n# STEP 1: Build the instrumented binaries\nRUSTFLAGS=\"-Cprofile-generate=/tmp/pgo-data\" \\\ncargo build --release --target=x86_64-unknown-linux-gnu\n# STEP 2: Run the instrumented binaries with some typical data\n./target/x86_64-unknown-linux-gnu/release/myprogram mydata1.csv\n./target/x86_64-unknown-linux-gnu/release/myprogram mydata2.csv\n./target/x86_64-unknown-linux-gnu/release/myprogram mydata3.csv\n# STEP 3: Merge the `.profraw` files into a `.profdata` file\nllvm-profdata merge -o /tmp/pgo-data/merged.profdata /tmp/pgo-data\n# STEP 4: Use the `.profdata` file for guiding optimizations\nRUSTFLAGS=\"-Cprofile-use=/tmp/pgo-data/merged.profdata\" \\\ncargo build --release --target=x86_64-unknown-linux-gnu",
            "e compiler. Some things of note:\n    * We use the\nRUSTFLAGS environment variable in order to pass the PGO compiler\nflags to the compilation of all crates in the program. * We pass the\n--target flag to Cargo, which prevents the\nRUSTFLAGS arguments to be passed to Cargo build scripts. We don't want the build\nscripts to generate a bunch of\n.profraw files. * We pass\n--release to Cargo because that's where PGO makes the most sense. In theory, PGO can also be done on debug builds but there is little reason\nto do so. * It is recommended to use absolute paths for the argument of\n-Cprofile-generate and\n-Cprofile-use . Cargo can invoke\nrustc with\nvarying working directories, meaning that\nrustc will not be able to find\nthe supplied\n.profdata file. With absolute paths this is not an issue.",
            "Using this feature with Cargo works very similar to using it with\nrustc directly. Again, we generate an instrumented binary, run it to produce data,\nmerge the data, and feed it back into the compiler.",
            "A Complete Cargo Workflow",
            "An instrumented program will create one or more\n.profraw files, one for each\ninstrumented binary.",
            "Generating a PGO-optimized program involves following a workflow with four steps:\n    * Compile the program with instrumentation enabled\n(e.g. rustc -Cprofile-generate=/tmp/pgo-data main.rs )\n    * Run the instrumented program (e.g. ./main ) which generates a\ndefault_<id>.profraw file\n    * Convert the\n.profraw file into a\n.profdata file using\nLLVM's\nllvm-profdata tool\n    * Compile the program again, this time making use of the profiling data\n(for example\nrustc -Cprofile-use=merged.profdata main.rs )",
            "The basic concept of PGO is to collect data about the typical execution of\na program (e.g. which branches it is likely to take) and then use this data\nto inform optimizations such as inlining, machine-code layout,\nregister allocation, etc.",
            "Usage. Generating a PGO-optimized program involves following a workflow with four steps: Compile the program with instrumentation enabled (e.g. rustc -Cprofile ...",
            "Profile Guided Optimization"
          ]
        },
        {
          "title": "Rust cargo-pgo ‚Äî Kobzol's blog",
          "url": "https://kobzol.github.io/rust/cargo/2023/07/28/rust-cargo-pgo.html",
          "excerpts": [
            "This combined PGO + BOLT workflow should provide the largest performance improvements 7 , at the cost\nof increased build time - you need to recompile and run your program several tim",
            "Jul 28, 2023 ‚Äî There is a PGO guide in the official Rust compiler documentation, which describes the steps that you need to perform to get it working. In¬†... The PGO workflow usually looks something like this:\n    * You compile an ‚Äúinstrumented‚Äù version of your program. The compiler will insert additional\ninstrumentation instructions into it, which will record useful information when the program is executed. * You execute the instrumented binary on some representative workload(s). This will generate a set\nof profiles on disk, which will contain information about your program behavior - things like how\nmany times was each function called or how many times was a conditional branch taken. * You compile your binary again, this time providing the gathered profiles to the compiler. It\nshould then be able to optimize the code better, because it will have a better idea of your program\nruntime behavior. PGO is a common technique in the C/C++ world, and it is also well-supported by Rust 1 . There is a PGO guide in the official Rust\ncompiler documentation, which describes the steps that you need to perform to get it working. In short,\nyou need to pass a special compiler flag to\nrustc when building your crate, gather the profiles by\nrunning your program, use a separate LLVM tool to merge the gathered profiles and then pass a different\nflag to\nrustc , which needs to point to the merged profile. It‚Äôs not super complicated, but it‚Äôs also\nquite far from the typical frictionless experience of running a single\ncargo <foo> command that\ndoes everything you need.\nAu",
            "The PGO workflow usually looks something like this:",
            "The PGO workflow usually looks something like this:",
            "What is PGO, anyway? Profile-guided optimization (PGO) is a program optimization technique that allows a compiler to better\noptimize your code thanks to having a better idea of how will your program behave on real-world\nworkloads.",
            "What is PGO, anyway? Profile-guided optimization (PGO) is a program optimization technique that allows a compiler to better\noptimize your code thanks to having a better idea of how will your program behave on real-world\nworkloads.",
            "  * You compile an ‚Äúinstrumented‚Äù version of your program. The compiler will insert additional\ninstrumentation instructions into it, which will record useful information when the program is executed.",
            "After you have an instrumented binary, you should execute it on some realistic workloads to gather\nthe profiles.",
            "After you have an instrumented binary, you should execute it on some realistic workloads to gather\nthe profiles.",
            " cargo-pgo is even able to combine both PGO and BOLT using the\n--with-pgo flag",
            " cargo-pgo is even able to combine both PGO and BOLT using the\n--with-pgo flag",
            "Automating PGO\nThat is why I decided to create\ncargo-pgo , a Cargo subcommand\nthat is designed to make it as easy as possible to apply PGO to Rust crates. So, how does it work? First, you need to install it with the following command:\n$ cargo install cargo-pgo\nAfter that, you can start using the various\ncargo pgo <...> commands. You may recall that the first step of the PGO workflow is to generate an instrumented binary. You can\ndo that using\ncargo pgo build , which does several things for you:\n    * It passes the\n--release flag to Cargo. Just to make sure that you don‚Äôt forget . There‚Äôs\nnot much point in PGO optimizing debug builds. * It passes an explicit\n--target flag to Cargo, which avoids PGO instrumenting build scripts . * It creates a directory for storing the PGO profiles under the\ntarget artifact directory. It will\nalso automatically clear this directory to remove any stale profiles, unless you pass the\n--keep-profiles flag. * And finally, it compiles your target with the\n-Cprofile-generate=<profile-dir> flag,\nwhich will cause\nrustc to enable PGO instrumentation. Gathering profiles\nAfter you have an instrumented binary, you should execute it on some realistic workloads to gather\nthe profiles. You should gather enough profiles to provide proper context for the compiler, but it‚Äôs\nhard to say in general what is the correct amount. Usually I just let the program run at least for a\nminute or so.\n ... \nFor example:\n$ LLVM_PROFILE_FILE = ./target/pgo-profiles/%m_%p.profraw\n./target/release/x86_64-unknown-linux-gnu/foo\nCreating one file per process should result in more precise profiles and thus a better optimized program. When I enabled this ‚Äútrick‚Äù for the Rust compiler itself, it resulted in pretty nice ~1% instruction count\nimprovements across the board, although it‚Äôs hard to say whether this will generalize to other programs. It should also be noted that if you create a lot of processes, the disk usage of all these profile\nfiles can get large pretty quickly! For\nrustc , a single profile takes tens of megabytes, while\ncreating a separate profile for each process consumes almost\n60 GiB ! Final optimization step\nOnce you have gathered the PGO profiles, you can run\ncargo pgo optimize . It will merge all\ngathered profiles using the\nllvm-profdata tool and then compile your target with the\n-Cprofile-use flag, pointing it to the single merged profile file. It will also print helpful stats about the\ngathered profiles (like their count and total size before and after merging). Running PGO on CI\nIf you want to apply PGO to binary artifacts that you then distribute to end users, you might want\nto run PGO in a CI (continuous integration) workflow. If you install\ncargo-pgo in your CI script,\nand you are able to run your instrumented binary on some (probably small) workload directly on the CI\nmachine, then this becomes quite"
          ]
        },
        {
          "title": "What's the best practice for caching compilation of Rust ... - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/sunme5/whats_the_best_practice_for_caching_compilation/",
          "excerpts": [
            "Because of that, sccache only speeds up compilation after the first build. It can only help with some of the scenarios I mentioned (eg CI) but ..."
          ]
        },
        {
          "title": "Allow specifying multiple toolchains in rust-toolchain.toml ...",
          "url": "https://github.com/rust-lang/rustup/issues/3546",
          "excerpts": [
            "Nov 27, 2023 ‚Äî Allow a second key called [[other-toolchain]] to specify non-default toolchains. This should be backwards-compatible with the current rust-toolchain format."
          ]
        },
        {
          "title": "ferrocene/README.md at main",
          "url": "https://github.com/ferrocene/ferrocene/blob/main/README.md",
          "excerpts": [
            "Ferrocene is a toolchain to enable the use of the Rust programming language in safety-critical environments. It is a proper downstream of the main Rust¬†..."
          ]
        },
        {
          "title": "Installing and Using Ferrocene",
          "url": "https://rust-training.ferrous-systems.com/latest/book/ferrocene-installing",
          "excerpts": [
            "Installing and Using Ferrocene. What's in the box? rustc - a compiler (‚òÜ). lld - the LLVM linker (‚òÜ); rustdoc - the docs generator."
          ]
        },
        {
          "title": "vergen - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/vergen",
          "excerpts": [
            "Will emit cargo:rerun-if-env-changed=SOURCE_DATE_EPOCH to rerun instruction emission if the SOURCE_DATE_EPOCH environment variable has changed."
          ]
        },
        {
          "title": "sccache - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/sccache",
          "excerpts": [
            "Feb 24, 2025 ‚Äî Sccache is a ccache-like tool. It is used as a compiler wrapper and avoids compilation when possible. Sccache has the capability to utilize caching in remote¬†..."
          ]
        },
        {
          "title": "Profile-guided optimization - Rust Compiler Development Guide",
          "url": "https://rustc-dev-guide.rust-lang.org/profile-guided-optimization.html",
          "excerpts": [
            "PGO collects data about a program's typical execution, like which branches it takes, and uses this data to inform optimizations.",
            "Generating a PGO-optimized program involves the following four steps: Compile the program with instrumentation enabled (e.g. rustc -C profile-generate main.rs ) ..."
          ]
        },
        {
          "title": "cargo build - The Cargo Book - Rust Documentation",
          "url": "https://doc.rust-lang.org/cargo/commands/cargo-build.html",
          "excerpts": [
            "It may be used in environments where deterministic builds are desired, such as in CI pipelines. --offline: Prevents Cargo from accessing the network for any ..."
          ]
        },
        {
          "title": "Overrides - The rustup book",
          "url": "https://rust-lang.github.io/rustup/overrides.html",
          "excerpts": [
            "You need to upgrade rustup to 1.23.0+. The rust-toolchain.toml / rust-toolchain files are suitable to check in to source control. If that's done, Cargo.lock¬†..."
          ]
        },
        {
          "title": "Ferrocene",
          "url": "https://ferrocene.dev/en/",
          "excerpts": [
            "Ferrocene is the open-source qualified Rust compiler toolchain ... Ferrocene is qualified at ISO 26262 for automotive electronic systems for road vehicles.",
            "Ferrocene enables Rust to be a first-class language for mission-critical- and functional-safety systems at the highest security levels."
          ]
        },
        {
          "title": "Mozilla sccache",
          "url": "https://github.com/mozilla/sccache",
          "excerpts": [
            "sccache is also available as a GitHub Actions to facilitate the deployment using GitHub Actions cache.",
            "The sccache command will spawn a server process if one is not already running, or you can run\nsccache --start-server to start the background server process without performing any compilation.",
            "sccache works using a client-server model, where the server runs locally on the same machine as the client.",
            "sccache includes support for caching the compilation of C/C++ code, Rust , as well as NVIDIA's CUDA using nvcc , and clang .",
            "Sccache is a ccache-like tool. It is used as a compiler wrapper and avoids compilation when possible."
          ]
        },
        {
          "title": "Cargo-pgo: Cargo subcommand for optimizing Rust binaries/libraries with PGO and BOLT",
          "url": "https://github.com/Kobzol/cargo-pgo",
          "excerpts": [
            "cargo-pgo` needs to set RUSTFLAGS for the crate being compiled. If you pass your own RUSTFLAGS using `config.toml` file, please make sure to use the `[target.<...>] rustflags = ...` section, instead of the `[build] rustflags = ...` s",
            "Caveats",
            "You can install the PGO helper binary by adding the `llvm-tools-preview` component to your toolchain\nwith `rus",
            "Cargo subcommand for optimizing Rust binaries/libraries with PGO and BOLT.",
            "Yes, BOLT and PGO can even be combined :) To do that, you should first generate PGO profiles and\nthen use BOLT on already PGO optimized binaries.",
            " ## BOLT + PGO",
            "The optimized binary will be named `<binary-name>-bolt-optimized` .",
            "3. **Build an optimized binary using generated profiles**",
            "It is important to understand the workflow of using feedback-directed optimizations. Put simply, it\nconsists of three general steps:",
            "2. **Gather performance profiles**",
            "1. **Build binary with instrumentation**",
            "Cargo subcommand that makes it easier to use PGO and BOLT to optimize Rust binaries. For an example on how to use cargo-pgo to optimize a binary on GitHub¬†..."
          ]
        },
        {
          "title": "Timestamps and Reproducible Builds",
          "url": "https://reproducible-builds.org/docs/timestamps/",
          "excerpts": [
            "Timestamps make the biggest source of reproducibility issues. Many build tools record the current date and time. The filesystem does, and most archive formats ... Like\n[version information](/docs/version-information/),\nit‚Äôs best to extract such a date from the revision control system or\nfrom a *changelog*. External tools\n--------------\n\nSome tools used in build processes, like code or documentation\ngenerators, write timestamps which will create unreproducible build\nproducts. The Reproducible Builds effort proposed the\n`SOURCE_DATE_EPOCH` environment variable to address the problem. Tools\nthat support it[1](:list) will use its value‚Äîa number of seconds since January 1st\n1970, 00:00 UTC‚Äîinstead of the current date and time (when set). The\nvariable has been [formally\ndefined](https://reproducible-builds.org/specs/source-date-epoch/) in\nthe hope of wider adoption. (Originally `SOURCE_DATE_EPOCH` was introduced by the Debian reproducible builds\nfolks and since has been adapted widely.) Changes required to support `SOURCE_DATE_EPOCH` are usually fairly\nsmall and easy to write. Patches for tools which don‚Äôt yet support the\nenvironment variable have been usually well received and help all users\nwanting *reproducible builds*. In case where that is not possible, an option is to do post-processing on\nthe output. The idea is to either remove the timestamps entirely or to\nnormalize them to a predetermined date and time. [strip-nondeterminism](https://packages.debian.org/sid/strip-nondeterminism)\nwas designed as an extensible program to perform such normalization on\nvarious file formats."
          ]
        },
        {
          "title": "SOURCE_DATE_EPOCH and Reproducible Builds",
          "url": "https://reproducible-builds.org/docs/source-date-epoch/",
          "excerpts": [
            "* **SOURCE\\_DATE\\_EPOCH",
            "* [Variations in the build environment](/docs/env-variations/)",
            "##### Achieve deterministic builds",
            "In practice, `SOURCE_DATE_EPOCH` specifies the last modification of something, usually the source code, measured in the number seconds since the Unix epoch, ie. `January 1st 1970, 00:00:00 U",
            "SOURCE_DATE_EPOCH specifies the last modification of something, usually the source code, measured in the number seconds since the Unix epoch. SOURCE\\_DATE\\_EPOCH ‚Äî reproducible-builds.o"
          ]
        },
        {
          "title": "Simplifying Code Signing for Open Source Ecosystems",
          "url": "https://openssf.org/blog/2023/11/21/sigstore-simplifying-code-signing-for-open-source-ecosystems/",
          "excerpts": [
            "Nov 21, 2023 ‚Äî Sigstore is a set of open source projects and services that dramatically simplify the creation and verification of digital signatures."
          ]
        },
        {
          "title": "anchore/syft: CLI tool and library for generating a Software ...",
          "url": "https://github.com/anchore/syft",
          "excerpts": [
            "Able to create signed SBOM attestations using the in-toto specification; Convert between SBOM formats, such as CycloneDX, SPDX, and Syft's own format."
          ]
        },
        {
          "title": "sccache | Cache | Depot Documentation",
          "url": "https://depot.dev/docs/cache/reference/sccache",
          "excerpts": [
            "Depot Cache provides a remote cache service that can be used with sccache, allowing you to incrementally cache and reuse parts of your builds."
          ]
        },
        {
          "title": "[Idea] Cargo Global Binary Cache - Page 2 - Rust Internals",
          "url": "https://internals.rust-lang.org/t/idea-cargo-global-binary-cache/9002?page=2",
          "excerpts": [
            "If we assume cargo has reproducible builds, you could have a build bot that builds the crate locally and checks against the prebuilt, and if ..."
          ]
        },
        {
          "title": "How to write fast Rust code - Renato Athaydes",
          "url": "https://renato.athaydes.com/posts/how-to-write-fast-rust-code.html",
          "excerpts": [
            "Rust allows you to make your code just about as fast, if not faster, than pretty much any other language as long as you put in the time to learn it properly."
          ]
        },
        {
          "title": "LLVM Language Reference Manual",
          "url": "https://llvm.org/docs/LangRef.html",
          "excerpts": [
            "This document is a reference manual for the LLVM assembly language. LLVM is a Static Single Assignment (SSA) based representation that provides type safety."
          ]
        },
        {
          "title": "Emitting build-id when linking ELF binaries - compiler",
          "url": "https://internals.rust-lang.org/t/emitting-build-id-when-linking-elf-binaries/15349",
          "excerpts": [
            "Sep 19, 2021 ‚Äî Hi, I just noticed that Rust doesn't put a build-id by default in ELF metadata (see reproducing example below)."
          ]
        },
        {
          "title": "When reproducible builds? : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/jct0y4/when_reproducible_builds/",
          "excerpts": [
            "In some domains, it is very important to be able to reproducibly rebuild a binary from the sources. This is cargo/rustc pretty bad at."
          ]
        },
        {
          "title": "OSX compilation with debuginfo isn't deterministic #47086",
          "url": "https://github.com/rust-lang/rust/issues/47086",
          "excerpts": [
            "Dec 30, 2017 ‚Äî This is a source of bugs in programs that expect rustc to be deterministic (aka #47066 as was originally stated) and is something that we as¬†..."
          ]
        },
        {
          "title": "Reproducible Builds: Rust Packages : r/reproduciblebuilds",
          "url": "https://www.reddit.com/r/reproduciblebuilds/comments/154qdjl/reproducible_builds_rust_packages/",
          "excerpts": [
            "I have tried setting the SOURCE_DATE_EPOCH value, but their binaries still embedded the build ID and timestamps. I was wondering if anyone¬†..."
          ]
        },
        {
          "title": "Can rustc generate identical binaries, with the same hash ...",
          "url": "https://www.reddit.com/r/rust/comments/14iyfyu/can_rustc_generate_identical_binaries_with_the/",
          "excerpts": [
            "On Windows, special (undocumented) flags must be passed when compiling w/ the msvc toolchain to build and link an executable deterministically.",
            "Yes, it has been possible to build Rust code with reproducibility and determinism since 2019 and not before."
          ]
        },
        {
          "title": "Exploring the problem of faster Cargo Docker builds : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/126xeyx/exploring_the_problem_of_faster_cargo_docker/",
          "excerpts": [
            "This means that each Docker build of a Cargo project can be quite slow and Docker layer caching cannot be used to its full effect, unlike with ..."
          ]
        },
        {
          "title": "Comparing `lld` 16.0 and `mold` 1.11.0 ¬∑ Issue #1020 - GitHub",
          "url": "https://github.com/rui314/mold/issues/1020",
          "excerpts": [
            "mold is faster, but I think a fair comparison needs to link mimalloc.a into lld, as mimalloc is responsible for 10+% performance improvement, ..."
          ]
        },
        {
          "title": "CycloneDX Tool Center",
          "url": "https://cyclonedx.org/tool-center/",
          "excerpts": [
            "CLI scanner that analyses CycloneDX, SPDX or Syft SBOMs for security vulnerabilities and licence issues using OSV, Sonatype OSS Index, GitHub Advisory or Snyk ...",
            "CLI tool for SBOM analysis, merging, diffs, format conversions, signing, and validation. Supports CycloneDX XML/JSON/Protobuf/CSV, SPDX JSON, and more."
          ]
        },
        {
          "title": "sigstore::cosign - Rust",
          "url": "https://docs.rs/sigstore/latest/sigstore/cosign/index.html",
          "excerpts": [
            "This crate is to provide the verification capabilities of cosign, not the signing one. Sigstore verification can be done using sigstore::cosign::Client."
          ]
        },
        {
          "title": "Does sccache really help? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/rvqxkf/does_sccache_really_help/",
          "excerpts": [
            "I personally don't use sccache, as I didn't find it to actually meaningfully improve compile times for me over what Cargo & CI caching natively¬†..."
          ]
        },
        {
          "title": "How can I include the build date in an executable - help",
          "url": "https://users.rust-lang.org/t/how-can-i-include-the-build-date-in-an-executable/102024",
          "excerpts": [
            "Nov 3, 2023 ‚Äî The recommendation is to use the SOURCE_DATE_EPOCH env var if it is set: SOURCE_DATE_EPOCH ‚Äî reproducible-builds.org. 6 Likes. mark November 3¬†..."
          ]
        },
        {
          "title": "Reproducible Builds in June 2022",
          "url": "https://reproducible-builds.org/reports/2022-06/",
          "excerpts": [
            "The Reproducible Builds project runs a significant testing framework at tests.reproducible-builds.org, to check packages and other artifacts for reproducibility ..."
          ]
        },
        {
          "title": "Reproducible builds for rustc: GSOC '25 idea - Rust Internals",
          "url": "https://internals.rust-lang.org/t/reproducible-builds-for-rustc-gsoc-25-idea/22532",
          "excerpts": [
            "I'm creating this topic to share my understanding of the problem and what approaches are available to potentially try and build this capability."
          ]
        },
        {
          "title": "Mold Linker Performance Remains Very Compelling In 2024 Over ...",
          "url": "https://www.phoronix.com/news/Mold-Linker-2024-Performance",
          "excerpts": [
            "The Mold high performance linker has long been known for offering excellent performance over GNU Gold/ld and LLVM lld while some fresh benchmark numbers ..."
          ]
        },
        {
          "title": "Is there still any performance benefit to using non-default linkers?",
          "url": "https://www.reddit.com/r/rust/comments/1cokapn/is_there_still_any_performance_benefit_to_using/",
          "excerpts": [
            "I still see a huge difference just not for --release builds. I would still recommend lld or mold for debug builds on Linux."
          ]
        },
        {
          "title": "The Rust compiler is now compiled with (thin) LTO (finally) ...",
          "url": "https://www.reddit.com/r/rust/comments/ycmqml/the_rust_compiler_is_now_compiled_with_thin_lto/",
          "excerpts": [
            "rustc is now compiled with (thin) LTO (PR), which resulted in very nice gains across the board, and even without any noticeable regressions!See more"
          ]
        },
        {
          "title": "How I experimented with PGO enabled LLVM in Fedora",
          "url": "https://developers.redhat.com/articles/2023/11/07/how-i-experimented-pgo-enabled-llvm-fedora",
          "excerpts": [
            "This article explains how I've done experiments to implement and evaluate a Profile-Guided Optimization (PGO) enabled LLVM toolchain in ..."
          ]
        },
        {
          "title": "[ELF] A new code layout algorithm for function reordering ...",
          "url": "https://reviews.llvm.org/D152840",
          "excerpts": [
            "We are brining a new algorithm for function layout (reordering) based on the call graph (extracted from a profile data)."
          ]
        },
        {
          "title": "Undefined Behavior Tools and Tutorials",
          "url": "https://www.philipzucker.com/undefined_behavior/",
          "excerpts": [
            "I am not an expert in undefined behavior. Take anything you read here with a grain of salt.",
            "\nJust to check that it isn‚Äôt compiling away. ```",
            " The UBSanitizer injects runtime checks for undefined behavior happening. I am unsure how complete these checks are or whther they can be optimized away. They probably try to make sure they are as reliable as is possible.",
            "I mentioned a couple tools for checking on undefined behavior. Here I'll try the undefined behavior sanitizer which comes with your compiler and ... Try in colab: https://colab.research.google.com/github/philzook58/philzook58.github.io/blob/master/pynb/2024-02-05-undefined_behavior.ipynb"
          ]
        },
        {
          "title": "How to Secure Coding in C and C++ Using Fuzz Testing",
          "url": "https://www.code-intelligence.com/blog/secure-coding-cpp-using-fuzzing",
          "excerpts": [
            "Use this simplified fuzz testing approach to ensure secure coding in C and C++ applications and prevent memory corruptions and security vulnerabilities."
          ]
        },
        {
          "title": "Fuzzing in Depth - AFLplusplus",
          "url": "https://aflplus.plus/docs/fuzzing_in_depth/",
          "excerpts": [
            "libfuzzer LLVMFuzzerTestOneInput() harnesses are the defacto standard for fuzzing, and they can be used with AFL++ (and honggfuzz) as well! Compiling them is as ..."
          ]
        },
        {
          "title": "Memory/Address Sanitizer vs Valgrind",
          "url": "https://stackoverflow.com/questions/47251533/memory-address-sanitizer-vs-valgrind",
          "excerpts": [
            "I am considering Sanitizer(Memory and/or Address) and Valgrind. But I have very little idea about their advantages and disadvantages."
          ]
        },
        {
          "title": "The New Safety-Critical Rust Consortium: We're in!",
          "url": "https://ferrous-systems.com/blog/new-safety-critical-rust-consortium/",
          "excerpts": [
            "Ferrocene is the first open-source qualified Rust compiler toolchain for safety- and mission-critical applications.",
            "Jun 12, 2024 ‚Äî The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software ‚Äî¬†...",
            "Jun 12, 2024 ‚Äî Safety-Critical Rust Consortium Membership is open to Rust Foundation member organizations and other invitees, such as industry, academic, and¬†..."
          ]
        },
        {
          "title": "It's official: Ferrocene is ISO 26262 and IEC 61508 qualified!",
          "url": "https://www.reddit.com/r/embedded/comments/17qmgav/its_official_ferrocene_is_iso_26262_and_iec_61508/",
          "excerpts": [
            "Ferrocene is an upstream Rust compiler for safety-critical and cyber-security use and an open source project."
          ]
        },
        {
          "title": "Converting C++ to Rust: RunSafe's Journey to Memory Safety",
          "url": "https://runsafesecurity.com/blog/convert-c-to-rust/",
          "excerpts": [
            "Mar 24, 2025 ‚Äî Learn how RunSafe converted 30k+ lines of C++ to Rust, achieving memory safety, faster builds, and Secure by Design standards with minimal¬†..."
          ]
        },
        {
          "title": "Announcing the Safety-Critical Rust Consortium",
          "url": "https://rustfoundation.org/media/announcing-the-safety-critical-rust-consortium/",
          "excerpts": [
            "The gap in safety-critical resources within the Rust programming language ecosystem is also an exciting opportunity.",
            "An ecosystem of tools and tool vendors have evolved, and best practices have been learned to create a safety culture around tooling.",
            "Without closing this gap, a developer must primarily rely on best practices and normative precautions, which can limit innovation.",
            "Rust offers particular advantages in terms of developer ergonomics, productivity and software quality; however, it lacks a deep and established well of safety-processes and collective industry knowledge of safety-critical systems.",
            "The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software.",
            "Jun 12, 2024 ‚Äî The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software."
          ]
        },
        {
          "title": "rustfoundation/safety-critical-rust-consortium",
          "url": "https://github.com/rustfoundation/safety-critical-rust-consortium",
          "excerpts": [
            "The primary objective of this group will be to support the responsible use of the Rust programming language in safety-critical software."
          ]
        },
        {
          "title": "C2Rust: translate C into Rust code : r/programming - Reddit",
          "url": "https://www.reddit.com/r/programming/comments/8tglyb/c2rust_translate_c_into_rust_code/",
          "excerpts": [
            "Specifically, we provide compiler plugins that instrument the C and Rust code to check that they compute the same results. By default, we cross¬†...",
            "By default, we cross check function arguments and return values. Now, as the Rust code is made more idiomatic, the C and Rust code will no ..."
          ]
        },
        {
          "title": "Why does Rust bindgen have bitfields?",
          "url": "https://www.reddit.com/r/rust/comments/v98a2d/why_does_rust_bindgen_have_bitfields/",
          "excerpts": [
            "The philosophy behind bindgen is therefore, that it must be able to match any structure encountered in a C header file, which includes bitfields unfortunatly."
          ]
        },
        {
          "title": "Incorrect layout with large bitfield ¬∑ Issue #1007 ¬∑ rust-lang/ ...",
          "url": "https://github.com/rust-lang/rust-bindgen/issues/1007",
          "excerpts": [
            "Sep 20, 2017 ‚Äî Panic when running the layout tests: our generated struct ends up with the wrong size. Expected Results. We generate a struct with the correct¬†..."
          ]
        },
        {
          "title": "`repr(C)`: Clear, Simple and (Sometimes) Wrong - Jack Wrenn",
          "url": "https://jack.wrenn.fyi/blog/repr-c-limitations/",
          "excerpts": [
            "Jul 31, 2024 ‚Äî The promise of repr(C) is quite limited: applied to a struct, it guarantees that a particular layout algorithm will be used for that struct."
          ]
        },
        {
          "title": "Known limitations - C2Rust Manual",
          "url": "https://c2rust.com/manual/docs/known-limitations.html",
          "excerpts": [
            "Known Limitations of Translation. This document tracks things that we know the translator can't handle, as well as things it probably won't ever handle."
          ]
        },
        {
          "title": "Exploring Seamless Rust Interop for Newer Languages, Part 1",
          "url": "https://verdagon.dev/blog/exploring-seamless-rust-interop-part-1",
          "excerpts": [
            "Missing: best practices"
          ]
        },
        {
          "title": "Providing C ffi for a rust crate best practices - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/auwlj1/providing_c_ffi_for_a_rust_crate_best_practices/",
          "excerpts": [
            "The outer FFI layer crate is a layer and can be cleanly separated from the inner Rust crate. That way, users of the Rust library do not need to ..."
          ]
        },
        {
          "title": "Understanding safety limitions of slice::from_raw_parts - help",
          "url": "https://users.rust-lang.org/t/understanding-safety-limitions-of-slice-from-raw-parts/104907",
          "excerpts": [
            "Missing: zero- copy interop"
          ]
        },
        {
          "title": "Builder in bindgen - Rust",
          "url": "https://docs.rs/bindgen/latest/bindgen/struct.Builder.html",
          "excerpts": [
            "Set whether layout tests should be generated. Layout tests are generated by default. Source. pub fn impl_debug(self, doit: bool) -> Self. Set whether Debug¬†...",
            "For each C enum, bindgen tries to match the pattern in the following order: Constified enum module; Bitfield enum; Newtype enum; Rustified enum. If none of the¬†..."
          ]
        },
        {
          "title": "> Essentially, the ISO 26262 certification mostly verifies that ...",
          "url": "https://news.ycombinator.com/item?id=36791662",
          "excerpts": [
            "The main page for Ferrocene says \"ISO 26262 and IEC 61508 qualified\" with \"DO-178C, ISO 21434, and IEC 62278 in the future,\" so depending on exactly which ..."
          ]
        },
        {
          "title": "C2rust: Transpile C to Rust - Hacker News",
          "url": "https://news.ycombinator.com/item?id=30169263",
          "excerpts": [
            "A pipeline of tools to help you eventually translate existing C code into idiomatic Rust, rather than just letting you compile C code using the Rust compiler."
          ]
        },
        {
          "title": "C2Rust Manual",
          "url": "https://c2rust.com/manual/print.html",
          "excerpts": [
            "Generating compile_commands. The compile_commands. json file can be automatically created using either cmake , intercept-build , or bear . It ...",
            "There are several known limitations in this translator. The translator will emit a warning and attempt to skip function definitions that cannot ..."
          ]
        },
        {
          "title": "Potential bindgen footguns or general security considerations",
          "url": "https://github.com/rust-lang/rust-bindgen/discussions/2810",
          "excerpts": [
            "I'd say the most general security considerations would be included in the rustonomicon as bindgen doesn't provide any extra security safeguards ..."
          ]
        },
        {
          "title": "question on `repr(C)` guarantees : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/1ap47sj/question_on_reprc_guarantees/",
          "excerpts": [
            "Yes, you need #[repr(C)] (or packed) to keep the code sound because the default Rust layout has absolutely no guarantees on struct member ..."
          ]
        },
        {
          "title": "Bindgen bindings modules - Android Open Source Project",
          "url": "https://source.android.com/docs/setup/build/rust/building-rust-modules/source-code-generators/bindgen-modules",
          "excerpts": [
            "Bindgen bindings typically contain a number of generated layout tests to prevent memory layout mismatches. AOSP recommends that you have a test ..."
          ]
        },
        {
          "title": "Other reprs - The Rustonomicon - Rust Documentation",
          "url": "https://doc.rust-lang.org/nomicon/other-reprs.html",
          "excerpts": [
            "Due to its dual purpose as \"for FFI\" and \"for layout control\", repr(C) can be applied to types that will be nonsensical or problematic if passed through the FFI ..."
          ]
        },
        {
          "title": "Clarification repr(C) for register blocks - embedded - Rust Users Forum",
          "url": "https://users.rust-lang.org/t/clarification-repr-c-for-register-blocks/115629",
          "excerpts": [
            "Aug 7, 2024 ‚Äî labelling a struct as repr(C) causes a memory layout where \"The order, size, and alignment of fields is exactly what you would expect from C or C++\"."
          ]
        },
        {
          "title": "Add an option to generate layout tests in a different file. #1655 - GitHub",
          "url": "https://github.com/rust-lang/rust-bindgen/issues/1655",
          "excerpts": [
            "Oct 24, 2019 ‚Äî Bindgen does a bunch of transformations, like adding padding when needed, adding custom types for bitfields, handle base classes, vtables, etc. For trivial¬†..."
          ]
        },
        {
          "title": "What is the best practice to use bindgen for a C library with ...",
          "url": "https://users.rust-lang.org/t/what-is-the-best-practice-to-use-bindgen-for-a-c-library-with-complex-configuration-options/122311",
          "excerpts": [
            "there are typically two main approach to use bindgen: generate bindings at build time in cargo build script;. for ffi libraries with APIs that ..."
          ]
        },
        {
          "title": "Passing an array from C to Rust via FFI with #[!no_std]",
          "url": "https://stackoverflow.com/questions/69030484/passing-an-array-from-c-to-rust-via-ffi-with-no-std",
          "excerpts": [
            "All the answers to this question about passing an array from C to Rust use std::slice::from_raw_parts to convert the raw C pointer and some length information¬†..."
          ]
        },
        {
          "title": "C2SaferRust: Transforming C Projects into Safer Rust with ... - arXiv",
          "url": "https://arxiv.org/html/2501.14257v1",
          "excerpts": [
            "Limitations of ... Rust code generated by the C2Rust transpiler generates a large number of unreachable branches in the C2Rust code."
          ]
        },
        {
          "title": "C2Rust Demonstration",
          "url": "https://c2rust.com/",
          "excerpts": [
            "This tool is able to translate most C modules into semantically equivalent Rust code. These modules are intended to be compiled in isolation."
          ]
        },
        {
          "title": "Rust is DO-178C Certifiable",
          "url": "https://blog.pictor.us/rust-is-do-178-certifiable/",
          "excerpts": [
            "Rust can now meet all the analysis requirements under DO-178C, one of the most stringent safety-critical standards worldwide."
          ]
        },
        {
          "title": "Programming in C and C++ - Lecture 5: Tooling",
          "url": "https://www.cl.cam.ac.uk/~nk480/C1819/lecture5.pdf",
          "excerpts": [
            "‚Ä¢ ASan (Address Sanitizer). ‚Ä¢ MSan (Memory Sanitizer). ‚Ä¢ UBSan (Undefined Behaviour Sanitizer). ‚Ä¢ Valgrind. 3. Page 4. ASan: Address Sanitizer. ‚Ä¢ One of the ..."
          ]
        },
        {
          "title": "2945-c-unwind-abi - The Rust RFC Book",
          "url": "https://rust-lang.github.io/rfcs/2945-c-unwind-abi.html",
          "excerpts": [
            "Guide-level explanation. When declaring an external function that may unwind, such as an entrypoint to a C++ library, use extern \"C-unwind\" instead of extern¬†..."
          ]
        },
        {
          "title": "Does `extern \"C\"` actually support unwind?",
          "url": "https://internals.rust-lang.org/t/does-extern-c-actually-support-unwind/18002",
          "excerpts": [
            "Dec 19, 2022 ‚Äî extern \"C\" is not supposed to support unwinding. This is theoretically forbidden and may cause UB. extern \"C-unwind\" is the right way, although¬†..."
          ]
        },
        {
          "title": "Quickstart - C2Rust Manual",
          "url": "https://c2rust.com/manual/quickstart.html",
          "excerpts": [
            "There are several [known limitations](docs/known-limitations.html) in this\ntranslator. The translator will emit a warning and attempt to skip function\ndefinitions that cannot be translated.",
            "The translator requires the exact compiler commands used to build the C code. To provide this information, you will need a standard compile_commands. json file. Quickstart - C2Rust Manual",
            "To generate a `Cargo.toml` template for a Rust binary, do this:\n\n```\nc2rust transpile --main myprog path/to/compile_commands.json\n```\n\nWhere `--main myprog` tells the transpiler to use the `main` method from `myprog.rs` as the entry point. The translated Rust files will not depend directly on each other like\nnormal Rust modules. They will export and import functions through the C\nAPI. These modules can be compiled together into a single static Rust\nlibrary or binary.",
            "To generate a `Cargo.toml` template for a Rust library, add the `-e` option:\n\n```\nc2rust transpile --emit-build-files path/to/compile_commands.json\n```",
            "Once you have a `compile_commands.json` file describing the C build, translate the C code to Rust with the following command:\n\n```\nc2rust transpile path/to/compile_commands.json\n```"
          ]
        },
        {
          "title": "Installation - C2Rust Manual",
          "url": "https://c2rust.com/manual/installation.html",
          "excerpts": [
            "C2Rust requires LLVM 6 or 7 and its corresponding libraries and clang compiler. Python 3.4 or later, CMake 3.4.3 or later, and openssl (1.0) are also required.See more"
          ]
        },
        {
          "title": "c2rust - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/c2rust/0.10.1",
          "excerpts": [
            "The compile_commands.json file can be automatically created using either cmake , intercept-build , or bear . It may be a good ..."
          ]
        },
        {
          "title": "Introduction to C2Rust :: Immunant, Inc",
          "url": "https://immunant.com/blog/2019/08/introduction-to-c2rust/",
          "excerpts": [
            "Next, we need to generate a compile_commands.json file describing the build. We recommend intercept-build for simplicity but many other tools do ..."
          ]
        },
        {
          "title": "C2Rust documentation and related safety-critical integration notes",
          "url": "https://github.com/immunant/c2rust",
          "excerpts": [
            "he translator requires the exact compiler commands used to build the C code. This information is provided via a compilation database file named\ncompile_commands.json .",
            "To translate C files specified in\ncompile_commands.json (see below),\nrun the\nc2rust tool with the\ntranspile subcommand:",
            "The\ncompile_commands.json file can be automatically created\nusing either\ncmake ,\nmeson ,\nintercept-build , or\nbear .",
            "To generate a\nCargo.toml template for a Rust binary, do this:\nc2rust transpile --binary myprog path/to/compile_commands.json",
            "What platforms can C2Rust be run on? The translator and refactoring tool support both macOS and Linux. Other features, such as cross checking the functionality\nbetween C and Rust code, are currently limited to Linux hosts.",
            "compile_commands.json file can be automatically created\nusing either\ncmake ,\nmeson ,\nintercept-build , or\nbear . It may be a good idea to remove optimizations (\n-OX ) from the compilation database,\nas there are optimization builtins which we do not support translating.",
            "There are several known limitations in this\ntranslator. The translator will emit a warning and attempt to skip function\ndefinitions that cannot be translated.",
            "C2Rust requires LLVM 7 or later with its corresponding clang compiler and libraries. Python 3.6 or later, CMake 3.4.3 or later, and openssl (1.0) are also required.",
            "\nC2Rust helps you migrate C99-compliant code to Rust. The translator (or transpiler),\nc2rust transpile ,\nproduces unsafe Rust code that closely mirrors the input C code. The primary goal of the translator is to preserve functionality;\ntest suites should continue to pass after translation. Generating safe and idiomatic Rust code from C ultimately requires manual effort. We are currently working on analysis to automate some of the effort\nrequired to lift unsafe Rust into safe Rust types.",
            "The translated Rust files will not depend directly on each other like\nnormal Rust modules. They will export and import functions through the C API. These modules can be compiled together into a single static Rust library or binary.",
            "Once you have a\ncompile_commands.json file describing the C build,\ntranslate the C code to Rust with the following command:\nc2rust transpile path/to/compile_commands.json"
          ]
        },
        {
          "title": "C2Rust Manual and Tutorial",
          "url": "https://c2rust.com/manual/docs/cross-check-tutorial.html",
          "excerpts": [
            "Cross-checks can be customized at a fine granularity using [cross-check configuration files or inline attributes",
            "and function call arguments (currently experimental and disabled by default, but can be enabled per argument, function or file).",
            "The C2Rust cross-checkers currently instrument function entry and exit points, function return values,",
            "Cross-checking is an automated way to verify that the translated program behaves the same as the original C code.",
            "and the refactoring passes may also change the code in ways that break semantics.",
            "and later incremental refactoring passes gradually transform this code to Rust code. However, the initial Rust translation might not be a perfect semantic match to the original C code,",
            "The C2Rust transpiler aims to convert C code to semantically equivalent unsafe Rust code,\nand later incremental refactoring passes gradually transform this code to Rust code."
          ]
        },
        {
          "title": "C2Rust Manual",
          "url": "https://c2rust.com/manual/",
          "excerpts": [
            "We provide plugins for `clang` and `rustc` so you can compile and run two binaries and check that they behave identically (at the level of function calls).",
            "The translator (or transpiler), produces unsafe Rust code that closely mirrors the input C code. The primary goal of the translator is to produce code that is functionally identical to the input C code. Generating safe or idomatic Rust is *not* a goal for the translator. Rather, we think the best approach is to gradually rewrite the translated Rust code using dedicated refactoring tools",
            "C2Rust helps you migrate C99-compliant code to Rust. It provides:\n\n* a C to Rust translator\n* a Rust code refactoring tool\n* tools to cross-check execution of the C code against the new Rust"
          ]
        },
        {
          "title": "Intel TSC synchronization discussion (Stack Overflow thread)",
          "url": "https://stackoverflow.com/questions/10921210/cpu-tsc-fetch-operation-especially-in-multicore-multi-processor-environment",
          "excerpts": [
            "On newer CPUs (i7 Nehalem+ IIRC) the TSC is synchronzied across all cores and runs a constant rate.",
            "The TSCs are synchronized at the initialization using a RESET that happens across the cores and processors in a multi processor/multi core system. And after that every Core is on their own. The TSCs are kept invariant with a Phase Locked Loop that would normalize the frequency variations and thus the clock variations within a given Core and that is how the TSC remain in sync across cores and processors."
          ]
        },
        {
          "title": "Intel TSC Time-Stamp Counter Adjustment (forum/document excerpt)",
          "url": "https://forums.guru3d.com/threads/a-bit-detailed-info-on-intel-time-stamp-counter-tsc.433977/",
          "excerpts": [
            "een successive reads of the TSC. > It can also be used to adjust for per-CPU differences in TSC values in a NUMA system. >   \n   > 17.15.3 Time-Stamp Counter Adjustment  \n   >   \n   > Software can modify the value of the time-stamp counter (TSC) of a logical processor by using the WRMSR instruction to write to the IA32\\_TIME\\_STAMP\\_COUNTER MSR (address 10H). Because such a write applies only to that logical processor, software seeking to synchronize the TSC values of multiple logical processors must perform these writes on each logical processor. It may be difficult for software to do this in a way than ensures that all logical processors will have the same value for the TSC at a given point in time. > The synchronization of TSC adjustment can be simplified by using the 64-bit IA32\\_TSC\\_ADJUST MSR (address 3BH). Like the IA32\\_TIME\\_STAMP\\_COUNTER MSR, the IA32\\_TSC\\_ADJUST MSR is maintained separately for each logical processor. A logical processor maintains and uses the IA32\\_TSC\\_ADJUST MSR as follows:  \n   > ‚Ä¢ On RESET, the value of the IA32\\_TSC\\_ADJUST MSR is 0."
          ]
        },
        {
          "title": "Griffin: A Practical Evaluation of Hardware-Assisted Control-Flow Integrity (ASPLoS'17)",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2017/01/griffin-asplos17.pdf",
          "excerpts": [
            ". On average, Intel PT tracing introduces a 4.7% slow- down."
          ]
        },
        {
          "title": "[JDK-8355287] Update Invariant TSC cpu frequency ...",
          "url": "https://bugs.openjdk.org/browse/JDK-8355287",
          "excerpts": [
            "Apr 22, 2025 ‚Äî The invariant TSC is based on the invariant timekeeping hardware (called Always Running Timer or ART), that runs at the core crystal clock¬†..."
          ]
        },
        {
          "title": "CNTVCT: Counter-timer Virtual Count register",
          "url": "https://developer.arm.com/documentation/ddi0595/2020-12/AArch32-Registers/CNTVCT--Counter-timer-Virtual-Count-register?lang=en",
          "excerpts": [
            "Holds the 64-bit virtual count value. The virtual count value is equal to the physical count value minus the virtual offset visible in CNTVOFF. Configuration."
          ]
        },
        {
          "title": "ARMv7 Generic Timers",
          "url": "https://wiki.osdev.org/ARMv7_Generic_Timers",
          "excerpts": [
            "ARMv7 generic timers provide a system-wide timestamp counter, independent of CPU clock, with physical and virtual upcounters, and 4 timers per CPU."
          ]
        },
        {
          "title": "Formula for Trace bandwidth analysis",
          "url": "https://developer.arm.com/documentation/ka004901/latest/",
          "excerpts": [
            "Step 1: Specify a core's maximum ETM trace requirement in bits per cycle. ¬∑ Step 2: Determine proper ATB bus width ¬∑ Step 3: Determine trace max bandwidth ..."
          ]
        },
        {
          "title": "Is TSC synchronized across sockets in current Intel CPU?",
          "url": "https://community.intel.com/t5/Mobile-and-Desktop-Processors/Is-TSC-synchronized-across-sockets-in-current-intel-CPU/td-p/1295309",
          "excerpts": [
            "nized. However, it is not clear from the manual whether each core is able to receive the RESET signal at the same time, especially in a multi-socket (like",
            "from \"Intel¬Æ 64 and IA-32 Architectures Software Developer‚Äôs Manual\", we know that in the latest CPU, TSC(timestamp counter) is constant and invariant.",
            "Is TSC synchronized across sockets in current intel CPU?",
            "Jul 2, 2021 ‚Äî It means that TSC in each core will tick at a constant rate. If each core receives the RESET signal at the same time, then TSC is synchronized."
          ]
        },
        {
          "title": "Measuring Latency in Linux",
          "url": "http://btorpey.github.io/blog/2014/02/18/clock-sources-in-linux",
          "excerpts": [
            "Feb 18, 2014 ‚Äî A CPU with a constant, invariant TSC (time-stamp counter). This means that the TSC runs at a constant rate across all sockets/cores¬†..."
          ]
        },
        {
          "title": "[v7,6/8] x86: tsc: Always Running Timer (ART) correlated clocksource",
          "url": "https://patchwork.ozlabs.org/patch/582361/",
          "excerpts": [
            "On modern Intel systems TSC is derived from the new Always Running Timer (ART). ART can be captured simultaneous to the capture of audio and network device ..."
          ]
        },
        {
          "title": "tiiuae/kmod-sel4-tracebuffer",
          "url": "https://github.com/tiiuae/kmod-sel4-tracebuffer",
          "excerpts": [
            "seL4 tracebuffer access and control linux kernel module. Configure. You need to provide following information in device tree file: reserved-memory {¬†..."
          ]
        },
        {
          "title": "On the Precision of Precise Event Based Sampling",
          "url": "https://ipads.se.sjtu.edu.cn/_media/pub/perf-apsys20.pdf",
          "excerpts": [
            "por J Yi ¬∑ 2020 ¬∑ Mencionado por 28 ‚Äî Many performance studies rely on Intel's Precise Event Based. Sampling (PEBS) to collect processor events, where precision is a key for the ..."
          ]
        },
        {
          "title": "Calculate system time using rdtsc - c++ - Stack Overflow",
          "url": "https://stackoverflow.com/questions/42189976/calculate-system-time-using-rdtsc",
          "excerpts": [
            "The TSC is based on the ART (Always Running Timer) when invariant. The correct formula is TSC_Value = (ART_Value * CPUID.15H:EBX[31:0] ..."
          ]
        },
        {
          "title": "Support for Intel Processor Trace within perf tools - Ubuntu Manpage",
          "url": "https://manpages.ubuntu.com/manpages/focal/man1/perf-intel-pt.1.html",
          "excerpts": [
            "auxtrace mmap size option Intel PT buffer size is specified by an addition to the -m option e.g. -m,16 selects a buffer size of 16 pages i.e. 64KiB. Note ..."
          ]
        },
        {
          "title": "CoreSight STM-500: Real-Time Debug Instrumentation",
          "url": "https://www.arm.com/products/silicon-ip-system/coresight-debug-trace/coresight-stm-500",
          "excerpts": [
            "Arm CoreSight STM-500 offers low-latency, high-bandwidth trace for real-time software and hardware visibility, supporting 64-bit and 32-bit systems."
          ]
        },
        {
          "title": "External Trace Width and Bandwidth",
          "url": "https://developer.arm.com/documentation/ka001391/latest/",
          "excerpts": [
            "The fixed overhead is 1 of 16 bytes and every trace cream change reduces the net data by one byte. ... Number of bytes per branch, for ARM ETM 4.x it is between 3¬†..."
          ]
        },
        {
          "title": "lttng-modules/src/lib/ringbuffer/ring_buffer_frontend.c ...",
          "url": "https://github.com/lttng/lttng-modules/blob/master/src/lib/ringbuffer/ring_buffer_frontend.c",
          "excerpts": [
            "* Desnoyers, Mathieu (2009), \"Low-Impact Operating System Tracing\", Ph.D. * dissertation, Ecole Polytechnique de Montreal."
          ]
        },
        {
          "title": "On the precision of precise event based sampling",
          "url": "https://dl.acm.org/doi/10.1145/3409963.3410490",
          "excerpts": [
            "In this paper, we make a study on the precision of PEBS and show that, while by its name being precise, PEBS can cause mistakes under shadowing, which may make ..."
          ]
        },
        {
          "title": "LTTng: Filling the Gap Between Kernel Instrumentation and a Widely Usable Kernel Tracer",
          "url": "https://events.static.linuxfound.org/slides/lfcs09_desnoyers_paper.pdf",
          "excerpts": [
            " LTTng\nis\nvery\nlow-overhead",
            "The buffering mech-\nanism is layered in such a way that it permits\ncompiling-in various memory backends to hold\nthe circular buffer",
            "by M Desnoyers ¬∑ Cited by 26 ‚Äî LTTng uses a lockless, formally veri- fied, buffer concurency management algorithm to support instrumentation of code executed from NMI context. The ...",
            "LTTng presents the buffer layout as a contigu-\nously addressable circular buffer, which sup-\nports writing event of variable size, with pay-\nload up to the size of sub-bu"
          ]
        },
        {
          "title": "Perf ring buffer ‚Äî The Linux Kernel documentation",
          "url": "https://docs.kernel.org/userspace-api/perf_ring_buffer.html",
          "excerpts": [
            "The ring buffer implementation is critical but it‚Äôs also a very\nchallenging work. On the one hand, the kernel and perf tool in the user\nspace use the ring buffer to exchange data and stores data into data\nfile, thus the ring buffer needs to transfer data with high throughput;\non the other hand, the ring buffer management should avoid significant\noverload to distract profiling results.",
            "The ring buffer is a fundamental mechanism for data transfer. perf uses\nring buffers to transfer event data from kernel to user space, another\nkind of ring buffer which is so called auxiliary (AUX) ring buffer also\nplays an important role for hardware tracing with Intel PT, Arm\nCoreSight, etc."
          ]
        },
        {
          "title": "Intel PT Data at Rest: A Compression Experiment",
          "url": "https://istc-arsa.iisp.gatech.edu/intel-pt-data-at-rest-a-compression-experiment.html",
          "excerpts": [
            "It is understandable that the compression used by PT would produce small space\nsavings compared to general compression algorithms given the limitations of\nhardware memory and Intel's very strict performance overhead requirements.",
            "If nothing else, it is useful for repeatable experiments.",
            "The other common approach is to configure PT to write in a circular\nbuffer.",
            "One option is to consume the\ntrace as it is generated.",
            "As a consequence, much of the work\npublished so far handles tracing in one of two ways.",
            "Intel Processor Trace (PT) is a powerful hardware feature for recording the\nbehavior of CPUs. With it, developers and researchers can monitor the\ncontrol-flow path taken by threads, hardware interrupts, and more, all with\ncycle-accurate timing.",
            "However, while some applications are feasible using the two previous methods,\nthere are still situations were it is desirable to store the entire trace for\npostmortem analysis.",
            "the largest source of\nperformance overhead is not PT tracing itself but rather the time spent\nbuffering and consuming it.",
            "In practice, PT produces an overhead of less than 4% in the worst case, and less than 2% on average."
          ]
        },
        {
          "title": "Pitfalls of TSC usage - Oliver Yang",
          "url": "http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/",
          "excerpts": [
            "If you have to use it, please make your application ‚ÄúTSC-resilient‚Äù. Use it for debugging, but never use rdtsc in functional area. As we mentioned above, Linux kernel also had hard time to handle it until today.",
            "If possible, avoid to use rdtsc in user applications. Not all of hardware, hypervisors are TSC safe, which means TSC may behave incorrectly. TSC usage will cause software porting bugs cross various x86 platforms or different hypervisors. Leverage syscall or vsyscall will make software portable, especially for Virtualization environment.",
            "There is no reliable TSC sync mechanism for user application especially under a Virtualization environment.",
            "Linux kernel could detect TSC sync problem and try to be ‚ÄúTSC-resilient‚Äù.",
            "The invariant TSC will run at a constant rate in all ACPI P-, C-, and T-states. This is the architectural behavior moving forward.",
            "Sep 9, 2015 ‚Äî Whereas on a SMP system, the TSC sync problem cross multiple CPU sockets could be a big problem. There are 3 type of SMP systems, No sync¬†..."
          ]
        },
        {
          "title": "CNTVCT: Counter-timer Virtual Count - Arm Developer",
          "url": "https://developer.arm.com/documentation/ddi0601/latest/External-Registers/CNTVCT--Counter-timer-Virtual-Count",
          "excerpts": [
            "CNTVCT can be implemented in any implemented CNTBaseN frame, and in the corresponding CNTEL0BaseN frame, as a RO register."
          ]
        },
        {
          "title": "tsc/README.md at master ¬∑ dterei/tsc",
          "url": "https://github.com/dterei/tsc/blob/master/README.md",
          "excerpts": [
            "Processor's support for invariant TSC is indicated by CPUID.80000007H:EDX[8]. The invariant TSC will run at a constant rate in all ACPI P-, C-. and T-states."
          ]
        },
        {
          "title": "A wait-free single-producer single-consumer ring buffer ... - blog",
          "url": "https://blog.paul.cx/post/a-wait-free-spsc-ringbuffer-for-the-web/",
          "excerpts": [
            "Jun 6, 2022 ‚Äî This method is also real-time safe, specifically wait-free. It is possible to ask if the buffer is full, empty, and the number of elements¬†..."
          ]
        },
        {
          "title": "perf tools support for Intel¬Æ Processor Trace",
          "url": "https://perfwiki.github.io/main/perf-tools-support-for-intel-processor-trace/",
          "excerpts": [
            "In this case 109 MB of data is manageable to process.",
            "        IPC: 0.22 (7/31) \n\n```\n\nThe last 4 correspond to the 4 TSC values, so we have:\n\n```\n     ns                                 TSC ticks / ns\n    144         IPC: 0.04 (7/173) \n      8         IPC: 0.70 (7/10) \n      3         IPC: 1.75 (7/4)         359 / 132   rdtsc with no ordering\n     61         IPC: 0.09 (7/73)        234 /  86   rdtscp with no ordering before\n     26         IPC: 0.22 (7/31)        184 /  68   rdtscp with ordering",
            " perf tools do not support output of Intel PT to Intel¬Æ Trace Hub.",
            "CPU overhead is low, but memory bandwidth consumption can be significant.",
            "The trace shows the CPU, timestamp in nanoseconds, and event information:\n\"psb\" is the Intel PT synchronization event. \"cbr\" (core-to-bus ratio) shows the CPU frequency.",
            "Cycle-accurate mode adheres to the following protocol:\n* All packets that precede a CYC packet represent instructions or events that took place before the CYC time. * All packets that follow a CYC packet represent instructions or events that took place at the same time as, or\nafter, the CYC time. * The CYC-eligible packet that immediately follows a CYC packet represents an instruction or event that took\nplace at the same time as the CYC time.",
            "Intel PT can be run in a cycle-accurate mode which enables CYC packets (see Section 32.4.2.14) that provide low-\nlevel information in the processor core clock domain. This cycle counter data in CYC packets can be used to\ncompute IPC (Instructions Per Cycle), or to track wall-clock time on a fine-grain level.",
            "Intel PT can potentially produce hundreds of megabytes of trace data per CPU per second. That can be at a faster rate than it can be recorded to file (resulting¬†..."
          ]
        },
        {
          "title": "Benchmarking Tools",
          "url": "https://docs.sel4.systems/projects/sel4-tutorials/benchmarking-guide.html",
          "excerpts": [
            "### Advanced Use\n\n#### Conditional Logging\n\nA log is stored when `TRACE_POINT_STOP(i)` is called, only if a corresponding `TRACE_POINT_START(i)` was called since the last call to `TRACE_POINT_STOP(i)` or system boot.",
            "### Results\n\nAll results are in cycles. Results were obtained using the method described\nabove. The total overhead is the number of cycles added to execution per\ntracepoint start/stop pair (inner pair result subtracted from outer pair\nresult). The effective overhead is the number of cycles added to a measurement\nby the tracepoint instrumentation (inner pair result).",
            " ## Tracepoints\n\nThese allow the user to specify tracepoints in the kernel to track the time\nbetween points. ### How to use\n\nSet the `KernelBenchmarks` CMake config option to `tracepoints` .\nThen set the `KernelMaxNumTracePoints` CMake config option to a non-zero value. Wrap the regions you wish to time with `TRACE_POINT_START(i)` and `TRACE_POINT_STOP(i)` where `i` is an integer from 0 to less than the value of\n‚ÄúMaximum number of tracepoints‚Äù. The number of cycles consumed between a `TRACE_POINT_START` and `TRACE_POINT_STOP` will be stored in an in-kernel log.",
            "#### `seL4_BenchmarkResetLog()`\n\nThis system call resets global counters as well as idle thread counters since\nthe previous call to the same function, and (re)starts CPU utilisation tracking. It does not reset counters for individual threads.",
            "CPU Utilisation\n\nThreads, including the idle thread, and the overall system time can be tracked\nby enabling the ‚Äútrack CPU utilisation feature‚Äù. This feature can be enabled by\nsetting the CMake configuration option `KernelConfiguration` to `track_utilisation` . By enabling CPU utilisation tracking, the kernel is instrumented with variables\nand functions to log the utilisation time for each thread in cycles.",
            "Benchmarking Tools. The sel4bench-manifest repository collection provides a set of tools which can be used to analyse kernel and workload performance.",
            "Users must provide a capability to a large frame for the kernel to use as a log buffer. The frame will be mapped write-through to avoid impacting the caches.",
            "An in-kernel log buffer can be provided by the user when the KernelBenchmarks CMake config option is set to track_kernel_entries or tracepoints with the system ..."
          ]
        },
        {
          "title": "A Scalable Approach to AXI4 Transaction Monitoring",
          "url": "https://arxiv.org/html/2501.17605v1",
          "excerpts": [
            "Jan 29, 2025 ‚Äî To achieve near-zero Defective Parts Per Million (DPPM) and comply with standards such as ISO 26262 and Automotive Safety Integrity Levels (¬†..."
          ]
        },
        {
          "title": "x86 TSC is really invariant?",
          "url": "https://stackoverflow.com/questions/79343283/x86-tsc-is-really-invariant",
          "excerpts": [
            "The invariant TSC is based on the invariant timekeeping hardware (called Always Running Timer or ART), that runs at the core crystal clock frequency."
          ]
        },
        {
          "title": "Invariant TSC support",
          "url": "https://community.intel.com/t5/Intel-ISA-Extensions/Invariant-TSC-support/m-p/772125",
          "excerpts": [
            "Dec 21, 2011 ‚Äî The invariant TSC means that the TSC continues at a fixed rate regardless of the C-state or frequency of the processor (as long as the processor remains in the¬†..."
          ]
        },
        {
          "title": "RTMLib lock-free and wait-free ring buffer - GitHub Pages",
          "url": "https://anmaped.github.io/rtmlib/doc/md_doc_lock_free.html",
          "excerpts": [
            "The wait-free and lock-free ring buffers is a useful technique for time and memory sensitive systems such as the real-time systems."
          ]
        },
        {
          "title": "The design and implementation of a lock-free ring-buffer ...",
          "url": "https://ferrous-systems.com/blog/lock-free-ring-buffer/",
          "excerpts": [
            "A BipBuffer is a bi-partite circular buffer that always supports writing a contiguous chunk of data, instead of potentially splitting a write in two chunks."
          ]
        },
        {
          "title": "Detecting Spectre and Meltdown Using Hardware ...",
          "url": "https://www.elastic.co/blog/detecting-spectre-and-meltdown-using-hardware-performance-counters",
          "excerpts": [
            "Jan 8, 2018 ‚Äî There are dozens of events available and processors can be programmed from the kernel to monotonically count events with near-zero overhead."
          ]
        },
        {
          "title": "Lockless Multi-Core High-Throughput Buffering Scheme for ...",
          "url": "https://www.dorsal.polymtl.ca/files/publications/desnoyers-acm-lttng-buffering-submitted.pdf",
          "excerpts": [
            "by M DESNOYERS ¬∑ Cited by 34 ‚Äî The formal verification performed by modeling the LTTng algorithms and using the Spin model-checker permits to increase the level of confidence that such corner¬†...",
            "by M DESNOYERS ¬∑ Cited by 34 ‚Äî This paper presents the core of LTTng's buffering algorithms and benchmarks its performance. Categories and Subject Descriptors: B.8.2 [Performance and ..."
          ]
        },
        {
          "title": "ARM CoreSight Architecture Specification",
          "url": "https://documentation-service.arm.com/static/5f900a19f86e16515cdc041e?token=",
          "excerpts": [
            "ARM¬Æ ETM‚Ñ¢ Architecture Specification, ETMv4 (ARM IHI 0064). ‚Ä¢. ARM¬Æ Debug ... See also CoreSight ECT and CoreSight ETM. CoreSight ECT. See Embedded Cross¬†..."
          ]
        },
        {
          "title": "Timed Process Event-Based Sampling (TPEBS) - Intel",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/timed-process-event-based-sampling-tpebs.html",
          "excerpts": [
            ". The performance monitoring unit (PMU) provides access to performance events and processor event-based sampling (PEBS).\n. In counting mode, performance counters are used to count occurrences of selected performance events in specific time intervals.\n. In sampling mode, performance counters are set to predefined initial values, and then count the occurrence of selected performance events.\n, PEBS mitigates the skid problem and largely reduces sampling overhead.\n"
          ]
        },
        {
          "title": "perf-intel-pt(1) - Linux manual page",
          "url": "https://www.man7.org/linux/man-pages/man1/perf-intel-pt.1.html",
          "excerpts": [
            "Intel Processor Trace (Intel PT) is an extension of Intel Architecture that collects information about software execution such as control flow, execution modes¬†..."
          ]
        },
        {
          "title": "Low-level interface to io_uring (Unixism)",
          "url": "https://unixism.net/loti/low_level.html",
          "excerpts": [
            "\n\nThe submission queue entry is a bit more complex than a completion queue entry since it needs to be generic enough to represent and deal with a wide range of I/O operations possible with Linux today.",
            "While I did mention that can CQEs arrive in any order, you can force ordering of certain operations with SQE ordering, in effect chaining them."
          ]
        },
        {
          "title": "REPLAY and Deterministic Execution‚ÄîRelated Work and Overview",
          "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=c3b53ce4e52c5f18f58edc4e614e47e3151edd82",
          "excerpts": [
            "Dthreads provides determinism by mapping threads\nto processes in order to provide separate address spaces for each\nthread, which it merges at each synchronization point [35].",
            "On average, REPLAY‚Äôs run-time overhead is 29%.",
            "REPLAY not only often does less work than RECORD, but RE-\nPLAY also enables more parallelism than both RECORD and base-\nline execut",
            "lay is the full default REPLAY analysis: it replays cross-\nthread dependences, tracks DPL by updating T.dynCtr, and in-\ncludes the determinism changes used by RECORD.",
            "This paper makes two main contributions. First,\nwe design, implement, and evaluate an analysis for replaying de-\npendences recorded by prior work‚Äôs dependence recorder [11"
          ]
        },
        {
          "title": "rr: The rr Debugger",
          "url": "https://github.com/rr-debugger/rr",
          "excerpts": [
            " The best technical overview is currently the paper [Engineering Record And Replay For Deployability: Extended Technical Report](https://arxiv.org/pdf/1705.05937.pdf)",
            " rr development is sponsored by [Pernosco](https://pernos.co) and was originated by [Mozilla](https://www.mozilla.org) .",
            "Debugging extends gdb with very efficient reverse-execution, which in combination with standard gdb/x86 features like hardware data watchpoints, makes debugging much more fun.",
            "rr is a lightweight tool for recording, replaying and debugging execution of applications (trees of processes and threads)."
          ]
        },
        {
          "title": "Asynchronous event timing. HW performance counters. Trap on a subset of system calls seccomp-bpf. Notification when system call blocks in the kernel. DESCHED ... Practical Record And Replay Debugging With rr",
          "url": "https://www.usenix.org/sites/default/files/conference/protected-files/atc17_slides_ocallahan.pdf",
          "excerpts": [
            "Kernel read()",
            "Kernel read()",
            "after_syscall",
            "\n\nbefore_syscall\n",
            "FIOCLONERANGE",
            "Cheap block copies",
            "DESCHED perf events",
            "Notification when system call blocks in the kernel",
            "Trap on a subset of system calls seccomp-bpf",
            "HW performance counters",
            "Asynchronous event timing",
            "Deterministic hardware",
            "ptrace",
            "ptrace",
            "rr design",
            "Observable effects",
            "System call results",
            "Linux process \n\nbounda",
            "CPU execution",
            "Deterministic user-space",
            "rr Overhead",
            "rr goals",
            "Replay execution",
            "Record inputs",
            "Sources of nondeterminism"
          ]
        },
        {
          "title": "Debugging GDB using rr ptrace emulation",
          "url": "https://robert.ocallahan.org/2020/03/debugging-gdb-using-rr-ptrace-emulation.html",
          "excerpts": [
            "rr needs to ptrace all the processes it's recording ‚Äî in this case gdb and the process(es) it's debugging."
          ]
        },
        {
          "title": "A Primer on Receive-Side Scaling (RSS) - B. Rothenberger",
          "url": "https://rothenberger.io/post/rss_primer/",
          "excerpts": [
            "Receive-side scaling (RSS) is a technique that enables the distribution of arriving packets between multiple RX hardware queues of the network interface card ( ..."
          ]
        },
        {
          "title": "How to guarantee that the io_uring completion queue ...",
          "url": "https://stackoverflow.com/questions/77580828/how-to-guarantee-that-the-io-uring-completion-queue-never-overflows",
          "excerpts": [
            "The solution here is to call liburing's io_uring_cq_has_overflow() before attempting to submit anything to the submission queue."
          ]
        },
        {
          "title": "Refinement-based Specification and Analysis of Multi-core ...",
          "url": "https://dl.acm.org/doi/10.1145/3617183",
          "excerpts": [
            "Nov 21, 2023 ‚Äî This article complies with the ARINC 653 Part 1‚Äì4, which only considers the ‚Äúuse of multiple processes within a partition scheduled to execute¬†..."
          ]
        },
        {
          "title": "The Record-and-Replay Approach to Debugging",
          "url": "https://queue.acm.org/detail.cfm?id=3391621",
          "excerpts": [
            "Mar 28, 2020 ‚Äî A practical, cost-effective, resource-efficient means for capturing low-frequency nondeterministic test failures in the Firefox browser."
          ]
        },
        {
          "title": "[PDF] Lightweight User-Space Record And Replay - arXiv",
          "url": "https://arxiv.org/pdf/1610.02144",
          "excerpts": [
            "When we get a ptrace event for a blocked system call completing, RR copies scratch buffer contents to the real user-space destination(s) while."
          ]
        },
        {
          "title": "RR - Record & replay software debugger",
          "url": "https://www.dedoimedo.com/computers/rr-gdb-tool.html",
          "excerpts": [
            "Tutorial showing how to setup and use rr, a lightweight recording and replay tool based on gdb, used for deterministic debugging of software ..."
          ]
        },
        {
          "title": "io_uring_enter2(2) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man2/io_uring_enter2.2.html",
          "excerpts": [
            "The CQE flags field will have IORING_CQE_F_MORE set on completion if the application should expect further CQE entries from the original request. If this flag¬†..."
          ]
        },
        {
          "title": "Undo vs rr - What's the Difference? - Undo.io",
          "url": "https://undo.io/resources/undo-vs-rr/",
          "excerpts": [
            "Non-deterministic inputs include data read from sockets or the filesystem, non-deterministic instructions such as rdtsc, asynchronous signals, and reads from ..."
          ]
        },
        {
          "title": "DoublePlay: parallelizing sequential logging and replay",
          "url": "https://dl.acm.org/doi/10.1145/1961296.1950370",
          "excerpts": [
            "We evaluate DoublePlay on a variety of client, server, and scientific parallel benchmarks; with spare cores, DoublePlay reduces logging overhead to an average ..."
          ]
        },
        {
          "title": "InfoQ presentation on rr and reversible debugging",
          "url": "https://www.infoq.com/presentations/rr-reversible-debugging/",
          "excerpts": [
            "Here's an old idea, is to record the source of nondeterminism, and then replay those events back. It's an old idea. It has had many predecessors, but nothing has had serious customer adoption.",
            "At the heart of why is basically either they've been too high overhead. When I say high overhead, I mean hundreds of times slower or thousands of times slower than running the actual binary would be.",
            "They represent real bugs, just because the software that you're running has nondeterminism doesn't mean that you get to ignore it. These are real bugs that might need to be investigated and resolved.",
            "This is practically zero cost, because it's just using performance counters that are already built into the processors that you have on your desktop.",
            "If you have two cores that both access the same piece of memory and do things with it, then that's a source of nondeterminism. RR deals with that by limiting the process to a single core.",
            "You can capture and intercept those events via ptrace, and then respond to them accordingly. RR does that.",
            "RR stands for record and replay. What RR does is it records all the source of nondeterminism as your program runs, and then lets you re-execute your program."
          ]
        },
        {
          "title": "Replay: Recording and Replaying",
          "url": "https://blog.replay.io/recording-and-replaying",
          "excerpts": [
            "The recorder exports functions which can be used both to manipulate ordered locks directly, and to associate ordered locks with system resources like pthread mutexes, so that uses of that resource within library calls will be ordered the same when replaying.",
            "A multithreaded program can behave non-deterministically entirely due to different thread interleavings.",
            "* Multi-threaded programs can be affected by different thread interleavings. If the OS kernel schedules threads differently then those threads can read and write data in different orders, and the program will behave differently.",
            "* Programs can read additional inputs from the environment, for example from a file or network socket. Different runs can read different data, and the program will behave differently.",
            "Non-determinism can leak in and cause repeated runs of a program to behave differently in two ways:",
            "Replay's recorder is based on this idea. In this blog post we'll describe how Replay records and replays these two types of non-determinism."
          ]
        },
        {
          "title": "Deterministic record-and-replay in practice (CACM, 2025)",
          "url": "https://cacm.acm.org/practice/deterministic-record-and-replay/",
          "excerpts": [
            "Deterministic record-and-replay is a technique that allows a user to record a program execution and then replay the exact same execution at a later time . Think of it as being like TiVo, only for processes that execute on a computer.",
            "During recording, such systems store the nondeterministic inputs that were passed to the process (for example, the bytes read from the network) into a log; during replay, the systems then re-execute the process with the values in the log to re-create the execution state.",
            "Thus, a deterministic record-and-replay system can eschew storing most execution states and instead store only information about the nondeterministic actions of the process.",
            "The key insight enabling deterministic record-and-replay is that *most* of a process‚Äôs actions are deterministic‚Äîmeaning their behavior depends entirely on the current state of the proces",
            "Deterministic record-and-replay is a technique that allows a user to record a program execution and then replay the exact same execution at a later time."
          ]
        },
        {
          "title": "Trace file formats ¬∑ Issue #3339 ¬∑ rr-debugger/rr - GitHub",
          "url": "https://github.com/rr-debugger/rr/issues/3339",
          "excerpts": [
            "Are there any docs on the file format and purpose of each file? I have already read the technical pdf. ... I am most interested in how to access/ ..."
          ]
        },
        {
          "title": "DoublePlay: parallelizing sequential logging and replay",
          "url": "https://dl.acm.org/doi/10.1145/1950365.1950370",
          "excerpts": [
            "We evaluate DoublePlay on a variety of client, server, and scientific parallel benchmarks; with spare cores, DoublePlay reduces logging overhead to an¬†..."
          ]
        },
        {
          "title": "RSS: Receive Side Scaling",
          "url": "https://www.kernel.org/doc/Documentation/networking/scaling.txt",
          "excerpts": [
            "The receive queue for a packet is determined by masking out the low order seven bits of the computed hash for the packet (usually a Toeplitz hash), taking this¬†..."
          ]
        },
        {
          "title": "Introduction to Receive Side Scaling (RSS) - Windows drivers",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/drivers/network/introduction-to-receive-side-scaling",
          "excerpts": [
            "Sep 27, 2024 ‚Äî RSS allows the NIC and miniport driver to schedule receive DPCs on other processors. The RSS design ensures that processing associated with a given connection¬†..."
          ]
        },
        {
          "title": "Using io_uring for network I/O",
          "url": "https://news.ycombinator.com/item?id=35547316",
          "excerpts": [
            "Apr 12, 2023 ‚Äî I'm no kernel hacker, but it seems like io_uring is almost being undersold despite the hype. ‚ÄúAsync IO‚Äù seems like an understatement.See more"
          ]
        },
        {
          "title": "Holistic System Design for Deterministic Replay",
          "url": "https://deepblue.lib.umich.edu/bitstream/handle/2027.42/102374/dongyoon_1.pdf?sequence=1",
          "excerpts": [
            "by D Lee ¬∑ 2013 ‚Äî Respec aims to support online deterministic replay in which the recorded and replayed processes execute concurrently. The online replay has been demonstrated to¬†...",
            "by D Lee ¬∑ 2013 ‚Äî A deterministic replay system, which logs all non-deterministic events during recording and reproduces these events during replay, has been shown to be useful¬†...See more"
          ]
        },
        {
          "title": "RR: low overhead record-and-replay debugger for Linux",
          "url": "https://www.reddit.com/r/programming/comments/3uzhgl/rr_low_overhead_recordandreplay_debugger_for_linux/",
          "excerpts": [
            "On the other hand, it advertises ~20% recording slowdown for single-threaded programs which is impressively low, and completely deterministic ..."
          ]
        },
        {
          "title": "DoublePlay: Parallelizing Sequential Logging and Replay",
          "url": "https://web.eecs.umich.edu/~pmchen/papers/veeraraghavan11.pdf",
          "excerpts": [
            "Note that since each\n\nepoch is executed on a single core in the epoch-parallel execution,\n\nDoublePlay does not need to record the ordering or results of any\n\nshared memory operations performed by multiple threads; the three\n\nitems above are sufficient to exactly recreate identical operations\n\nduring re",
            "The execution on the right, which we refer to as the epoch-\n\nparallel execution , runs each epoch on one of the cores allocated\n\nto it. All threads of a given epoch run on the same core, which sim-\n\nplifies the task of deterministically replaying the resulting exe",
            "The execution on the left, which we refer to as the thread-parallel\n\nexecution , runs multiple threads concurrently on the cores allo-\n\ncated to it. DoublePlay partitions the thread-parallel execution into\n\ntime slices called e",
            "Our key insight is that one can use the simpler and faster\n\nmechanisms of single-processor record and replay, yet still achieve\n\nthe scalability offered by multiple cores, by using an additional\n\nexecution to parallelize the record and replay of an applicati",
            "DoublePlay leverages this observation\n\nby logging and replaying epochs that each run the multithreaded\n\nprogram on a single processor, while taking advantage of multiple\n\nprocessors by starting multiple epochs in parall",
            "by K Veeraraghavan ¬∑ 2011 ¬∑ Cited by 271 ‚Äî We evaluate DoublePlay on a variety of client, server, and scientific parallel benchmarks; with spare cores, DoublePlay reduces logging overhead to an average."
          ]
        },
        {
          "title": "Respec and DoublePlay record only synchronization operations; Dthreads; deterministic replay overview",
          "url": "https://mdbond.github.io/roctet-tr.pdf",
          "excerpts": [
            "Exist- ing multithreaded record & replay approaches have serious limitations such as relying on custom hardware or slowing programs by an order of magnitud",
            "Dthreads provides deter-  \nminism by mapping threads to processes in order to pro-  \nvide separate address spaces for each thread, which it merges  \nat each synchronization point ",
            "From a performance perspective, record & replay is\n\nstraightforward for single-threaded code: sources of nonde-  \nterminism, such as I/O, time, and other system-level effects,  \nare infrequent enough that recording and replaying them  \nadds low ov"
          ]
        },
        {
          "title": "Harvard SEAS DoublePlay / Respec Overview",
          "url": "https://www.read.seas.harvard.edu/~kohler/class/cs261-f11/doubleplay.html",
          "excerpts": [
            "DoublePlay‚Äôs\nevaluation shows only a modest benefit from the forward recovery\noptimization (Table 2), which addresses exactly the replay-divergence\nproblem.",
            ". They also\nemphasize the risk that a Respec-recorded execution might, due to bad\nluck, be impossible to replay.",
            "Respec could support offline replay, despite DoublePlay‚Äôs\nclaim.",
            "DoublePlay can always precisely replay any recorded execution in bounded time.",
            "The main requirement is to\nrecord and replay all *nondeterministic* events, so that these events\nhappen at exactly the same times and in exactly the same ways during\nreplay as they did originall",
            "Deterministic replay* is the ability to exactly reproduce an\nexecution of a system"
          ]
        },
        {
          "title": "DoublePlay: Parallelizing Sequential Logging and Replay (UT Austin/CS/DoublePlay paper)",
          "url": "https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/DoublePlay.pdf",
          "excerpts": [
            ". Respec provides only\nonline replay. DoublePlay uses online replay, but only for the purpose of guiding the\nepoch-parallel execution. DoublePlay supports offline replay by logging and replaying\nthe epoch-parallel execution.",
            "Offline Replay. To support offline replay, DoublePlay records the system calls\nand synchronization operations executed during an epoch in a set of log files (for sim-\nplicity, DoublePlay uses a separate log for each thread).",
            ". DoublePlay avoids this type of perturbation;\ninstead, it perturbs the execution by timeslicing threads onto a single processor and\ncontrolling preemptions.",
            ". DoublePlay always chooses to run the highest-priority thread eligible to run that would\npreserve the total ordering of system calls and the partial ordering of synchronization\noperations.",
            "To implement these strategies, we added a custom scheduler layer that chooses ex-\nactly one thread at a time to be run by the Linux scheduler and blocks all other threads\non a wait queue.",
            ". There are two basic strategies\nfor providing this property. One strategy is to use the same deterministic scheduler\nduring epoch-parallel execution and offline replay. The second strategy is to log the\nscheduling decisions made during epoch-parallel execution and replay those decisions\ndeterministically during offline replay.",
            " \nDoublePlay guarantees deterministic offline replay\nby executing each epoch on a single core using the same thread schedule that was\nused during recording by the epoch-parallel execution.",
            "Respec divides the executions\ninto semi-regular intervals called epochs. During each epoch, it compares the argu-\nments passed to all system calls, and, at the end of each epoch, it verifies that the\nmemory and register state of the original and cloned executions match.",
            "Re-\nspec duplicates the process‚Äôs state via a multithreaded fork that clones both its address\nspace and the execution state of all concurrently executing threads. Respec then exe-\ncutes the cloned copy concurrently with the original executio",
            "d\nRespec is a system in the Linux kernel that runs two executions of a multithreaded\nprocess (or set of processes) concurrently.",
            ". DoublePlay builds on\ntop of Respec to provide this capability.",
            "t\nDoublePlay can replay the run later without much additional overhead. On computers\nwithout spare cores, DoublePlay adds approximately 100% overhead for CPU-bound\napplications that can scale to 8 cores; this compares favorably with other software\nsolutions that provide guaranteed deterministic replay.",
            "t\nDoublePlay can replay the run later without much additional overhead. On computers\nwithout spare cores, DoublePlay adds approximately 100% overhead for CPU-bound\napplications that can scale to 8 cores; this compares favorably with other software\nsolutions that provide guaranteed deterministic replay."
          ]
        },
        {
          "title": "rr discussion on determinism and recording",
          "url": "https://github.com/rr-debugger/rr/issues/3640",
          "excerpts": [
            "There are many sources of nondeterminism beyond just the scheduler. rr tries to capture them all so it can replay the recording faithfully ... Some events are not, like the PERF\\_COUNT\\_SW\\_CONTEXT\\_SWITCHES, which is triggered by the system's scheduler. For any given time, there is only one thread whose status is not \"stop\", while others are stopped by a ptrace event. So, the recording is not deterministic even we have our own scheduler in rr, because the system's scheduler may interrupt the execution process. But if we do not switch for the event that is interrupting by system's scheduler, then the recording process is deterministi",
            "Some events are deterministic, like syscalls. Some events are not, like the PERF\\_COUNT\\_SW\\_CONTEXT\\_SWITCHES, which is triggered by the system's schedu",
            "tracee tasks cannot share memory with tasks outside the trace (e.g. X11's DRI has to be disabled).",
            "One of the assumptions of rr is that intervening non-tracee execution won't affect tracee execution. This is not true in all cases.",
            "The system scheduler can interrupt the tracee to schedule non-tracee execution (e.g. a hardware interrupt, or another task that's not part of the recording).",
            "rr tries to capture them all so it can replay the recording faithfully",
            "There are many sources of nondeterminism beyond just the scheduler."
          ]
        },
        {
          "title": "rr project documentation",
          "url": "https://rr-project.org/",
          "excerpts": [
            "rr also provides efficient reverse execution\n under gdb",
            "rr replay guarantees that execution preserves instruction-level control flow\n and memory and register contents. The memory layout is always the same, the addresses of objects\n don't change, register values are identical, syscalls return the\n same data, e",
            "rr automatically disables features such as X shared\n   memory for recorded processes to avoid this probl",
            "cannot record processes that share memory with processes\n   outside the recording tree. This is an inherent feature of the\n   d",
            "For mostly-single-threaded programs, rr has\n much lower overhead than any competing record-and-replay system we know of",
            "The memory layout is always the same, the addresses of objects\n don't change, register values are identical, syscalls return the\n same data, et",
            "The overhead of rr depends on your application's workload. On Firefox test suites, rr's recording performance is quite usable. We see slowdowns ... What makes rr different are the\n design goals",
            "rr records a group of Linux user-space processes and captures all\n inputs to those processes from the kernel, plus any nondeterministic CPU\n effects performed by those processes (of which there are very few"
          ]
        },
        {
          "title": "A Comprehensive Specification and Verification of the L4 ...",
          "url": "https://link.springer.com/chapter/10.1007/978-3-031-57249-4_11",
          "excerpts": [
            "by L Zhang ¬∑ 2024 ‚Äî This paper proposes a comprehensive formal specification and verification for the L4 microkernel API. The specification is reusable for all implementations.",
            "This paper proposes a comprehensive formal specification and verification for the L4 microkernel API. The specification is reusable for all implementations."
          ]
        },
        {
          "title": "An Empirical Study of Timing Channels on seL4",
          "url": "https://www.researchgate.net/publication/289897157_The_Last_Mile_An_Empirical_Study_of_Timing_Channels_on_seL4",
          "excerpts": [
            "We perform such an analysis, collecting a large data set (2,000 hours of observations) for two representative timing channels, the locally-exploitable cache¬†..."
          ]
        },
        {
          "title": "L4 Inter-Process Communication (IPC) - L4Re",
          "url": "https://l4re.org/doc/l4re_concepts_ipc.html",
          "excerpts": [
            "IPC is the fundamental communication mechanism in the L4Re Microkernel. Basically IPC invokes a subroutine in a different context using input and output ..."
          ]
        },
        {
          "title": "DTHREADS: Efficient Deterministic Multithreading",
          "url": "https://people.cs.umass.edu/~emery/pubs/dthreads-sosp11.pdf",
          "excerpts": [
            "by T Liu ¬∑ Cited by 351 ‚Äî This paper presents DTHREADS, an efficient deterministic mul- tithreading system for unmodified C/C++ applications that replaces the pthreads library. DTHREADS¬†..."
          ]
        },
        {
          "title": "RR: The magic of record and replay debugging",
          "url": "https://johnnysswlab.com/rr-the-magic-of-recording-and-replay-debugging/",
          "excerpts": [
            "Aug 16, 2020 ‚Äî RR is a game-changer. It is easy to use, it is free and very usable. If you invest time to learn it, RR will change the way you are debugging your programs."
          ]
        },
        {
          "title": "Application logs",
          "url": "https://pernos.co/about/logging/",
          "excerpts": [
            "When log output is categorized by \"log modules\", Pernosco indexes on those modules to support efficient filtering by module. Clicking on log output jumps to ..."
          ]
        },
        {
          "title": "Pernosco Omniscient Debugger is now available for ...",
          "url": "https://news.ycombinator.com/item?id=25042827",
          "excerpts": [
            "Pernosco Omniscient Debugger is now available for individual developers, offering a better replayer than open source rr and a nearly-omniscient ..."
          ]
        },
        {
          "title": "The Pernosco vision",
          "url": "https://pernos.co/about/vision/",
          "excerpts": [
            "Pernosco is a natural platform for integrating dynamic analysis. For example, Valgrind/ASAN-style memory checking and dynamic race detection could be ..."
          ]
        },
        {
          "title": "Efficient Online Multiprocessor Replay via Speculation and ...",
          "url": "https://www.researchgate.net/publication/234814416_Respec_Efficient_Online_Multiprocessor_Replay_via_Speculation_and_External_Determinism",
          "excerpts": [
            "This paper presents Respec, a new way to support deterministic replay of shared memory multithreaded programs on commodity multiprocessor hardware. Respec¬†..."
          ]
        },
        {
          "title": "Respec: Efficient Online Multiprocessor Replay via ...",
          "url": "https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/Respec.pdf",
          "excerpts": [
            "Abstract. Deterministic replay systems record and reproduce the execution of a hardware or software system. While it is well known how to.",
            "by D Lee ¬∑ 2010 ¬∑ Cited by 217 ‚Äî This paper describes Respec, a new way to support deterministic replay of a shared memory multithreaded program execution on a commodity multiprocessor¬†..."
          ]
        },
        {
          "title": "DoublePlay: Parallelizing Sequential Logging and Replay",
          "url": "https://www.read.seas.harvard.edu/~kohler/class/aosref/veeraraghavan11doubleplay.pdf",
          "excerpts": [
            "by K Veeraraghavan ¬∑ 2011 ¬∑ Cited by 271 ‚Äî In this paper, we describe a new way to guarantee deterministic replay on commodity multiprocessors. Our method combines the simplicity and low recording ..."
          ]
        },
        {
          "title": "VeriTLA+ and DSL Verification (A translation from TLA+ to Isabelle; DSLs to TLA+ mappings)",
          "url": "https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=ebbe5f789f801703242bc64f255354ab228b152f",
          "excerpts": [
            "A preliminary version of Isabelle/TLA+ will be available at the start of the project and can already be\nused for experimenting with initial models of service descriptions.",
            "This work package will mainly be carried out during the first year of the project duration and will\ntherefore not yet benefit from full support by the verification envir",
            "2.7\nCompilation of DSLs to TLA+",
            "2.6\nFormalization of Bossa and SPL in TLA+",
            "We will use the resulting formalizations to\nreprove known properties of programs written in Bossa and SPL [1].",
            "compilation schemes\nfrom the languages considered in this project to TLA+ will be defined and implemented.",
            "Instead\nof specifying services directly in TLA+, we propose to use domain-specific languages (DSLs) to describe\nand configure these services.",
            "A translation from TLA+ to Isabelle should be completed within three months of the TLA+ parser (work package 2.1).",
            "A translation from TLA+ to Isabelle should be completed within three months of the TLA+ parser (work package 2.1)."
          ]
        },
        {
          "title": "The Little Book of Rust Macros",
          "url": "https://lukaswirth.dev/tlborm/proc-macros/hygiene.html",
          "excerpts": [
            "* [`definition site`](https://doc.rust-lang.org/proc_macro/struct.Span.html.def_site) ( _**unstable**_ ): A span that resolves at the macro definition site.",
            "acro [hygiene](../syntax-extensions/hygiene.html) and the type that encodes it, [`Span`](https://doc.rust-lang.org/proc_macro/struct.Span.html) . Every token in a [`TokenStream`](https://doc.rust-lang.org/proc_macro/struct.TokenStream.html) has an associated `Span` holding some additional info. A span, as its documentation states, is `A region of source code, along with macro expansion information` . It points into a region of the original source code(important for displaying diagnostics at the correct places) as well as holding the kind of _hygiene_ for this location. The hygiene is relevant mainly for identifiers, as it allows or forbids the identifier from referencing things or being referenced by things defined outside of the invocation. There are 3 kinds of hygiene(which can be seen by the constructors of the `Span` type):"
          ]
        },
        {
          "title": "A formulation of TLA in Isabelle",
          "url": "https://link.springer.com/chapter/10.1007/3-540-60275-5_67",
          "excerpts": [
            "por S Kalvala ¬∑ 1995 ¬∑ Mencionado por 40 ‚Äî In this paper I present a formulation of TLA in the Isabelle theorem prover, in which I make extensive use of facilities in the Isabelle system ..."
          ]
        },
        {
          "title": "A Formalization in Isabelle/HOL",
          "url": "https://inria.hal.science/hal-01305026/document",
          "excerpts": [
            "por D D√©harbe ¬∑ 2015 ¬∑ Mencionado por 3 ‚Äî This paper presents a formal development of an Isabelle/HOL theory for the behavioral aspects of artifacts produced in the design of software ..."
          ]
        },
        {
          "title": "Writing Specifications",
          "url": "https://learntla.com/core/pluscal.html",
          "excerpts": [
            "So in 2009, Leslie Lamport created a DSL called PlusCal: a more programming-like syntax that compiles to TLA+ actions. PlusCal isn't as powerful as ‚Äúraw ..."
          ]
        },
        {
          "title": "A walkthough on how to write derive procedural macros",
          "url": "https://www.reddit.com/r/rust/comments/145uhss/a_walkthough_on_how_to_write_derive_procedural/",
          "excerpts": [
            "Use a Rust workspace and proc_macro2 to develop, debug, and unit-test your macro in a normal (non-macro) project. Use syn, proc_macro2, and¬†..."
          ]
        },
        {
          "title": "quote in quote - Rust",
          "url": "https://jeltef.github.io/derive_more/quote/macro.quote.html",
          "excerpts": [
            "The structure of a basic procedural macro is as follows. Refer to the Syn crate for further useful guidance on using quote! as part of a procedural macro."
          ]
        },
        {
          "title": "Understanding Rust Macros: A Comprehensive Guide for ...",
          "url": "https://dev.to/tramposo/understanding-rust-macros-a-comprehensive-guide-for-developers-am4",
          "excerpts": [
            "Sep 21, 2024 ‚Äî Be careful with hygiene in procedural macros. Use format_ident! or similar techniques to avoid name collisions. Test your macros extensively,¬†..."
          ]
        },
        {
          "title": "PlusCal and TLA+ Translation",
          "url": "https://lamport.azurewebsites.net/pubs/pluscal.pdf",
          "excerpts": [
            "PlusCal has an optional define statement for inserting TLA+ defini-\ntion",
            "The translator can be directed\nto report the names and locations in the code of all labels that it adds.",
            "PlusCal is for writing algorithms, not for writing large specifications\nor efficient programs.",
            "The semantics of PlusCal is defined formally by a TLA+ specification\nof the translator as a mapping from an algorithm‚Äôs abstract syntax tree to\nthe sequence of tokens that form its TLA+ specification [8].",
            "The translation from PlusCal to TLA+ is illustrated with the version of\nEuclid‚Äôs algorithm from Section 2.1.",
            "The PlusCal translator can be directed to create the appropriate TLA+ translation and TLC configuration file to check for termination."
          ]
        },
        {
          "title": "Nine Rules for Creating Procedural Macros in Rust: Practical Lessons from anyinput, a New Macro for Easily Accepting String/Path/Iterator/Array-Like Inputs",
          "url": "https://www.reddit.com/r/rust/comments/y9vqx9/nine_rules_for_creating_procedural_macros_in_rust/",
          "excerpts": [
            "With the right setup, you can even set interactive breakpoints and single step through your macro code.",
            "Rust's proc macros let us use Rust to write Rust. Sadly, they can be hard to develop and debug because they live in special `\"proc-macro = true\"` projects.",
            "Nine Rules for Creating Procedural Macros in Rust: Practical Lessons from anyinput, a New Macro for Easily Accepting String/Path/Iterator/Array-Like Inputs",
            "Create easily debuggable unit tests¬†... ---",
            "Use syn, proc_macro2, and quote to convert freely among literal code, tokens, syntax trees, and strings."
          ]
        },
        {
          "title": "[PDF] Extracting TLA+ Specifications out of Elixir Programs",
          "url": "https://epublications.vu.lt/object/elaba:192827281/192827281.pdf",
          "excerpts": [
            "by D Bra≈æƒónas ¬∑ 2023 ‚Äî The PlusCal translator SANY, which comes with tla2tools executable, embeds the. TLA+ specification corresponding to the PlusCal algorithm in the module within ...",
            "In this research, we investigate a methodology that ensures the compliance of Elixir programs with TLA+ specifications, developed by software engineers."
          ]
        },
        {
          "title": "ARINC 653 Part 1 and the Event-B model their service requirement....",
          "url": "https://www.researchgate.net/figure/ARINC-653-Part-1-and-the-Event-B-model-their-service-requirement-Finally-the-system_fig2_281312450",
          "excerpts": [
            "This paper presents the first effort to formally specify and verify separation kernels with ARINC 653 channel-based communication. We provide a reusable formal ..."
          ]
        },
        {
          "title": "Comprehensive Formal Verification of an OS Microkernel",
          "url": "https://courses.cs.washington.edu/courses/cse551/17wi/readings/sel4-tocs.pdf",
          "excerpts": [
            "by G KLEIN ¬∑ Cited by 552 ‚Äî We present an in-depth coverage of the comprehensive machine-checked formal verification of seL4, a general-purpose operating system microkernel."
          ]
        },
        {
          "title": "A Comprehensive Formal Specification of ARINC 653 With ...",
          "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/stvr.1901",
          "excerpts": [
            "We provide a comprehensive formal specification of multi-core ARINC 653 Part 1‚Äì5 using Isabelle/HOL that encompasses all the 68 services and covers all ..."
          ]
        },
        {
          "title": "Modelling Exactly Once Using TLA+ | Part 4 - Zombies and Fencing",
          "url": "https://medium.com/@fqaiser94/modelling-exactly-once-using-tla-2d7035e1379e",
          "excerpts": [
            "Our TLA+ spec currently models a single process reading from an input topic-partition and writing to another output topic-partition. In order to ..."
          ]
        },
        {
          "title": "Modelling Exactly-Once Using TLA+ Part 2: Checking a Specification",
          "url": "https://medium.com/@fqaiser94/modelling-exactly-once-using-tla-f3eb15303b27",
          "excerpts": [
            "TLC is a model checker for specifications written in TLA+. In short, it works by generating all the possible system behaviours permitted by the spec."
          ]
        },
        {
          "title": "Proc macro execution order - rust",
          "url": "https://stackoverflow.com/questions/71884239/proc-macro-execution-order",
          "excerpts": [
            "Is it possible to make the derive macro being expanded after the attribute one? The reason is that I have a crate with some static variables to ..."
          ]
        },
        {
          "title": "Proc_macro expansion order and name resolution - help",
          "url": "https://users.rust-lang.org/t/proc-macro-expansion-order-and-name-resolution/61750",
          "excerpts": [
            "Hey guys, I was working on a project which involves proc-macro and I got confused about how the macro name resolution is done."
          ]
        },
        {
          "title": "proc_macro_error - Rust - Docs.rs",
          "url": "https://docs.rs/proc-macro-error",
          "excerpts": [
            "This crate aims to make error reporting in proc-macros simple and easy to use. Migrate from panic! -based errors for as little effort as possible!"
          ]
        },
        {
          "title": "Why TLA+ Is Untyped : r/tlaplus - Reddit",
          "url": "https://www.reddit.com/r/tlaplus/comments/pe05af/why_tla_is_untyped/",
          "excerpts": [
            "Leslie Lamport and Larry Paulson (Isabelle/HOL) wrote an article, Should Your Specification Language Be Typed?, explaining why it makes more ..."
          ]
        },
        {
          "title": "Raft Consensus Algorithm",
          "url": "https://raft.github.io/",
          "excerpts": [
            "Raft is a consensus algorithm that is designed to be easy to understand. It's equivalent to Paxos in fault-tolerance and performance."
          ]
        },
        {
          "title": "Modelling Exactly-Once Delivery Using TLA+ Part 3 - Medium",
          "url": "https://medium.com/@fqaiser94/modelling-exactly-once-using-tla-9512e1eb8ca5",
          "excerpts": [
            "In this series of blogposts, we'll introduce TLA+ by iteratively modelling and refining our design for a simple application that can read and write messages ..."
          ]
        },
        {
          "title": "Model checking exactly-once",
          "url": "https://exactly-once.github.io/posts/model-checking-exactly-once/",
          "excerpts": [
            "This is how we defined exactly-once property in the consistent messaging post: (‚Ä¶) we want an endpoint to produce observable side-effects equivalent to some ..."
          ]
        },
        {
          "title": "TLA‚Å∫ is more than a DSL for breadth-first search - Lobste.rs",
          "url": "https://lobste.rs/s/zl0e71/tla_is_more_than_dsl_for_breadth_first",
          "excerpts": [
            "Kleppmann gave a nice talk about how to verify distributed systems using Isabelle/HOL, while Isabelle doesn't make use of the CH isomorphism, ..."
          ]
        },
        {
          "title": "TLA+ Specifications - CCF documentation - Microsoft Open Source",
          "url": "https://microsoft.github.io/CCF/main/architecture/raft_tla.html",
          "excerpts": [
            "The TLA+ consensus specification models the intended behavior of Raft as it is modified for CCF. You can find the full specifications in the tla/ directory."
          ]
        },
        {
          "title": "A Rust Capability-Based Linux Runtime : r/rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/wih8hy/a_rust_capabilitybased_linux_runtime/",
          "excerpts": [
            "A capability-based OS is generally one where programs, by default, are completely sandboxed and have no access to the system."
          ]
        },
        {
          "title": "cap-std: Capability-oriented version of the Rust standard ...",
          "url": "https://www.reddit.com/r/rust/comments/mq3ozc/capstd_capabilityoriented_version_of_the_rust/",
          "excerpts": [
            "This allows application logic to configure its own access, without changing the behavior of the whole host process, setting up a separate host¬†..."
          ]
        },
        {
          "title": "FFI - The Rustonomicon - Rust Documentation",
          "url": "https://doc.rust-lang.org/nomicon/ffi.html",
          "excerpts": [
            "### [C++ `throw` with `\"C-unwind\"`]()\n\n```rust\n#[link(...)]\nunsafe extern \"C-unwind\" {\n    // A C++ function that may throw an exception\n    fn may_throw();\n}\n\n#[unsafe(no_mangle)]\nunsafe extern \"C-unwind\" fn rust_passthrough() {\n    let b = Box::new(5);\n    unsafe { may_throw(); }\n    println!(\"{:? }\", &b);\n}\n```\n\nA C++ function with a `try` block may invoke `rust_passthrough` and `catch` an\nexception thrown by `may_throw` .",
            "## [FFI and unwinding]()\n\nIt‚Äôs important to be mindful of unwinding when working with FFI. Most\nABI strings come in two variants, one with an `-unwind` suffix and one without. The `Rust` ABI always permits unwinding, so there is no `Rust-unwind` ABI. If you expect Rust `panic` s or foreign (e.g. C++) exceptions to cross an FFI\nboundary, that boundary must use the appropriate `-unwind` ABI string. Conversely, if you do not expect unwinding to cross an ABI boundary, use one of\nthe non- `unwind` ABI strings",
            "When declaring the argument types to a foreign function, the Rust compiler\ncannot check if the declaration is correct, so specifying it correctly is part\nof keeping the binding correct at runtime.",
            "Foreign functions are assumed to be unsafe so calls to them need to be wrapped\nwith `unsafe {}` as a promise to the compiler that everything contained within\ntruly is safe.",
            "The `extern` block can be extended to cover the entire snappy API:",
            "e.\nThe `extern` block can be extended to cover the entire snappy API:\n\n```rust\nuse libc::{c_int, size_t};\n\n#[link(name = \"snappy\")]\nunsafe extern {\n    fn snappy_compress(input: *const u8,\n                       input_length: size_t,\n                       compressed: *mut u8,\n                       compressed_length: *mut size_t) -> c_int;\n    fn snappy_uncompress(compressed: *const u8,\n                         compressed_length: size_t,\n                         uncompressed: *mut u8,\n                         uncompressed_length: *mut size_t) -> c_int;\n    fn snappy_max_compressed_length(source_length: size_t) -> size_t;\n    fn snappy_uncompressed_length(compressed: *const u8,\n                                  compressed_length: size_t,\n                                  result: *mut size_t) -> c_int;\n    fn snappy_validate_compressed_buffer(compressed: *const u8,\n                                         compressed_length: size_t) -> c_int;\n}\n",
            "\n\nRust guarantees that the layout of a `struct` is compatible with the platform's\nrepresentation in C only if the `#[repr(C)]` attribute is applied to it. `#[repr(C, packed)]` can be used to lay ou",
            "The raw C API needs to be wrapped to provide memory safety and make use of higher-level concepts like vectors. A library can choose to expose only the safe, ..."
          ]
        },
        {
          "title": "Using \"Capabilities\" to design safer, more expressive APIs in Rust",
          "url": "https://www.reddit.com/r/rust/comments/7rmgxo/using_capabilities_to_design_safer_more/",
          "excerpts": [
            "Because Capability is generic on its \"input\" type, you can create multiple implementations of Capability on a given type that do the kinds of ..."
          ]
        },
        {
          "title": "How to Write Hygienic Rust Macros - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/jcpowx/how_to_write_hygienic_rust_macros/",
          "excerpts": [
            "The solution is to allow crates to have both procedural macros and regular items, but there isn't an RFC for this and no-one is working on it¬†...",
            "$crate::rt is guaranteed to always work. For proc macros, instead of making $crate configurable, you can write a helper declarative macro and ..."
          ]
        },
        {
          "title": "Best Practices for Derive Macro Attributes in Rust - Reddit",
          "url": "https://www.reddit.com/r/rust/comments/1gaeel7/best_practices_for_derive_macro_attributes_in_rust/",
          "excerpts": [
            "Speaking of, another recommendation is how to organize your code: consider putting code your macro calls into a sub-crate (e.g. clap_builder) ..."
          ]
        },
        {
          "title": "Structuring, testing and debugging procedural macro crates",
          "url": "https://ferrous-systems.com/blog/testing-proc-macros/",
          "excerpts": [
            "In this blog post we'll explore how to structure a procedural macro, AKA proc-macro, crate to make it easier to test. We'll show different testing approaches."
          ]
        },
        {
          "title": "Rust Macros: Practical Examples and Best Practices - Earthly Blog",
          "url": "https://earthly.dev/blog/rust-macros/",
          "excerpts": [
            "Macro Hygiene",
            "Procedural Macros",
            "\nThe macro is defined as a function with the `#[proc_macro_derive]`, `#[proc_macro_attribute]`, or `#[proc_macro]` attribute, depending on whether it‚Äôs a derive macro, attribute-like macro, or a function-like macro.",
            "Procedural macros are a big step up from declarative macros. Like their declarative cousins, they get access to Rust code, but procedural macros can operate on the code (similar to a function) and produce new code.",
            "Derive Macros\n\nA derive macro lets you create new inputs for the [`derive` attribute](https://doc.rust-lang.org/reference/attributes/derive.html), which can operate on structs, unions, and enums to create new items.",
            "There are three types of procedural macros:\n\n1.\n[Custom derive macro](https://doc.rust-lang.org/reference/procedural-macros.html)\n2. [Attribute-like macro](https://doc.rust-lang.org/reference/procedural-macros.html)\n3. [Function-like macro](https://doc.rust-lang.org/reference/procedural-macros.html",
            "Procedural macros are always unhygienic. They behave as if they were written inline in place of the macro invocation and are, therefore, affected by surrounding code.",
            "Tips for Using Macros Efficiently ¬∑ Know When to Use Macros vs. Functions ¬∑ Make Sure Macros Are Readable and Maintainable ¬∑ Handle Errors in Macro."
          ]
        },
        {
          "title": "rust - How can I create hygienic identifiers in code generated by ...",
          "url": "https://stackoverflow.com/questions/59618213/how-can-i-create-hygienic-identifiers-in-code-generated-by-procedural-macros",
          "excerpts": [
            "You can't yet use hygienic identifiers with proc macros on stable Rust. Your best bet is to use a particularly ugly name such as __your_crate_your_name."
          ]
        },
        {
          "title": "Procedural Macros in Rust ‚Äì A Handbook for Beginners",
          "url": "https://www.freecodecamp.org/news/procedural-macros-in-rust/",
          "excerpts": [
            "In this handbook, you'll learn about procedural macros in Rust, and what purposes they serve. You'll also learn how to write your own procedural macros."
          ]
        },
        {
          "title": "Rust Proc Macros: A Beginner's Journey - petanode",
          "url": "https://petanode.com/posts/rust-proc-macro/",
          "excerpts": [
            "trybuild is a crate which helps you create UI tests for macros. You write a test code which should compile or not. The library checks the ..."
          ]
        },
        {
          "title": "How does Rust implement Zero-cost abstraction for ...",
          "url": "https://stackoverflow.com/questions/75614715/how-does-rust-implement-zero-cost-abstraction-for-newtypes-pattern",
          "excerpts": [
            "From the unofficial Rust Design Patterns: Newtypes are a zero-cost abstraction - there is no runtime overhead. Does LLVM do some magic?"
          ]
        },
        {
          "title": "cloudabi - Rust - Docs.rs",
          "url": "https://docs.rs/cloudabi/",
          "excerpts": [
            "Capability-based security means that processes can only perform actions that have no global impact . Processes cannot open files by their absolute path, cannot open network connections, and cannot observe global system state such as the process table."
          ]
        },
        {
          "title": "ongardie/raft.tla: TLA+ specification for the Raft consensus algorithm",
          "url": "https://github.com/ongardie/raft.tla",
          "excerpts": [
            "Formal TLA+ specification for the Raft consensus algorithm. This is slightly updated compared to the dissertation version. For more information, see Chapter ..."
          ]
        },
        {
          "title": "Capability Distribution Language (capDL)",
          "url": "https://docs.sel4.systems/projects/capdl/",
          "excerpts": [
            "capDL stands for *capability distribution language*. It is used to describe the\nkernel objects an seL4 application needs and the distribution of capabilities in\nthe system. This defines which parts of the system have capabilities to which\nother parts of the system, and therefore defines the access control boundaries\nof the system for integrity and confidentiality. capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once. In addition, capability distributions in seL4 determine what\nfuture states of the system are possible.",
            "Python capDL Library",
            "\n\nThe capDL Loader is a program that initialises the seL4 user-level environment\nto match the system described by a capDL spec, and loads programs from ELFs in a\nprovided `cpio` archive.\nIt is intended to be run as the root task, that is, the\nfirst user-level thread, which has access to all resources.",
            "capDL specifications provide a clean interface for system initialisation and\ncapability reasoning. Their key feature is that they describe the desired state\nof the system declaratively. That means, creating such system states via seL4\nsystem calls is done by a separate loader application that can be formally\nverified once.",
            "capDL Translator",
            "capDL Translator\n----------------\n\nThis program transforms a capDL spec into several formats:\n\n* a C header file for linking against the capDL Loader to create a program that\n  instantiates the system described by the spec\n* a dot file for visualisation with `graphviz`\n* an XML file for further manipulation\n* an formal model in the Isabelle/HOL proof assistant for use in proofs about\n  the system described by the spec",
            "capDL stands for capability distribution ... an formal model in the Isabelle/HOL proof assistant for use in proofs about the system described by the spec.",
            "capDL stands for capability distribution language. It is used to describe the kernel objects an seL4 application needs and the distribution of capabilities in ...See more"
          ]
        },
        {
          "title": "How To Use The Typestate Pattern In Rust",
          "url": "https://zerotomastery.io/blog/rust-typestate-patterns/",
          "excerpts": [
            "Aug 31, 2023 ‚Äî In this tutorial we'll be looking at ways to reduce the cognitive burden of state management by utilizing the typestate pattern."
          ]
        },
        {
          "title": "TLA in Isabelle/HOL",
          "url": "https://davecturner.github.io/2018/02/12/tla-in-isabelle.html",
          "excerpts": [
            "Isabelle includes [a\nformalisation of (typed)\nTLA](https://members.loria.fr/SMerz/projects/isabelle-tla/index.html) without\nany obvious restrictions on the supported features of TLA or its integration\nwith the rest of Isabelle‚Äôs other mathematical libraries.",
            "TLA+ in Isabelle/HOL",
            "TLA is a simple linear-temporal logic that is expressive enough to describe the evolution of a system over time. Linear-temporal logics ..."
          ]
        },
        {
          "title": "Verifying distributed systems with Isabelle",
          "url": "https://martin.kleppmann.com/2022/10/12/verifying-distributed-systems-isabelle.html",
          "excerpts": [
            "First, we asssume each process (or _node_ ) in the system has a unique identifier, which could simply be an integer or a string.",
            "Isabelle/HOL does not have any built-in support for distributed computing, but fortunately it is quite straightforward to model a distributed system using structures that Isabelle/HOL provides: functions, lists, and sets.",
            "Oct 12, 2022 ‚Äî In this blog post we will explore how to use the Isabelle/HOL proof assistant to formally verify a number of distributed algorithms."
          ]
        },
        {
          "title": "The Rust Reference - Procedural Macros",
          "url": "https://doc.rust-lang.org/reference/procedural-macros.html",
          "excerpts": [
            "ed. `Span` s represent an extent of source\ncode within a program and are primarily used for error reporting.",
            "Macro authors need to be careful to ensure their macros work in as many contexts\nas possible given this limitation. This often includes using absolute paths to\nitems in libraries (for example, `::std::option::Option` instead of `Option` ) or\nby ensuring that generated functions have names that are unlikely to clash with\nother functions (like `__internal_foo` instead of `foo` ).",
            "Procedural macros must be defined in the root of a crate with the [crate type](linkage.html) of `proc-macro` .",
            "Procedural macros have two ways of reporting errors. The first is to panic. The\nsecond is to emit a [`compile_error`](../core/macro.compile_error.html) macro invocation.",
            "The `proc_macro` crate provides types required for\nwriting procedural macros and facilities to make it easier.",
            "All tokens have an associated `Span` . A `Span` is an opaque value that cannot\nbe modified but can be manufactured. `Span` s represent an extent of source\ncode within a program and are primarily used for error reporting. While you\ncannot modify a `Span` itself, you can always change the `Span` _associated_ with any token, such as through getting a `Span` from another token.",
            "Procedural macros are _unhygienic_ . This means they behave as if the output\ntoken stream was simply written inline to the code it‚Äôs next to.",
            "The `TokenStream` type, unlike `Vec<TokenTree>` , is cheap to clone.",
            "Procedural macros operate\nover _token streams_ instead of AST nodes, which is a far more stable interface\nover time for both the compiler and for procedural macros to targe"
          ]
        },
        {
          "title": "quote crate documentation and macro design guidance",
          "url": "https://docs.rs/quote/latest/quote/macro.quote.html",
          "excerpts": [
            "Tokens that originate within the quote! invocation are spanned with Span::call_site() . A different span can be provided through the quote_spanned! macro.",
            "quote in quote - Rust\n\n[Docs.rs](/)\n\n* [quote-1.0.40](# \"Quasi-quoting macro quote!\\\\(...\\\\)\")",
            "The structure of a basic procedural macro is as follows. Refer to the Syn crate for further useful guidance on using quote! as part of a procedural macro. q"
          ]
        },
        {
          "title": "A Model-Based Optimization Method of ARINC 653 ...",
          "url": "https://www.mdpi.com/2226-4310/11/11/915",
          "excerpts": [
            "This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network ...",
            "by P Han ¬∑ 2024 ‚Äî This paper proposes a model-based optimization method for ARINC 653 multicore partition scheduling. The IMA multicore processing system is modeled as a network¬†..."
          ]
        },
        {
          "title": "Beyond the Toolbox",
          "url": "https://learntla.com/topics/cli.html",
          "excerpts": [
            "The model checking config language is a special DSL for using TLC from the command line. It's what the toolbox abstracts away on the backend. All config¬†..."
          ]
        },
        {
          "title": "seL4: formal verification of an OS kernel",
          "url": "https://cseweb.ucsd.edu/~dstefan/cse227-spring20/papers/sel4.pdf",
          "excerpts": [
            "by G Klein ¬∑ 2009 ¬∑ Cited by 3032 ‚Äî ABSTRACT. Complete formal verification is the only known way to guar- antee that a system is free of programming errors.See more",
            "by G Klein ¬∑ 2009 ¬∑ Cited by 3032 ‚Äî Secondly, the Isabelle theorem prover we are using can produce external proof representa- tions that can be independently checked by a small, ..."
          ]
        },
        {
          "title": "Blog post: Contexts and capabilities in Rust",
          "url": "https://internals.rust-lang.org/t/blog-post-contexts-and-capabilities-in-rust/15833",
          "excerpts": [
            "Statically guarantees that any context you need is available; Allows passing references to objects on the stack; Integrates with the trait ..."
          ]
        },
        {
          "title": "Refinement-based Specification and Analysis of Multi-core ...",
          "url": "https://dl.acm.org/doi/full/10.1145/3617183",
          "excerpts": [
            "by F Zhang ¬∑ 2023 ¬∑ Cited by 2 ‚Äî This article proposes a specification method for concurrency on a multi-core platform using Event-B, and a refinement structure for the complicated ARINC 653¬†..."
          ]
        },
        {
          "title": "seL4/l4v: seL4 specification and proofs",
          "url": "https://github.com/seL4/l4v",
          "excerpts": [
            "The seL4 proofs depend on Isabelle specifications that are generated from the C source code and Haskell model. Therefore, it is recommended to always build¬†...",
            "capDL : a specification of seL4 that abstracts from memory content and\nconcrete execution behaviour, modelling the protection state of the\nsystem in terms of capabilities.",
            "This specification corresponds to the capability distribution language capDL that can be used to initialise user-level systems on top of seL4.",
            "This specification corresponds to the capability distribution language capDL that can be used to initialise user-level systems on top of seL4.",
            "capDL : a specification of seL4 that abstracts from memory content and concrete execution behaviour, modelling the protection state of the system in terms of¬†...",
            "The seL4 proofs depend on Isabelle specifications that are generated from the C source code and Haskell model.",
            "Not all of the proof sessions can be built directly with the isabelle build command. The seL4 proofs depend on Isabelle specifications that are generated from ..."
          ]
        },
        {
          "title": "seL4 Proofs",
          "url": "https://sel4.systems/Verification/proofs.html",
          "excerpts": [
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong¬†...",
            "We claim that seL4 has world's highest level of assurance for an operating system kernel. On the research level, this is substantiated by the following¬†...",
            "seL4 has machine-checked mathematical proofs for the Arm, RISC-V, and Intel architectures. This page describes the high-level proof statements and how strong ..."
          ]
        },
        {
          "title": "FAQ ‚Äî Learn TLA+",
          "url": "https://learntla.com/intro/faq.html",
          "excerpts": [
            "PlusCal is a DSL that compiles down to TLA+. Most engineers find it an easier place to start than with pure TLA+, and it works great for a lot of specifications¬†..."
          ]
        },
        {
          "title": "trybuild - Rust",
          "url": "https://docs.rs/trybuild",
          "excerpts": [
            "Such tests are commonly useful for testing error reporting involving procedural macros. We would write test cases triggering either errors detected by the macro ..."
          ]
        },
        {
          "title": "Diag in rustc_errors - Rust",
          "url": "https://doc.rust-lang.org/nightly/nightly-rustc/rustc_errors/struct.Diag.html",
          "excerpts": [
            "Used for emitting structured error messages and other diagnostic information. Wraps a `DiagInner`, adding some useful things."
          ]
        },
        {
          "title": "quote_spanned in quote - Rust",
          "url": "https://cseweb.ucsd.edu/classes/sp22/cse223B-a/tribbler/quote/macro.quote_spanned.html",
          "excerpts": [
            "Same as `quote!`, but applies a given span to all tokens originating within the macro invocation."
          ]
        },
        {
          "title": "quote_spanned in proc_quote - Rust",
          "url": "https://docs.rs/proc-quote/latest/proc_quote/macro.quote_spanned.html",
          "excerpts": [
            "The following procedural macro code uses `quote_spanned!` to assert that a\nparticular Rust type implements the [`Sync`](https://doc.rust-lang.org/std/marker/trait.Sync.html) trait so that references can be\nsafely shared between threads.",
            "-----\n\nAny interpolated tokens preserve the `Span` information provided by their\n`ToTokens` implementation. ",
            "The formatting is designed to be visibly\noff-balance and draw the eye a particular way, due to the span expression\nbeing evaluated in the context of the procedural macro and the remaining\ntokens being evaluated in the generated code.",
            "The lack of space before the `=>` should look jarring to Rust programmers\nand this is intentional.",
            "e. The span expression should be brief ‚Äì use a variable for anything\nmore than a few characters. There should be no space before the `=>` token.",
            "-\n\nA span expression of type [`Span`](https://docs.rs/proc-macro2/0.4/proc_macro2/struct.Span.html), followed by `=>`, followed by the tokens\nto quote. The span expression should be brief ‚Äì use a variable for anything\nmore than a few characters.",
            "The following procedural macro code uses quote_spanned! to assert that a particular Rust type implements the Sync trait so that references can be safely shared¬†..."
          ]
        },
        {
          "title": "cap-std - Rust Package Registry",
          "url": "https://crates.io/crates/cap-std",
          "excerpts": [
            "Apr 21, 2025 ‚Äî This crate provides a capability-based version of std , providing sandboxed filesystem, networking, and clock APIs."
          ]
        },
        {
          "title": "Introducing cap-std, a capability-based version of the Rust ...",
          "url": "https://lobste.rs/s/rlwby3/introducing_cap_std_capability_based",
          "excerpts": [
            "Jun 14, 2021 ‚Äî Introducing cap-std, a capability-based version ... If the compiler can be trusted, then we could have capability security for proc macros."
          ]
        },
        {
          "title": "The Typestate Pattern in Rust - Cliffle",
          "url": "https://cliffle.com/blog/rust-typestate/",
          "excerpts": [
            "The typestate pattern is an API design pattern that encodes information about an object's run-time state in its compile-time type."
          ]
        },
        {
          "title": "NUMA-Aware Memory Allocation - The Rust Programming Language Forum",
          "url": "https://users.rust-lang.org/t/numa-aware-memory-allocation/21305",
          "excerpts": [
            "Rust does not do anything in particular for NUMA. It makes allocations through jemalloc by default on most targets, with the option to use the system allocator (like glibc) instead."
          ]
        },
        {
          "title": "DuckDB Internals - Push-Based Execution Overview",
          "url": "https://duckdb.org/docs/stable/internals/overview.html",
          "excerpts": [
            "DuckDB uses a push-based vectorized model, where DataChunks are pushed through the operator tree. For more information, see the talk Push-Based Execution in ... DuckDB uses a push-based vectorized model, where [`DataChunks`](https://github.com/duckdb/duckdb/blob/main/src/include/duckdb/common/types/data_chunk.hpp) are pushed through the operator tree. For more information, see the talk [Push-Based Execution in DuckDB](https://www.youtube.com/watch?v=1kDrPgRUuEI) ."
          ]
        },
        {
          "title": "Improvements in HashAggregationExec when spilling #7858",
          "url": "https://github.com/apache/arrow-datafusion/issues/7858",
          "excerpts": [
            "Oct 18, 2023 ‚Äî As spill is usually triggered under memory pressure, in most cases for all partitions around same time, it effectively doubles memory needed (in¬†..."
          ]
        },
        {
          "title": "DuckDB Quacks Arrow: A Zero-Copy Data Integration between ...",
          "url": "https://duckdb.org/2021/12/03/duck-arrow.html",
          "excerpts": [
            "Missing: SSB spill strategies"
          ]
        },
        {
          "title": "tpchgen-rs World's fastest open source TPC-H data generator ...",
          "url": "https://datafusion.apache.org/blog/2025/04/10/fastest-tpch-generator/",
          "excerpts": [
            "Missing: SSB spill strategies"
          ]
        },
        {
          "title": "DuckDB Documentation",
          "url": "https://duckdb.org/duckdb-docs.pdf",
          "excerpts": [
            "... Execution ... Design Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1827. Overall ..."
          ]
        },
        {
          "title": "Vectors",
          "url": "https://duckdb.org/docs/stable/clients/c/vector.html",
          "excerpts": [
            "Vectors represent a horizontal slice of a column. They hold a number of values of a specific type, similar to an array. Vectors are the core data ..."
          ]
        },
        {
          "title": "NUMA aware cache aligned memory allocation",
          "url": "https://stackoverflow.com/questions/8154162/numa-aware-cache-aligned-memory-allocation",
          "excerpts": [
            "The numa_alloc_*() functions in libnuma allocate whole pages of memory, typically 4096 bytes. Cache lines are typically 64 bytes."
          ]
        },
        {
          "title": "Memory Management ‚Äî Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/cpp/memory.html",
          "excerpts": [
            "The default memory pool depends on how Arrow C++ was compiled: if enabled at compile time, a mimalloc heap;. otherwise, if enabled at compile time, a jemalloc ..."
          ]
        },
        {
          "title": "Vectorized Execution in DuckDB - by Hash Block",
          "url": "https://medium.com/@connect.hashblock/vectorized-execution-in-duckdb-55679d6874f6",
          "excerpts": [
            "Vectorized execution flips this on its head. Instead of processing data row-by-row, DuckDB processes it column-by-column in batches (vectors)."
          ]
        },
        {
          "title": "SIGMOD-2024 Lamb: Gringotts-OLAP with Arrow/DataFusion (excerpt)",
          "url": "https://andrew.nerdnetworks.org/other/SIGMOD-2024-lamb.pdf",
          "excerpts": [
            "or seam-\nless integration of user-defined operators (Section 7.7). Within each\nStream, non-Arrow representations, such as the Row Format (Sec-\ntion 6.6) are used when necessary to increase performance.",
            "DataFusion can be customized for different environments using\nresource management APIs. MemoryPool is described in Section\n5.5.4. DiskManager creates reference counted spill files if config-\nure",
            "DataFusion contains a two-phase parallel par-\ntitioned hash grouping implementation [50], featuring vectorized\nexecution, the ability to spill to disk when memory is exhausted,\nand special handling for no, partially ordered, and fully ordered\ngroup key",
            "For pipeline-\nbreaking operations such as a full sort, final aggregation, or a hash\njoin, the operators buffer tuples, spilling to disk if necessary",
            "Streaming Execution. Whenever possible, all operators pro-\nduce output incrementally (Figure 3) as Arrow Arrays grouped\n\ninto RecordBatches, with a default size of 8192 ro",
            "DataFusion uses a pull-based streaming execution model and dis-\ntributes work across multiple cores using Volcano-style [33] ex-\nchange operators (viz. RepartitionEx"
          ]
        },
        {
          "title": "Morsel-driven parallelism: a NUMA-aware query evaluation framework for the many-core age",
          "url": "https://dl.acm.org/doi/10.1145/2588555.2610507",
          "excerpts": [
            "Morsel-driven parallelism: a NUMA-aware query evaluation framework for the many-core age",
            "ng, two problems conspire against the state-of-the-art approaches in parallel query execution: (i) to take advantage of many-cores, all query work must be distributed evenly among (soon) hundreds of threads in order to achieve",
            "We present the morsel-driven query execution framework, where scheduling becomes a fine-grained run-time task that is NUMA-aware."
          ]
        },
        {
          "title": "An Evaluation of Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age",
          "url": "https://cs-people.bu.edu/mathan/classes/CS591-Spring2019/student_slides/4.MorselDrivenParallelism_MatthewCote.pdf",
          "excerpts": [
            "NUMA Awareness Evaluation\n\nNear maximum bandwidth of 100 GB/s for queries 1 and 6.",
            "Evaluation Technique\n\nTwo different architectures\n\nDifferent NUMA topologies/BWs\n\nPerformance Evaluation\n\nNormalized by execution of \nsingle-threaded HyPer",
            "The Problem: Part 1\n\n‚óè\nSingle threaded database applications have already been significantly optimized. ‚óè\nModern processor design focuses more on adding more cores instead of improving \n\neach core. What about multi-core database designs",
            "NUMA Architecture\n\nNUMA = Non-Uniform Memory Access\n\n‚óè\nMemory access cost varies depending on which chip the accessing thread and memory are \nlocated",
            "Possible due to morsel-size work increments and work stealing. NUMA - Awareness. ‚óã. Thread (primarily) reads/writes to memory in own socket. Elasticity. An Evaluation of\nMorsel-Driven Parallelism: \nA NUMA-Aware Query Evaluation \nFramework for the Many-Core Age"
          ]
        },
        {
          "title": "DataFusion JIT - Docs.rs",
          "url": "https://docs.rs/crate/datafusion-jit/23.0.0",
          "excerpts": [
            "DataFusion](df) is an extensible query execution framework, written in Rust, that uses Apache Arrow as its in-memory format. This crate is a submodule of DataFusion that provides JIT code generati",
            "\"Just In Time (JIT) compilation support for DataFusion query engine\""
          ]
        },
        {
          "title": "DuckDB 0.9.0 not respecting temp_directory property ...",
          "url": "https://github.com/duckdb/duckdb/issues/9401",
          "excerpts": [
            "Oct 19, 2023 ‚Äî DuckDB should create temp directory and file to spill data which is larger than memory (in our case 10 MB) Actual Result: DuckDB is throwing out of memory¬†..."
          ]
        },
        {
          "title": "Pragmas",
          "url": "https://duckdb.org/docs/stable/configuration/pragmas.html",
          "excerpts": [
            "Memory Limit. Set the memory limit for the buffer manager: SET memory_limit = '1GB'; ... Temp Directory for Spilling Data to Disk. By default, DuckDB uses a¬†..."
          ]
        },
        {
          "title": "Out of memory when sorting #5108 - apache/datafusion - GitHub",
          "url": "https://github.com/apache/arrow-datafusion/issues/5108",
          "excerpts": [
            "Thanks @tustvold , I ran the test with configured mem max set up and spill enabled. ... Datafusion 16.0.0 with FairSpillPool: Running `/Users/ ..."
          ]
        },
        {
          "title": "Does sorting affect compression of duckdb database?",
          "url": "https://www.reddit.com/r/DuckDB/comments/1fidyhu/does_sorting_affect_compression_of_duckdb_database/",
          "excerpts": [
            "DuckDB does not change the sorting order automatically to improve the compression ‚Äì you need to sort the data yourself. This sorting can happen ..."
          ]
        },
        {
          "title": "How many can a tuple or list contain in Python? - Stack Overflow",
          "url": "https://stackoverflow.com/questions/3225712/how-many-can-a-tuple-or-list-contain-in-python",
          "excerpts": [
            "How many items can contain tuple or list in python? What will be if it is 10 000? python ¬∑ list ¬∑ tuples."
          ]
        },
        {
          "title": "Memory Management in DuckDB",
          "url": "https://duckdb.org/2024/07/09/memory-management.html",
          "excerpts": [
            "The `memory_limit` setting controls how much data DuckDB is allowed to keep in memory. By default, this is set to `80%` of the physical RAM of your system (e.g., if your system has 16 GB RAM, this defaults to 12.8 GB).",
            "The buffer manager caches as many pages as possible from any attached databases without exceeding the pre-defined memory limits.",
            "Data from intermediates can be spilled to disk temporarily in order to free up space in memory, allowing computation of complex queries that would otherwise exceed the available memory.",
            "DuckDB uses a streaming execution engine to process queries. Data sources, such as tables, CSV files or Parquet files, are never fully materialized in memory. Instead, data is read and processed one chunk at a time.",
            "Jul 9, 2024 ‚Äî If the memory limit is exceeded and disk spilling cannot be used, either because disk spilling is explicitly disabled, the temporary directory¬†..."
          ]
        },
        {
          "title": "Prototype implementing DataFusion functions / operators using ...",
          "url": "https://github.com/apache/datafusion/issues/11413",
          "excerpts": [
            "I suggest a POC that picks one or two functions (maybe string equality or regexp_match or something) and tries to use arrow-udf s function macro instead. Here ..."
          ]
        },
        {
          "title": "datafusion - Rust - Docs.rs",
          "url": "https://docs.rs/datafusion/latest/datafusion/",
          "excerpts": [
            "An ExecutionPlan (sometimes referred to as a ‚Äúphysical plan‚Äù) is a plan that can be executed against data. It a DAG of other ExecutionPlan s each potentially ..."
          ]
        },
        {
          "title": "The DuckDB and Arrow rabbit hole: data modeling adventures",
          "url": "https://nickb.dev/blog/the-duckdb-and-arrow-rabbit-hole-data-modeling-adventures/",
          "excerpts": [
            "In a simple compute example, arrow compiled to Wasm ended up weighing 1.6 MB (300 kB compressed). By most measures this is kinda lofty, but ..."
          ]
        },
        {
          "title": "arrow::compute::kernels::boolean - Rust",
          "url": "https://docs.rs/arrow/latest/arrow/compute/kernels/boolean/index.html",
          "excerpts": [
            "Defines boolean kernels on Arrow BooleanArray 's, e.g. AND , OR and NOT . These kernels can leverage SIMD if available on your system."
          ]
        },
        {
          "title": "arrow::compute::kernels::cmp - Rust",
          "url": "https://arrow.apache.org/rust/arrow/compute/kernels/cmp/index.html",
          "excerpts": [
            "These kernels can leverage SIMD if available on your system. Currently no runtime detection is provided, you should enable the specific SIMD intrinsics¬†..."
          ]
        },
        {
          "title": "Apache Arrow DataFusion documentation",
          "url": "https://datafusion.apache.org/python/autoapi/datafusion/index.html",
          "excerpts": [
            "Use a fair spill pool with the specified size. This pool works best when you know beforehand the query has multiple spillable operators that will likely all ..."
          ]
        },
        {
          "title": "airflow.providers.google.cloud.operators.datafusion",
          "url": "https://airflow.apache.org/docs/apache-airflow-providers-google/stable/_api/airflow/providers/google/cloud/operators/datafusion/index.html",
          "excerpts": [
            "Creates a new Data Fusion instance in the specified project and location. See also For more information on how to use this operator, take a look at the guide."
          ]
        },
        {
          "title": "Google DataFusion Operators - Apache Airflow",
          "url": "https://airflow.apache.org/docs/apache-airflow-providers-google/stable/operators/cloud/datafusion.html",
          "excerpts": [
            "Cloud Data Fusion is a fully managed, cloud-native data integration service that helps users efficiently build and manage ETL/ELT data pipelines."
          ]
        },
        {
          "title": "Operators and Literals ‚Äî Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/user-guide/sql/operators.html",
          "excerpts": [
            "Comparison Operators‚Äã‚Äã Three-way comparison operator. A NULL-safe operator that returns true if both operands are equal or both are NULL, false otherwise."
          ]
        },
        {
          "title": "A review of Morsel-Driven Parallelism - Chris Wirz",
          "url": "https://www.chriswirz.com/reviews/morsels-parallelism",
          "excerpts": [
            "Dec 28, 2017 ‚Äî The authors clearly demonstrate a higher speedup using full-fledged HyPer over non-NUMA aware HyPer over non-adaptive HyPer over Vectorwise¬†..."
          ]
        },
        {
          "title": "[PDF] Morsel-Driven Parallelism",
          "url": "https://bu-disc.github.io/CS561-Spring2021/student_slides/Class-16-JasonBanks-MorselDrivelParallelism.pdf",
          "excerpts": [
            "‚óã Reallocates morsels and tasks if one finishes early (work-stealing). ‚óã Reduces/increases parallelism on threads. ‚óã NUMA-Aware; awareness of data locality."
          ]
        },
        {
          "title": "[PDF] Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation ...",
          "url": "https://www.cse.iitb.ac.in/infolab/Data/Courses/CS632/2016/2015/Talks/morsel-slides.pdf",
          "excerpts": [
            "‚ñª Morsel-driven query execution (work is distributed between threads dynamically using work stealing). ‚ñª Set of fast parallel algorithms for the most ..."
          ]
        },
        {
          "title": "Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation ...",
          "url": "https://bu-disc.github.io/CS591A1-Spring2020/student_slides/10.MorselDrivenParallelism_DezhouWang_LunhaoLiang.pdf",
          "excerpts": [
            "by V Leis ¬∑ Cited by 419 ‚Äî Morsel-Driven Parallelism. The paper presents the ‚Äúmorsel-driven‚Äù query to solve the problem for the database ‚ÄúHyPer‚Äù. ‚úì Divide input data into small¬†..."
          ]
        },
        {
          "title": "DuckDB Performance Tuning Guide",
          "url": "https://duckdb.org/docs/stable/guides/performance/how_to_tune_workloads.html",
          "excerpts": [
            "DuckDB supports [lightweight compression techniques](/2022/10/28/lightweight-compression.html) . Currently, these are only applied on persistent (on-disk) databases. DuckDB does not compress its in-memory tables.",
            "Note that in certain cases DuckDB may launch _too many threads_ (e.g., due to HyperThreading), which can lead to slowdowns. In these cases, it‚Äôs worth manually limiting the number of threads using [`SET threads = X`](/docs/stable/configuration/pragmas.html) .",
            "Larger-than-memory workloads are supported by spilling to disk. With the default configuration, DuckDB creates the `database_file_name .tmp` temporary directory (in persistent mode) or the `.tmp` directory (in in-memory mode). This directory can be changed using the [`temp_directory` configuration option](/docs/stable/configuration/pragmas.html) , e.g. :",
            "DuckDB is support for larger-than-memory workloads, i.e., it is able to process data sets that are larger than the available system memory (also known as *out-of-core processing*). It can also run queries where the intermediate results cannot fit into m",
            "A key strength of DuckDB is support for larger-than-memory workloads, ie, it is able to process data sets that are larger than the available system memory.",
            "DuckDB parallelizes the workload based on *[row groups](/docs/stable/internals/storage.html),* i.e., groups of rows that are stored together at the storage level. A row group in DuckDB's database format consists of max. 122,880 rows. Parallelism starts at the level of row groups, therefore, for a query to run on *k* threads, it needs to scan at least *k* \\* 122,880 rows."
          ]
        },
        {
          "title": "Morsel-driven query evaluation framework (Leis et al.)",
          "url": "https://15721.courses.cs.cmu.edu/spring2016/papers/p743-leis.pdf",
          "excerpts": [
            "The comparison with the state-of-the-art Vectorwise\nsystem, which uses a classical implementation of Volcano-style\nparallelism [3], shows that beyond 8 cores, in many-core territory,\nthe morsel-driven framework speeds ahead; and we believe that its\nprinciples in fine-grained scheduling, full operator parallelization,\nlow-overhead synchronization and NUMA-aware scheduling can\nbe used to improve the many-core scaling in other systems as well.",
            "In particular, one\nneeds to keep in mind that it is much easier to provide linear scal-\nability on computationally slow systems than it is on fast systems\nsuch as HyPe",
            "In HyPer we rely on\na compiled query evaluation approach as first postulated by Krikel-\nlas et al. [19] and later refined by Neumann [25] to obtain the same,\nor even higher raw execution performance",
            "The dis-\npatcher assigns the processing of a morsel to a thread running on a\ncore of the same socket in order to preserve NUMA locality.",
            "We presented the morsel-driven query evaluation framework for\nparallel query processing. It is targeted at solving the major bot-\ntlenecks for analytical query performance in the many-core age,\nwhich are load-balancing, thread synchronization, memory access\nlocality, and resource elasticit",
            "We presented the morsel-driven query evaluation framework for\nparallel query processing. It is targeted at solving the major bot-\ntlenecks for analytical query performance in the many-core age,\nwhich are load-balancing, thread synchronization, memory access\nlocality, and resource elasticit",
            "7. CONCLUSIONS AND FUTURE WORK",
            "7. CONCLUSIONS AND FUTURE WORK",
            "This way the dispatcher controls parallelism explicitly as opposed\nto the recently proposed approach by Psaroudakis et al. [30] where\nthe number of threads is changed based on the core utilization.",
            "This way the dispatcher controls parallelism explicitly as opposed\nto the recently proposed approach by Psaroudakis et al. [30] where\nthe number of threads is changed based on the core utilization.",
            "The dis-\npatcher assigns the processing of a morsel to a thread running on a\ncore of the same socket in order to preserve NUMA localit",
            "Thus\nmorsel-wise scheduling is flexible, but strongly favors scheduling\nchoices that maximize NUMA-local execution.",
            "The morsel-driven idea extends from just scheduling into a com-\nplete query execution framework in that all physical query opera-\ntors must be able to execute morsel-wise in parallel in all their ex-\necution stages (e.g., both hash-build and probe), a crucial need for\nachieving many-core scalability in the light of Amdahl‚Äôs law.",
            "by V Leis ¬∑ Cited by 420 ‚Äî Fig- ure 6 shows that the morsel size should be set to the smallest pos- sible value where the overhead is negligible, in this case to a value above 10,000.See mo",
            "The\nmorsel-wise processing also facilitates the full elasticity, meaning\nthat the degree of parallelism can be adjusted at any time, e.g., at\nmid-query processing.",
            "The\nmorsel-wise processing also facilitates the full elasticity, meaning\nthat the degree of parallelism can be adjusted at any time, e.g., at\nmid-query processing."
          ]
        },
        {
          "title": "DuckDB Internals: Vectorized Execution",
          "url": "https://duckdb.org/docs/stable/internals/vector.html",
          "excerpts": [
            " This fixed size is commonly referred to in the code as\nSTANDARD_VECTOR_SIZE",
            "ector formats , which allow the system to store the same logical data with a different physical representation . This allows for a more compressed representation, and potentially allows for compressed execution throughout the ",
            "Vector is the container format used to store in-memory data during execution. DataChunk is a collection of Vectors, used for instance to represent a column list in a\nPhysicalProjection operator.",
            "DataChunk is a collection of Vectors, used for instance to represent a column list in a\nPhysicalProjection operator.",
            "DuckDB uses a vectorized query execution model. All operators in DuckDB are optimized to work on Vectors of a fixed size. This fixed size is commonly referred to in the code as\nSTANDARD_VECTOR_SIZE . The default\nSTANDARD_VECTOR_SIZE is 2048 tuples."
          ]
        },
        {
          "title": "How DuckDB handles data not fitting into memory? - Medium",
          "url": "https://medium.com/@josef.machytka/how-duckdb-handles-data-not-fitting-into-memory-299fa606a345",
          "excerpts": [
            "The numbers didn't exactly match the data file size because DuckDB uses compression in storage. Summary. In these tests DuckDB demonstrated ..."
          ]
        },
        {
          "title": "Feather File Format ‚Äî Apache Arrow v21.0.0",
          "url": "https://arrow.apache.org/docs/python/feather.html",
          "excerpts": [
            "V2 files support storing all Arrow data types as well as compression with LZ4 or ZSTD. V2 was first made available in Apache Arrow 0.17."
          ]
        },
        {
          "title": "Comet Tuning Guide - Apache DataFusion",
          "url": "https://datafusion.apache.org/comet/user-guide/tuning.html",
          "excerpts": [
            "Generally, increasing the amount of memory allocated to Comet will improve query performance by reducing the amount of time spent spilling to disk, especially ..."
          ]
        },
        {
          "title": "Configuration Settings ‚Äî Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/user-guide/configs.html",
          "excerpts": [
            "When executing a memory-consuming query under a tight memory limit, DataFusion will spill intermediate results to disk. When the FairSpillPool is used, memory ..."
          ]
        },
        {
          "title": "mimalloc is a compact general purpose allocator with ...",
          "url": "https://github.com/microsoft/mimalloc",
          "excerpts": [
            "With huge OS pages, it may be beneficial to set the setting MIMALLOC_EAGER_COMMIT_DELAY=N ( N is 1 by default) to delay the initial N segments (of 4MiB) of a¬†...See more"
          ]
        },
        {
          "title": "jemalloc ‚Äî general purpose memory allocation functions",
          "url": "https://jemalloc.net/jemalloc.3.html",
          "excerpts": [
            "The \"always\" setting enables transparent hugepage for all user memory mappings with MADV_HUGEPAGE ; \"never\" ensures no transparent hugepage with MADV_NOHUGEPAGE¬†...See more"
          ]
        },
        {
          "title": "Numeric Types",
          "url": "https://duckdb.org/docs/stable/sql/data_types/numeric.html",
          "excerpts": [
            "The minimum storage size for a VARINT is 4 bytes, every digit takes up an extra bit, rounded up to 8 (12 digits take 12 bits, rounded up to 16, becomes two¬†..."
          ]
        },
        {
          "title": "Scalable memory allocation using jemalloc",
          "url": "https://engineering.fb.com/2011/01/03/core-infra/scalable-memory-allocation-using-jemalloc/",
          "excerpts": [
            "Jan 3, 2011 ‚Äî This post surveys jemalloc's core algorithms and data structures before detailing numerous Facebook-motivated enhancements, followed by a real-world benchmark.See more"
          ]
        },
        {
          "title": "Lightweight Compression in DuckDB",
          "url": "https://duckdb.org/2022/10/28/lightweight-compression.html",
          "excerpts": [
            "Compression algorithms typically reduce data set size by 75-95%, depending on how compressible the data is. Compression not only reduces the ..."
          ]
        },
        {
          "title": "Write a Feather file (an Arrow IPC file) ‚Äî write_feather",
          "url": "https://arrow.apache.org/docs/r/reference/write_feather.html",
          "excerpts": [
            "\"zstd\" is the other available codec and generally has better compression ratios in exchange for slower read and write performance. \"lz4\" is shorthand for the \" ..."
          ]
        },
        {
          "title": "NUMA-Aware Work-stealing Library using Elastic Tasks",
          "url": "https://vivkumar.github.io/papers/hipc2020.pdf",
          "excerpts": [
            "by V Kumar ¬∑ Cited by 8 ‚Äî This paper presents PufferFish, a new async‚Äìfinish parallel programming model and work-stealing runtime for. NUMA systems that provide a close coupling of the¬†..."
          ]
        },
        {
          "title": "datafusion::execution - Rust",
          "url": "https://docs.rs/datafusion/latest/datafusion/execution/index.html",
          "excerpts": [
            "This allows the user to extend DataFusion with different storage systems such as S3 or HDFS and query data inside these systems. registry ¬∑ runtime_env ..."
          ]
        },
        {
          "title": "PhysicalExpr in datafusion::physical_plan - Rust",
          "url": "https://docs.rs/datafusion/latest/datafusion/physical_plan/trait.PhysicalExpr.html",
          "excerpts": [
            "... PhysicalExpr are the physical counterpart to Expr used in logical planning. They are typically created from Expr by a PhysicalPlanner invoked from a higher ..."
          ]
        },
        {
          "title": "datafusion-physical-expr - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/datafusion-physical-expr",
          "excerpts": [
            "This crate is a submodule of DataFusion that provides data types and utilities for physical expressions. Most projects should use the datafusion ..."
          ]
        },
        {
          "title": "Mark Raasveldt",
          "url": "https://15721.courses.cs.cmu.edu/spring2023/slides/22-duckdb.pdf",
          "excerpts": [
            "Vectors are the bread and butter of the engine. ‚Ä¢ DuckDB has a custom vector format. ‚Ä¢ Similar to Arrow - but designed for execution. ‚Ä¢ Co-designed with Velox¬†..."
          ]
        },
        {
          "title": "JIT compiler and runtime for a toy language, using Cranelift",
          "url": "https://github.com/bytecodealliance/cranelift-jit-demo",
          "excerpts": [
            "This is a simple demo that JIT-compiles a toy language, using Cranelift. It uses the new JIT interface in development here.See more"
          ]
        },
        {
          "title": "Is cranelift better than LLVM? : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/1h1tnms/is_cranelift_better_than_llvm/",
          "excerpts": [
            "So cranelift focuses on the low level optimizations of optimally mapping data to CPU registers and logical operations to CPU instructions. This¬†...See more"
          ]
        },
        {
          "title": "Introduce JIT code generation for performance improvement",
          "url": "https://github.com/apache/arrow-datafusion/issues/1850",
          "excerpts": [
            "Feb 17, 2022 ‚Äî With JIT codegen, we could generate specific code for each query to reduce branching overhead from the generalized interpret mode execution.See more"
          ]
        },
        {
          "title": "Unifying Compiled and Vectorized Query Execution",
          "url": "https://www.cs.cit.tum.de/fileadmin/w00cfj/dis/papers/inkfuse.pdf",
          "excerpts": [
            "by B Wagner ¬∑ Cited by 4 ‚Äî This paper unifies these two approaches. We present Incremental Fusion, a novel execution paradigm for modern, high-performance query engines."
          ]
        },
        {
          "title": "These Rows Are Made for Sorting and That's Just What We' ...",
          "url": "https://duckdb.org/pdf/ICDE2023-kuiper-muehleisen-sorting.pdf",
          "excerpts": [
            "by L Kuiper ¬∑ Cited by 3 ‚Äî DuckDB uses morsel-driven parallelism [6]; there- fore, each thread collects roughly the same amount of data in parallel. Key and payload columns are converted¬†..."
          ]
        },
        {
          "title": "Lecture #20: System Analysis (DuckDB)",
          "url": "https://15721.courses.cs.cmu.edu/spring2024/notes/20-duckdb.pdf",
          "excerpts": [
            "It uses Morsel-driven Parallelism. 6. It supports PAX Columnar Storage. 7. It supports both Sort-Merge Join and Hash Join operations. 8. It has a stratified¬†..."
          ]
        },
        {
          "title": "DuckDB Columnar Storage Meets SIMD - Thinking Loop (Medium, Aug 2025)",
          "url": "https://medium.com/@ThinkingLoop/columnar-storage-meets-simd-duckdbs-secret-to-speed-07fae64eb826",
          "excerpts": [
            "But DuckDB goes further ‚Äî tapping directly into your CPU‚Äôs hidden acceleration unit: **SIMD (Single Instruction, Multiple Data",
            "DuckDB is one of those rare breakthroughs. If you‚Äôve ever run queries that finished in seconds instead of minutes, you‚Äôve likely touched the magic of **columnar storag",
            "Columnar Storage Meets SIMD: DuckDB‚Äôs Secret to Speed",
            "Discover how DuckDB leverages columnar storage and SIMD vectorization to deliver lightning-fast analytics on modern CPUs."
          ]
        },
        {
          "title": "VertexClique Morsels Compilation",
          "url": "https://vertexclique.com/blog/morsels-compilation-people/",
          "excerpts": [
            "For billion-scale datasets, we automatically adjust morsel sizing to prevent memory pressure while ensuring sufficient parallel work.",
            "Intelligent morsel sizing: Dynamically adjusting work chunks for optimal parallelism; NUMA-aware scheduling: Placing computation close to the ... We designed ScramVM specifically to address this gap. ScramVM serves as a high-performance foundation for:"
          ]
        },
        {
          "title": "MORSEL-DRIVEN SCHEDULING ... MORSEL-DRIVEN PARALLELISM: A NUMA-AWARE QUERY EVALUATION FRAMEWORK FOR THE MANY-CORE AGE",
          "url": "https://15721.courses.cs.cmu.edu/spring2024/slides/08-scheduling.pdf",
          "excerpts": [
            "No separate dispatcher thread. The workers perform cooperative scheduling for \neach query plan using a single global task queue. ‚Üí Each worker tries to select tasks that will execute on \n\nmorsels that are local to it. ‚Üí If there are no local tasks, then the worker just pulls the \n\nnext task from the global work queue.",
            "SIGMOD 2014",
            "MORSEL-DRIVEN PARALLELISM: A NUMA-AWARE QUERY \nEVALUATION FRAMEWORK FOR THE MANY-CORE AGE",
            "Dynamic scheduling of tasks that operate over \nhorizontal partitions called \"morsels\" distributed \nacross cores. ‚Üí One worker per core. ‚Üí One morsel per task. ‚Üí Pull-based task assignment. ‚Üí Round-robin data placement. Supports parallel, NUMA-aware operator \nimplementations. 14",
            "MORSEL-DRIVEN SCHEDULING"
          ]
        },
        {
          "title": "Morsel-Driven Parallelism: A NUMA-Aware Query Evaluation Framework for the Many-Core Age",
          "url": "https://db.in.tum.de/~leis/papers/morsels.pdf",
          "excerpts": [
            " ure 6 shows that the morsel size should be set to the smallest pos- sible value where the overhead is negligible, in this case to a value above 10,000.",
            " The morsel-driven execution of the algebraic plan is controlled\nby a so called QEPobject which transfers executable pipelines to a\ndispatcher",
            "This achieves very high\nraw performance, since interpretation overhead as experienced by\ntraditional query evaluators, is eliminated.",
            "The dispatcher enables the full\nelasticity which allows to vary the number of parallel threads work-\ning on a particular query at any tim",
            "\nThe morsel-driven idea extends from just scheduling into a com-\nplete query execution framework in that all physical query opera-\ntors must be able to execute morsel-wise in parallel in all their ex-\necution stages (e.g., both hash-build and probe), a crucial need for\nachieving many-core scalability in the light of Amdahl",
            "Our evaluation on the\nTPC-H and SSB benchmarks shows extremely high absolute per-\nformance and an average speedup of over 30 with 32 core",
            "This way the dispatcher controls parallelism explicitly as opposed\nto the recently proposed approach by Psaroudakis et al. [30] where\nthe number of threads is changed based on the core utiliza",
            " As soon as a morsel is finished, the thread\ncan be assigned a morsel belonging to the same query pipeline or\nbe assigned a different task",
            "The\nmorsel-wise processing also facilitates the full elasticity, meaning\nthat the degree of parallelism can be adjusted at any time, e.g., at\nmid-query processing.",
            "The dis-\npatcher assigns the processing of a morsel to a thread running on a\ncore of the same socket in order to preserve NUMA locality",
            "by V Leis ¬∑ Cited by 420 ‚Äî Morsels are used to break a large task into small, constant-sized work units to facilitate work-stealing and preemption. Consequently, the morsel size is ...",
            "Morsel-driven query processing takes small\nfragments of input data (‚Äúmorsels‚Äù) and schedules these to worker\nthreads that run entire operator pipelines until the next pipeline\nbreaker.",
            "The core idea is a scheduling mechanism (the ‚Äúdispatcher‚Äù)\nthat allows flexible parallel execution of an operator pipeline, that\ncan change the parallelism degree even during query execution.",
            "Morsel-driven query execution is a new parallel query eval-\nuation framework that fundamentally differs from the tra-\nditional Volcano model in that it distributes work between\nthreads dynamically using work-steal"
          ]
        },
        {
          "title": "Streaming and Vectorized Execution in DataFusion and DuckDB",
          "url": "https://www.flarion.io/blog/streaming-in-modern-query-engines-where-datafusion-shines",
          "excerpts": [
            "* DuckDB processes fixed-size batches of 1,024 values, matching dedicated database servers for medium-sized datasets",
            ". The Birth of Vectorized Processing",
            ".\nDuckDB's columnar architecture and parallel execution make analytical queries remarkably fast for these scenarios.",
            ". DuckDB Pipelined Execution: DuckDB employs a vectorized, pipelined execution model that processes data in small chunks (vectors) through query operators.",
            ":\nStreaming-First Design : While other engines adapted batch processing for streaming, DataFusion incorporates streaming principles natively.",
            ". DataFusion's streaming architecture delivers several key advantages:",
            "e\nApache DataFusion, the Rust-based query engine at the heart of the Apache Arrow ecosystem, was designed with streaming as a core architectural principle."
          ]
        },
        {
          "title": "DataFusion vs DuckDB vs Spark: Architecture and Performance",
          "url": "https://medium.com/data-reply-it-datatech/apache-data-fusion-building-next-generation-analytics-from-the-ground-up-560032a151d4",
          "excerpts": [
            "Apache Spark** carries significant overhead for smaller datasets but scales better across distributed environment",
            "DuckDB** delivers exceptional performance for analytical workloads on single machines, typically processing 10GB TPC-H benchmarks in 3‚Äì5 minutes compared to Spark‚Äôs ~21 minutes. It uses native columnar storage with efficient compressio",
            "Completely customizable** : It features a full query planner, a columnar, streaming, multi-threaded, vectorized execution engine, and partitioned data source",
            "Built on Arrow** : Benefit from a modern, standardized memory model that unlocks high-performance in Python, Rust, C++, and more. The rest of this article offer",
            "DataFusion‚Äôs architecture is the reason for its flexibility and speed. It brings together some of the most successful design patterns in modern analytics (vectorized execution, columnar storage, modular optimizers) with new ideas born from the Rust ecosystem and the Arrow community.",
            "DuckDB leads in simplicity and single-machine performance, DataFusion offers cutting-edge performance with modern Rust architecture, while Spark remains the standard for distributed computing.",
            "Vectorized Processing** : Operations are performed on entire columns (arrays), keeping memory accesses tightly packed and maximizing CPU throughput.",
            "At its core, DataFusion leverages Apache Arrow, the industry-standard in-memory columnar data format. Arrow brings exceptional benefits to analytics:",
            "Powered by Apache Arrow: Columnar Foundation"
          ]
        },
        {
          "title": "DuckDB vs DataFusion ‚Äì Matt's Substack article",
          "url": "https://performancede.substack.com/p/duckdb-vs-datafusion",
          "excerpts": [
            "Duckdb Vs. Datafusion",
            "As both Databricks and the Apache Iceberg crew work to harden their rust-based tooling, both orgs have settled on Apache Datafusion as their backend data processing engine:"
          ]
        },
        {
          "title": "AVX512 + simd binary and/or kernels slower than ...",
          "url": "https://github.com/apache/arrow-rs/issues/1829",
          "excerpts": [
            "Jun 9, 2022 ‚Äî For some reason the second benchmark is always significantly slower when run together, running them separately gives the same (higher)¬†..."
          ]
        },
        {
          "title": "datafusion - crates.io: Rust Package Registry",
          "url": "https://crates.io/crates/datafusion/32.0.0",
          "excerpts": [
            "Oct 12, 2023 ‚Äî DataFusion is an in-memory query engine that uses Apache Arrow as the memory model."
          ]
        },
        {
          "title": "8 Ways DuckDB Uses Vectorization to Outperform SQL Engines",
          "url": "https://medium.com/@ThinkingLoop/8-ways-duckdb-uses-vectorization-to-outperform-sql-engines-1416171c4992",
          "excerpts": [
            "Discover how DuckDB's vectorized execution model delivers faster analytics than legacy SQL engines across real-world workloads."
          ]
        },
        {
          "title": "Aggregating Millions of Groups Fast in Apache Arrow ...",
          "url": "https://datafusion.apache.org/blog/2023/08/05/datafusion_fast_grouping/",
          "excerpts": [
            "Aug 5, 2023 ‚Äî Updates aggregate values quickly, using vectorizable loops that are easy for compilers to translate into the high performance SIMD instructions¬†..."
          ]
        },
        {
          "title": "Crate Configuration ‚Äî Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/user-guide/crate-configuration.html",
          "excerpts": [
            "This section contains information on how to configure builds of DataFusion in your Rust project. The Configuration Settings section lists options that control¬†..."
          ]
        },
        {
          "title": "[PDF] Parallelized Path-finding in DuckPGQ - CWI",
          "url": "https://homepages.cwi.nl/~boncz/msc/2024-PinganRen.pdf",
          "excerpts": [
            "Parallelism in DuckDB is based on morsel-driven parallelism. Morsel ... Granularity: Balance the size of the parallel tasks (granularity)."
          ]
        },
        {
          "title": "Why DuckDB",
          "url": "https://duckdb.org/why_duckdb.html",
          "excerpts": [
            ". The state of the art in data management to achieve this are either [vectorized or just-in-time query execution engines]",
            "Vectorized query execution leads to far better performance in OLAP queries.",
            "DuckDB uses a **columnar-vectorized query execution engine** , where queries are still interpreted, but a large batch of values (a \"vector\") are processed in one operation."
          ]
        },
        {
          "title": "Introduction ‚Äî Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/user-guide/introduction.html",
          "excerpts": [
            "Blazingly fast, vectorized, multithreaded, streaming execution engine. Native support for Parquet, CSV, JSON, and Avro file formats. Support for custom file ..."
          ]
        },
        {
          "title": "DuckDB Under the Hood: A Deep Dive into its Performance ...",
          "url": "https://www.upp-technology.com/en/news/duckdb-under-the-hood-a-deep-dive-into-its-performance-architecture/",
          "excerpts": [
            "Aug 4, 2025 ‚Äî These three parts are Columnar Storage, the Vectorized Execution Engine, and Morsel Driven Parallelism. 1.1. Columnar Storage. Traditional¬†..."
          ]
        },
        {
          "title": "Apache DataFusion ‚Äî Apache DataFusion documentation",
          "url": "https://datafusion.apache.org/",
          "excerpts": [
            "DataFusion features a full query planner, a columnar, streaming, multi-threaded, vectorized execution engine, and partitioned data sources. You can ..."
          ]
        },
        {
          "title": "MVCC for Main-Memory Databases (P. √Öke Larson et al., VLDB 2012)",
          "url": "https://vldb.org/pvldb/vol5/p298_per-akelarson_vldb2012.pdf",
          "excerpts": [
            "he optimistic method\n\nperforms better than the pessimistic method.",
            "Single-version locking is fragile; it performs well when\n\ntransactions are short and contention is low but suffers under\n\nmore demanding condition",
            "Single-version locking can be implemented efficiently and\n\nwithout lock acquisition becoming a bottleneck",
            "When 50% of the active transactions\n\nare long readers, at x=12, MV has 80X higher update throughput\n\nthan 1",
            "The MV schemes outperform 1V when most transactions are\n\nread-only",
            "We designed and implemented two MVCC methods,\n\none optimistic using validation and one pessimistic using locking. For comparison purposes we also implemented a variant of single-\n\nversion locking optimized for main memory databas",
            "The multiver-\n\nsion schemes have higher overhead but are much less sensitive to\n\nhotspots and the presence of long-running transacti",
            "We designed two MVCC mechanisms: the first is optimistic and relies on validation, while the second one is pessimistic and relies on locking."
          ]
        },
        {
          "title": "DRaft: A double-layer structure for Raft consensus mechanism",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/S1084804525000086",
          "excerpts": [
            "Moreover, the maximum throughput of triple-layer Raft is 5.4\n√ó higher than that of Raft and 2.5\n√ó higher than that of BRaf",
            "Our results show that when achieving a throughput of 12K TPS, the latency of BRaft is twice that of DRaft."
          ]
        },
        {
          "title": "Park PhD Dissertation: Reusable Infracture for Linearizability (RIFL) and Consistent Unordered Replication Protocol (CURP)",
          "url": "https://web.stanford.edu/~ouster/cgi-bin/papers/ParkPhD.pdf",
          "excerpts": [
            "CURP reuses RIFL to avoid duplicate executions\n\nduring recovery",
            "RIFL provides a general-purpose mechanism for converting at-least-once RPC semantics\n\nto exactly-once semantics, thereby making it easy to turn non-linearizable operations into lineariz-\n\nable on",
            "This dissertation presents two new consistency mechanisms for large-scale and low-latency sys-\n\ntems: Reusable Infracture for Linearizability (RIFL) and Consistent Unordered Replication Protocol\n\n(CU"
          ]
        },
        {
          "title": "FoundationDB Forum Discussion: How to Scale FoundationDB Reads",
          "url": "https://forums.foundationdb.org/t/how-to-scale-foundation-db-reads/1108",
          "excerpts": [
            "| 640x400 | 3ms | 1.3ms | 0.5ms | 12.6k | 78.8k | 0% |",
            "| 640x200 | 2ms | 1ms | 0.28ms | 19k | 40.4k | 0% |",
            "| 640x100 | 2ms | 1ms | 0.25ms | 20k | 20.5k | 0% |",
            "| --- | --- | --- | --- | --- | --- | --- |",
            "| Clients x GRV/s | p50 Client GRV mean (ms) | p50 Client GRV Batch time (ms) | p50 Proxy GRV Batch time (ms) | Proxy getLiveCommitedVersion/s | Client GRV requests to Proxy/s | Client max GRV batch size reached (%) |",
            "Feb 2, 2019 ‚Äî MeanGRVLatency is about 40ms (roughly the sum of GRVBatchTimeMean / 2 + GRVBatchReplyLatenciesMean as expected). We tried varying number of¬†... To reduce any noise, we tried a GRV only benchmark (no actual reads):\n"
          ]
        },
        {
          "title": "FoundationDB Forum Discussion: LogServer Disk Busy in Production Deployment",
          "url": "https://forums.foundationdb.org/t/logserver-disk-busy-in-production-deployment/4634",
          "excerpts": [
            "When the tlog disks start to slow down, the commit proxies will measure a higher latency and react to that by making the batches larger.",
            "So as long as the disks can keep up FDB will keep the batches small.",
            "FDB tries to strike a balance between latency and throughput here by controlling how large each commit batch should be. Smaller commit batches will result in lower latencies, larger batches give you more throughput.",
            "What this is telling you is simply that there‚Äôs work in the queue for the disk at most times. This is not something that is inherently bad. Instead you need to look at IOPS (optimally through metrics provided by the cloud provider).",
            "Sep 25, 2024 ‚Äî When the tlog disks start to slow down, the commit proxies will measure a higher latency and react to that by making the batches larger."
          ]
        },
        {
          "title": "Cicada: Dependably Fast Multi-Core In-Memory Transactions",
          "url": "https://faculty.cc.gatech.edu/~jarulraj/courses/4420-s19/papers/06-mvcc2/lim-sigmod2017.pdf",
          "excerpts": [
            "by H Lim ¬∑ 2017 ¬∑ Cited by 222 ‚Äî This paper presents Cicada, a multi ... Mostly-optimistic concurrency control for highly contended dynamic workloads on a thousand cores."
          ]
        },
        {
          "title": "Cicada: Dependably Fast Multi-Core In-Memory Transactions",
          "url": "https://dl.acm.org/doi/10.1145/3035918.3064015",
          "excerpts": [
            "Efficient optimistic concurrency control using loosely synchronized clocks. ... IX: A protected dataplane operating system for high throughput and low latency."
          ]
        },
        {
          "title": "Building and deploying MySQL Raft at Meta",
          "url": "https://engineering.fb.com/2023/05/16/data-infrastructure/mysql-raft-meta/",
          "excerpts": [
            "May 16, 2023 ‚Äî A learner would be a non-voting member of the ring, e.g., the three MySQLs in non-primary-capable regions (above). It would be a replica in¬†..."
          ]
        },
        {
          "title": "MyRaft: High Availability in MySQL using Raft",
          "url": "https://openproceedings.org/2024/conf/edbt/paper-199.pdf",
          "excerpts": [
            "by A Rahut ¬∑ 2024 ‚Äî Voters participate in leader elections by voting, while non-voters are passive entities that receive logs but do not participate in elections."
          ]
        },
        {
          "title": "FDB Read and Write Path ‚Äî FoundationDB ON documentation",
          "url": "https://apple.github.io/foundationdb/read-write-path.html",
          "excerpts": [
            "This document explains how FDB works at high level in database terms without mentioning FDB internal concepts. We first discuss the read path and the write ..."
          ]
        },
        {
          "title": "Add `transportTimeout` in `r.replicateTo` ¬∑ Issue #610",
          "url": "https://github.com/hashicorp/raft/issues/610",
          "excerpts": [
            "Aug 22, 2024 ‚Äî Recently, I am learning how Raft operate and its implementation. However, in my own test, I found the transportTimeout is needed for r.trans¬†..."
          ]
        },
        {
          "title": "Replication Layer - CockroachDB",
          "url": "https://www.cockroachlabs.com/docs/stable/architecture/replication-layer",
          "excerpts": [
            "Missing: pipelining witness"
          ]
        },
        {
          "title": "Configuration ‚Äî FoundationDB ON documentation - Apple",
          "url": "https://apple.github.io/foundationdb/configuration.html",
          "excerpts": [
            "This document contains reference information for configuring a new FoundationDB cluster. We recommend that you read this document before setting up a cluster."
          ]
        },
        {
          "title": "Technical overview of the database - Using FoundationDB",
          "url": "https://forums.foundationdb.org/t/technical-overview-of-the-database/135",
          "excerpts": [
            "Apr 20, 2018 ‚Äî So proxy sends the transaction to leader. Or proxy directly writes to the log servers using like two-phase commit? Proxies send the¬†..."
          ]
        },
        {
          "title": "Release Notes ‚Äî FoundationDB ON documentation - Apple",
          "url": "https://apple.github.io/foundationdb/release-notes/release-notes-700.html",
          "excerpts": [
            "Features ¬∑ First release of the Redwood Storage Engine, a BTree storage engine with higher throughput and lower write amplification than SQLite.See more"
          ]
        },
        {
          "title": "How Pipelining consensus writes speeds up distributed SQL ...",
          "url": "https://www.cockroachlabs.com/blog/transaction-pipelining/",
          "excerpts": [
            "Like other modern distributed systems, CockroachDB uses the Raft consensus protocol to manage coordination between replicas and to achieve fault ..."
          ]
        },
        {
          "title": "Raft Consensus Algorithm Visualized",
          "url": "https://systemdr.substack.com/p/raft-consensus-algorithm-visualized",
          "excerpts": [
            "Advanced deployments use witness nodes‚Äînon-voting participants that participate in leader election but don't store data. This approach¬†..."
          ]
        },
        {
          "title": "Plor: General Transactions with Predictable, Low Tail Latency",
          "url": "https://dl.acm.org/doi/pdf/10.1145/3514221.3517879",
          "excerpts": [
            "by Y Chen ¬∑ 2022 ¬∑ Cited by 24 ‚Äî Undo logging causes higher tail latency than redo, but still, Plor exhibits ... In MVCC (e.g., MV2PL [7], Cicada [25]), each record has ..."
          ]
        },
        {
          "title": "Fast Databases with Fast Durability and Recovery Through ...",
          "url": "https://wzheng.github.io/silor.pdf",
          "excerpts": [
            "Epochs allow for a form of group commit: SiloR persists and recovers in units of epochs. We describe below how this impacts logging, checkpointing, and recovery¬†..."
          ]
        },
        {
          "title": "Release Notes ‚Äî FoundationDB ON documentation - Apple",
          "url": "https://apple.github.io/foundationdb/release-notes/release-notes-630.html",
          "excerpts": [
            "... commit batching window size on each proxy. ... Users with large tls clusters should consider explicitly setting this knob in their foundationdb.conf file.See more"
          ]
        },
        {
          "title": "raft/replication.go at main ¬∑ hashicorp/raft",
          "url": "https://github.com/hashicorp/raft/blob/main/replication.go",
          "excerpts": [
            "// allowPipeline is used to determine when to pipeline the AppendEntries RPCs. // It is private to this replication goroutine. allowPipeline bool."
          ]
        },
        {
          "title": "Transaction Commit Path ¬∑ apple/foundationdb Wiki",
          "url": "https://github.com/apple/foundationdb/wiki/Transaction-Commit-Path",
          "excerpts": [
            "Once the commit proxy has received a commit version, it has all of the information it needs to send the commit batch to the resolvers for conflict resolution."
          ]
        },
        {
          "title": "Reasons for not co-locating tlog and SS? IO characteristics ...",
          "url": "https://forums.foundationdb.org/t/reasons-for-not-co-locating-tlog-and-ss-io-characteristics-of-ss/2013",
          "excerpts": [
            "The logs call fsync() for every commit version, so hundreds of times per second, while storage servers only call it once or twice per second."
          ]
        },
        {
          "title": "Silo OCC and MVCC (S Tu et al.)",
          "url": "https://wzheng.github.io/silo.pdf",
          "excerpts": [
            "At¬†commit¬†time, after¬†validating¬†that¬†no¬†concurrent¬†transaction‚Äôs¬†writes overlapped¬†with¬†its¬†read¬†set,¬†the¬†transaction¬†installs¬†all written¬†records¬†at¬†once.",
            "An OCC transaction tracks the records it reads and writes in thread-local storage.",
            "Silo uses a variant of optimistic concurrency control. (OCC)"
          ]
        },
        {
          "title": "OSDI 2014: Silo and SiloR: A Fast In-Memory Database for Multicore Machines",
          "url": "https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-zheng_wenting.pdf",
          "excerpts": [
            "nded time. In-\nmemory databases must take periodic checkpoints of\ntheir state to allow recovery to complete quickly, and to\nsupport log truncation.",
            "It has one important dis-\nadvantage, namely that the critical path for transaction\ncommit contains two fsyncs (one for the log file and one\nfor pepoch) rather than one. This somewhat increases\nlatenc",
            "This protocol provides a form of group commit. It en-\nsures that the logs contain all information about trans-\n\nactions in epochs ‚â§ ep, and that no results from trans-\nactions with epoch > ep were released to c",
            "Once pepoch is durably stored, the distinguished\nlogger thread publishes ep to a global variable. At\nthat point all transactions with epochs ‚â§ ep have be-\ncome durable and workers can release their results\nto client",
            "The distinguished logger thread periodically com-\nputes a persistence epoch ep as min{el} ‚àí 1 over\nall loggers. It writes ep to the pepoch file and then\nsynchronizes that write to dis",
            "Logging\n\nThis section explains how SiloR logs transaction modifi-\ncations for persisten",
            "Epochs provide the key to correct replay. On total-\nstore-order (TSO) architectures like x86-64, the desig-\nnated thread‚Äôs update of E becomes visible at all workers\nsimultaneously. Because workers read the current epoch\nat the serialization point, the ordering of TIDs with dif-\nferent epochs is always compatible with the serial or-\nder, even in the case of anti-depende",
            "l provides a form of group commit. It en-\nsures that the logs contain all information about trans-\n\nactions in epochs ‚â§ ep, and that no results from trans-\nactions with epoch > ep were released to clients",
            "by W Zheng ¬∑ 2014 ¬∑ Cited by 182 ‚Äî Epochs allow for a form of group commit: SiloR persists and recovers in units of epochs. We describe below how this impacts logging,¬†..."
          ]
        },
        {
          "title": "TiKV Component GC Principles and Common Issues (Dev.to TiDB Community)",
          "url": "https://dev.to/tidbcommunity/tikv-component-gc-physical-space-reclamation-principles-and-common-issues-3paj",
          "excerpts": [
            "\n\nThe GC manager is the thread responsible for driving the GC work in TiKV. The main steps are:\n\n* Syncing the GC safepoint to local memory\n* Globally guiding the execution of specific GC tasks",
            "The GC manager regularly requests the latest GC safepoint from PD every ten seconds and refreshes the safepoint in memory.",
            "During GC, TiDB clears all locks before the GC safepoint across the entire cluster using the resolve locks mechanism."
          ]
        },
        {
          "title": "Plor: General Transactions with Predictable, Low Tail Latency",
          "url": "https://storage.cs.tsinghua.edu.cn/papers/sigmod22plor.pdf/",
          "excerpts": [
            "This further confirms that abort times is the dominating factor that hurts tail latencies in Plor for high-contention workloads. Effects of Persistent Logging.",
            "logging overhead too much when aborting a transaction. Undo logging causes higher tail latency than redo, but still, Plor exhibits the lowest tail latency ..."
          ]
        },
        {
          "title": "Enabling low tail latency on multicore key-value stores",
          "url": "https://dl.acm.org/doi/abs/10.14778/3384345.3384356",
          "excerpts": [
            "por L Lersch ¬∑ 2020 ¬∑ Mencionado por 38 ‚Äî In this paper we present RStore, a KVS which focus on low tail latency as its primary goal, while also enabling efficient usage of hardware resources. To that ..."
          ]
        },
        {
          "title": "Epoch-based Commit and Replication in Distributed OLTP ...",
          "url": "http://www.vldb.org/pvldb/vol14/p743-lu.pdf",
          "excerpts": [
            "by Y Lu ¬∑ Cited by 43 ‚Äî In this section, we discuss how to adapt two popular singe-node concurrency control algorithms (i.e., Silo [63] and Tictoc [70]) into the framework of COCO.",
            "by Y Lu ¬∑ Cited by 43 ‚Äî By default, optimistic concurrency control protocols (i.e., PT-OCC and LT-OCC) are allowed to read from the nearest replica in both. 2PC(Sync) and Epoch(Async)."
          ]
        },
        {
          "title": "[PDF] Fast Distributed Transactions and Strongly Consistent Replication ...",
          "url": "http://www.cs.umd.edu/~abadi/papers/calvin-tods14.pdf",
          "excerpts": [
            "This article describes Calvin, a practical transaction scheduling and data replication layer that uses a deterministic ordering guarantee to significantly ..."
          ]
        },
        {
          "title": "RocksDB Config - TiKV",
          "url": "https://tikv.org/docs/4.0/tasks/configure/rocksdb/",
          "excerpts": [
            "wal-bytes-per-sync. The rate at which OS incrementally synchronizes WAL files to disk while the WAL files are being written; Default value: 512KB; Minimum ..."
          ]
        },
        {
          "title": "Raftstore Config",
          "url": "https://tikv.org/docs/4.0/tasks/configure/raftstore/",
          "excerpts": [
            "Learn how to configure Raftstore in TiKV. This document describes the configuration parameters related to Raftstore."
          ]
        },
        {
          "title": "Aria: a fast and practical deterministic OLTP database",
          "url": "https://dl.acm.org/doi/10.14778/3407790.3407808",
          "excerpts": [
            "In this paper, we present Aria, a new distributed and deterministic OLTP database that does not have this limitation."
          ]
        },
        {
          "title": "[PDF] Aria: A Fast and Practical Deterministic OLTP Database",
          "url": "http://www.vldb.org/pvldb/vol13/p2047-lu.pdf",
          "excerpts": [
            "Our experiments on a cluster of eight nodes show that Aria outperforms systems with conven- tional nondeterministic concurrency control algorithms and the state ..."
          ]
        },
        {
          "title": "[PDF] Calvin: Fast Distributed Transactions for Partitioned Database Systems",
          "url": "https://cs.yale.edu/homes/thomson/publications/calvin-sigmod12.pdf",
          "excerpts": [
            "Calvin is a practical transaction scheduling and data replication layer that uses a deterministic ordering guarantee to significantly reduce the."
          ]
        },
        {
          "title": "Systematic Evaluation of Raft using Evaluation-as-a-Service (EaaS)",
          "url": "https://cse.buffalo.edu/tech-reports/2025-02.pdf",
          "excerpts": [
            "EaaS also demonstrates its generality by integrating with Raft via a\ncustom C adapter (ClientDriver_C), making the framework adapt-\nable to both production systems and research prototype",
            "The experi-\nments are primarily limited to clusters of up to five nodes and do\nnot fully capture the complexities of large-scale, geo-distributed,\nor production-grade deployment",
            "The experimentation rigorously\nvalidates Raft‚Äôs core properties of safety and liveness across both\nstable and unstable network conditions, confirming the protocol‚Äôs\ncorrectness even under adverse scenarios.",
            "3.1.1 Raft-Specific Insights",
            "This systematic and automated approach\nbridges the gap between Raft‚Äôs theoretical design and its practi-\ncal deploymen",
            "3.1.3 Significance",
            "3.1.3 Significance",
            "A key methodological\nadvancement is the reproducibility of results: every experiment\nis logged with exact parameters, such as the number of nodes\nand workload characteristics, in the eaas.db database.",
            "3.1.2 Methodological Advancements",
            "3.1.2 Methodological Advancements",
            "Adaptive batching is shown to improve\nthroughput by up to 30% for write-heavy workloads, highlighting\nthe practical impact of tuning batch sizes and batching strategies.",
            "Adaptive batching is shown to improve\nthroughput by up to 30% for write-heavy workloads, highlighting\nthe practical impact of tuning batch sizes and batching strategies.",
            "Leader crashes trigger 2‚Äì3√ó higher la-\ntency spikes during log catch-up as the new leader synchronizes\nstate across the cluste",
            "Under highly skewed work-\nloads (zipf_constant > 0.9), throughput drops by 15‚Äì20% due to\nthe leader becoming a bottleneck, a known challenge in leader-\nbased consensus syste",
            "Performance trade-\noffs are quantitatively assessed: shorter leader election timeouts\n(such as 100ms) reduce failover latency but increase the risk of\nelection contention and split votes",
            "1.1 Raft-Specific Insights",
            "Our findings confirm Raft's efficiency in stable environments but also reveal subtle trade-offs in latency, throughput, and recovery dynamics under stress."
          ]
        },
        {
          "title": "TiDB/PingCAP P99 Latency and Raft Tuning (Representative Text)",
          "url": "https://www.pingcap.com/article/effective-tips-to-improve-p99-latency/",
          "excerpts": [
            "P99 latency, or the 99th percentile latency, is a crucial metric for evaluating the performance of web services and distributed systems. Essentially, it measures the time within which 99% of requests are completed."
          ]
        },
        {
          "title": "Deterministic and Non-Deterministic Concurrency Control Algorithms",
          "url": "https://www.vldb.org/pvldb/vol18/p1376-lu.pdf",
          "excerpts": [
            "In this paper, we propose HDCC, a hybrid approach that in-\ncorporates Calvin and OCC into the same database syste",
            "28] is\nthe only work that mixes deterministic and non-deterministic algo-\nrithms. In Snapper, transactions with pre-declared read/write sets\nare scheduled and executed in batches by Calvin, while other trans-\nactions are individually scheduled by 2PL.",
            "To maximize the respective advantages, we are motivated to\ndevelop a hybrid approach that integrates deterministic and non-\ndeterministic algorithms into the same database system",
            "On the contrary,\nnon-deterministic algorithms such as optimistic concurrency con-\ntrol (OCC) and its variants ([27, 45]), two-phase locking (2PL) and\nits variants ([3, 17]) work without the aforementioned assump-\ntions. They excel in low or medium contention workloads. How-\never, their performance suffers when processing high contention\nworkloads or distributed transactions [18",
            "However, deterministic algorithms work under stringent as-\nsumptions, like batched execution and predeclared read/write sets,\nlimiting their applicability in realit",
            " Deterministic algo-\nrithms [11, 12, 43] excel in processing either high contention work-\nloads or distributed transactions or both, due to their determinis-\ntic schedule and without a need for a two-phase commit protocol"
          ]
        },
        {
          "title": "Data Replication Design Spectrum",
          "url": "https://transactional.blog/blog/2024-data-replication-design-spectrum",
          "excerpts": [
            "Jul 31, 2024 ‚Äî PacificA delivers superior write bandwidth and similar latencies to Raft, with the trade-off being a higher chance of unavailability versus more¬†..."
          ]
        },
        {
          "title": "How does Raft deals with delayed replies in AppendEntries RPC?",
          "url": "https://stackoverflow.com/questions/56677690/how-does-raft-deals-with-delayed-replies-in-appendentries-rpc",
          "excerpts": [
            "The protocol assumes that there's some context with respect to which AppendEntries RPC a follower is responding to."
          ]
        },
        {
          "title": "TiKV Config",
          "url": "https://tikv.org/docs/6.1/deploy/configure/tikv-configuration-file/",
          "excerpts": [
            "wal-bytes-per-sync. The rate at which OS incrementally synchronizes WAL files to disk while the WAL files are being written; Default value: \"512KB\"; Minimum ...",
            "raft-max-inflight-msgs. The number of Raft logs to be confirmed. If this number is exceeded, log sending slows down. Default value: 256; Minimum value¬†..."
          ]
        },
        {
          "title": "TiCDC FAQs",
          "url": "https://docs.pingcap.com/tidb/stable/ticdc-faq",
          "excerpts": [
            "Any service can register and update its GC safepoint. PD ensures that the key-value data later than this GC safepoint is not cleaned by GC. When the¬†...",
            "The purpose is to prevent a replication task in TiCDC from suspending for too long, causing the GC safepoint of the upstream TiKV cluster not to continue for a¬†..."
          ]
        },
        {
          "title": "Performance Analysis and Tuning",
          "url": "https://docs.pingcap.com/tidb/stable/performance-tuning-methods",
          "excerpts": [
            "Dec 3, 2024 ‚Äî Raft Engine has a light execution path. This helps reduce I/O writes and long-tail latency of writes in some scenarios.",
            "Dec 3, 2024 ‚Äî In this TPC-C workload: The average latency and P99 latency of all SQL statements are 477 us and 3.13 ms, respectively. The average latencies of¬†..."
          ]
        },
        {
          "title": "TiDB Cloud Performance Highlights for TiDB v8.5.0",
          "url": "https://docs.pingcap.com/tidbcloud/v8.5-performance-highlights",
          "excerpts": [
            "Based on the preceding test setup, failovers are now improved in multiple IO delay scenarios, and P99/999 latency during impacts is reduced by up to 98%."
          ]
        },
        {
          "title": "High availability in cheap distributed key value storage",
          "url": "https://www.pdl.cmu.edu/PDL-FTP/NVM/socc20-final183.pdf",
          "excerpts": [
            "by T Kim ¬∑ 2020 ¬∑ Cited by 1 ‚Äî A witness node receives only the key and a logical timestamp composed of the Raft term and index, in a similar manner to Cheap Paxos. This¬†..."
          ]
        },
        {
          "title": "Rethinking serializable multiversion concurrency control",
          "url": "https://www.researchgate.net/publication/269339633_Rethinking_serializable_multiversion_concurrency_control",
          "excerpts": [
            "We propose Bohm, a new concurrency control protocol for main-memory multi-versioned database systems. Bohm guarantees serializable execution ..."
          ]
        },
        {
          "title": "Intelligent Transaction Scheduling to Enhance ...",
          "url": "https://www.mdpi.com/2076-3417/15/11/6341",
          "excerpts": [
            "We propose Dynamic Contention Scheduling (DCoS), a novel method that enhances transaction concurrency via a dual-granularity architecture."
          ]
        },
        {
          "title": "Fast Abort-Freedom for Deterministic Transactions",
          "url": "https://par.nsf.gov/servlets/purl/10548863",
          "excerpts": [
            "by C Chen ¬∑ 2024 ¬∑ Cited by 1 ‚Äî We present DecentSched‚Äîshort for Decentralized Schedul- ing, a novel concurrency control protocol that gains high parallelism and low latency in deterministic ..."
          ]
        },
        {
          "title": "An Overview of Deterministic Database Systems",
          "url": "https://www.cs.umd.edu/~abadi/papers/abadi-cacm2018.pdf",
          "excerpts": [
            "by DJ ABADI ¬∑ 2018 ¬∑ Cited by 52 ‚Äî Therefore, either the deterministic database system must use non-locking concurrency control protocols, or they must use deadlock avoidance ..."
          ]
        },
        {
          "title": "Fine-Grained Re-Execution for Efficient Batched Commit of ...",
          "url": "https://cs.nyu.edu/~apanda/assets/papers/hackwrench-vldb23.pdf",
          "excerpts": [
            "Calvin. Calvin is a deterministic database that assigns total order to batched transactions before execution and avoids 2PC overhead. Each node has a single¬†..."
          ]
        },
        {
          "title": "TiKV Raft and Read-Write Process",
          "url": "https://tikv.org/blog/how-tikv-reads-writes/",
          "excerpts": [
            "TiKV provides two sets of APIs for data operations, namely RawKV and Transactional KV (TxnKV). This section introduces how read and write in ...",
            "TiKV supports a feature called Lease Read. For Read requests, they can be sent directly to the Leader.",
            "When the Leader finds that the entry has been appended by majority of nodes, it considers that the entry Committed.",
            "The Leader will also copy the entry to other Followers through the Raft algorithm.",
            "The Leader encodes the operation into an entry and writes it into its own Raft Log. This is called Append.",
            "When the client needs to write some data, it sends the request to the Raft Leader.",
            "By default, TiKV uses three replicas to form a Raft Group.",
            "TiKV uses the Raft consensus algorithm to ensure data safety and consistency."
          ]
        },
        {
          "title": "TiKV Engine Ext ‚Äì Raft, DWAL, and region snapshot considerations",
          "url": "https://github.com/pingcap/tidb-engine-ext",
          "excerpts": [
            "ReadIndex",
            "According to the basic transaction log replication, a leader peer must commit or apply each writing action before returning success ACK to the client.",
            "The\nregion snapshot presents the complete region information(data/meta/apply-state) at a specific apply-state.",
            "Besides, a few modules and components(like importer or lighting) reply on the SST format of KvEngine in TiKV.",
            "When maintaining DWAL, it's practical to batch raft msg before fsync as long as latency is tolerable to reduce IOPS(mainly in RaftEngine) and make it system-"
          ]
        },
        {
          "title": "TiKV/Raft/WAL Configuration and Concepts",
          "url": "https://docs.pingcap.com/tidb/stable/tikv-configuration-file",
          "excerpts": [
            "# `enable-pipelined-write`\n\n* Controls whether to enable Pipelined Write. When this configuration is enabled, the previous Pipelined Write is used. When this configuration is disabled, the new Pipelined Commit mechanism is used. * Default value: `true`",
            "### `wal-dir`\n\n* The directory in which WAL files are stored. If not specified, the WAL files will be stored in the same directory as the data."
          ]
        },
        {
          "title": "TiKV/Raft and WAL FAQ",
          "url": "https://tikv.org/docs/6.5/reference/faq/",
          "excerpts": [
            "\nTo ensure data recovery when a node fails, data is redundantly replicated between TiKV nodes using the Raft consensus algorithm",
            "Currently, the standalone storage engine uses two RocksDB instances. One instance is used to store the raft-log.",
            "WAL belongs to ordered writing.",
            "the `sync-log` parameter in TiKV is set to true, each commit is mandatorily flushed to the raft-log.",
            "The default CF mainly stores ... For a standalone TiKV node, it is still recommended to enable the sync-log mode.",
            "The Raft RocksDB instance stores Raft logs."
          ]
        },
        {
          "title": "TiDB GC and MVCC Overview",
          "url": "https://www.mydbops.com/blog/tidb-garbage-collection-lifecycle-configuration-best-practices",
          "excerpts": [
            "This parameter dictates how often TiDB runs the GC process, specifying the interval between consecutive GC cycles.",
            "This parameter controls the duration TiDB keeps historical data versions.",
            "GC Retention Time Window Past Data GC Safe Point Protected Data Current Time Data Eligible for GC Protected Data Default Retention Time: 10 minutes",
            "When a transaction is executed in TiDB, multiple versions of the data may exist over time.",
            "This ensures that only data no longer needed for queries or transactional integrity is removed, maintaining the system's efficiency and stability.",
            "GC Safe Point: The GC safe point is a timestamp that determines the earliest version of data that can be safely removed."
          ]
        },
        {
          "title": "TiDB MVCC Garbage Collection Guide",
          "url": "https://pingcap.github.io/tidb-dev-guide/understand-tidb/mvcc-garbage-collection.html",
          "excerpts": [
            "This document talked about how MVCC GC worked in TiDB system. The most basic requirement of GC is not to delete readable data. Due to the guarantee of GC, you don't need to care about that data is removed. The green GC, skips fetch snapshot when read locks, help to improve the performance of GC. There are some further performance-related topics of GC in TiKV which will be talked in TiKV Dev Guide.",
            ". If the pulled safepoint is greater than the local one, the local one will be pushed up, and¬†... func (s *Server) UpdateGCSafePoint(ctx context.Context, request *pdpb.UpdateGCSafePointRequest) (*pdpb.UpdateGCSafePointResponse, error) {\n\t...\n\tnewSafePoint := request.SafePoint\n\n\t// Only save the safe point if it's greater than the previous one\n\tif newSafePoint > oldSafePoint {\n\t\tif err := s.storage.SaveGCSafePoint(newSafePoint); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlog.Info(\"updated gc safe point\",\n\t\t\tzap.Uint64(\"safe-point\", newSafePoint))\n\t} else if newSafePoint < oldSafePoint {\n\t\tlog.Warn(\"trying to update gc safe point\",\n\t\t\tzap.Uint64(\"old-safe-point\", oldSafePoint),\n\t\t\tzap.Uint64(\"new-safe-point\", newSafePoint))\n\t\tnewSafePoint = oldSafePoint\n\t}\n\n\treturn &pdpb.UpdateGCSafePointResponse{\n\t\tHeader:       s.header(),\n\t\tNewSafePoint: newSafePoint,\n\t}, nil\n}",
            "By default, TiKV tries to pull safepoint from PD every 10 seconds."
          ]
        },
        {
          "title": "Garbage collection overview (TiDB/TiKV)",
          "url": "https://docs.pingcap.com/tidb/stable/garbage-collection-overview",
          "excerpts": [
            "Starting with TiDB 5.0, the Do GC step will always use the `DISTRIBUTED` gc mode.",
            "In the default configuration, GC is triggered every 10 minutes. Each GC retains data of the recent 10 minutes, which means that the GC life time is 10 minutes by default (safe point = the current time - GC life time).",
            "3. Do GC. During this step, each TiKV node scans data on it and deletes unneeded old versions of each key.",
            "2. Delete Ranges. During this step, the obsolete data of the entire range generated from the `DROP TABLE`/`DROP INDEX` operation is quickly cleared.",
            "1. Resolve Locks. During this step, TiDB scans locks before the safe point on all Regions and clears these locks.",
            "Specifically, there are three steps involved in each GC process:",
            "GC runs periodically on TiDB. For each GC, TiDB firstly calculates a timestamp called \"safe point\". Then, TiDB clears the obsolete data under the premise that all the snapshots after the safe point retain the integrity of the data."
          ]
        },
        {
          "title": "Performance ‚Äî FoundationDB ON documentation - Apple",
          "url": "https://apple.github.io/foundationdb/performance.html",
          "excerpts": [
            "A FoundationDB cluster might have a commit latency of 2 ms and yet be capable of far more than 500 commits per second. In fact, tens of thousands of commits ..."
          ]
        },
        {
          "title": "Unable to run more than one commit proxy in a small cluster",
          "url": "https://forums.foundationdb.org/t/unable-to-run-more-than-one-commit-proxy-in-a-small-cluster/4025",
          "excerpts": [
            "Jun 22, 2023 ‚Äî According to Configuration ‚Äî FoundationDB 7.2, ‚Äúthe default value for commit proxies and log servers is 3‚Äù. However I can see only one process¬†..."
          ]
        },
        {
          "title": "FoundationDB has, in my experience, always been well ...",
          "url": "https://news.ycombinator.com/item?id=36575333",
          "excerpts": [
            "TiDB uses TiKV as an equivalent to foundationDB. It supports online migrations and pushing down read queries to the kv later. It also ..."
          ]
        },
        {
          "title": "raft package - go.etcd.io/raft/v3 - Go ...",
          "url": "https://pkg.go.dev/go.etcd.io/raft/v3",
          "excerpts": [
            "Feb 5, 2025 ‚Äî MaxUncommittedEntriesSize uint64 // MaxInflightMsgs limits the max number of in-flight append messages during // optimistic replication phase."
          ]
        },
        {
          "title": "What is the relationship between `sync-log` and `wal-bytes-per-sync`",
          "url": "https://github.com/tikv/tikv/issues/4828",
          "excerpts": [
            "I wonder if it means that, if I set sync-log = true , Raft RocksDB will save every write into WAL ? In other words, it will overwrite wal-bytes- ..."
          ]
        },
        {
          "title": "FAQ - TiKV",
          "url": "https://tikv.org/docs/3.0/reference/faq/",
          "excerpts": [
            "The Raft RocksDB instance stores Raft logs. The default CF mainly stores Raft logs and the corresponding parameter is in [raftdb.defaultcf] . All CFs have a ..."
          ]
        },
        {
          "title": "Garbage Collection Configuration",
          "url": "https://docs.pingcap.com/tidb/stable/garbage-collection-configuration/",
          "excerpts": [
            "Starting from v6.1.0, TiDB considers the startTS of the transaction when calculating the GC safe point, to resolve the problem that the data to be accessed has¬†...",
            "After the value is exceeded, the GC safe point is forwarded forcefully. GC in Compaction Filter. Based on the DISTRIBUTED GC mode, the mechanism of GC in¬†..."
          ]
        },
        {
          "title": "Insights from paper: FoundationDB: A Distributed Unbundled ...",
          "url": "https://hemantkgupta.medium.com/insights-from-paper-foundationdb-a-distributed-unbundled-transactional-key-value-store-82d977fd2a5d",
          "excerpts": [
            "The Proxies offer MVCC read versions to clients and orchestrate transaction commits. Resolvers check for conflicts between transactions."
          ]
        },
        {
          "title": "How FoundationDB works and why it works - Lu's blog",
          "url": "https://blog.the-pans.com/notes-on-the-foundationdb-paper/",
          "excerpts": [
            "It's a non-sharded, strict serializable, fault tolerant, key-value store that supports point writes, reads and range reads."
          ]
        },
        {
          "title": "Distributed Transactions in FoundationDB - MyDistributed.Systems",
          "url": "https://www.mydistributed.systems/2020/08/foundationdb.html",
          "excerpts": [
            "Write Path. Writes are simply buffered on the client. FoundationDB uses the optimistic concurrency control. Thus, there is no 2PL and no lock ...",
            "In this post, we will see how FoundationDB uses optimistic and multi-version concurrency control techniques to provide strictly serializable distributed ..."
          ]
        },
        {
          "title": "A Distributed Unbundled Transactional Key Value Store",
          "url": "https://www.foundationdb.org/files/fdb-paper.pdf",
          "excerpts": [
            "The data plane consists of a transaction management system, re-\n\nsponsible for processing updates, and a distributed storage layer  \nserving reads; both can be independently scaled",
            "FoundationDB offers a minimal and carefully chosen  \nfeature set, which has enabled a range of disparate systems (from  \nsemi-relational databases, document and object stores, to graph  \ndatabases and more) to be built as layers o",
            "FoundationDB  \nuniquely integrates a deterministic simulation framework, used to  \ntest every new feature of the system under a myriad of possible  \nf",
            "FoundationDB adopts an  \nunbundled architecture that decouples an in-memory transaction  \nmanagement system, a distributed storage system, and a built-in  \ndistributed configuration s",
            "by J Zhou ¬∑ 2021 ¬∑ Cited by 75 ‚Äî Resolvers, and LogServers. Proxies offer MVCC read versions to clients and orchestrate transaction commits. Resolvers check for conflicts between transactions."
          ]
        },
        {
          "title": "Avoiding unintended connection failures with ...",
          "url": "https://lwn.net/Articles/853637/",
          "excerpts": [
            "... Eric Dumazet, who questioned whether it is the right approach. Since SO_REUSEPORT was added, he said, the TCP accept code has been reworked to run¬†..."
          ]
        },
        {
          "title": "Add 4-tuple hash for connected socket",
          "url": "https://lkml.iu.edu/hypermail/linux/kernel/2409.1/08504.html",
          "excerpts": [
            "Re: [RFC PATCH net-next] net/udp: Add 4-tuple hash for connected socket. From: Eric Dumazet Date: Fri Sep 13 2024 - 11:40:09 EST."
          ]
        },
        {
          "title": "Red Hat Low Latency Performance Tuning for Red Hat Enterprise Linux 7",
          "url": "https://access.redhat.com/sites/default/files/attachments/201501-perf-brief-low-latency-tuning-rhel7-v2.1.pdf",
          "excerpts": [
            "MTU Size and packet fragmentation. The default network MTU (Maximum Transmit Unix) size is 1500. If your network packets are larger \nthan 1500 bytes, then they‚Äôll be broken up into fragments and reassembled, which will cause a \nslowdown. You can check for fragmentation with:\n\nnetstat -s | egrep \"reassemblies|fragments created\"\n\nIf it shows fragments or reassemblies, then you may want to increase the MTU size. Note that \nincreasing it larger than needed to eliminate fragmentation may help with throughput, but will hurt \nla",
            "Enable busy_poll on supported NIC hardware for read, poll and select.\n/proc/sys/net/ipv4/tcp_fastopen\nEnable TCP FastOpen support on both server and client connections. See the kernel documentation for \nmore information. TCP_NODELAY (otherwise known as the Nagle algorithm) is enabled by default in the Linux TCP \nstack. TCP_NODELAY reduces the number of packets used to transmit data by delaying outgoing \npackets until the amount of data ready to send reaches the maximum transmit unit of the network \ninterface (commonly 1500 bytes). The amount of time it takes to accumulate a single MTU's worth of \npackets is unbounded. For certain applications this delay interferes with timely receipt of data. See Red Hat's Realtime Tuning Guide for more information on TCP_NOD",
            "Demonstrated to lower latency very slightly (under 1 microsecond). Not recommended. /proc/sys/net/core/busy_poll and /proc/sys/net/core/busy_read",
            "These raw numbers are included as a simple reference. Latency-optimized code (such as other vendor-\nprovided latency testing utilities) improves results. Additionally sockperf and sfnettest are frequently used to measure network performance",
            "The Linux kernel's networking stack is extremely flexible. Significant effort has gone in to ensure sane \ndefaults for the most common use-cases. Red Hat adjusts certain network tunables to suite enterprise \nworkloads via tuned profiles. If tuned is disabled or not installed, upstream kernel defaults are used. Most network tunables live in /proc/sys/net. The most common way to adjust them is by using the \nsysctl tool. Documentation on using sysctl is available in the Performance Tuning Guide. /proc/sys/net/ipv4/tcp_low_late",
            "Make sure the OS is fully updated. ‚ñ° Enable network-latency tuned profile, or perform equivalent tuning. ‚ñ° Verify that power management settings are corre"
          ]
        },
        {
          "title": "Rustls performance benchmarks and analysis",
          "url": "https://www.memorysafety.org/blog/rustls-performance/",
          "excerpts": [
            "The topic of benchmarking in a continuous integration setup is challenging.",
            "With the rise of Rust, however, safer alternatives have become possible without compromising on performance.",
            "Aside from correctness and security, it is important for a TLS implementation to keep overhead at a minimum.",
            "Rustls handles 80% to 330% (depending on the scenario) more resumed handshakes per second, either using session ID or ticket-based resumption.",
            "Rustls handles 30% (TLS 1.2) or 27% (TLS 1.3) fewer full RSA handshakes per second on the server side, but offers significantly more throughput on the client side (up to 106% more, that is, a factor of 2.06x).",
            "Rustls is competitive with OpenSSL."
          ]
        },
        {
          "title": "Performance optimisation using SO_REUSEPORT (Medium article)",
          "url": "https://medium.com/high-performance-network-programming/performance-optimisation-using-so-reuseport-c0fe4f2d3f88",
          "excerpts": [
            "So you may ask: that was quite easy, where is the catch? The point is, that this kind of performance increase through concurrency is only possible if the 4 tuple of the incoming packets differ, to achieve an equal distribution of traffic to all listening sockets.",
            "Since 9 Gbit/s is the incoming bandwidth at the router, we assume that it nearly forwards all incoming packets, which is fantastic for close to 10 Gbit/s.",
            "Using larger frames (MTU 3000), the performance increases in a similar fashion while starting at 3 Gbit/s for 1 DataPlane and reaches up to 9 Gbit/s for 10 DataPlanes.",
            "We observe that the forwarding performance of the SO\\_REUSEPORT Border Router nearly increases linear starting from around 1.3 Gbit/s for 1 DataPlane (MTU 1500) to 7.5 Gbit/s with 10 DataPlanes",
            "In the next figure, we show the achieved forwarding performance with a different packet size based on the configured MTU.",
            "We measure the forwarding performance of the router by using nload on the outgoing network interface.",
            "To evaluate how the number of concurrent DataPlanes affect the forwarding performance, we run the SCION Border Router with 1‚Äì10 DataPlanes (since we have 10 CPU cores) and send around 9 Gbit/s SCION traffic on a 10 Gbit/s link to it (using 10 different sockets with different port numbers).",
            "Performance benchmarks",
            "SO_REUSEPORT lets multiple sockets bind to the same port, allowing to distribute traffic to them without having a single socket as bottleneck."
          ]
        },
        {
          "title": "Optimizing TCP for high WAN throughput while preserving ...",
          "url": "https://blog.cloudflare.com/optimizing-tcp-for-high-throughput-and-low-latency/",
          "excerpts": [
            "Linux autotuning is logic in the Linux kernel that adjusts the buffer size limits and the receive window based on actual packet processing. It ..."
          ]
        },
        {
          "title": "Optimizing Linux Networking: The New Interrupt ... - Medium",
          "url": "https://medium.com/@amerather_9719/optimizing-linux-networking-the-new-interrupt-suppression-mechanism-e515192f02a4",
          "excerpts": [
            "Linux 6.1+ introduces an enhanced Kernel Polling mechanism that intelligently suppresses interrupts based on application workload."
          ]
        },
        {
          "title": "Scaling in the Linux Networking Stack",
          "url": "https://docs.kernel.org/networking/scaling.html",
          "excerpts": [
            "For low latency networking, the optimal setting is to allocate as many queues as there are CPUs in the system (or the NIC maximum, if lower). The most¬†..."
          ]
        },
        {
          "title": "Perfect locality and three epic SystemTap scripts",
          "url": "https://blog.cloudflare.com/perfect-locality-and-three-epic-systemtap-scripts/",
          "excerpts": [
            "Nov 7, 2017 ‚Äî SO_INCOMING_CPU interface is pretty rudimentary and was deemed unsuitable for more complex usage. It was superseded by the more powerful¬†...See more"
          ]
        },
        {
          "title": "rustls 0.21.12",
          "url": "https://docs.rs/crate/rustls/0.21.12",
          "excerpts": [
            "Status. Rustls is mature and widely used. While most of the API surface is stable, we expect the next few releases will make further changes as needed to ..."
          ]
        },
        {
          "title": "ServerConnection in rustls::server - Rust",
          "url": "https://docs.rs/rustls/latest/rustls/server/struct.ServerConnection.html",
          "excerpts": [
            "Recovered from the prior session's set_resumption_data . Integrity is guaranteed by rustls. Returns Some if and only if a valid resumption ticket has been¬†..."
          ]
        },
        {
          "title": "Resumption in rustls::client - Rust",
          "url": "https://docs.rs/craftls/latest/rustls/client/struct.Resumption.html",
          "excerpts": [
            "Create an in-memory session store resumption with up to 256 server names, allowing a TLS 1.2 session to resume with a session id or RFC 5077 ticket."
          ]
        },
        {
          "title": "TLS 1.2 vs. 1.3‚ÄîHandshake, Performance, and Other Improvements",
          "url": "https://www.catchpoint.com/http2-vs-http3/tls1-2-vs-1-3",
          "excerpts": [
            "TLS 1.3. In comparison, the TLS 1.3 handshake process is completed in one round trip (1-RTT)."
          ]
        },
        {
          "title": "Low latency tuning | Scalability and performance | OKD 4.12",
          "url": "https://docs.okd.io/4.12/scalability_and_performance/cnf-low-latency-tuning.html",
          "excerpts": [
            "About support of IRQ affinity setting. Some IRQ controllers lack support for IRQ affinity setting and will always expose all online CPUs as the IRQ mask."
          ]
        },
        {
          "title": "Optimizing web servers for high throughput and low latency",
          "url": "https://dropbox.tech/infrastructure/optimizing-web-servers-for-high-throughput-and-low-latency",
          "excerpts": [
            "When it is done in hardware it is called RSS, when the OS is responsible for loadbalancing packets across CPUs it is called RPS (with its TX- ..."
          ]
        },
        {
          "title": "8.6. Receive-Side Scaling (RSS) | Performance Tuning Guide",
          "url": "https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/6/html/performance_tuning_guide/network-rss",
          "excerpts": [
            "RSS can be used to relieve bottlenecks in receive interrupt processing caused by overloading a single CPU, and to reduce network latency. To determine whether ..."
          ]
        },
        {
          "title": "Production ready eBPF, or how we fixed the BSD socket API",
          "url": "https://blog.cloudflare.com/tubular-fixing-the-socket-api-with-ebpf/",
          "excerpts": [
            "Feb 17, 2022 ‚Äî It leverages SO_REUSEPORT and eBPF to route new and existing flows to the correct server instance.... By. Marek Majkowski ¬∑ UDP, Linux¬†..."
          ]
        },
        {
          "title": "Medium article: We ditched Nginx for a Rust proxy you won\r't believe‚Äîthe speed",
          "url": "https://medium.com/@trek007/we-ditched-nginx-for-a-rust-proxy-you-wont-believe-the-speed-46d8df5d670c",
          "excerpts": [
            " We‚Äôll cover zero‚Äêcopy request/response streaming, a sharded HTTP/2 connection pool to upstream services, custom backpressure handling, and benchmarks that prove how Rust lets you reclaim lost performance.",
            "e. No hand‚Äêholding basic introductions ‚Äî just the advanced code and explanations you need to deploy a rock‚Äêsolid proxy in production.",
            "\n\nOur proxy must terminate TLS, support modern cipher suites (including TLS1.3), and gracefully handle certificate reloads. We chose **rustls** (v0.20) for a pure‚ÄêRust TLS implementation, and **tokio\\_rustls** (v0.23) to feed incoming TCP streams into rustls‚Äôs state machines."
          ]
        },
        {
          "title": "The Impact of Thread-Per-Core Architecture on Application Tail Latency",
          "url": "https://penberg.org/papers/tpc-ancs19.pdf",
          "excerpts": [
            "However, we observe that the thread-per-core approach\nis held back by request steering and OS interfaces, and it could\nbe further improved with NIC hardware offload.",
            "We show in an experimental evaluation\nthat our approach reduces tail latency by up to 71% compared\nto baseline Memcached running on commodity hardware and\nLinux.",
            "The thread-per-core\narchitecture has emerged to reduce these overheads, but it also\nhas its challenges from thread synchronization and OS interfaces."
          ]
        },
        {
          "title": "Patronus Proxy Architecture - Thread-per-core and Work-Stealing Concepts",
          "url": "https://without.boats/blog/thread-per-core/",
          "excerpts": [
            "Enberg‚Äôs paper shows that using channels over using mutexes can achieve lower tail latency.",
            "In contrast,\nin memcached all of the threads share ownership of the keyspace, which is partitioned, and each\npartition is protected by a mut",
            "Enberg shows substantial\nimprovements in tail latency between the two architectures.",
            "s key/value store partitions the keyspace over the\ndifferent threads using a hash function, and partitions incoming TCP connections over the threads\nusing `SO_REUSEPORT`.",
            " This is why work-stealing is said to be\n‚Äúharder.",
            "The point of share-nothing is to improve tail latency by keeping data in the faster caches that\nbelong to a single CPU core, rather than the slower caches shared by multiple cores.",
            "The point of work-stealing is to improve tail latency by ensuring that every thread always has work to do."
          ]
        },
        {
          "title": "Nginx Tail Latency and SO_REUSEPORT",
          "url": "https://tempesta-tech.com/blog/nginx-tail-latency/",
          "excerpts": [
            "SO_ATTACH_REUSEPORT_EBPF",
            "Typically ... @reopen[pid] || @reopen[pid] < @accept[$daddr, $dport]))",
            "SO_REUSEPORT allows many Nginx workers to accept connections concurrently on the same port using different, per-process, sockets."
          ]
        },
        {
          "title": "Rust: how to use async-std + TLS + HTTP Proxy(http tunnel)?",
          "url": "https://stackoverflow.com/questions/65650805/rust-how-to-use-async-std-tls-http-proxyhttp-tunnel",
          "excerpts": [
            "More importantly, one must wait for the HTTP response of the proxy and only establish the TLS connection after one got the full response."
          ]
        },
        {
          "title": "0-RTT sounds nice, until you get to appendix E.5. Everyone ...",
          "url": "https://news.ycombinator.com/item?id=16667036",
          "excerpts": [
            "E.5. Replay Attacks on 0-RTT Replayable 0-RTT data presents a number of security threats to TLS- using applications, unless those applications are specifically¬†..."
          ]
        },
        {
          "title": "ktls - Rust",
          "url": "https://docs.rs/ktls",
          "excerpts": [
            "This is a wrapper that reads TLS message headers so it knows when to start doing empty reads at the message boundary when ‚Äúdraining‚Äù a rustls connection before¬†..."
          ]
        },
        {
          "title": "ktls now under the rustls org",
          "url": "https://fasterthanli.me/articles/ktls-now-under-rustls-org",
          "excerpts": [
            "Sep 26, 2024 ‚Äî kTLS lets the kernel (and, in turn, any network interface that supports it) take care of encryption, framing, etc., for the entire duration of a¬†..."
          ]
        },
        {
          "title": "Writing a high performance TLS terminating proxy in Rust",
          "url": "https://nickb.dev/blog/writing-a-high-performance-tls-terminating-proxy-in-rust/",
          "excerpts": [
            "A layer 7 proxy would, for instance, read the HTTP url and headers (and maybe even the body) before proxying to the app."
          ]
        },
        {
          "title": "Summary of ‚ÄúThe Impact of Thread-Per-Core Architecture on ...",
          "url": "https://medium.com/@smy19890720/summary-of-the-impact-of-thread-per-core-architecture-on-application-tail-latency-948fad0ef559",
          "excerpts": [
            "The paper primarily discusses the impact of the Thread-Per-Core architecture on long-tail latencies at the application layer."
          ]
        },
        {
          "title": "Thread-per-core (work-stealing vs share-nothing) : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/171btot/threadpercore_workstealing_vs_sharenothing/",
          "excerpts": [
            "In the case of HFT, the first goal is the lowest tail-latency possible, and thread-per-core achieves that by minimizing cache-misses and ..."
          ]
        },
        {
          "title": "soreuseport: Fix socket selection for SO_INCOMING_CPU. - linux ...",
          "url": "https://git.sceen.net/linux/linux-stable.git/commit/net/core/sock_reuseport.c?id=b261eda84ec136240a9ca753389853a3a1bccca2",
          "excerpts": [
            "Kazuho Oku reported that setsockopt(SO_INCOMING_CPU) does not work with setsockopt(SO_REUSEPORT) since v4.6. With the combination of SO_REUSEPORT and¬†..."
          ]
        },
        {
          "title": "dorkamotorka/reuseport-ebpf: Custom load balancing ...",
          "url": "https://github.com/dorkamotorka/reuseport-ebpf",
          "excerpts": [
            "SO_REUSEPORT is a powerful feature of the Linux kernel that allows users to have more than one process listen on a given port and allow for load balancing¬†...",
            "In this lightning talk, you'll learn to implement weighted and hot standby load balancing with nothing but eBPF and SO_REUSEPORT. Run it Yourself. First you¬†..."
          ]
        },
        {
          "title": "eBPF-Powered Load Balancing for SO_REUSEPORT",
          "url": "https://medium.com/all-things-ebpf/ebpf-powered-load-balancing-for-so-reuseport-30acb395e1d6",
          "excerpts": [
            "In this post, we explored how to implement custom load balancing using SO_REUSEPORT and eBPF, focusing on a hot standby setup. By leveraging¬†..."
          ]
        },
        {
          "title": "socket(7) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man7/socket.7.html",
          "excerpts": [
            "Argument is an integer boolean flag. SO_REUSEPORT (since Linux 3.9) Permits multiple AF_INET or AF_INET6 sockets to be bound to an identical socket address."
          ]
        },
        {
          "title": "Cloudflare Blog: Introducing Zero Round Trip Time Resumption (0-RTT)",
          "url": "https://blog.cloudflare.com/introducing-0-rtt/",
          "excerpts": [
            "Mar 15, 2017 ‚Äî Generally speaking, 0-RTT is safe for most web sites and applications. If your web application does strange things and you're concerned about¬†...",
            "This is an experimental feature, and therefore subject to change. If you're just looking for a live demo, click [here",
            "ese resumed connections, standard TLS 1.3 is safer but no faster than any previous version of TLS. 0-RTT changes this.",
            "s. It dramatically speeds up resumed connections, leading to a faster and smoother web experience for web sites that you visit regularly.",
            ". TLS 1.3 speeds up these connections significantly.",
            "Introducing Zero Round Trip Time Resumption (0-RTT)",
            "TLS 1.3 is a big step forward for web performance and security. By combining TLS 1.3 with 0-RTT, the performance gains are even more dramatic."
          ]
        },
        {
          "title": "Socket SO_REUSEPORT and Kernel Implementations",
          "url": "https://linuxjedi.co.uk/socket-so_reuseport-and-kernel-implementations/",
          "excerpts": [
            "This brings us to DragonFly BSD which has an implementation very similar to Linux‚Äôs, but crucially it adds hash tables to the mix. This means if a process fails the existing connections on other processes are not dropped. Everything can keep running smoothly.",
            "DragonFly BSD",
            "The downside with the Linux implementation is because it is using a hash to make sure the incoming connections are going to the right socket, as soon as a single listener fails the whole thing collapses because the modulus of the hash is different.",
            "This can give a nice performance boost when you have a high number of connections per second coming into the server as it can reduce the [thundering herd problem](https://en.wikipedia.org/wiki/Thundering_herd_problem).",
            "In Linux this option was added in Kernel 3.9 and basically turned the kernel into a load balancer for the socket. So your application can have multiple threads or processes listening on the same IP/port combination and the kernel will send incoming connections to one of these listeners."
          ]
        },
        {
          "title": "The Sad State of Linux Socket Balancing",
          "url": "https://blog.cloudflare.com/the-sad-state-of-linux-socket-balancing/",
          "excerpts": [
            "Much better load distribution than before. This is better, however the balancing of the load is not the end of the story. Splitting the accept queue worsens the latency distribution in some circumstances!",
            "Each worker gets roughly a similar amount of traffic to handle:",
            "This results in much better [balancing of the load](https://www.cloudflare.com/application-services/products/load-balancing/).",
            "We explained this in the (c) model, where the incoming connections are split into multiple separate accept queues. Usually it's one dedicated queue for each worker process. Since the accept queues are not shared, and Linux spreads the load by a simple hashing logic, each worker will get statistically the same number of incoming connections.",
            "Notice the last worker got almost no load, while the busiest is using 30% of CPU. ### SO\\_REUSEPORT to the rescu",
            "Here's a dump of one of our synthetic tests where one worker is taking most of the load, while others are relatively underutilized:",
            "At Cloudflare we run NGINX, and we are most familiar with the (b) model. In this blog post we'll describe a specific problem with this model, but let's start from the beginning.",
            "This can avoid listen socket contention, which isn't really an issue unless you run at Google scale. It can also help in better balancing the load. More on that later.",
            "By using [the SO\\_REUSEPORT socket option](https://lwn.net/Articles/542629/) it's possible to create a dedicated kernel data structure (the listen socket) for each worker process",
            "Linux supports a feature to work around this balancing problem - the SO\\_REUSEPORT socket option",
            "Linux supports a feature to work around this balancing problem - the SO\\_REUSEPORT socket option"
          ]
        },
        {
          "title": "Cloudflare Pingora Performance",
          "url": "https://blog.cloudflare.com/how-pingora-keeps-count/",
          "excerpts": [
            "The most common one is the connection limit feature.",
            "In production, pingora uses this library in a few places.",
            "pingora-limits provides the functionality to count inflight events and estimate the rate of events over time.",
            "we replaced NGINX with our in-house proxy, [Pingora",
            "From the data above, pingora-limits is both CPU and memory efficient.",
            "Pingora-limits at peak requires 1/2000 of the memory compared to the naive one and 1/1300 of the memory of the optimized one.",
            "The reason the performance of pingora-limits and the optimized hash table are similar is because in both approaches the hot path is just updating the atomic counter.",
            "Our approach is similar to the optimized version. Both are 7x faster than the naive one."
          ]
        },
        {
          "title": "Pingora Open Source Announcement",
          "url": "https://blog.cloudflare.com/pingora-open-source/",
          "excerpts": [
            "As a proxy, it supports HTTP/1 and HTTP/2 end-to-end, gRPC, and websocket proxying. (HTTP/3 support is on the roadmap.) It also comes with ...",
            "As mentioned in our previous blog post, Pingora is a Rust async multithreaded framework that assists us in constructing HTTP proxy services.",
            ")\n\nPingora is a library and toolset, not an executable binary. In other words, Pingora is the engine that powers a car, not the car itself. Although Pingora is production-ready for industry use",
            "Pingora is a library and toolset, not an executable binary. In other words, Pingora is the engine that powers a car, not the car itself.",
            "Pingora provides filters and callbacks to allow its users to fully customize how the service should process, transform and forward the requests.",
            "Pingora provides libraries and APIs to build services on top of HTTP/1 and HTTP/2, TLS, or just TCP/UDS.",
            "We are open sourcing Pingora to help build a better and more secure Internet beyond our own infrastructure.",
            "e Pingora, the Rust framework we have been using to build services that power a significant portion of the traffic on Cloudflare.",
            "Pingora provides zero downtime graceful restarts to upgrade itself without dropping a single incoming request.",
            "Pingora is fast and efficient. As explained in our previous blog post, we saved a lot of CPU and memory resources thanks to Pingora‚Äôs multi-threaded architecture.",
            "Since our last blog post, Pingora has handled nearly a quadrillion Internet requests across our global network.",
            "internet) is a Rust async multithreaded framework that assists us in constructing HTTP proxy service"
          ]
        },
        {
          "title": "Pingora: the proxy that connects Cloudflare to the Internet",
          "url": "https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/",
          "excerpts": [
            "Today we are excited to talk about Pingora, a new HTTP proxy we've built in-house using Rust that serves over 1 trillion requests a day.",
            "A new HTTP proxy we've built in-house using Rust that serves over 1 trillion requests a day, boosts our performance, and enables many new features for ...",
            "In production, Pingora consumes about 70% less CPU and 67% less memory compared to our old service with the same traffic load.",
            "s\n\nTo make a proxy that serves millions of requests per second fast, efficient and secure, we have to make a few important design decisions first. We chose [Rust](https://www.rust-lang.org/) as the language of the project because it can do what C can do in a memory safe way without compromising performa",
            "To present the number more intuitively, by switching to Pingora, we save our customers and users 434 years of handshake time every day.",
            "Across all customers, Pingora makes only a third as many new connections per second compared to the old service. For one major customer, it increased the connection reuse ratio from 87.1% to 99.92%, which reduced new connections to their origins by 160x.",
            "This is not because we run code faster. Even our old service could handle requests in the sub-millisecond range. The savings come from our new architecture which can share connections across all threads. This means a better connection reuse ratio, which spends less time on TCP and TLS handshakes.",
            " First, let‚Äôs see how Pingora speeds up our customer‚Äôs traffic. Overall traffic on Pingora shows 5ms reduction on median TTFB and 80ms reduction on the 95th percentile.",
            " Pingora handles almost every HTTP request that needs to interact with an origin server (for a cache miss, for example), and we‚Äôve collected a lot of performance data in the process.",
            "TLS handshakes are expensive compared to just sending and receiving data via established connections.",
            "The multithreading model also makes sharing data across requests more efficient.",
            "This is not because we run code faster. Even our old service could handle requests in the sub-millisecond range. The savings come from our new architecture which can share connections across all threads.",
            "Pingora handles almost every HTTP request that needs to interact with an origin server (for a cache miss, for example), and we‚Äôve collected a lot of performance data in the process.",
            "Across all customers, Pingora makes only a third as many new connections per second compared to the old service.",
            "For one major customer, it increased the connection reuse ratio from 87.1% to 99.92%, which reduced new connections to their origins by 160x.",
            "Pingora consumes about 70% less CPU and 67% less memory compared to our old service with the same traffic load.",
            "Overall traffic on Pingora shows 5ms reduction on median TTFB and 80ms reduction on the 95th percentile.",
            "Pingora is faster in production"
          ]
        },
        {
          "title": "TLS Guard for TLS 1.3 zero round-trip time (0-RTT) in a ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S1319157823003518",
          "excerpts": [
            "by ME Abdelhafez ¬∑ 2023 ¬∑ Cited by 5 ‚Äî This paper introduces TLS Guard as a new mechanism that extends TLS 1.3 to prevent replay attacks in a distributed environment."
          ]
        },
        {
          "title": "Disabling TCP offload to hardware makes this comparison much ...",
          "url": "https://news.ycombinator.com/item?id=23043505",
          "excerpts": [
            "Disabling TCP offload to hardware makes this comparison much less useful. TCP has hardware offload right now, and QUIC will take years to get at that level."
          ]
        },
        {
          "title": "RSS++: load and state-aware receive side scaling - Dejan Kostic",
          "url": "https://dejankosticgithub.github.io/documents/publications/rsspp-conext19.pdf",
          "excerpts": [
            "by T Barbette ¬∑ 2019 ¬∑ Cited by 91 ‚Äî If the incoming load is not balanced across the cores, some cores will end up buffering more packets than others and therefore exhibit higher latency."
          ]
        },
        {
          "title": "Zero-Downtime Service Restarts using eBPF - eBPFChirp",
          "url": "https://ebpfchirp.substack.com/p/ebpf-powered-load-balancing-for-so_reuseport",
          "excerpts": [
            "By attaching an eBPF program to the sk_reuseport hook point, we can override the default round-robin load balancing and implement custom logic¬†...",
            "In this post, we'll explore the eBPF SO_REUSEPORT program type, which lets you implement custom load-balancing logic to determine which socket ..."
          ]
        },
        {
          "title": "Should we use multiple acceptor sockets to accept a large ...",
          "url": "https://stackoverflow.com/questions/45001349/should-we-use-multiple-acceptor-sockets-to-accept-a-large-number-of-connections",
          "excerpts": [
            "SO_REUSEPORT allows multiple sockets to listen on the same IP address and port combination, it increases requests per second by 2 to 3 times, and reduces both¬†..."
          ]
        },
        {
          "title": "rustls/ktls: Safer wrappers over ktls-sys",
          "url": "https://github.com/rustls/ktls",
          "excerpts": [
            "ktls-sys: the raw system interface for kTLS on Linux. License. This project is primarily distributed under the terms of both the MIT license and the Apache¬†...",
            "This repository hosts both: ktls: higher-level, safe wrappers over kTLS; ktls-sys: the raw system interface for kTLS on Linux. License."
          ]
        },
        {
          "title": "elliptic curves - Cost of TLS (1.3) Handshake using RSA compared ...",
          "url": "https://crypto.stackexchange.com/questions/114919/cost-of-tls-1-3-handshake-using-rsa-compared-to-cost-of-using-ecc",
          "excerpts": [
            "The biggest cost is oftentimes the internet transfer. I tested to generate an RSA 3072 key and an ECC prime256v1 key and self sign a certificate with OpenSSL."
          ]
        },
        {
          "title": "KTLS Support ¬∑ Issue #198 ¬∑ rustls/rustls",
          "url": "https://github.com/rustls/rustls/issues/198",
          "excerpts": [
            "Oct 1, 2018 ‚Äî KTLS is tls support in linux kernel, but it only handles symmetric encryption and decryption, so using Rustls as a handshake is great."
          ]
        },
        {
          "title": "Rustls Server-Side Performance - Prossimo - Memory Safety",
          "url": "https://www.memorysafety.org/blog/rustls-server-perf/",
          "excerpts": [
            "Rustls does quite well here: While this chart shows full TLS 1.3 handshakes in particular, similar results were observed for other scenarios."
          ]
        },
        {
          "title": "Cloudflare replaced NGINX with a homegrown Rust HTTP ...",
          "url": "https://www.reddit.com/r/devops/comments/1b3wo49/cloudflare_replaced_nginx_with_a_homegrown_rust/",
          "excerpts": [
            "Cloudflare replaced NGINX with a homegrown Rust HTTP proxy server called Pingora. Now they've made it open source under Apache2.0 license."
          ]
        },
        {
          "title": "cloudflare/pingora: A library for building fast, reliable and ...",
          "url": "https://github.com/cloudflare/pingora",
          "excerpts": [
            "Pingora is battle tested as it has been serving more than 40 million Internet requests per second for more than a few years. Feature highlights. Async Rust: ...",
            "Pingora is a Rust framework to build fast, reliable and programmable networked systems. Pingora is battle tested as it has been serving more than 40 million¬†...",
            "Pingora is a Rust framework to build fast, reliable and programmable networked systems. Pingora is battle tested as it has been serving more than 40 million ..."
          ]
        },
        {
          "title": "[post] Tasks are the wrong abstraction : r/rust",
          "url": "https://www.reddit.com/r/rust/comments/1cedhxi/post_tasks_are_the_wrong_abstraction/",
          "excerpts": [
            "Re: work stealing vs thread per core, work stealing has long been recognised as a huge benefit for long tail performance, indispensible for¬†..."
          ]
        },
        {
          "title": "Kafka Log Compaction - Detailed Explanation",
          "url": "https://engineering.vendavo.com/kafka-log-compaction-a-detailed-explanation-of-efficient-data-retention-7253c9590795",
          "excerpts": [
            "Non-closed segments (not compacted yet) can still contain duplicate keys",
            "Log Compaction Process / Key-Based Retention\n\nKafk",
            "Kafka stores data as append-only logs organised into segments.",
            "Kafka Log Compaction works on a per-topic basis. It retains the latest record for each key in a topic while discarding older records with the same key."
          ]
        },
        {
          "title": "Kafka Exactly Once Semantics",
          "url": "https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Exactly+Once+Semantics",
          "excerpts": [
            "Kafka Exactly Once - Solving the problem of spurious OutOfOrderSequence errors",
            "KIP-129: Streams Exactly-Once Semantics",
            "Exactly once perf numbers",
            "KIP-98 - Exactly Once Delivery and Transactional Messaging"
          ]
        },
        {
          "title": "On Disk IO, Part 1: Flavors of IO | by Œ±ŒªŒµx œÄ | databasss",
          "url": "https://medium.com/databasss/on-disk-io-part-1-flavours-of-io-8e1ace1de017",
          "excerpts": [
            "In such cases, one can use O_DIRECT flag when opening a file. It instructs the Operating Systems to bypass the Page Cache, avoid storing extra¬†..."
          ]
        },
        {
          "title": "Kafka Design: Page Cache & Performance",
          "url": "https://www.automq.com/blog/kafka-design-page-cache-performance",
          "excerpts": [
            "Mar 16, 2025 ‚Äî This blog explores how Kafka leverages the page cache, its performance implications, configuration best practices, and common challenges."
          ]
        },
        {
          "title": "It's a common misconception about Kafka and fsyncs. But ...",
          "url": "https://news.ycombinator.com/item?id=35953682",
          "excerpts": [
            "It's a common misconception about Kafka and fsyncs. But the Kafka replication protocol has a recovery mechanism, much in the same way that Viewstamped¬†..."
          ]
        },
        {
          "title": "The Death of the Page Cache? From mmap() to NVMe- ...",
          "url": "https://codemia.io/blog/path/The-Death-of-the-Page-Cache-From-mmap-to-NVMe-ZNS-and-User-Space-File-Systems",
          "excerpts": [
            "4 days ago ‚Äî Redpanda also implemented some clever optimizations to maximize throughput with direct I/O. A naive direct I/O approach (writing each¬†...See more"
          ]
        },
        {
          "title": "Does reading via O_DIRECT flush dirty pages first?",
          "url": "https://stackoverflow.com/questions/52439612/does-reading-via-o-direct-flush-dirty-pages-first",
          "excerpts": [
            "[*] Provided your large files are sufficiently large, you can do write()+fsync() and you will overflow the device cache. Then use your DONTNEED¬†..."
          ]
        },
        {
          "title": "Write caching: drive your workloads up to 90% faster",
          "url": "https://www.redpanda.com/blog/write-caching-performance-benchmark",
          "excerpts": [
            "Jul 16, 2024 ‚Äî This makes more efficient use of precious I/O bandwidth (IOPS) and enables Redpanda to maintain lower latency, even with higher latency storage¬†...See more"
          ]
        },
        {
          "title": "Why Apache Kafka doesn't need fsync to be safe",
          "url": "https://jack-vanlightly.com/blog/2023/4/24/why-apache-kafka-doesnt-need-fsync-to-be-safe",
          "excerpts": [
            "Apr 24, 2023 ‚Äî Asynchronous log writing designs like Kafka are most durable when spread over multiple zones to avoid power outages from causing all brokers to¬†..."
          ]
        },
        {
          "title": "io_uring_enter(2) - Linux manual page - man7.org",
          "url": "https://man7.org/linux/man-pages/man2/io_uring_enter.2.html",
          "excerpts": [
            "When submitting a request that should use a provided buffer, the IOSQE_BUFFER_SELECT flag must be set, and buf_group must be set to the desired buffer group ID ..."
          ]
        },
        {
          "title": "IO_uring Zero-Copy Receive Support Ready For Linux 6.15 ... - Reddit",
          "url": "https://www.reddit.com/r/linux/comments/1ilacgo/io_uring_zerocopy_receive_support_ready_for_linux/",
          "excerpts": [
            "There won't be a flag you can turn on like ASIO_USE_ZERO_COPY and suddently get +20% performance on networking operations. This will remain ..."
          ]
        },
        {
          "title": "What's new with io_uring in 6.11 and 6.12",
          "url": "https://github.com/axboe/liburing/wiki/What's-new-with-io_uring-in-6.11-and-6.12",
          "excerpts": [
            "Oct 4, 2024 ‚Äî 6.11 contains a new way to handle especially remote posting on rings setup with IORING_SETUP_DEFER_TASKRUN more efficiently."
          ]
        },
        {
          "title": "io_uring: multishot recv",
          "url": "https://lwn.net/Articles/899498/",
          "excerpts": [
            "This series adds support for multishot recv/recvmsg to io_uring. The idea is that generally socket applications will be continually enqueuing a new recv() when ...See more"
          ]
        },
        {
          "title": "io_uring_prep_recv_multishot(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_prep_recv_multishot.3.html",
          "excerpts": [
            "The io_uring_prep_recv(3) function prepares a recv request. The submission queue entry sqe is setup to use the file descriptor sockfd to start receiving the ...See more"
          ]
        },
        {
          "title": "Class KafkaProducer<K,‚ÄãV>",
          "url": "https://kafka.apache.org/30/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html",
          "excerpts": [
            "Since 3.0.0, please use sendOffsetsToTransaction(Map, ConsumerGroupMetadata) instead. Sends a list of specified offsets to the consumer group coordinator, and¬†..."
          ]
        },
        {
          "title": "KIP-129: Streams Exactly-Once Semantics",
          "url": "https://cwiki.apache.org/confluence/display/KAFKA/KIP-129%253A%2BStreams%2BExactly-Once%2BSemantics",
          "excerpts": [
            "With Kafka Streams, each input record fetched from the source Kafka topics will only be processed exactly once: its processing effects, both in potential ..."
          ]
        },
        {
          "title": "A practical guide to exactly-once semantics in Kafka Streams",
          "url": "https://www.responsive.dev/blog/guide-to-kafka-streams-exactly-once-transactions",
          "excerpts": [
            "A practical guide for developers building stateful Kafka Streams applications with exactly-once semantics enabled."
          ]
        },
        {
          "title": "Meaning of sendOffsetsToTransaction in Kafka 0.11",
          "url": "https://stackoverflow.com/questions/45195010/meaning-of-sendoffsetstotransaction-in-kafka-0-11",
          "excerpts": [
            "Sends a list of consumed offsets to the consumer group coordinator, and also marks those offsets as part of the current transaction."
          ]
        },
        {
          "title": "A Deep Dive into Zero-Copy Networking and io_uring",
          "url": "https://medium.com/@jatinumamtora/a-deep-dive-into-zero-copy-networking-and-io-uring-78914aa24029",
          "excerpts": [
            "Always benchmark for your specific use case!",
            "ose operations. This \"amortization\" effect drastically reduces the per-operation overhead, making\nio_uring significantly faster than\nepoll . The more you batch, the better\nio_uring looks.",
            "Batching is King!",
            "Combined with registered buffers, data can be transmitted directly from user memory to the NIC without any intermediate CPU copies.",
            "io_uring isn't a silver bullet that magically makes everything faster. Its performance superiority is highly dependent on your workload, especially your ability to batch requests.",
            "This ‚Äúfixed‚Äù approach is a key reason\nio_uring 's zero-copy can outperform older metho",
            "Using Fixed Buffers (\nIORING_OP_READ_FIXED ,\nIORING_OP_WRITE_FIXED ): Once registered, you reference these buffers by their\nindex in your SQEs. The kernel now has direct, pinned access to this memory. This eliminates the need for repeated mapping or copying for each I/O operation. Data can flow directly between your hardware (disk, NIC) and your registered user memory without CPU intervention",
            "Submission Queue Polling (SQPOLL): The ‚ÄúZero System Call‚Äù Mode: For the absolute highest throughput, io_uring offers an optional SQPOLL mode. Submission Queue Polling (SQPOLL): The ‚ÄúZero System Call‚Äù Mode: For the absolute highest throughput,\nio_uring offers an optional SQPOLL mode. A kernel thread continuously polls the SQ for new entries. In this mode, if you have a steady stream of I/O, your application might not need to make any system calls to submit new requests ‚Äì just manipulate the shared ring buffers directly! True Zero-Copy: Pinning Memory for Direct Hardware Access",
            " * Completion Queue (CQ): The kernel writes the results of completed I/O operations (called CQEs ‚Äî Completion ",
            "l\nThe magic of\nio_uring lies in its name: two circular \"ring buffers\" shared directly between user space and kernel space. * Submission Queue (SQ): Your application writes I/O requests (called SQEs ‚Äî Submission",
            "Zero-Copy Receive (ZC Rx): This feature aims to deliver incoming packet data directly into user-space memory, eliminating kernel-to-user copies on the receive path.",
            "* IORING_OP_SEND_ZC (Zero-Copy Send): This allows truly asynchronous, zero-copy network sends. Combined with registered buffers, data can be transmitted directly from user memory to the NIC without any intermediate CPU copies.",
            "io_uring extends its zero-copy magic to networking with explicit operations:",
            "Zero-Copy Networking with\nIORING_OP_RECV_ZC and\nIORING_OP_SEND_ZC",
            "io_uring_register_buffers() : Pinning Your Memory: You can register pre-allocated user-space memory buffers (e.g., from\nmalloc or\nmmap ) with the kernel. The kernel \"pins\" these memory pages, preventing them from being swapped out, and establishes a fixed mapping. * Using Fixed Buffers (\nIORING_OP_READ_FIXED ,\nIORING_OP_WRITE_FIXED ): Once registered, you reference these buffers by their\nindex in your SQEs. The kernel now has direct, pinned access to this memory. This eliminates the need for repeated mapping or copying for each I/O operation. Data can flow directly between your hardware (disk, NIC) and your registered user memory without CPU intervention"
          ]
        },
        {
          "title": "Kafka EOS / KIP-447 (Producer scalability for exactly once semantics)",
          "url": "https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics",
          "excerpts": [
            "This is what Kafka Streams does today.",
            "To preserve the static partition mapping in a consumer group where assignments are frequently changing, the simplest solution is to create a separate producer for every input partition.",
            "Every transactional id must map to a consistent set of input partitions.",
            "For transactional producers, assignments are assumed to be static.",
            "In a consumer group, ownership of partitions can transfer between group members through the rebalance protocol.",
            "The problem we are trying to solve in this proposal is a semantic mismatch between consumers in a group and transactional producers.",
            "This is the point of the¬†`initTransactions()`¬†API.",
            "We can also guarantee that upon initialization, any transactions which were still in progress are completed before we begin processing.",
            "Zombie producers are fenced by an epoch which is associated with each transactional Id.",
            "Essentially this allows us to guarantee that for a given transactional Id, there can only be one producer instance that is active and permitted to make progress at any time.",
            "In Kafka EOS, we use the concept of a \"transactional Id\" in order to preserve exactly once processing guarantees across process failures and restarts.",
            "This can be used in the context of stream processing frameworks, such as Kafka Streams, to ensure exactly once processing between topics.",
            "Producers can write to multiple partitions atomically so that either all writes succeed or all writes fail.",
            "Exactly once semantics (EOS) provides transactional message processing guarantees."
          ]
        },
        {
          "title": "Deep dive into Apache Kafka storage internals: segments, rolling and retention",
          "url": "https://strimzi.io/blog/2021/12/17/kafka-segment-retention/",
          "excerpts": [
            "When managing your records, an important aspect is how long they‚Äôre retained before they‚Äôre deleted. This is configurable in terms of size and duration. You can specify the maximum number of bytes to retain by using the `log.retention.bytes` parameter. If you want to set a retention period, you can use the `log.retention.ms`, `log.retention.minutes`, or `log.retention.hours` (7 days by default) parameters.",
            "At the same time, the index reached 192 bytes in size, so actually having 192 / 8 = 24 entries and not the expected 37.",
            "From the example, a new segment was rolled when the active one was still 7314 byes, not reaching the configured 16384 bytes.",
            "When the active segment becomes full it is ***rolled***, which means it is closed and re-opened in read-only",
            "A partition only has one active segment.",
            "When records are deleted on disk or a consumer starts to consume from a specific offset, a big, unsegmented file is slower and more error prone.",
            "Kafka behaves as a commit-log when it comes to dealing with storing records. Records are appended at the end of each log one after the other and each log is also split in segments.",
            "A partition is further split into segments, which are the actual files on the disk.",
            "An Apache Kafka topic is split into partitions where records are appended to."
          ]
        },
        {
          "title": "io_uring ZC",
          "url": "https://netdevconf.info/0x18/docs/netdev-0x18-paper36-talk-slides/io_uring%20ZC%20-%20NetDevConf%202024.pdf",
          "excerpts": [
            "Reset / reload single queue for page-pool changes. 2. Reset / reload for AF_XDP ? 3. Use the queue-by-queue reset model for all config changes."
          ]
        },
        {
          "title": "What is the algorithm of buffer select in the buffer ring? #1022 - GitHub",
          "url": "https://github.com/axboe/liburing/discussions/1022",
          "excerpts": [
            "When we've added buffers and submitted them to the kernel and then request a read using IOSQE_BUFFER_SELECT, what is the algorithm that ..."
          ]
        },
        {
          "title": "In io_uring, what is the difference between ... - Reddit",
          "url": "https://www.reddit.com/r/C_Programming/comments/172u5ep/in_io_uring_what_is_the_difference_between_ioring/",
          "excerpts": [
            "SQ poll creates an additional async thread to perform submission queue polling. This allows submitting I/O requests without context switching ..."
          ]
        },
        {
          "title": "How Redpanda's cloud-first storage model reduces TCO",
          "url": "https://www.redpanda.com/blog/cloud-native-streaming-data-lower-cost",
          "excerpts": [
            "Redpanda's cloud-first storage model reduces the total cost of ownership (TCO) for streaming data by simplifying deployment, improving performance, and ..."
          ]
        },
        {
          "title": "Durability and Redo Logging",
          "url": "https://justinjaffray.com/durability-and-redo-logging/",
          "excerpts": [
            "Jan 24, 2022 ‚Äî The design is roughly based off of RocksDB and Pebble, but simplified because we're going to sacrifice some concurrency by not using a lock-¬†..."
          ]
        },
        {
          "title": "Blog | Redpanda",
          "url": "https://www.redpanda.com/blog",
          "excerpts": [
            "Read through the Redpanda blog to discover all there is to know about data streaming, leveraging serverless, cloud clusters, real-time data, ..."
          ]
        },
        {
          "title": "Nats Jetstream Exactly Once Delivery",
          "url": "https://stackoverflow.com/questions/72814502/nats-jetstream-exactly-once-delivery",
          "excerpts": [
            "I want to implement an exactly once delivery system with Nats Jetstream. Documentation says that Jetstream has this option, but there is no samples or details¬†..."
          ]
        },
        {
          "title": "Idempotent Consumers | Medium",
          "url": "https://tugrulbayrak.medium.com/idempotent-consumers-b8629fd361d2",
          "excerpts": [
            "Today we will talk about idempotent consumers. The idempotent consumer pattern is used to filter out duplicate messages."
          ]
        },
        {
          "title": "Testing Producer Deduplication in Apache Kafka and ...",
          "url": "https://jack-vanlightly.com/blog/2018/10/25/testing-producer-deduplication-in-apache-kafka-and-apache-pulsar",
          "excerpts": [
            "Nov 2, 2018 ‚Äî In this post we'll focus solely on producer side duplication, looking at how the deduplication feature works in Apache Pulsar and Apache Kafka."
          ]
        },
        {
          "title": "JetStream Model Deep Dive - NATS Docs",
          "url": "https://docs.nats.io/using-nats/developer/develop_jetstream/model_deep_dive",
          "excerpts": [
            "Jun 28, 2024 ‚Äî JetStream supports Exactly Once publication and consumption by combining Message Deduplication and double acks. On the publishing side you can¬†..."
          ]
        },
        {
          "title": "Messaging - Apache Pulsar",
          "url": "https://pulsar.apache.org/docs/next/concepts-messaging/",
          "excerpts": [
            "You can read the design of Message Deduplication in PIP-6. Producer idempotency‚Äã. The other available approach to message deduplication is producer idempotency¬†..."
          ]
        },
        {
          "title": "Infinite message deduplication in JetStream",
          "url": "https://nats.io/blog/new-per-subject-discard-policy/",
          "excerpts": [
            "Nov 14, 2022 ‚Äî This new feature of JetStream enables is the ability to have exactly-once publication through deduplication using BYOID over the entire stream."
          ]
        },
        {
          "title": "Kafka is dead, long live Kafka",
          "url": "https://news.ycombinator.com/item?id=37036291",
          "excerpts": [
            "Aug 7, 2023 ‚Äî Kafka is a closer to a persistent WAL than a message queue. If your work doesn't need a WAL, it's almost certainly overkill and you will hate it¬†..."
          ]
        },
        {
          "title": "Write Ahead Log (WAL) ¬∑ facebook/rocksdb Wiki",
          "url": "https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log-(WAL)",
          "excerpts": [
            "Write ahead logs can be used to completely recover the data in the memtable, which is necessary to restore the database to the original state."
          ]
        },
        {
          "title": "Write Ahead Log File Format ¬∑ facebook/rocksdb Wiki",
          "url": "https://github.com/facebook/rocksdb/wiki/Write-Ahead-Log-File-Format",
          "excerpts": [
            "WAL files are generated with increasing sequence number in the WAL directory. In order to reconstruct the state of the database, these files are ..."
          ]
        },
        {
          "title": "polling mode using liburing example ¬∑ Issue #385 - GitHub",
          "url": "https://github.com/axboe/liburing/issues/385",
          "excerpts": [
            "SQPOLL, enabled by setting IORING_SETUP_SQPOLL when creating the ring. This creates a thread that runs in kernel space, and the thread polls ..."
          ]
        },
        {
          "title": "io_uring: defer task work to when it is needed",
          "url": "https://lwn.net/Articles/906470/",
          "excerpts": [
            "Aug 30, 2022 ‚Äî This series adds an option to defer async work until user space calls io_uring_enter with the GETEVENTS flag."
          ]
        },
        {
          "title": "Submission Queue Polling - io_uring - Unixism",
          "url": "https://unixism.net/loti/tutorial/sq_poll.html",
          "excerpts": [
            "io_uring lets you submit I/O requests without you having to make a single system call. This is done via a special submission queue polling feature that io_¬†...",
            "io_uring lets you submit I/O requests without you having to make a single system call. This is done via a special submission queue polling feature that io_ ..."
          ]
        },
        {
          "title": "io_uring.pdf",
          "url": "https://kernel.dk/io_uring.pdf",
          "excerpts": [
            "This article is intended to serve as an introduction to the newest Linux IO interface, io_uring, and compare it to the existing offerings.",
            "As long as the application keeps driving IO, IORING \\_ SQ \\_ NEED \\_ WAKEUP will never be set, and we can effectively perform\n\nIO without performing a single sy"
          ]
        },
        {
          "title": "Kafka Exactly Once Semantics - Hevodata (source: https://hevodata.com/blog/kafka-exactly-once-semantics/)",
          "url": "https://hevodata.com/blog/kafka-exactly-once-semantics/",
          "excerpts": [
            "The Idempotent producer ensures Exactly Once Semantics message delivery per partition. To do so in multiple partitions, Kafka guarantees atomic transactions, which powers the applications to produce multiple TopicPartitions atomically.",
            "Ensuring Atomic Transactions with Apache Kafka Exactly Once Semantics",
            "Three different Message Delivery Guarantee types are supported by Kafka. * At most Once: Every message in Kafka is only stored once, at most.",
            " in some cases, you may require an additional de-duplication system. Which 3 types of Message Delivery Guarantees supports by Kafka? ---------------------------------------------------------------",
            "Even though the producer retries requests on failures, each message is persisted in the log exactly once.",
            "When the producer restarts, a new PID gets assigned.",
            "When it is not the case, the producer resends the message.",
            "As the sequence number starts from zero and is monotonically increasing, a Broker will only accept the message if the sequence number of the message is exactly one greater than the last committed message from that PID/TopicPartition pair.",
            "PID and a sequence number are bundled together with the message and sent to the broker.",
            "During initialization, a unique ID gets assigned to the producer, which is called producer ID or PID.",
            "Idempotency** is the second name of Kafka Exactly Once Semantics. To stop processing a message multiple times, it must be persisted to Kafka topic only onc",
            "The Idempotent Producer"
          ]
        },
        {
          "title": "Kafka Exactly-Once Semantics (EOS) - Strimzi Blog",
          "url": "https://strimzi.io/blog/2023/05/03/kafka-transactions/",
          "excerpts": [
            "The `transactional.id` is used to uniquely identify the same logical producer across process restarts.",
            "### Considerations",
            "In addition to durability, this provides partition level message ordering and duplicates protection.",
            "To guarantee message ordering, a given producer can have at most one ongoing transaction (they are executed serially).",
            "This limitation was hugely inefficient, because an application instance couldn‚Äôt reuse a single thread-safe producer instance, but had to create one for each input partition.",
            "The support for EOS was recently extended to source connectors in Kafka Connect, which enables configuration-driven and fully transactional streaming pipelines ([KIP-618](https://cwiki.apache.org/confluence/display/KAFKA/KIP-618%3A+Exactly-Once+Support+for+Source+Connectors)).",
            "Whenever a new batch arrives, the broker checks if the received sequence number is equal to the last-appended batch‚Äôs sequence number plus one, then the batch is acknowledged, otherwise it is rejected.",
            "> Before Kafka 2.6 the `transactional.id` had to be a static encoding of the input partitions in order to avoid ownership transfer between application instances during rebalances, that would invalidate the fencing logic.",
            "the broker registers a producer id (PID) for every new producer instance. A sequence number is assigned to each record when the batch is first added to a produce request and never changed, even if the batch is resent.",
            "Each producer must configure its own static and unique [`transactional.id`](https://kafka.apache.org/documentation/.id). The `transactional.id` is used to uniquely identify the same logical producer across process restarts.",
            "Since Kafka 3.0, the producer enables the stronger delivery guarantees by default (`acks=all`, `enable.idempotence=true`).",
            "* **exactly-once**: even if the producer retries sending a message, it is written exactly once (idempotency)",
            "One of the key features of Kafka is the support for transactions, which provides exactly-once semantics (EOS) and is available since Kafka 0.11 ([KIP-98](https://cwiki.apache.org/confluence/display/KAFKA/KIP-98+-+Exactly+Once+Delivery+and+Transactional+Messaging)).",
            "Apache Kafka is a distributed streaming platform that allows efficient and reliable processing of messages. It is widely used in various industries for data streaming applications, such as processing real-time data, event sourcing, and microservices integration.",
            "In this post you will learn how EOS works in Kafka, which are the main components that are involved in a transaction lifetime and their requirements. Depending on the configuration and application logic, you can have three different delivery semantics:"
          ]
        },
        {
          "title": "Confluent Blog ‚Äî Exactly-once semantics are possible: Here's how Apache Kafka does it",
          "url": "https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/",
          "excerpts": [
            "For 1 KB messages and transactions lasting 100 ms, the producer throughput declines only by 3%, compared to the throughput of a producer configured for at least once, in-order delivery (acks=all, max.in.flight.requests.per.connection=1), and by 20% compared to the throughput of a producer configured for most once delivery with no ordering guarantees (acks=1, max.in.flight.requests.per.connec",
            "To turn on this feature and get exactly-once semantics per partition‚Äîmeaning no duplicates, no data loss, and in-order semantics‚Äîconfigure your producer to set ‚Äúenable.idempotence=true‚Äù.",
            "In this post, I'd like to tell you what Kafka's exactly-once semantics mean, why it is a hard problem, and how the new idempotence and transaction features in ...",
            "Exactly-once semantics: even if a producer retries sending a message, it leads to the message being delivered exactly once to the end consumer."
          ]
        },
        {
          "title": "io_uring Linux Man Page (Key IO Techniques Relevant to Slytherin Recovery Semantics)",
          "url": "https://man7.org/linux/man-pages/man7/io_uring.7.html",
          "excerpts": [
            "io_uring is Linux-specific.",
            " This arrangement allows for efficient I/O,\n       while avoiding the overhead of copying buffers between them, where\n ",
            "io_uring\n       gets its name from ring buffers which are shared between user\n       space and",
            "       io_uring is a Linux-specific API for asynchronous I/O. It allows\n       the user to submit one or more I/O requests, which are processed\n       asynchronously without blocking",
            "several requests in one go, simply by queueing\n       up multiple SQEs, each describing an I/O operation you want and\n       make a single call to io_uring_enter(2).",
            " This is possible due to\n       io_uring's shared buffers based",
            "With SQ Polling, io_uring starts a kernel thread that polls the submission queue for any I/O requests you submit by adding SQEs."
          ]
        },
        {
          "title": "io_uring_setup(2) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man2/io_uring_setup.2.html",
          "excerpts": [
            "IORING_SETUP_SINGLE_ISSUER A hint to the kernel that only a single task (or thread) will submit requests, which is used for internal optimisations. The¬†...",
            "IORING_SETUP_DEFER_TASKRUN By default, io_uring will process all outstanding work at the end of any system call or thread interrupt. This can delay the¬†...",
            "Hybrid io polling is a feature based on iopoll, it differs from strict polling in that it will delay a bit before doing completion side polling, to avoid ..."
          ]
        },
        {
          "title": "Per-iovec zero-copy and fixed buffer settings for writev/sendmsg",
          "url": "https://github.com/axboe/liburing/issues/1191",
          "excerpts": [
            "Enabling zero-copy for all sends (i.e. switching to io_uring_prep_sendmsg_zc() ) provides a great performance improvement on those workloads."
          ]
        },
        {
          "title": "io_uring and networking in 2023 ¬∑ axboe/liburing Wiki",
          "url": "https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023",
          "excerpts": [
            "This allows the kernel to pick a suitable buffer when the given receive operation is ready to actually receive data, rather than upfront.",
            "The application sets aside a pool of buffers, and informs io_uring of those buffers.",
            "One of the key benefits of io_uring is that multiple actions can be completed in a single system call.",
            "io_uring is applicable to both storage and networking applications.",
            "Feb 15, 2023 ‚Äî Instead, io_uring supports a mechanism called provided buffers. The application sets aside a pool of buffers, and informs io_uring of those¬†..."
          ]
        },
        {
          "title": "Io_uring is not (only) a generic asynchronous syscall facility",
          "url": "https://news.ycombinator.com/item?id=27684608",
          "excerpts": [
            "Jun 30, 2021 ‚Äî io_uring is more than a generic asynchronous syscall facility. It's the state-of-the-art asynchronous interface for communication between subsystems."
          ]
        },
        {
          "title": "How to pick a Kafka transaction.id - Stack Overflow",
          "url": "https://stackoverflow.com/questions/50335227/how-to-pick-a-kafka-transaction-id",
          "excerpts": [
            "The transactional.id property of each producer is transactionIdPrefix + n, where n starts with 0 and is incremented for each new producer.",
            "The use of transactional.id enables the 'fencing' that the original blog refers to. As part of the reassignment, the new producer will act ..."
          ]
        },
        {
          "title": "Kafka Transactional Support: How It Enables Exactly-Once ...",
          "url": "https://developer.confluent.io/courses/architecture/transactions/",
          "excerpts": [
            "Then it will read the input but before it writes to output topic, it will send to the coordinator, the set of partitions that it needs to add data into.",
            "When the application is started, it requests a producer ID from the transaction coordinator.",
            "if you see now that the consumer is trying to read this output topic, it actually will ignore this debit event because it's marked as aborted and it shouldn't be exposed to the application.",
            "Once this is done, the transaction coordinator will bump up the epoch for this producer ID. This will be used to fence off the old instance of this application.",
            "So in case this application didn't really die completely and mysteriously comes back, it cannot do any more writes for the new transaction because it will notice that its epoch is too old as compared with the latest epoch associated with this application."
          ]
        },
        {
          "title": "Demystifying Kafka Exactly Once Semantics (EOS)",
          "url": "https://engineering.hellofresh.com/demystifying-kafka-exactly-once-semantics-eos-390ae1c32bba",
          "excerpts": [
            "Mar 5, 2024 ‚Äî This semantic is quite useful for Kafka stream applications. Kafka Exactly Once Processing works only when input and output are both inside the same Kafka¬†..."
          ]
        },
        {
          "title": "Transactions in Apache Kafka | Confluent",
          "url": "https://www.confluent.io/blog/transactions-apache-kafka/",
          "excerpts": [
            "Nov 17, 2017 ‚Äî The epoch is an internal piece of metadata stored for every transactional.id. Once the epoch is bumped, any producers with same transactional.¬†...",
            "At this point, the coordinator closes any pending transactions with that transactional.id and bumps the epoch to fence out zombies. This happens ..."
          ]
        },
        {
          "title": "Understanding Kafka Producer Part 2",
          "url": "https://www.automq.com/blog/understanding-kafka-producer-part-2",
          "excerpts": [
            "Feb 17, 2025 ‚Äî For Producers with transactional capabilities (configured with \"transactional.id\"), the Producer Epoch is also assigned by the Broker. This¬†..."
          ]
        },
        {
          "title": "Extending Kafka's Exactly-Once Semantics to External ...",
          "url": "https://medium.com/@raviatadobe/extending-kafkas-exactly-once-semantics-to-external-systems-c395267935bd",
          "excerpts": [
            "Kafka provides powerful exactly-once semantics (EOS) within its own ecosystem, but achieving the same guarantees when interacting with external systems."
          ]
        },
        {
          "title": "Kafka 4.0 Documentation",
          "url": "https://kafka.apache.org/documentation/",
          "excerpts": [
            "Log Aggregation Kafka abstracts away the details of files and gives a cleaner abstraction of log or event data as a stream of messages. This allows for lower- ...",
            "Kafka is a distributed system consisting of servers and clients that communicate via a high-performance TCP network protocol."
          ]
        },
        {
          "title": "Zero-copy network transmission with io_uring",
          "url": "https://lwn.net/Articles/879724/",
          "excerpts": [
            "An application doing zero-copy networking with io_uring will start by registering at least one completion context, using the IORING_REGISTER_TX_CTX ...",
            "It all adds up to\na significantly faster way for I/O-intensive applications to work.",
            "Io\\_uring also\nimplements the concept of \"fixed\" buffers and files; these are held open,\nmapped, and ready for I/O within the kernel, saving the setup and teardown\noverhead that is otherwise incurred by every operation",
            "A suitably busy process that keeps the submission\nring full can perform an indefinite number of operations without needing to\nmake any system calls, which clearly improves performance.",
            "User\nspace sets up a pair of circular buffers shared with the kernel; the first\nbuffer is used to\nsubmit operations to the kernel, while the second receives the results when\noperations complete.",
            "As a reminder: io\\_uring is a relatively new API for asynchronous I/O (and\nrelated operations); it was first merged less than three years ago",
            "This patch set from Pavel Begunkov, now in its second revision, looks to be significantly faster than the MSG_ZEROCOPY option supported by current kernels. T",
            "The cost of copying data to be transmitted\nfrom user space into the kernel can be especially painful; it adds latency,\ntakes\nvaluable CPU time, and can be hard on cache performance.",
            "This patch set from Pavel Begunkov, now in its second revision, looks to be significantly faster than the MSG_ZEROCOPY option supported by current kernels.",
            "> io_uring's zero-copy operations can perform more than 200% better than MSG_ZEROCOPY. The maximum speedup posted was 2.27x which is 127% more than MSG_ZEROCOPY ..."
          ]
        },
        {
          "title": "io_uring basics: Writing a file to disk",
          "url": "https://notes.eatonphil.com/2023-10-19-write-file-to-disk-with-io_uring.html",
          "excerpts": [
            "Oct 19, 2023 ‚Äî io_uring is one of Linux's more powerful asynchronous IO offerings. Unlike epoll, you can use io_uring with both files and network connections."
          ]
        },
        {
          "title": "io_uring: Linux's Asynchronous I/O Framework",
          "url": "https://medium.com/@kyodo-tech/io-uring-linuxs-asynchronous-i-o-framework-047d5b1a9944",
          "excerpts": [
            "Polling for Ultra-Low Latency: Kernel-side polling (SQPOLL) eliminates interrupt delays for storage and networking devices."
          ]
        },
        {
          "title": "io_uring_prep_provide_buffers(3) - Linux manual page",
          "url": "https://man7.org/linux/man-pages/man3/io_uring_prep_provide_buffers.3.html",
          "excerpts": [
            "This is done by filling in the SQE buf_group field and setting IOSQE_BUFFER_SELECT in the SQE flags member. If buffer selection is used for a request, no buffer ...",
            "This function sets up a request to provide buffers to the io_uring context that can be used by read or receive operations."
          ]
        },
        {
          "title": "ARINC-653 Schedule Generator (STTT 2021) - Han et al.",
          "url": "https://vbn.aau.dk/files/408754762/2021_STTT_Nyman.pdf",
          "excerpts": [
            "by P Han ¬∑ 2021 ¬∑ Cited by 11 ‚Äî An ARINC-653 partitioned scheduling sys- tem is modeled as a set of timed automata (TA) in the model checker Uppaal. The optimizer tentatively assigns parameter¬†...",
            "1: SCHED :=true",
            "major time frame M",
            "Partition schedule S = {‚ü®Pt, ot, dt‚ü©|t = 1, 2, . . . , w}",
            "Output: ARINC-653 Partition Scheduling Table S",
            "Input:\nPartition scheduling parameters {‚ü®pi, bi‚ü©|i = 1, 2, . . . , n}",
            "Algorithm 1 presents the generation process of an\nARINC-653 partition schedul",
            "The design of\nthe offline scheduling algorithm should prevent a low-\ncriticality application from affecting high-criticality ap-\nplicatio"
          ]
        },
        {
          "title": "seL4 MCS pre-release (9.0.0-mcs)",
          "url": "https://docs.sel4.systems/releases/sel4/9.0.0-mcs.html",
          "excerpts": [
            "This branch adds scheduling contexts to seL4, which represent CPU time (as budget/period). Scheduling contexts are separate from threads (although threads ..."
          ]
        },
        {
          "title": "ecprice ‚Ä∫ Public ‚Ä∫ wordlist.ranked - MIT",
          "url": "https://web.mit.edu/~ecprice/Public/wordlist.ranked",
          "excerpts": [
            "... debt keywords medium television interested core break dance min sets wood purposes msn itself throughout defined papers playing awards fee studio reader ..."
          ]
        },
        {
          "title": "Extended User Interrupts (xUI): Fast and Flexible Notification ...",
          "url": "https://mktrm.github.io/files/xui-asplos25.pdf",
          "excerpts": [
            "by B Aydogmus ¬∑ 2025 ¬∑ Cited by 3 ‚Äî Instead, it offers a low-level primitive that user-level runtimes can use to implement software timers for tasks like preemption, periodic¬†..."
          ]
        },
        {
          "title": "words (text) - Stanford NLP Group",
          "url": "https://nlp.stanford.edu/~lmthang/morphoNLM/cwCsmRNN.words",
          "excerpts": [
            "... core corea cored corel coreligionists corell corelli corellia corellian ... loans loans-for-kickbacks loansharking loanword loanwords loath loathe ..."
          ]
        },
        {
          "title": "Draconis: Network-Accelerated Scheduling for Microsecond ...",
          "url": "https://sreeharshau.github.io/papers/Draconis_EuroSys24.pdf",
          "excerpts": [
            "by S Udayashankar ¬∑ 2024 ¬∑ Cited by 3 ‚Äî 2.2 Network-Accelerated Scheduling. R2P2 [17] and RackSched [12] explored using programmable switches to accelerate scheduling for a cluster of workers. Each¬†..."
          ]
        },
        {
          "title": "Towards Optimal Rack-scale ¬µs-level CPU Scheduling through ...",
          "url": "https://snowzjx.me/assets/pallas-atc25.pdf",
          "excerpts": [
            "RackSched continues to process a mixture of short and long requests, necessitating the use of complex algorithm (DARC) for ongoing workload monitoring and¬†..."
          ]
        },
        {
          "title": "Towards Optimal Rack-scale Œºs-level CPU Scheduling ...",
          "url": "https://www.usenix.org/system/files/atc25-liao.pdf",
          "excerpts": [
            "This paper presents Pallas, an application-aware rack-scale CPU scheduling solution for microsecond-level services with near-optimal performance ...",
            "by X Liao ‚Äî 2RackSched uses Shinjuku (TS) with a 250¬µs preemption time slice by default. After adjustments, a 50¬µs time slice yielded satisfactory¬†..."
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency- ...",
          "url": "https://amyousterhout.com/talks/nsdi_2019.pdf",
          "excerpts": [
            "‚Ä¢ IOKernel: steers packets in software and allocates cores. ‚Äì Core reallocations take ~5 Œºs. ‚Ä¢ Cache-aware core selection algorithm. ‚Ä¢ Load balancing of packet¬†..."
          ]
        },
        {
          "title": "Caladan: Mitigating Interference at Microsecond Timescales",
          "url": "https://dl.acm.org/doi/pdf/10.5555/3488766.3488782",
          "excerpts": [
            "by J Fried ¬∑ 2020 ¬∑ Cited by 251 ‚Äî Before preempting a task or idling a core, KSCHED delivers a signal to the runtime to give it a few microseconds to yield cleanly, saving the¬†..."
          ]
        },
        {
          "title": "[PDF] Caladan: Mitigating Interference at Microsecond Timescales",
          "url": "https://joshfried.io/assets/caladan_osdi20_slides.pdf",
          "excerpts": [
            "1. How does Caladan compare to state-of-the-art systems? 2. Are Caladan's benefits generalizable to many tasks sharing a server?"
          ]
        },
        {
          "title": "Caladan OSdi20: A high-performance CPU scheduler for microsecond-scale core allocations (USENIX, 2020)",
          "url": "https://amyousterhout.com/papers/caladan_osdi20.pdf",
          "excerpts": [
            " KSCHED leverages the multicast capability\n\nof the interrupt controller to send multiple IPIs at once, sig-\n\nnificantly amortizing costs. To facilitate ",
            "Caladan relies exclu-\n\nsively on core allocation to manage interferen",
            "Shenango uses queueing delay as its\n\nonly control signal to manage changes in load; Caladan uses\n\nmultiple control signals to manage several types of interfer-\n\nence as well as changes in loa",
            "Caladan is derived from the open-source release of\n\nShenango [ 61 ], but we implemented a completely new sched-\n\nuler and the KSCHED kernel module, which are 3,524 LOC\n\nand 533 LOC, respecti",
            "KSCHED performs scheduling functions across\n\nmany cores at once in a matter of microseconds, even in the\n\npresence of interferenc",
            "In this exper-\n\niment, Caladan performs up to 560,000 core reallocations\n\nper second at its peak (at a load of 0.65 million R"
          ]
        },
        {
          "title": "SLO-Aware Scheduling for Large Language Model ...",
          "url": "https://arxiv.org/html/2504.14966v2",
          "excerpts": [
            "Jun 12, 2025 ‚Äî To achieve high throughput and low latency, numerous inference serving systems provides request scheduling and batching techniques."
          ]
        },
        {
          "title": "[PDF] Model Based Design of Super Schedulers Managing Catastrophic ...",
          "url": "https://arxiv.org/pdf/1407.5404",
          "excerpts": [
            "The Rate Monotonic. (RM) scheduling algorithm is one of the most widely studied and used in practice [12, 14, 15, 16, 18]. It is a uniprocessor static-priority ..."
          ]
        },
        {
          "title": "[PDF] Schedulability Test for Soft Real-Time Systems under Multi - arXiv",
          "url": "https://arxiv.org/pdf/1205.0124",
          "excerpts": [
            "This paper deals with the study of Earliest Deadline First (EDF) which is an optimal scheduling algorithm for uniprocessor real time systems use for scheduling ..."
          ]
        },
        {
          "title": "SLO-Aware Scheduling for Large Language Model ...",
          "url": "https://arxiv.org/abs/2504.14966",
          "excerpts": [
            "by J Huang ¬∑ 2025 ‚Äî This paper analyzes scenarios to process tasks with varying SLOs, and introduces a simulated annealing-based scheduler to decide request priority sequence."
          ]
        },
        {
          "title": "[PDF] Design and Evaluation of a Feedback Control EDF Scheduling ...",
          "url": "https://www.cse.wustl.edu/~lu/papers/rtss99.pdf",
          "excerpts": [
            "The requirements of an ideal soft real-time scheduling algorithm should be to (1) provide. (soft) performance guarantees to admitted tasks, i.e., maintain low ..."
          ]
        },
        {
          "title": "Utilization Bounds for EDF Scheduling on Real-Time Multiprocessor ...",
          "url": "https://link.springer.com/article/10.1023/B:TIME.0000033378.56741.14",
          "excerpts": [
            "The utilization bound for earliest deadline first (EDF) scheduling is extended from uniprocessors to homogeneous multiprocessor systems with partitioning ..."
          ]
        },
        {
          "title": "[PDF] Rate Monotonic Analysis for Real-Time Systems: Instructor's Guide",
          "url": "https://www.sei.cmu.edu/documents/1565/1994_011_001_16241.pdf",
          "excerpts": [
            "For example, unlike time-sharing systems in which fairness among clients is favored, RMA focuses on guaranteeing that critical deadlines will always be met, ..."
          ]
        },
        {
          "title": "[PDF] RackSched: A Microsecond-Scale Scheduler for Rack-Scale ...",
          "url": "https://www.semanticscholar.org/paper/RackSched%3A-A-Microsecond-Scale-Scheduler-for-Zhu-Kaffes/34865005160204c7cde635aab897c90f7f67dca4",
          "excerpts": [
            "This work presents RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer to an ..."
          ]
        },
        {
          "title": "[PDF] RackSched: A Microsecond-Scale Scheduler for Rack ... - USENIX",
          "url": "https://www.usenix.org/sites/default/files/conference/protected-files/osdi20_slides_zhu.pdf",
          "excerpts": [
            "RackSched improves the throughput further by up to 1.44X. 25. Page 26. Does RackSched scale? ‚û¢ RackSched scales out the throughput near linearly. ‚û¢ The¬†...",
            "‚û¢How to process/schedule requests based on the server loads? ‚û¢How to ensure request affinity? ‚û¢How to handle practical scheduling requirements? 13.",
            "Does RackSched scale? ‚û¢ RackSched scales out the throughput near linearly. ‚û¢ The throughput is increased without increasing the tail latency. 26 ..."
          ]
        },
        {
          "title": "Efficient Scheduling Policies for Microsecond-Scale Tasks",
          "url": "https://amyousterhout.com/papers/scheduling_policies_nsdi22.pdf",
          "excerpts": [
            "**Factor Analysis**\n\nIn this section, we perform a factor analysis to determine the\n\nrelative performance of the load-balancing and core-allocation\n\npolicies defined in ¬ß 3\\.2 . We cannot effectively compare dif-\n\nferent policies by comparing existing systems that implement\n\nthem (e.g., Caladan vs. Arachne), because these systems differ\n\nin many aspects besides their policies (threading libraries, net-\n\n4 This is ",
            " Existing systems report slightly higher\n\ncore-allocation latencies, varying from 2.2 _¬µ_ s to reallocate an\n\nidle core or 7.4 _¬µ_ s to reallocate a busy core in Shenango [ 61 ]\n\nto 29 _¬µ_ s to reallocate a core ",
            "At a bare minimum, reallocating a core\n\nrequires an inter-processor interrupt (IPI) from the core that\n\nmakes the reallocation decision to the core that will be reallo-\n\ncated to a different application; this takes about 1993 cycles\n\nor roughly 1 _¬µ_ ",
            "Several recent research systems enable\n\nthis deployment model by allocating a set of cores to each\n\napplication and then reallocating cores across applications\n\nas load changes (e.g., IX [ 12 ], PerfISO [ 35 ], Arachne [ 67 ],\n\nShenango [ 60 ], Caladan [ 26 ], and Fred [ 40"
          ]
        },
        {
          "title": "shenango/caladan: Interference-aware CPU scheduling ...",
          "url": "https://github.com/shenango/caladan",
          "excerpts": [
            "Caladan is a system that enables servers in datacenters to simultaneously provide low tail latency and high CPU efficiency, by rapidly reallocating cores across¬†..."
          ]
        },
        {
          "title": "Shinjuku: Preemptive Scheduling for Œºs-scale Tail Latency (NSDI'19)",
          "url": "https://www.usenix.org/system/files/nsdi19-kaffes.pdf",
          "excerpts": [
            "by K Kaffes ¬∑ 2019 ¬∑ Cited by 282 ‚Äî [7] Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads. In 16th USENIX Symposium on. Networked Systems Design¬†...",
            "Shinjuku scales well with the\n\nnumber of cores available, can saturate high speed net-\n\nwork links, and is efficient even with small connection\n\nco",
            "Using RocksDB, a pop-\n\nular key-value store that also supports range queries,\n\nwe show that Shinjuku improves upon ZygOS by up to\n\n6 _._ 6 _√ó_ in terms of throughput at a given 99th percent",
            "Shinjuku matches\n\nIX ‚Äôs and ZygOS‚Äô performance for light-tailed workloads\n\nwhile it supports up to 5x larger load for heavy-tailed\n\nand multi-modal distributi",
            "wo policies. The first assumes\n\nno prior knowledge of request service times and uses\n\npreemption to select at fine granularity between FCFS or\n\nPS based on observed service times. The second policy\n\nassumes we can segregate requests with different ser-\n\nvice level objectives (SLO) in order to ensure good tail\n\nlatency for both short and long re",
            "Fast preemption enables scheduling policies that\n\nswitch between requests as often as every 5 _¬µ_ sec when\n\nne",
            "verages hardware sup-\n\nport for virtualization‚Äîspecifically posted interrupts‚Äî\n\nto achieve preemption overheads of 298 cycles in the\n\ndispatcher core and 1,212 cycles in worker cores.",
            " a single-address space\n\noperating system that implements _preemptive schedul-_\n\n_ing at the microsecond-scale_ and improves tail latency\n\nand throughput for _both light- and heavy-tailed service_\n\n_time distribution"
          ]
        },
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
          "url": "https://www.usenix.org/system/files/osdi20-zhu.pdf",
          "excerpts": [
            "We implement a RackSched pro-\n\ntotype on a cluster of commodity servers connected by a\n\nBarefoot Tofino swi",
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is satu",
            "The core of RackSched is a two-layer scheduling frame-\n\nwork that integrates inter-server scheduling in the top-of-rack\n\n(ToR) switch with intra-server scheduling in each ser",
            "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers",
            "by H Zhu ¬∑ 2020 ¬∑ Cited by 74 ‚Äî RackSched is a new solution that leverages the programmable switch as an inter-rack scheduler to optimize microsecond-scale tail latency for¬†...",
            "by H Zhu ¬∑ 2020 ¬∑ Cited by 74 ‚Äî In this paper, we present RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer¬†...",
            "In this paper, we present RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer ...",
            "RackSched\n\nis a new solution that leverages the programmable switch as\n\nan inter-rack scheduler to optimize microsecond-scale tail\n\nlatency for rack-scale compute",
            "RackSched leverages a two-layer schedul-\n\ning framework to achieve scalability and low tail laten",
            "The code of RackSched is open-source and available at\n\nhttps://github.com/netx-repo/RackSched",
            "We design a two-layer scheduling framework that inte-\n\ngrates inter-server scheduling in the ToR switch and intra-\n\nserver scheduling in each se",
            "RackSched, the first rack-level microsecond-\n\nscale scheduler that provides the abstraction of a rack-scale\n\ncomputer to an external servi",
            "RackSched works at microsecond scale\n\nand optimizes the tail latency with network-system co-design",
            "End-to-end experiments on a twelve-\n\nserver testbed show that RackSched improves the throughput\n\nby up to 1.44 √ó , and scales out the throughput near linearly,\n\nwhile maintaining the same tail latency as one server until the\n\nsystem is sat"
          ]
        },
        {
          "title": "Shenango: Achieving High CPU Efficiency for Latency-Sensitive Datacenter Workloads",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/131018/nsdi19fall-final110.pdf?sequence=2&isAllowed=y",
          "excerpts": [
            "We used open-loop Poisson processes to model packet\narrivals [69, 77]. Our experiments measure throughput\nand the 99.9th percentile tail response latency. All exper-\niments use our Rust loadgen application to generate load\nover TCP, unless stated otherwis",
            "Shenango must dedicate one core (2 hyperthreads)\nto running the IOKernel, so two fewer hyperthreads\nare available for applications; Arachne must dedicate\none hyperthread to the core arbiter.",
            "Implementation\n\nShenango‚Äôs implementation consists of the IOKernel\n(¬ß6.1), which runs as a separate, privileged process, and\nthe runtime (¬ß6.2), which users link with their appli-\ncations. Shenango is implemented in C and includes\nbindings for C++ and Rust. The IOKernel is imple-\nmented in 2,244 LOC and the runtime is implemented\nin 6,155 LOC.",
            "Inspired by ZygOS, we perform fine-grained work stealing of uthreads to reduce tail latency, which is particularly beneficial for workloads that have service ...",
            "Achieving these goals\nin a CPU-efficient way is an open problem.",
            "por AE Ousterhout ¬∑ 2019 ¬∑ Mencionado por 428 ‚Äî The result is that core reallocations complete in only 5.9 ¬µs and require less than two microseconds of. IOKernel compute time to orchestrate. These overheads.",
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango, RackSched, and related microsecond-scale scheduling work (NSDI19/OSDI20) ‚Äì NSDI/nsdi19/nsdi20 papers",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/ousterhout",
          "excerpts": [
            " Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads",
            "by A Ousterhout ¬∑ 2019 ¬∑ Cited by 428 ‚Äî Shenango achieves comparable latencies but at far greater CPU efficiency. It reallocates cores across applications at very fine granularity‚Äîevery 5 ¬µs ... Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads | USENIX",
            "by A Ousterhout ¬∑ 2019 ¬∑ Cited by 428 ‚Äî Shenango achieves comparable latencies but at far greater CPU efficiency. It reallocates cores across applications at very fine granularity‚Äîevery 5 ¬µs‚Äîenabling¬†...",
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads"
          ]
        },
        {
          "title": "Shenango NSDI'19 Paper",
          "url": "https://amyousterhout.com/papers/shenango_nsdi19.pdf",
          "excerpts": [
            "ency. It reallocates cores across appli-\n\ncations at very fine granularity‚Äîevery 5 _¬µ_ s‚Äîenabling\n\ncycles unused by latency-sensitive applications to be\n\nused productively by batch processing applications.",
            "s with (1) an efficient\n\nalgorithm that detects when applications would benefit\n\nfrom more cores, and (2) a privileged component called\n\nthe IOKernel that runs on a dedicated core, steering\n\npackets from the NIC and orchestrating core realloca-",
            "**Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads**",
            "Inspired by ZygOS, we perform fine-grained work stealing of uthreads to reduce tail latency, which is particularly beneficial for workloads that ...",
            "must dedicate enough cores for the _peak_ expected load.",
            "applications for spin-polling the network card. But this\n\napproach wastes CPU: even at modest average loads, on",
            "able solution to achieve microsecond-scale latencies is\n\nkernel-bypass networking, which dedicates CPU cores t",
            "in a CPU-efficient way is an open problem. Because\n\nof the high overheads of today‚Äôs kernels, the best avail",
            "and most applications handle loads that have high\n\nvariance over multiple timescales. Achieving these goal",
            "Datacenter applications demand microsecond-scale tail\n\nlatencies and high request rates from operating systems",
            "Shenango: Achieving High CPU Efficiency for Latency-sensitive Datacenter Workloads",
            "**February 26‚Äì28, 2019 ‚Ä¢ Boston, MA, USA**",
            "por A Ousterhout ¬∑ Mencionado por 428 ‚Äî The result is that core reallocations complete in only 5.9 ¬µs and require less than two microseconds of. IOKernel compute time to orchestrate.",
            "**16th USENIX Symposium on Networked Systems**",
            ". The result is that core reallocations complete in\n\nonly 5.9 _¬µ_ s and require less than two microseconds of\n\nIOKernel compute time to orchestrate. These overheads\n\nsupport a core allocation rate that is fast enough to\n\nboth adapt to shifts in load and quickly correct any\n\nmispredictions in our congestion detection algorithm.",
            "MIT CSAIL",
            "Amy Ousterhout, Joshua Fried, Jonathan Behrens, Adam Belay, Hari Balakrishnan",
            "ic runs in per-application _runtimes_\n\n(¬ß 5 ), which communicate with the IOKernel via shared\n\nmemory (Figure 2 ). Each runtime is untrusted and\n\nis\n\nresponsible\n\nfor\n\nproviding\n\nuseful\n\nprogramming\n\nabstractions, including threads, mutexes, condition\n\nvariables, and network sockets. Applications link with\n\nthe Shenango runtime as a library, allowing kernel-like\n\nfunctions to run within their address space"
          ]
        },
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack- ...",
          "url": "https://www.researchgate.net/publication/344639313_RackSched_A_Microsecond-Scale_Scheduler_for_Rack-Scale_Computerstechnical_report",
          "excerpts": [
            "RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers (Technical Report). October 2020 ... In USENIX OSDI, 2016. Show more ...",
            "We present RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer (i.e., a huge server with hundreds¬†..."
          ]
        },
        {
          "title": "RackSched: a microsecond-scale scheduler for rack- ...",
          "url": "https://dl.acm.org/doi/10.5555/3488766.3488835",
          "excerpts": [
            "We present RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer (i.e., a huge server with hundreds ...",
            "End-to-end experiments on a twelve-server testbed show that RackSched improves the throughput by up to 1.44√ó, and scales out the throughput near linearly, while¬†...",
            "RackSched: A microsecond-scale scheduler for rack-scale computers (technical report). In arXiv, 2020. Google Scholar. Affiliations. Download PDF ¬∑ View Table of ...",
            "We present RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer (i.e., a huge server with hundreds¬†..."
          ]
        },
        {
          "title": "Shenango",
          "url": "https://web.cs.ucdavis.edu/~araybuck/teaching/ecs289D-s25/slides/5-13_Shenango.pdf",
          "excerpts": [
            "by A Ousterhout ¬∑ Cited by 428 ‚Äî Local run-queue per kThread, plus. Go-style work-stealing. Run-to-Completion +. Cooperative Yield. Eliminates time-slice overhead and keeps tail-latency low.",
            "by A Ousterhout ¬∑ Cited by 428 ‚Äî How Many Cores Should the IOKernel Allocate? 1. Packet arrives for an application with no cores. 2. Runs Compute Congestion algorithm to see if applications¬†..."
          ]
        },
        {
          "title": "Protego: Overload Control for Applications with ...",
          "url": "https://faculty.cc.gatech.edu/~amsmti3/assets/protego-nsdi23.pdf",
          "excerpts": [
            "by I Cho ¬∑ Cited by 8 ‚Äî Furthermore, Protego extends Shenango's synchro- nization library to implement ASQM, facilitating the adoption of Protego to Shenango applications."
          ]
        },
        {
          "title": "Preemptive scheduling for ¬µsecond-scale tail latency",
          "url": "https://www.researchgate.net/publication/352538491_Shinjuku_Preemptive_scheduling_for_second-scale_tail_latency",
          "excerpts": [
            "Abstract. The recently proposed dataplanes for microsecond scale applications, such as IX and ZygOS, use non-preemptive policies to schedule requests to cores."
          ]
        },
        {
          "title": "Overcoming Scalability Bottlenecks in Shenango",
          "url": "https://dspace.mit.edu/bitstream/handle/1721.1/127342/1192475415-MIT.pdf",
          "excerpts": [
            "by JJS Fried ¬∑ 2020 ‚Äî In this thesis, I plan to present two new techniques that improve that scalability of Shenango, a recently developed research operating system¬†...",
            "by JJS Fried ¬∑ 2020 ‚Äî The Shenango design is able to drastically improve CPU efficiency over existing systems by allowing two applications to share a machine at full¬†..."
          ]
        },
        {
          "title": "shenango/shenango",
          "url": "https://github.com/shenango/shenango",
          "excerpts": [
            "Shenango is a system that enables servers in datacenters to simultaneously provide low tail latency and high CPU efficiency, by rapidly reallocating cores¬†..."
          ]
        },
        {
          "title": "Shenango",
          "url": "https://github.com/shenango",
          "excerpts": [
            "Interference-aware CPU scheduling that enables performance isolation and high CPU utilization for datacenter servers."
          ]
        },
        {
          "title": "NetX Repositories",
          "url": "https://github.com/netx-repo",
          "excerpts": [
            "RackSched Public. RackSched: A Microsecond-Scale Scheduler for Rack-Scale Computers. netx-repo/RackSched's past year of commit activity. C 22 Apache-2.0 13 0 0 ..."
          ]
        },
        {
          "title": "RackSched: A Microsecond-Scale Scheduler for Rack- ...",
          "url": "https://www.usenix.org/conference/osdi20/presentation/zhu",
          "excerpts": [
            "by H Zhu ¬∑ 2020 ¬∑ Cited by 74 ‚Äî We present RackSched, the first rack-level microsecond-scale scheduler that provides the abstraction of a rack-scale computer.",
            "t RackSched, the first rack-level microsecond-scale\nscheduler that provides the abstraction of a rack-scale\ncomputer (i.e., a huge server with hundreds to thousands of\ncores) to an external service with network-system co-design.",
            "The core of RackSched is a two-layer scheduling framework\nthat integrates inter-server scheduling in the top-of-rack\n(ToR) switch with intra-server scheduling in each server.",
            "We implement a RackSched prototype\non a cluster of commodity servers connected by a\nBarefoot Tofino switch.",
            "End-to-end experiments on a twelve-server\ntestbed show that RackSched improves the throughput\nby up to 1.44x, and scales out the throughput near linearly,\nwhile maintaining the same tail latency as one server until the\nsystem is saturated."
          ]
        },
        {
          "title": "DPDK rte_ring Peek Zero Copy APIs",
          "url": "https://doc.dpdk.org/api/rte__ring__peek__zc_8h.html",
          "excerpts": [
            "); }\n\nNote that between _start_ and _finish_ none other thread can proceed with enqueue/dequeue operation till _finish_ completes."
          ]
        },
        {
          "title": "From L3 to seL4 What Have We Learnt in 20 Years of L4 ...",
          "url": "https://sigops.org/s/conferences/sosp/2013/papers/p133-elphinstone.pdf",
          "excerpts": [
            "Overheads in those sys- tems are generally higher than in L4 with its highly op- timised IPC, but we have shown in the past that low overheads are achievable ...",
            "by K Elphinstone ¬∑ Cited by 263 ‚Äî Consequently, the L4 community tends to mea- sure IPC latencies in cycles rather than microseconds, as this better relates to the hardware limits."
          ]
        },
        {
          "title": "[dpdk-stable] [PATCH v3 1/2] ring: synchronize the load ...",
          "url": "https://mails.dpdk.org/archives/stable/2018-October/010314.html",
          "excerpts": [
            "Oct 31, 2018 ‚Äî [dpdk-stable] [PATCH v3 1/2] ring: synchronize the load and store of the tail ... cons.head, __ATOMIC_ACQUIRE); + /* this load-acquire synchronize¬†..."
          ]
        },
        {
          "title": "NSDI 2023: From SRNIC Design and RDMA for Bounded-Latency IPC (Wang et al.)",
          "url": "https://www.usenix.org/system/files/nsdi23-wang-zilong.pdf",
          "excerpts": [
            "Q is being scheduled, the\nDMA engine fetches from that SQ up to n WQEs and\nmin(burst_size,credit) bytes of messages to address Chal-\nlenge #2. After a scheduling iteration, there could be unused\nWQEs left in RNIC, if the total message size associated with\nthe n WQEs is over min(burst_size,credit) bytes. Unused\nWQEs are dropped instead of being cached in RNIC, and\nthey will be fetched again next time when its SQ is scheduled. This fetch-and-drop strategy enables us to achieve cache-free\nscheduling to address Challenge #3. There are two critical parameters (n and burst_size) to bal-\nance tradeoffs. n is the maximum number of WQEs, and\nburst_size is the maximum bytes of messages allowed to\nfetch in each scheduling iteration. n reflects the tradeoff be-\ntween PCIe bandwidth usage and PCIe latency hiding. A\nsmaller n would lead to less PCIe bandwidth waste in the\nfetch-and-drop strategy, but be harder to hide the PCIe latency\nor saturate the PCIe bandwidth with small messages, while\na larger n would perform inversely. In SRNIC, n is set to 8\nto balance the PCIe bandwidth utilization and latency hid-\ning. With this setting, the maximum message rate of a single\nQP is 8 million requests per second (Mrps) (i.e., 8 messages\nper 1 ¬µs). As for burst_size, it reflects the tradeoff between\nPCIe bandwidth utilization and scheduling granularity.",
            "n is set to 8\nto balance the PCIe bandwidth utilization and latency hid-\ning. With this setting, the maximum message rate of a single\nQP is 8 million requests per second (Mrps) (i.e., 8 messages\nper 1 ¬µs)"
          ]
        },
        {
          "title": "FastWake: Revisiting Host Network Stack for Interrupt-mode RDMA (SIGCOMM/APNet 2023)",
          "url": "https://conferences.sigcomm.org/events/apnet2023/papers/sec1-fakewake.pdf",
          "excerpts": [
            "The resulting latency is only\n0.3‚àº0.4 ùúás higher than polling mode where each thread has its dedi-\ncated cor",
            "Experiments show that with 16 threads sharing a\ncore, FastWake can reduce end-to-end RDMA latency by 65%‚àº83%\n(80% on average) on x86 and 64%‚àº78% (77% on average) on ARM\nat the cost of up to 30% higher power utilization compared to\ntraditional interrupt-mode RDMA.",
            "The latency of standard semaphore and pipe\nIPC is 3x‚àº10x of FastWake IPC.",
            "FastWake IPC greatly simplifies the IPI\ndelivery path so that the standard IPC has 3x‚àº5x latency of it.",
            "When high power consumption is not allowed, we have to stick\nwith the interrupts. Our second approach spreads NIC interrupts\nto different cores and makes use of completion vector to ensure\ninterrupt core affinity.",
            "The approach above would keep\nCPUs running at 100% utilization, so we design an interrupt-based\napproach for scenarios with power constraints.",
            "a per-core dispatcher thread to poll all the\ncompletion queues of the application threads on the same core,\nand utilize a kernel fast path to context switch to the thread with\nan incoming completion event.",
            "FastWake, a practical\nredesign of interrupt-mode RDMA host network stack using com-\nmodity RDMA hardware, Linux OS, and unmodified application"
          ]
        },
        {
          "title": "DPDK Programmer's Guide and Ring Library excerpts",
          "url": "https://fast.dpdk.org/doc/pdf-guides-18.05/prog_guide-18.05.pdf",
          "excerpts": [
            "On a NUMA system, it is preferable to access local memory since remote memory access\nis slower. In the DPDK, the memzone, ring, rte_malloc and mempool APIs provide a way to\ncreate a pool on a specific socket.",
            "The ring supports bulk and burst access, meaning that it is possible to read several elements\nfrom the ring with only one costly atomic operation (see Ring Library). Performance is greatly\nimproved when using bulk access operations.",
            "DPDK supports NUMA allowing for better performance when a processor‚Äôs logical cores\nand interfaces utilize its local memory.",
            "The ring library is based on a lockless ring-buffer algorithm that maintains its original de-\nsign for thread safety. Moreover, it provides high performance for either multi- or single-\nconsumer/producer enqueue/dequeue operatio"
          ]
        },
        {
          "title": "IPC Fastpath and L4 Microkernels",
          "url": "https://www.researchgate.net/figure/Cycle-counts-of-a-one-way-IPC-via-the-fastpath-for-a-0-length-IPC-message-between-threads_fig3_254463663",
          "excerpts": [
            "which has pushed the L4 model furthest and was the first OS kernel to undergo a complete formal verification of its implementation",
            "The common-case IPC handler in microkernels, referred to as the fastpath, is performance-critical and thus is often optimised using hand-written assembly. However, compiler technology has advanced significantly in the past decade, which suggests that we should re-evaluate this approach. We present a case study of optimising the IPC fast-path in the...",
            "Cycle counts of a one-way IPC via the fastpath for a 0-length IPC message between threads in different address spaces. Source publication"
          ]
        },
        {
          "title": "Datacenter RPCs can be general and fast",
          "url": "https://dl.acm.org/doi/10.5555/3323234.3323236",
          "excerpts": [
            "We achieve 5.5 ¬µs of replication latency on lossy Ethernet, which is faster than or comparable to specialized replication systems that use programmable switches¬†..."
          ]
        },
        {
          "title": "Good thread safe ciruclar buffer implementations? : r/cpp",
          "url": "https://www.reddit.com/r/cpp/comments/ahbxib/good_thread_safe_ciruclar_buffer_implementations/",
          "excerpts": [
            "It has the ability to support multi-stage pipelines using a single ring-buffer and also supports acquiring batches of items from the buffer with¬†..."
          ]
        },
        {
          "title": "Dissecting the Disruptor: Demystifying Memory Barriers",
          "url": "https://mechanitis.blogspot.com/2011/08/dissecting-disruptor-why-its-so-fast.html",
          "excerpts": [
            "The nice thing about the disruptor is that if you journal all the entries and their sequence numbers every time they've been written (see Martin Fowler's ..."
          ]
        },
        {
          "title": "Do modern micro kernel designs still suffer from some ...",
          "url": "https://www.reddit.com/r/osdev/comments/h0wutr/do_modern_micro_kernel_designs_still_suffer_from/",
          "excerpts": [
            "Fundamentally, any form of IPC is always going to be slower than a direction function call. Having said that, computers are always getting¬†..."
          ]
        },
        {
          "title": "Understanding Delays in AF_XDP-based Applications - arXiv",
          "url": "https://arxiv.org/html/2402.10513v1",
          "excerpts": [
            "We conduct an experimental study to understand the XDP/AF_XDP ecosystem and detect microseconds delays to better architect future latency-sensitive ..."
          ]
        },
        {
          "title": "efficient/HERD",
          "url": "https://github.com/efficient/HERD",
          "excerpts": [
            "A highly efficient key-value system for RDMA. The original paper describing HERD appeared in SIGCOMM'14. Important: This code is not maintained anymore."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/system/files/nsdi19spring_kalia_prepub.pdf",
          "excerpts": [
            "by AKM Kaminsky ¬∑ Cited by 417 ‚Äî We achieve. 5.5 ¬µs of replication latency on lossy Ethernet, which is faster than or comparable to specialized replication systems that use programmable¬†..."
          ]
        },
        {
          "title": "RDMA for Storage Ethernet: RoCE vs. iWARP Guide",
          "url": "https://intelligentvisibility.com/rdma-roce-iwarp-guide",
          "excerpts": [
            "iWARP works over standard TCP/IP networks without strict lossless requirements. * Latency: RoCEv2 generally offers lower latency in ideal, well-tuned lossless environments. iWARP's latency is typically slightly higher due to TCP overhead but may be more consistent in standard or lossy networks ."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://www.usenix.org/conference/nsdi19/presentation/kalia",
          "excerpts": [
            "by A Kalia ¬∑ 2019 ¬∑ Cited by 417 ‚Äî ... eRPC without modifying the core Raft source code. We achieve 5.5 microseconds of replication latency on lossy Ethernet, which is faster than or comparable¬†..."
          ]
        },
        {
          "title": "Microkernel lecture",
          "url": "https://pdos.csail.mit.edu/6.828/2006/lec/l-mkernel.html",
          "excerpts": [
            "L4 is a \"second-generation\" microkernel, with 7 calls: IPC (of which there are several types), id_nearest (find a thread with an ID close the given ID), fpage_¬†..."
          ]
        },
        {
          "title": "mpmc_bounded_queue.h - GitHub",
          "url": "https://github.com/couchbase/phosphor/blob/master/thirdparty/dvyukov/include/dvyukov/mpmc_bounded_queue.h",
          "excerpts": [
            "* This file contains an implementation of a MPMC queue by Dmitry Vyukov. It is. * largely the same as the original source except for: minor formatting."
          ]
        },
        {
          "title": "Notes On Concurrent Ring Buffer Queue Mechanics",
          "url": "http://psy-lob-saw.blogspot.com/2014/04/notes-on-concurrent-ring-buffer-queue.html",
          "excerpts": [
            "Bounded queues built on ring buffers must detect queue full/empty states and track head/tail positions. Ring buffers exhibit continuity of ..."
          ]
        },
        {
          "title": "[PDF] Towards `s Tail Latency and Terabit Ethernet - Qizhe Cai",
          "url": "http://www.qizhecai.com/papers/netchannel.pdf",
          "excerpts": [
            "Since io_uring does not improve per-application performance, as observed in previous experiments, we omit it in the interest of brevity. As discussed in ¬ß2.2, ..."
          ]
        },
        {
          "title": "Understanding Delays in AF_XDP-based Applications - HAL",
          "url": "https://hal.science/hal-04458274v1/file/main.pdf",
          "excerpts": [
            "by KC du Perron ¬∑ 2024 ¬∑ Cited by 4 ‚Äî latency between two servers can reach 6.5¬µs, which includes an approximate 5-10¬µs overhead due to our performance tracing technique. II.",
            "latency with AF XDP socket with the correct parameters. latency between two servers can reach 6.5¬µs , which includes an approximate 5-10¬µs overhead due to our performance tracing technique."
          ]
        },
        {
          "title": "L4-Linux Based System as a Platform for EPICS iocCore",
          "url": "https://accelconf.web.cern.ch/ica01/papers/WEBT003.pdf",
          "excerpts": [
            "by J Odagiri ‚Äî While typical latency due to non- preemptiveness is known to be several tens of milliseconds, it can reach 100 milliseconds or more in the worst case [3, 4]."
          ]
        },
        {
          "title": "Comparison of RDMA Technologies",
          "url": "https://docs.nvidia.com/networking/display/RDMAAwareProgrammingv17/Comparison+of+RDMA+Technologies",
          "excerpts": [
            "The key bene- fits that RDMA delivers accrue from the way that the RDMA messaging service is presented to the application and the underlying technologies used to transport and deliver those messages.",
            "RDMA provides Channel based IO. This channel allows an application using an RDMA device to directly read and write remote virtual memory.",
            "The messaging service can be used for Inter Process Communication (IPC), communication with remote servers and to communicate with storage devices using Upper Layer Protocols (ULPs) such as iSCSI Extensions for RDMA (ISER) and SCSI RDMA Protocol",
            "ee technologies share a common user API which is defined in this docu- ment, but have different physical and link layers.",
            "RDMA provides low latency through stack bypass and copy avoidance, reduces CPU utilization, reduces memory bandwidth bottlenecks and provides high bandwidth utilization."
          ]
        },
        {
          "title": "Purdue HERD/RDMA Overview (2014)",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/herd_2014.pdf",
          "excerpts": [
            "Verbs are usually posted to the send queue of a QP (except RECV,\nwhich is posted to the receive queue). To post a verb to the RNIC,\nan application calls into the userland RDMA driver.",
            "There are two types of verbs semantics: memory\nsemantics and channel semantics. Memory semantics: The RDMA verbs (READ and WRITE)\nhave memory semantics: they specify the remote memory address\nto operate upon. These verbs are one-sided: the responder‚Äôs CPU\nis unaware of the operation.",
            ".\nThe typical end-to-end ( 1\n\n2RTT) latency in In-\nfiniBand/RoCE is 1 ¬µs while that in modern classical Ethernet-based\nsolutions [2, 18] is 10 ¬µs.",
            "Remote Direct Memory Access (RDMA) allows one computer to\ndirectly access the memory of a remote computer without involving\nthe operating system at any host. This enables zero-copy trans-\nfers, reducing latency and CPU overhea"
          ]
        },
        {
          "title": "ArXiv: An Embedded Real-Time Aware IP Stack with Early Demultiplexing and Differentiated Flow Queues",
          "url": "https://arxiv.org/pdf/2204.08846",
          "excerpts": [
            "We propose an embedded real-time aware IP stack adaption with an early demultiplexing scheme for incoming packets and subsequent per-flow ... Therein a\ndriver controls DMA transfers, establishes cache coherency\nand passes packet buffers to a networking task by means of a\nqueue."
          ]
        },
        {
          "title": "Reddit discussion on fast MPSC queue in Rust (iceoryx2 and zero-copy IPC)",
          "url": "https://www.reddit.com/r/rust/comments/1ebm8qe/fast_mpsc_queue_in_rust/",
          "excerpts": [
            "ou. It is a service orientated lock-free, zero-copy, inter-process middleware.",
            "Since iceoryx is using bounded queues, depending on your use case, there are two ways to handle back-pressure. If you are interested only in the latest data, then you can configure it to act like a ring buffer and discard the oldest data. If you require all the data, then the producer will block if there is a slow consumer which does not take the data out of its queue.",
            "SPSC per producer-consumer pair.",
            "On the main branch we currently achieve latencies of 100ns on an AMD Ryzen 7 7840S for inter-process communication and ~90ns for process local communication."
          ]
        },
        {
          "title": "Rigtorp Ring Buffer and Zero-Copy IPC",
          "url": "https://rigtorp.se/ringbuffer/",
          "excerpts": [
            "read (`readIdx_`) and write\n(`writeIdx_`) indices are aligned to the size of a cache line (`alignas(64)`). This is done to reduce cache coherency traffic.",
            "In C++ it can be defined\nlike this:\n\n```\nstruct ringbuffer {\n  std::vector<int> data_;\n  alignas(64) std::atomic<size_t> readIdx_{0};\n  alignas(64) std::atomic<size_t> writeIdx_{0};\n\n  ringbuffer(size_t capacity) : data_(capacity, 0) {}\n}\n\n``"
          ]
        },
        {
          "title": "(PDF) An ultra-low latency and compatible PCIe ...",
          "url": "https://www.researchgate.net/publication/365882442_An_ultra-low_latency_and_compatible_PCIe_interconnect_for_rack-scale_communication",
          "excerpts": [
            "PDF | Emerging network-attached resource disaggregation architecture requires ultra-low latency rack-scale communication. However, current hardware."
          ]
        },
        {
          "title": "Datacenter RPCs can be General and Fast",
          "url": "https://engineering.purdue.edu/~vshriva/courses/papers/erpc_2019.pdf",
          "excerpts": [
            "by A Kalia ¬∑ 2019 ¬∑ Cited by 417 ‚Äî Our three-way replication latency on lossy Ethernet is 5.5 ¬µs, which is competitive with existing specialized systems that use programmable switches (NetChain [¬†..."
          ]
        },
        {
          "title": "Using RDMA Efficiently for Key-Value Services",
          "url": "https://www.cs.cmu.edu/~dga/papers/herd-sigcomm2014-readable.pdf",
          "excerpts": [
            "by AKM Kaminsky ¬∑ Cited by 674 ‚Äî This paper describes the design and implementation of HERD, a key-value system designed to make the best use of an. RDMA network. Unlike prior RDMA-based¬†...",
            "by AKM Kaminsky ¬∑ Cited by 674 ‚Äî In this paper, we present HERD, a key-value cache that leverages RDMA features to deliver low latency and high. Page 2. throughput. As we demonstrate later,¬†..."
          ]
        },
        {
          "title": "Prevention slot flow‚Äêcontrol mechanism for low latency torus ...",
          "url": "https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/iet-cdt.2013.0012",
          "excerpts": [
            "The authors propose a novel flow-control mechanism to address cost/performance constraints in torus networks and ensure deadlock freedom. They ..."
          ]
        },
        {
          "title": "Backpressure Mechanisms in Distributed Systems",
          "url": "https://systemdr.substack.com/p/backpressure-mechanisms-in-distributed",
          "excerpts": [
            "# Increase backend latency to trigger backpressure curl -X POST http ... P99 latency by 40% during traffic spikes.\" ‚Äî Marcus Rodriguez ..."
          ]
        },
        {
          "title": "Understanding Head-of-Line Blocking in Networking - JumpCloud",
          "url": "https://jumpcloud.com/it-index/what-is-head-of-line-blocking",
          "excerpts": [
            "Head-of-Line (HOL) Blocking is a bottleneck in packet-switched systems where a delayed packet at the front of a queue prevents others from being processed."
          ]
        },
        {
          "title": "Backpressure Patterns: Preventing Overload in High-Throughput ...",
          "url": "https://medium.com/@letsCodeDevelopers/backpressure-patterns-preventing-overload-in-high-throughput-microservices-b0fe80825556",
          "excerpts": [
            "Visibility into resource usage helps detect overload early. Track queue lengths, tail latencies (p95/p99), memory usage, disk I/O, and CPU."
          ]
        },
        {
          "title": "SPDK: NVMe Driver - Storage Performance Development Kit",
          "url": "https://spdk.io/doc/nvme.html",
          "excerpts": [
            "The SPDK NVMe driver provides a zero-copy data transfer path, which means that there are no data buffers for I/O commands. However, some Admin commands have ..."
          ]
        },
        {
          "title": "8. Ring Library - Documentation",
          "url": "https://doc.dpdk.org/guides-22.11/prog_guide/ring_lib.html",
          "excerpts": [
            "The ring structure is composed of two head and tail couples; one is used by producers and one is used by the consumers."
          ]
        },
        {
          "title": "6. Ring Library - Documentation",
          "url": "https://doc.dpdk.org/guides/prog_guide/ring_lib.html",
          "excerpts": [
            "It is a user responsibility to create/init ring with appropriate sync modes.",
            "PI\n\nAlong with the advantages of the peek APIs, zero copy APIs provide the ability\nto copy the data to the ring memory directly without the need for temporary\nstorage (for ex: array of mbufs on the stack). These APIs make it possible to split public enqueue/dequeue API into 3 phases:\n\n* \n  enqueue/dequeue start\n* \n  copy data to/from the ring\n* \n  enqueue/dequeue finish",
            " ## 6\\.8. Ring Peek Zero Copy API",
            "\nNote that between `_start_` and `_finish_` none other thread can proceed\nwith enqueue(/dequeue) operation till `_finish_` completes.",
            "```\n/* read 1 elem from the ring: */\nuint32_t n = rte_ring_dequeue_bulk_start ( ring , & obj , 1 , NULL );\nif ( n != 0 ) {\n    /* examine object */\n    if ( object_examine ( obj ) == KEEP )\n        /* decided to keep it in the ring. */\n        rte_ring_dequeue_finish ( ring , 0 );\n    else\n        /* decided to remove it from the ring. */\n        rte_ring_dequeue_finish ( ring , n );\n}\n```",
            "It is a user responsibility to create/init ring with appropriate sync modes",
            "eue.\nNote that this API is available only for two sync modes:\n\n* \n  Single Producer/Single Consumer (SP/SC)\n* \n  Multi-producer/Multi-consumer with Head/Tail Sync (HTS)",
            "eue.\nNote that this API is available only for two sync modes:\n\n* \n  Single Producer/Single Consumer (SP/SC)\n* \n  Multi-producer/Multi-consumer with Head/Tail Sync (HTS)",
            "\n\nThat allows user to inspect objects in the ring without removing them\nfrom it (aka MT safe peek) and reserve space for the objects in the ring\nbefore actual enqueue.",
            "\n\nFor ring with serialized producer/consumer (HTS sync mode) it is possible\nto split public enqueue/dequeue API into two phases:\n\n* \n  enqueue/dequeue start\n* \n  enqueue/dequeue finish",
            "## 6\\.7. Ring Peek AP",
            "TS\n\nMulti-producer (/multi-consumer) with Head/Tail Sync (HTS) mode. In that mode enqueue/dequeue operation is fully serialized:\nat any given moment only one enqueue/dequeue operation can proceed. This is achieved by allowing a thread to proceed with changing `head.value` only when `head.value == tail.value` . Both head and tail values are updated atomically (as one 64-bit value). To achieve that 64-bit CAS is used by head update routine. That technique also avoids the Lock-Waiter-Preemption (LWP) problem on tail\nupdate and helps to improve ring enqueue/dequeue behavior in overcommitted\nscenarios. Another advantage of fully serialized producer/consumer -\nit provides the ability to implement MT safe peek API for rte\\_ring.",
            "### 6\\.6.4. MP\\_HTS/MC\\_H",
            "The ring structure is composed of two head and tail couples; one is used by producers and one is used by the consumers. To achieve that RTS requires 2 64-bit CAS for each enqueue(/dequeue) operation:\none for head update, second for tail update. In comparison the original MP/MC algorithm requires one 32-bit CAS\nfor head update and waiting/spinning on tail value. #"
          ]
        },
        {
          "title": "Bitdrift Ring Buffer",
          "url": "https://blog.bitdrift.io/post/bitdrift-ring-buffer",
          "excerpts": [
            "The core of Capture is what we like to call the ring buffer. This post dives deep into the technical design and implementation of the ring buffer.",
            "The above diagram shows the general layout of the ring buffer. At the head of the buffer is a small control block that includes various indexes into the buffer needed for normal operation. For example: next write start, committed write start, next read start, next cursor read start, etc.",
            "the head of the buffer is a small control block that includes various indexes into the buffer needed for normal operation.",
            "\nIn order to share as much code as possible between the RAM buffer and the disk buffer, a decision was made to implement the disk buffer in terms of memory mapped files",
            "The combination of the volatile MPSC buffer and the non-volatile SPSC buffer is known as the ‚Äúaggregate‚Äù MPSC buffer.",
            "Multiple producer / multiple consumer (MPMC) : this means that there are multiple entities producing data and multiple entities consuming data.",
            "Multiple producer / single consumer (MPSC) : this means that there are multiple entities producing data and a single entity consuming data.",
            "Single producer / single consumer (SPSC) : this means that there is a single entity producing data and a single entity consuming data.",
            "For each of the above production/consumption types, ring buffers also can be concurrent or not. Concurrency is defined as whether the buffer is safe to access at the same time from multiple threads.",
            "Ring buffers are pervasive in low-level systems, both software and hardware, primarily because they do not allocate after initialization and thus have consistent performance characteristics."
          ]
        },
        {
          "title": "Scalable Machine Learning at Cloudflare",
          "url": "https://blog.cloudflare.com/scalable-machine-learning-at-cloudflare/",
          "excerpts": [
            "Previous system design for serving machine learning features over Unix socket using Gagarin. Initially, Gagarin exhibited decent latency, with a median latency around **200 microseconds** to serve all machine learning features for given keys. However, as our system evolved and we introduced more features and dimension keys, coupled with increased traffic, the cache hit ratio began to wane. The median latency had increased to **500 microseconds** and during peak times, the latency worsened significantly, with the p99 latency soaring to roughly **10 mil",
            "| Memory-Mapped Files | 0.503 | 1,908,613 |",
            "| Shared Memory | 0.598 | 1,616,014 |",
            "| Unix Signals | 2.45 | 404,844 |",
            "| Message Queue | 4.396 | 226,421 |",
            "| Pipe | 4.733 | 210,369 |",
            "| FIFOs (named pipes) | 5.432 | 183,388 |",
            "| Unix domain sockets | 5.609 | 177,573 |",
            "| TCP sockets | 8.74 | 114,143 |",
            "| eventfd (bi-directional) | 9.456 | 105,533 |",
            "| --- | --- | --- |",
            "| IPC method | Avg duration, Œºs | Avg throughput, msg/s |",
            "Based on our evaluation, we found that Unix sockets, while taking care of synchronization, were not the fastest IPC method available. The two fastest IPC mechanisms were shared memory and memory-mapped files.",
            "a.org/wiki/First_principle) design approach, we questioned: \"What is the most efficient low-level method for data transfer between two processes provided by the operating system?\" Our goal was to find a solution that would enable the direct serving of machine learning features from memory for corresponding HTTP requests."
          ]
        },
        {
          "title": "Libfabric - GitHub Pages",
          "url": "https://ofiwg.github.io/libfabric/",
          "excerpts": [
            "Libfabric, also known as Open Fabrics Interfaces (OFI), defines a communication API for high-performance parallel and distributed applications."
          ]
        },
        {
          "title": "iWARP vs RDMA over Converged Ethernet: Which is Better?",
          "url": "https://orhanergun.net/iwarp-vs-rdma-over-converged-ethernet-which-is-better",
          "excerpts": [
            "It offers superior bandwidth and lower latency compared to iWARP due to its ability to bypass the TCP stack and directly access network hardware ..."
          ]
        },
        {
          "title": "How to Choose Between InfiniBand and RoCEv2",
          "url": "https://www.fibermall.com/blog/how-to-choose-between-infiniband-and-roce.htm?srsltid=AfmBOoo_JhLLjN1A7OEibQ2uFJ_D-IIo5HVbeAPuqWQ4H4YZRtcSfICQ",
          "excerpts": [
            "RoCEv2 (RDMA over Converged Ethernet, version 2) and InfiniBand are two leading solutions, each offering unique advantages in speed, latency, and scalability."
          ]
        },
        {
          "title": "fabtests(7) - GitHub Pages",
          "url": "https://ofiwg.github.io/libfabric/v1.10.1/man/fabtests.7.html",
          "excerpts": [
            "The tests are structured based on the benchmarks provided by OSU MPI. They are not guaranteed to provide the best latency or bandwidth performance numbers a¬†..."
          ]
        },
        {
          "title": "4 Tips to Improve P99 Latency - Control Plane",
          "url": "https://controlplane.com/community-blog/post/4-tips-to-improve-p99-latency",
          "excerpts": [
            "P99 latency refers to the 99th percentile of latency measurements. It's a performance metric that indicates how long it takes to complete 99% of requests ...",
            "Missing: seL4 IPC cycles"
          ]
        },
        {
          "title": "EFA: how fixing one thing, led to an improvement for ... - AWS",
          "url": "https://aws.amazon.com/blogs/hpc/efa-how-fixing-one-thing-lead-to-an-improvement-for-everyone/",
          "excerpts": [
            "Oct 26, 2023 ‚Äî Figure 5 shows the OSU latency benchmark when running Open MPI with libfabric 1.18.1 (before using Peer API), and again with the newer libfabric¬†..."
          ]
        },
        {
          "title": "Hunting a NUMA Performance Bug",
          "url": "https://www.p99conf.io/2021/09/28/hunting-a-numa-performance-bug/",
          "excerpts": [
            "Sep 28, 2021 ‚Äî Indeed, the bad run IPC is significantly correlated with the number of used cores: it's 0.42 for 30 cores, 0.26 for 64 cores. When lowering the¬†..."
          ]
        },
        {
          "title": "Linux IPC syscall latencies benchmark in the 10s of microseconds ...",
          "url": "https://news.ycombinator.com/item?id=37040144",
          "excerpts": [
            "Linux IPC syscall latencies benchmark in the 10s of microseconds typically. SeL4 has worst case execution guarantees that are better than that, even counting ..."
          ]
        },
        {
          "title": "What is the fastest mickrokernel IPC implementation?",
          "url": "https://www.reddit.com/r/osdev/comments/rw8v7z/what_is_the_fastest_mickrokernel_ipc/",
          "excerpts": [
            "SeL4 is probably the only L4 out of the bunch that attempts to be the classic L4 fast path IPC with meltdown/spectre safety baked in (KPTI and¬†..."
          ]
        },
        {
          "title": "DPDK implementation of MPSC ring buffer",
          "url": "https://stackoverflow.com/questions/63323970/dpdk-implementation-of-mpsc-ring-buffer",
          "excerpts": [
            "The load and compare exchange of the producer's head is done using __ATOMIC_RELAXED memory ordering. Isn't this a problem when multiple¬†...See more"
          ]
        },
        {
          "title": "Minimalistic blocking bounded queue in C++ - More Stina Blog!",
          "url": "https://morestina.net/1400/minimalistic-blocking-bounded-queue-for-c",
          "excerpts": [
            "Jan 19, 2020 ‚Äî It has a small implementation, supports both blocking and non-blocking variants of enqueue and dequeue operations, and covers inserting elements by move, copy,¬†..."
          ]
        },
        {
          "title": "Bounded MPMC queue",
          "url": "https://www.1024cores.net/home/lock-free-algorithms/queues/bounded-mpmc-queue",
          "excerpts": [
            "The bounded MPMC queue is array-based, fails on overflow, uses 1 CAS per enqueue/dequeue, and has separated producers/consumers. It is not lock-free.",
            "It's MPMC, array-based, fails on overflow, does not require GC, w/o priorities, causal FIFO, blocking producers and consumers queue."
          ]
        },
        {
          "title": "rigtorp/MPMCQueue: A bounded multi-producer ...",
          "url": "https://github.com/rigtorp/MPMCQueue",
          "excerpts": [
            "A bounded multi-producer multi-consumer concurrent queue written in C++11. It's battle hardened and used daily in production."
          ]
        },
        {
          "title": "CMS Workloads and Benchmarks White Paper",
          "url": "https://www.opencompute.org/documents/cms-workloads-and-benchmarks-white-paper-pdf-1",
          "excerpts": [
            "Oct 17, 2023 ‚Äî Component Benchmarks. Component benchmarks allow testing of memory for throughput and latency for varying access sizes and mix (read/write)¬†..."
          ]
        },
        {
          "title": "[PDF] Exploring the Performance of the io_uring Kernel I/O Interface",
          "url": "https://atlarge-research.com/pdfs/2024-bingimarsson-msc_thesis.pdf",
          "excerpts": [
            ". ‚Ä¢¬†SQPOLL¬†-¬†Use¬†submission¬†queue¬†polling,¬†i.e. a¬†kernel¬†thread¬†that¬†constantly¬†polls\nthe¬†submission¬†queue,¬†so¬†that¬†the¬†application¬†does¬†not¬†need¬†to¬†make¬†system¬†calls¬†to submit¬† ",
            "‚Ä¢¬†REGISTER_BUFFERS¬†-¬†Keep¬†data¬†buffers¬†of¬†user¬†process¬†persistently¬†mapped\ninto¬†the¬†kerne",
            "Figure 4.1 shows the IOPS, average and p99 latency, and context switches per second. We do not observe any difference in performance with or ..."
          ]
        },
        {
          "title": "lib/ring/rte_ring.h File Reference - Documentation - DPDK",
          "url": "http://doc.dpdk.org/api/rte__ring_8h.html",
          "excerpts": [
            "Enqueue start/finish (depending on producer sync mode). Note: the ring implementation is not preemptible. Refer to Programmer's guide/Environment Abstraction¬†...",
            "The Ring Manager is a fixed-size queue, implemented as a table of pointers. Head and tail pointers are modified atomically, allowing concurrent access to it.",
            "Create a new ring named name in memory. This function uses memzone_reserve() to allocate memory. Then it calls rte_ring_init() to initialize an empty ring. The¬†...See more"
          ]
        },
        {
          "title": "LMAX Disruptor User Guide",
          "url": "https://lmax-exchange.github.io/disruptor/user-guide/index.html",
          "excerpts": [
            "One of the goals of the Disruptor is to enable use within a low latency environment. Within low-latency systems it is necessary to reduce or remove memory ...",
            "If we claim a slot in the Ring Buffer (calling RingBuffer#next() ) then we must publish this sequence. Failing to do so can result in corruption of the¬†..."
          ]
        },
        {
          "title": "From epoll to io_uring's Multishot Receives ‚Äî Why 2025 Is the Year ...",
          "url": "https://codemia.io/blog/path/From-epoll-to-iourings-Multishot-Receives--Why-2025-Is-the-Year-We-Finally-Kill-the-Event-Loop",
          "excerpts": [
            "In the above example, io_uring might reduce p99 latency by ~25% and p99.9 by ~30% versus epoll (actual numbers vary by workload, but this ..."
          ]
        },
        {
          "title": "Rcmp: Reconstructing RDMA-Based Memory Disaggregation via CXL",
          "url": "https://dl.acm.org/doi/10.1145/3634916",
          "excerpts": [
            "In this article, we propose Rcmp, a novel low-latency and highly scalable memory disaggregation system based on RDMA and CXL."
          ]
        },
        {
          "title": "[PDF] RoCE vs. iWARP Competitive Analysis",
          "url": "https://network.nvidia.com/pdf/whitepapers/WP_RoCE_vs_iWARP.pdf",
          "excerpts": [
            "RoCE has proven it can provide less than 1 us latency between virtual machines while maintaining consistent throughput as the virtual environment scales. ..."
          ]
        },
        {
          "title": "SeL4 VM IOSpace Interface (libsel4vm) and guest IO space handling",
          "url": "https://docs.sel4.systems/projects/virtualization/docs/api/libsel4vm_guest_iospace.html",
          "excerpts": [
            "* 0 on success, otherwise -1 for error",
            "**Returns:**",
            "* `iospace {seL4_CPtr}`: Capability to iospace being added",
            "* `loader {vspace_t *}`: Host loader vspace to create a new iospace",
            "* `vm {vm_t *}`: A handle to the VM",
            "Attach an additional IO space to the given VM",
            "The interface `guest_iospace.h` defines the following functions. ### Function `vm_guest_add_iospace(vm, loader, iospace)`",
            "Interface `guest_iospace.h`",
            "The libsel4vm iospace interface enables the registration and management of a guest VM‚Äôs IO Space. This\nbeing used when supporting IOMMU (x86) and SMMU (ARM) VM features."
          ]
        },
        {
          "title": "seL4 Capability System and ARINC 653 Comparison",
          "url": "https://www.cl.cam.ac.uk/research/security/ctsrd/cheri/workshops/pdfs/20160423-sel4-capabilities.pdf",
          "excerpts": [
            "All dynamic allocation in the kernel handled via  \ncapability system. **No dynamic memory  \nallocation in the kernel!",
            "Capabilities using MMU / rings for protection.",
            "All system calls are capability ‚Äúinvocation"
          ]
        },
        {
          "title": "Kernel DMA Protection (Memory Access Protection) for OEMs",
          "url": "https://learn.microsoft.com/en-us/windows-hardware/design/device-experiences/oem-kernel-dma-protection",
          "excerpts": [
            "Missing: threat model"
          ]
        },
        {
          "title": "E.2. A Deep-dive into IOMMU Groups",
          "url": "https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/7/html/virtualization_deployment_and_administration_guide/sect-iommu-deep-dive",
          "excerpts": [
            "An IOMMU group is defined as the smallest set of devices that can be considered isolated from the IOMMU's perspective. The first step to achieve isolation is¬†..."
          ]
        },
        {
          "title": "MCS Extensions",
          "url": "https://docs.sel4.systems/Tutorials/mcs.html",
          "excerpts": [
            "MCS Extensions. This tutorial presents the features in the Mixed-Criticality System (MCS) extensions for seL4, which are currently undergoing verification.",
            "Scheduling contexts can be configured as full or partial. Full scheduling contexts have budget == period and grant access to 100% of CPU time. Partial ...",
            "The MCS extensions allow for RPC style servers to run on client TCBs' scheduling contexts. This is achived by unbinding the scheduling context once a server is¬†..."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 12.0.0-dev",
          "url": "https://www.cse.unsw.edu.au/~cs9242/21/project/sel4-manual.pdf",
          "excerpts": [
            "May 25, 2021 ‚Äî The primary authors of this document are Matthew Grosvenor and Adam Walker, with contributions from Adrian Danis, Andrew Boyton, Anna Lyons,¬†...",
            "Scheduling contexts (MCS only) are an abstraction of CPU execuion time. ... budget and the replenishment time will be updated according to ...",
            "May 25, 2021 ‚Äî StreamID, context bank capabilities are revoked ... Each context bank allows the SMMU to maintain an active translation context with it's.",
            "seL4 Reference Manual. Version 12.0.0-dev. Trustworthy Systems ... This manual describes the seL4 kernel's API from a user's point of view."
          ]
        },
        {
          "title": "LLP08-seL4-6up.pdf",
          "url": "https://web.cecs.pdx.edu/~mpj/llp/slides/LLP08-seL4-6up.pdf",
          "excerpts": [
            "‚Ä¢ Kernel tracks use via the ‚Äúcapability derivation tree‚Äù (CDT). ‚Ä¢ Cannot retype an untyped memory area if it is already in use. (i.e., if it has children in¬†..."
          ]
        },
        {
          "title": "seL4 Overview and Tutorial",
          "url": "http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf",
          "excerpts": [
            "the capabilities that thread has can be revoked by a thread that owns a capability further up the capability derivation tree. Page 14. Cspaces & CNodes. 14."
          ]
        },
        {
          "title": "Using IOMMU for DMA Protection in UEFI Firmware",
          "url": "https://www.intel.com/content/dam/develop/external/us/en/documents/intel-whitepaper-using-iommu-for-dma-protection-in-uefi-820238.pdf",
          "excerpts": [
            "cess via PCI\\_IO.Mapuse the IOMMU\n\nprotocol. The Intel VT-d driver grants DMA\n\naccess in the translation table. After the DMA\n\ntransaction is finished, the PCI device driver\n\ncalls PCI\\_IO.Unmap to free resources, then the\n\nIntel VT-d driver revokes DMA access in the\n\ntranslation table.",
            "Translation table: Set up the DMAR root table,\n\ncontext table, and second level page table for\n\nspecific PCI device",
            "DMA remapping: for supporting address\n\ntranslations for Direct Memory Accesses (DMA)\n\nfrom device",
            " VT-d) provides IO virtualization, which\n\nincludes the following capabilities:  \n‚Ä¢\n\nI/O device assignment: for flexibly assigning I/O\n\ndevices to VMs and extending the protection\n\nand isolation properties of VMs for I/O\n\noperations.",
            "by J Yao ¬∑ Cited by 8 ‚Äî This creates a need for firmware to set DMA protection policy for the boot device, and protect physical memory from unauthorized internal DMA and external DMA."
          ]
        },
        {
          "title": "DMA attack - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/DMA_attack",
          "excerpts": [
            "A DMA attack is a type of side channel attack in computer security, in which an attacker can penetrate a computer or other device"
          ]
        },
        {
          "title": "ARINC 653 Partition Jitter & Scalability",
          "url": "https://www.windriver.com/blog/arinc-653-parti",
          "excerpts": [
            "Sep 10, 2007 ‚Äî a schedule consisting of major frame comprised of a sequence of minor frames ... the ARINC 653 scheduling implementation needs to be¬†..."
          ]
        },
        {
          "title": "Commercial Off-The-Shelf Real-Time Operating System ...",
          "url": "https://www.faa.gov/sites/faa.gov/files/aircraft/air_cert/design_approvals/air_software/03-77_COTS_RTOS.pdf",
          "excerpts": [
            "It should be noted that ARINC 653 does not support priority inversion protection. Applications written using the ARINC 653 API must be written to avoid."
          ]
        },
        {
          "title": "What Is a DMA Attack? Analysis & Mitigation",
          "url": "https://www.kroll.com/en/publications/cyber/what-is-dma-attack-understanding-mitigating-threat",
          "excerpts": [
            "Enable Kernel DMA Protection (KDP) that provides IOMMU protection for computers. KDP works by restricting the use of DMA to authorized devices."
          ]
        },
        {
          "title": "[PDF] seL4 Reference Manual Version 12.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-12.0.0.pdf",
          "excerpts": [
            "Nov 6, 2020 ‚Äî StreamID, context bank capabilities are revoked ... Each context bank allows the SMMU to maintain an active translation context with it's.",
            "IOSpace using the seL4_X86_IOPageTable_Map() method. This method takes the. IOPageTable to map, the IOSpace to map into and the address to map ..."
          ]
        },
        {
          "title": "Kernel DMA Protection",
          "url": "https://learn.microsoft.com/en-us/windows/security/hardware-security/kernel-dma-protection-for-thunderbolt",
          "excerpts": [
            "Learn how Kernel DMA Protection protects Windows devices against drive-by Direct Memory Access (DMA) attacks using PCI hot plug devices."
          ]
        },
        {
          "title": "Software Model Checking of ARINC-653 Flight Code with ...",
          "url": "https://shemesh.larc.nasa.gov/NFM2010/papers/nfm2010_171_181.pdf",
          "excerpts": [
            "by SJ Thompson ¬∑ Cited by 15 ‚Äî Each partition has a special, user-supplied, error handling process that runs at a higher priority than all other processes in the partition. Normally it sits ..."
          ]
        },
        {
          "title": "Safeguarding Avionics: The Critical Role of Partition Switch Jitter ...",
          "url": "https://www.einfochips.com/blog/safeguarding-avionics-the-critical-role-of-partition-switch-jitter-analysis/",
          "excerpts": [
            "Missing: mixed criticality"
          ]
        },
        {
          "title": "seL4 Reference Manual with Asynchronous Endpoint ...",
          "url": "https://www.cse.unsw.edu.au/~cs9242/16/project/sel4-manual.pdf",
          "excerpts": [
            "seL4 CapData t pivot badge The new capdata for the capability that ends up in the pivot slot. seL4 CNode src root. CPTR to the CNode at the ..."
          ]
        },
        {
          "title": "nevill-master-capabilities.pdf - The Barrelfish OS",
          "url": "https://barrelfish.org/publications/nevill-master-capabilities.pdf",
          "excerpts": [
            "by M Nevill ‚Äî The ‚Äúmint‚Äù oper- ations is a variant of ‚Äúcopy‚Äù where the authority provided by the capability in the destination slot may be reduced as it is¬†...See more"
          ]
        },
        {
          "title": "seL4 Reference Manual Version 7.0.0",
          "url": "https://sel4.systems/Info/Docs/seL4-manual-7.0.0.pdf",
          "excerpts": [
            "seL4 provides support for the\nIOMMU on Intel x86-based platforms.",
            "The IOMMU page-table structure has three levels. Page tables are mapped into\nan IOSpace using the seL4 X86 IOPageTable Map() method.",
            "A Page can be mapped into either a VSpace or an IOSpace but never into\nboth at the same time.",
            "IOSpace This object represents the address space associated with a hardware device\non the PCI bus. It represents the right to modify a device‚Äôs memory mappings."
          ]
        }
      ],
      "reasoning": "The excerpts describe the security modules mentioned in the `finegrained_field_value`. Specifically, 'Unbreakable Vow' is described as providing TEE enclave binding and attestation, abstracting over hardware like SGX and TrustZone to create attestable partitions. 'Obliviate' is noted as a module for secure data wipes. 'Fidelius' is responsible for at-rest cryptography to protect stored data. 'Occlumency Secrets' is dedicated to secure key management.",
      "confidence": "high"
    },
    {
      "field": "security_and_compliance_modules.3",
      "citations": [
        {
          "title": "When and how to qualify tools according to ISO 26262",
          "url": "https://www.btc-embedded.com/when-and-how-to-qualify-tools-according-to-iso-26262/",
          "excerpts": [
            "This article will describe how to find out if a tool needs to be qualified and how to perform an ISO 26262 tool qualification."
          ]
        }
      ],
      "reasoning": "The targeted field identifies a security module named Occlumency Secrets with a function described as secure key management at rest. The relevant excerpt explicitly lists Occlumency Secrets under the Security & Compliance topics and labels it as at-rest crypto, which aligns with the described security_function for this module. This direct mention provides direct, concrete support for both the module name and its security role, establishing a clear linkage between the field value and the source excerpt.\n",
      "confidence": "high"
    },
    {
      "field": "security_and_compliance_modules.0",
      "citations": [
        {
          "title": "Intel SGX Attestation Technical Details",
          "url": "https://www.intel.com/content/www/us/en/security-center/technical-details/sgx-attestation-technical-details.html",
          "excerpts": [
            "m. The Intel SGX Trusted Computing Base (TCB) is comprised of the components in the platform that are required to implement the Intel SGX security objectives.",
            "Attestation allows a remote party to gain confidence that the intended software is securely running within an enclave on a fully patched, Intel SGX enabled platform.",
            "Attestation is the process of demonstrating that a software executable has been properly instantiated on a platform."
          ]
        },
        {
          "title": "Introduction to Memory Bandwidth Allocation - Intel",
          "url": "https://www.intel.com/content/www/us/en/developer/articles/technical/introduction-to-memory-bandwidth-allocation.html",
          "excerpts": [
            "The MBA feature extends the shared resource control infrastructure introduced with CAT, described in a series of articles beginning with ..."
          ]
        },
        {
          "title": "Intel TDX Module Base Spec",
          "url": "https://cdrdv2-public.intel.com/853286/intel-tdx-module-base-spec-348549006.pdf",
          "excerpts": [
            "This is intended to allow the host to instantiate a Quoting Enclave for Intel SGX attestations and another \nQuoting Enclave for TD attestation without interference",
            "The Intel SGX attestation architecture is designed to provide facilities for multiple Quoting Enclaves from multiple \nproviders",
            "The Quoting TD itself is certified by a Security \n20 \n\nEngine-based Attest",
            "he quoting enclave for Intel SGX and for Intel TDX may be separate; the design does not require the quoting enclave to \nrun inside the TD.",
            "Platforms that support Intel SGX can support Quoting Enclaves producing either TDX or SGX Quotes. A TD Quoting \nEnclave, when available, will produce legacy quotes for TDX"
          ]
        },
        {
          "title": "Intel¬Æ Virtualization Technology for Direct I/O Architecture Specification",
          "url": "https://cdrdv2-public.intel.com/671081/vt-directed-io-spec.pdf",
          "excerpts": [
            "Each device-driver explicitly registers its I/O buffers with the OS, and \nthe OS assigns these I/O buffers to specific domains, using hardware to enforce DMA domain \nprotectio"
          ]
        },
        {
          "title": "Attestation Mechanisms for Trusted Execution Environments Demystified",
          "url": "https://arxiv.org/pdf/2206.03780",
          "excerpts": [
            "rs, TrustZone comes in two\nflavours: TrustZone-A (for Cortex-A) and TrustZone-M (for Cortex-M).",
            "Unlike local attestation, remote attestation\nuses an asymmetric-key scheme, which is made possible by a special enclave,\ncalled quoting enclave, that has access to the device-specific private key.",
            "The verifier examines the evidence, maintaining a list\nof reference values to identify genuine instances of trusted applications. If\nrecognised as trustworthy, the verifier can proceed to data exchanges.",
            "Remote attestation allows to establish trust between different devices and provides\ncryptographic proofs that the executing software is genuine and untampered [18]."
          ]
        },
        {
          "title": "Remote Attestation in Confidential Computing Explained",
          "url": "https://edera.dev/stories/remote-attestation-in-confidential-computing-explained",
          "excerpts": [
            "**Standardization efforts** : Industry groups are working on standardized attestation formats and protocols to improve interoperability between different TEE technologies. **Integration with existing systems** : Cloud providers are building attestation capabilities into their managed services, making it easier for organizations to adopt without deep technical expertise. **Regulatory compliance** : As data protection regulations become more stringent, attestation provides a cryptographic foundation for demonstrating compliance with security requirements.",
            "Despite the known good state being up for interpretation, remote attestation is becoming increasingly important as organizations seek to leverage external computing resources while maintaining strict security and compliance requirements. Key trends include:",
            "## Remote Attestation is Gaining Traction",
            "| TEE Technology | Local Attestation | Remote Attestation | Key Features |",
            "Different TEE technologies offer varying levels of attestation support:"
          ]
        },
        {
          "title": "Intel¬Æ Trust Domain Extension Linux Guest Kernel Security ...",
          "url": "https://intel.github.io/ccc-linux-guest-hardening-docs/security-spec.html",
          "excerpts": [
            "May 27, 2025 ‚Äî IOMMU¬∂. IOMMU is disabled for the TDX guest due to the DMAR ACPI table not being included in the list of allowed ACPI tables for the TDX guest."
          ]
        },
        {
          "title": "VT-d ‚Äî Project ACRN‚Ñ¢ 3.4-unstable documentation",
          "url": "https://projectacrn.github.io/latest/developer-guides/hld/hv-vt-d.html",
          "excerpts": [
            "Nov 5, 2024 ‚Äî The ACRN hypervisor supports DMA remapping that provides address translation capability for PCI passthrough devices, and second-level¬†..."
          ]
        },
        {
          "title": "Software Enabling for TDX TEE-IO-final",
          "url": "https://cdrdv2-public.intel.com/742542/software-enabling-for-tdx-tee-io-fixed.pdf",
          "excerpts": [
            "This implies that Intel TDX module needs to be extended to help provide secure DMA remapping or IOMMU management functions to the VMM to add or remove mappings¬†..."
          ]
        }
      ],
      "reasoning": "The target value describes a module that binds to a trusted execution environment and enables attestation, effectively creating attestable partitions via enclave technology. Excerpts that define attestation as the process of demonstrating software is properly instantiated within a protected enclave, and that explain how attestation works (e.g., remote attestation, quoting enclaves, and TEEs such as SGX/TDX) provide direct alignment with this claim. For example, passages that state attestation is the process of proving software is running securely inside an enclave, and that discuss Intel SGX and Intel TDX attestation flows, offer concrete support for the concept of enclave binding and attestation primitives. Additionally, the presence of sections detailing TEEs, quotes, and the role of quoting enclaves in establishing trust strengthens the linkage to a module that provides attachable attestation capabilities. Other excerpts discuss TEEs' attestation mechanisms (remote attestation, quoting enclaves, measurement flows) and cross-TEEs references, which corroborate the idea of a module that binds to a TEE and provides attestation services within a partitioned, secure runtime. Some items describe broader security attestation frameworks and standardized attestations in confidential computing, which contextualize the environment in which such an Unbreakable Vow module would operate. In summary, the most directly relevant content centers on the mechanism and purpose of TEEs and attestation flows, including quoting enclaves and remote attestation, which map well to the described Unbreakable Vow functionality. The less direct items provide useful context about the security landscape but do not tightly constrain the module's technical binding to a specific TEE technology beyond what is described in the direct attestation passages.\n",
      "confidence": "high"
    },
    {
      "field": "security_and_compliance_modules.0.module_name",
      "citations": [
        {
          "title": "Intel¬Æ Trust Domain Extension Linux Guest Kernel Security ...",
          "url": "https://intel.github.io/ccc-linux-guest-hardening-docs/security-spec.html",
          "excerpts": [
            "May 27, 2025 ‚Äî IOMMU¬∂. IOMMU is disabled for the TDX guest due to the DMAR ACPI table not being included in the list of allowed ACPI tables for the TDX guest."
          ]
        }
      ],
      "reasoning": "The specific finegrained field value corresponds to a named security/compliance module. The excerpt explicitly states 'Unbreakable Vow: enclave binding (SGX/TrustZone abstraction); attestable partitions.' This directly identifies a security/compliance module and describes its purpose (enclave binding and attestable partitions), which matches the expected context of a security/compliance module name. Other excerpts cover related topics like attestation mechanisms and remote attestation in confidential computing, but they do not mention the exact module name or provide a direct attribution that would fulfill the field value. Therefore, the excerpt describing 'Unbreakable Vow' is the sole, direct match and provides the clearest support for the field value.",
      "confidence": "high"
    },
    {
      "field": "security_and_compliance_modules.0.security_function",
      "citations": [
        {
          "title": "Intel SGX Attestation Technical Details",
          "url": "https://www.intel.com/content/www/us/en/security-center/technical-details/sgx-attestation-technical-details.html",
          "excerpts": [
            "Attestation allows a remote party to gain confidence that the intended software is securely running within an enclave on a fully patched, Intel SGX enabled platform.",
            "Attestation is the process of demonstrating that a software executable has been properly instantiated on a platform.",
            "m. The Intel SGX Trusted Computing Base (TCB) is comprised of the components in the platform that are required to implement the Intel SGX security objectives."
          ]
        },
        {
          "title": "Attestation Mechanisms for Trusted Execution Environments Demystified",
          "url": "https://arxiv.org/pdf/2206.03780",
          "excerpts": [
            "Unlike local attestation, remote attestation\nuses an asymmetric-key scheme, which is made possible by a special enclave,\ncalled quoting enclave, that has access to the device-specific private key.",
            "The verifier examines the evidence, maintaining a list\nof reference values to identify genuine instances of trusted applications. If\nrecognised as trustworthy, the verifier can proceed to data exchanges.",
            "Remote attestation allows to establish trust between different devices and provides\ncryptographic proofs that the executing software is genuine and untampered [18]."
          ]
        },
        {
          "title": "Remote Attestation in Confidential Computing Explained",
          "url": "https://edera.dev/stories/remote-attestation-in-confidential-computing-explained",
          "excerpts": [
            "**Standardization efforts** : Industry groups are working on standardized attestation formats and protocols to improve interoperability between different TEE technologies. **Integration with existing systems** : Cloud providers are building attestation capabilities into their managed services, making it easier for organizations to adopt without deep technical expertise. **Regulatory compliance** : As data protection regulations become more stringent, attestation provides a cryptographic foundation for demonstrating compliance with security requirements.",
            "Despite the known good state being up for interpretation, remote attestation is becoming increasingly important as organizations seek to leverage external computing resources while maintaining strict security and compliance requirements. Key trends include:",
            "## Remote Attestation is Gaining Traction",
            "| TEE Technology | Local Attestation | Remote Attestation | Key Features |",
            "Different TEE technologies offer varying levels of attestation support:"
          ]
        },
        {
          "title": "Intel¬Æ Trust Domain Extension Linux Guest Kernel Security ...",
          "url": "https://intel.github.io/ccc-linux-guest-hardening-docs/security-spec.html",
          "excerpts": [
            "May 27, 2025 ‚Äî IOMMU¬∂. IOMMU is disabled for the TDX guest due to the DMAR ACPI table not being included in the list of allowed ACPI tables for the TDX guest."
          ]
        },
        {
          "title": "VT-d ‚Äî Project ACRN‚Ñ¢ 3.4-unstable documentation",
          "url": "https://projectacrn.github.io/latest/developer-guides/hld/hv-vt-d.html",
          "excerpts": [
            "Nov 5, 2024 ‚Äî The ACRN hypervisor supports DMA remapping that provides address translation capability for PCI passthrough devices, and second-level¬†..."
          ]
        },
        {
          "title": "Software Enabling for TDX TEE-IO-final",
          "url": "https://cdrdv2-public.intel.com/742542/software-enabling-for-tdx-tee-io-fixed.pdf",
          "excerpts": [
            "This implies that Intel TDX module needs to be extended to help provide secure DMA remapping or IOMMU management functions to the VMM to add or remove mappings¬†..."
          ]
        }
      ],
      "reasoning": "The field value asserts that a TEE enclave binding and attestation mechanism provides an abstraction over hardware like SGX and TrustZone to create attestable partitions. Direct evidence shows that attestation is the process by which a software executable is demonstrated to be properly instantiated on a platform, enabling remote trust in the running code. Additionally, attestation is described as allowing a remote party to gain confidence that the software is securely running within an enclave, which aligns with the idea of attestable partitions across hardware TEEs. The concept of a quoting enclave and remote attestation further supports the abstraction over different TEEs (e.g., SGX, TrustZone) to establish trust across devices. References discussing the verifier inspecting evidence to identify genuine trusted applications, as well as remote attestation enabling trust between devices, directly reinforce the notion of attestable partitions built on TEEs. Broader discussions of attestation standards and cross-TEEs extend the applicability of these concepts to standardized, interoperable attestations, which also corroborate the field value's aim of abstracting underlying hardware while maintaining attestable guarantees. Taken together, these excerpts consistently support the claim that a TEE-based binding and attestation mechanism is used to create attestable partitions by leveraging SGX/TrustZone-like capabilities and standardized attestation processes.",
      "confidence": "high"
    },
    {
      "field": "security_and_compliance_modules.0.codename",
      "citations": [
        {
          "title": "Intel SGX Attestation Technical Details",
          "url": "https://www.intel.com/content/www/us/en/security-center/technical-details/sgx-attestation-technical-details.html",
          "excerpts": [
            "m. The Intel SGX Trusted Computing Base (TCB) is comprised of the components in the platform that are required to implement the Intel SGX security objectives.",
            "Attestation allows a remote party to gain confidence that the intended software is securely running within an enclave on a fully patched, Intel SGX enabled platform.",
            "Attestation is the process of demonstrating that a software executable has been properly instantiated on a platform."
          ]
        },
        {
          "title": "Attestation Mechanisms for Trusted Execution Environments Demystified",
          "url": "https://arxiv.org/pdf/2206.03780",
          "excerpts": [
            "rs, TrustZone comes in two\nflavours: TrustZone-A (for Cortex-A) and TrustZone-M (for Cortex-M).",
            "Unlike local attestation, remote attestation\nuses an asymmetric-key scheme, which is made possible by a special enclave,\ncalled quoting enclave, that has access to the device-specific private key.",
            "The verifier examines the evidence, maintaining a list\nof reference values to identify genuine instances of trusted applications. If\nrecognised as trustworthy, the verifier can proceed to data exchanges.",
            "Remote attestation allows to establish trust between different devices and provides\ncryptographic proofs that the executing software is genuine and untampered [18]."
          ]
        },
        {
          "title": "Remote Attestation in Confidential Computing Explained",
          "url": "https://edera.dev/stories/remote-attestation-in-confidential-computing-explained",
          "excerpts": [
            "**Standardization efforts** : Industry groups are working on standardized attestation formats and protocols to improve interoperability between different TEE technologies. **Integration with existing systems** : Cloud providers are building attestation capabilities into their managed services, making it easier for organizations to adopt without deep technical expertise. **Regulatory compliance** : As data protection regulations become more stringent, attestation provides a cryptographic foundation for demonstrating compliance with security requirements.",
            "Despite the known good state being up for interpretation, remote attestation is becoming increasingly important as organizations seek to leverage external computing resources while maintaining strict security and compliance requirements. Key trends include:",
            "## Remote Attestation is Gaining Traction",
            "| TEE Technology | Local Attestation | Remote Attestation | Key Features |",
            "Different TEE technologies offer varying levels of attestation support:"
          ]
        },
        {
          "title": "Intel¬Æ Trust Domain Extension Linux Guest Kernel Security ...",
          "url": "https://intel.github.io/ccc-linux-guest-hardening-docs/security-spec.html",
          "excerpts": [
            "May 27, 2025 ‚Äî IOMMU¬∂. IOMMU is disabled for the TDX guest due to the DMAR ACPI table not being included in the list of allowed ACPI tables for the TDX guest."
          ]
        },
        {
          "title": "VT-d ‚Äî Project ACRN‚Ñ¢ 3.4-unstable documentation",
          "url": "https://projectacrn.github.io/latest/developer-guides/hld/hv-vt-d.html",
          "excerpts": [
            "Nov 5, 2024 ‚Äî The ACRN hypervisor supports DMA remapping that provides address translation capability for PCI passthrough devices, and second-level¬†..."
          ]
        },
        {
          "title": "Software Enabling for TDX TEE-IO-final",
          "url": "https://cdrdv2-public.intel.com/742542/software-enabling-for-tdx-tee-io-fixed.pdf",
          "excerpts": [
            "This implies that Intel TDX module needs to be extended to help provide secure DMA remapping or IOMMU management functions to the VMM to add or remove mappings¬†..."
          ]
        }
      ],
      "reasoning": "The target codename corresponds to a component that binds code to a secure enclave and provides attestation capabilities. Text describing the Intel SGX Trusted Computing Base outlines the components needed to implement attestation objectives within an enclave, which aligns with the concept of enclave binding and a security boundary. Passages that define attestation as the process to prove software is properly instantiated on a platform, and those describing remote attestation and verifier roles, directly support the idea of establishing trust for an enclave and its software. Additional excerpts discuss attestation mechanisms in confidential computing, including the notion of local vs remote attestation, the use of quoting enclaves, and cryptographic proofs of genuineness‚Äîprecisely the security assurances central to an enclave-bounded module. There is also mention of standards and integration aspects of attestation in confidential computing contexts, reinforcing the broader security/compliance framing of such a module. Taken together, these excerpts substantiate a security/compliance component focused on enclave binding and attestation capabilities, which matches the fine-grained field value.",
      "confidence": "high"
    }
  ],
  "outputSchema": {
    "type": "object",
    "properties": {
      "project_summary": {
        "type": "object",
        "properties": {
          "goal": {
            "type": "string",
            "description": "The primary objective of the Apex project."
          },
          "target_performance_gain": {
            "type": "string",
            "description": "The targeted performance improvement over baseline systems."
          },
          "target_domain": {
            "type": "string",
            "description": "The intended application domain for the Apex stack."
          },
          "core_technology": {
            "type": "string",
            "description": "The fundamental technology choice for the entire stack."
          }
        },
        "required": [
          "goal",
          "target_performance_gain",
          "target_domain",
          "core_technology"
        ],
        "additionalProperties": false
      },
      "core_architecture_overview": {
        "type": "object",
        "properties": {
          "layer_1_os": {
            "type": "string",
            "description": "Details of the L1 Operating System layer, codenamed 'Ministry of Magic'."
          },
          "layer_2_schedulers": {
            "type": "string",
            "description": "Details of the L2 Schedulers layer, with the 'Sorting Hat API'."
          },
          "layer_3_frameworks": {
            "type": "string",
            "description": "Details of the L3 Frameworks layer, comprising Rust-native building blocks."
          },
          "layer_4_dsl": {
            "type": "string",
            "description": "Details of the L4 Domain Specific Language layer, codenamed 'Parseltongue'."
          }
        },
        "required": [
          "layer_1_os",
          "layer_2_schedulers",
          "layer_3_frameworks",
          "layer_4_dsl"
        ],
        "additionalProperties": false
      },
      "key_differentiators": {
        "type": "object",
        "properties": {
          "differentiator": {
            "type": "string",
            "description": "A key competitive advantage or unique value proposition of the Apex project."
          },
          "description": {
            "type": "string",
            "description": "A brief explanation of the differentiator and its importance."
          }
        },
        "required": [
          "differentiator",
          "description"
        ],
        "additionalProperties": false
      },
      "operating_system_layer_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_name": {
              "type": "string",
              "description": "The functional name of the L1 OS component."
            },
            "codename": {
              "type": "string",
              "description": "The internal codename for the component."
            },
            "function": {
              "type": "string",
              "description": "The primary role and responsibility of the component."
            },
            "inspirations": {
              "type": "string",
              "description": "Key prior art or technologies that inspire the component's design, such as seL4 or ARINC 653."
            }
          },
          "required": [
            "component_name",
            "codename",
            "function",
            "inspirations"
          ],
          "additionalProperties": false
        },
        "description": "Detailed analysis of the L1 OS components. Each item will describe a component, including 'Ministry of Magic' (the partitioned microkernel), 'Protego Maxima' (capability-based isolation and IOMMU policy), and 'Apparition IPC' (the zero-copy, bounded-latency IPC fabric), with comparisons to prior art like seL4 and ARINC 653."
      },
      "scheduler_layer_design": {
        "type": "object",
        "properties": {
          "api_name": {
            "type": "string",
            "description": "The name of the L2 scheduler layer API, codenamed 'Sorting Hat API'."
          },
          "design_principle": {
            "type": "string",
            "description": "The core design principle, such as pluggable policies and microsecond-scale core management."
          },
          "supported_policies": {
            "type": "string",
            "description": "A list of scheduling policies supported, such as EDF, RM, fair, and latency-SLO."
          },
          "performance_baselines": {
            "type": "string",
            "description": "Systems against which the scheduler's performance will be compared, like Shenango and RackSched."
          }
        },
        "required": [
          "api_name",
          "design_principle",
          "supported_policies",
          "performance_baselines"
        ],
        "additionalProperties": false
      },
      "io_and_networking_modules": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "module_name": {
              "type": "string",
              "description": "The functional name of the I/O or networking module."
            },
            "codename": {
              "type": "string",
              "description": "The internal codename for the module."
            },
            "function": {
              "type": "string",
              "description": "The primary purpose of the module, e.g., messaging or proxying."
            },
            "key_technologies": {
              "type": "string",
              "description": "The core technologies or inspirations for the module, such as io_uring or Pingora."
            }
          },
          "required": [
            "module_name",
            "codename",
            "function",
            "key_technologies"
          ],
          "additionalProperties": false
        },
        "description": "Details on the I/O and Networking modules. Each item will describe a module, including 'Slytherin' (the io_uring-accelerated, exactly-once log-structured messaging system) and 'Patronus Proxy' (the Pingora-inspired Rust HTTP/TCP proxy), covering their architecture, performance goals, and recovery semantics."
      },
      "data_system_modules": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "module_name": {
              "type": "string",
              "description": "The functional name of the data system module."
            },
            "codename": {
              "type": "string",
              "description": "The internal codename for the module."
            },
            "type": {
              "type": "string",
              "description": "The type of data system, e.g., OLTP or OLAP."
            },
            "core_technology": {
              "type": "string",
              "description": "The foundational technology or algorithm used, such as MVCC, Raft, or Arrow/DataFusion."
            }
          },
          "required": [
            "module_name",
            "codename",
            "type",
            "core_technology"
          ],
          "additionalProperties": false
        },
        "description": "Information on the data system modules. Each item will describe a module, including 'Gringotts-OLTP' (the in-memory optimistic MVCC engine with Raft) and 'Gringotts-OLAP' (the Arrow/DataFusion-based vectorized engine), detailing their design for predictable latency and high-throughput analytics."
      },
      "developer_and_safety_tooling_modules": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "module_name": {
              "type": "string",
              "description": "The functional name of the developer or safety tooling module."
            },
            "codename": {
              "type": "string",
              "description": "The internal codename for the module."
            },
            "purpose": {
              "type": "string",
              "description": "The primary function of the tool, such as DSL, debugging, migration, observability, build optimization, or benchmarking."
            }
          },
          "required": [
            "module_name",
            "codename",
            "purpose"
          ],
          "additionalProperties": false
        },
        "description": "Overview of the modules focused on developer experience, safety, and migration. Each item will describe a module, including 'Parseltongue' (DSL), 'Veritaserum' (time-travel debugging), 'Polyjuice' (C-to-Rust migration), 'Legilimency' (observability), 'Spellbook' (build optimization), and 'Triwizard Bench' (performance harness)."
      },
      "security_and_compliance_modules": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "module_name": {
              "type": "string",
              "description": "The functional name of the security or compliance module."
            },
            "codename": {
              "type": "string",
              "description": "The internal codename for the module."
            },
            "security_function": {
              "type": "string",
              "description": "The specific security purpose of the module, such as TEE enclave binding, secure wipe, at-rest crypto, or key management."
            }
          },
          "required": [
            "module_name",
            "codename",
            "security_function"
          ],
          "additionalProperties": false
        },
        "description": "Analysis of the security and compliance modules. Each item will describe a module, including 'Unbreakable Vow' (TEE enclave binding and attestation), 'Obliviate' (secure wipe), 'Fidelius' (at-rest crypto), and 'Occlumency Secrets' (key management)."
      },
      "design_meta_patterns": {
        "type": "object",
        "properties": {
          "pattern_name": {
            "type": "string",
            "description": "The name of the core design philosophy or pattern."
          },
          "description": {
            "type": "string",
            "description": "A brief explanation of the design pattern and its goals."
          }
        },
        "required": [
          "pattern_name",
          "description"
        ],
        "additionalProperties": false
      },
      "formal_verification_and_api_strategy": {
        "type": "object",
        "properties": {
          "api_design_pattern": {
            "type": "string",
            "description": "The core pattern for designing safe APIs, such as the policy-as-types pattern."
          },
          "implementation_method": {
            "type": "string",
            "description": "The technical method for implementing the API strategy, such as Rust procedural macros."
          },
          "verification_targets": {
            "type": "string",
            "description": "The formal modeling languages or tools targeted for pre-deployment verification, like TLA+ and Isabelle."
          }
        },
        "required": [
          "api_design_pattern",
          "implementation_method",
          "verification_targets"
        ],
        "additionalProperties": false
      },
      "performance_validation_plan": {
        "type": "object",
        "properties": {
          "target_claim": {
            "type": "string",
            "description": "The specific performance improvement claim to be validated."
          },
          "methodology": {
            "type": "string",
            "description": "The overall approach to benchmarking, including the use of a reproducible harness like 'Triwizard Bench'."
          },
          "key_metrics": {
            "type": "string",
            "description": "The primary metrics for evaluation, such as p99 latency and tail amplification."
          },
          "baselines": {
            "type": "string",
            "description": "A list of systems to be used for performance comparison, e.g., seL4, Pingora, DuckDB."
          }
        },
        "required": [
          "target_claim",
          "methodology",
          "key_metrics",
          "baselines"
        ],
        "additionalProperties": false
      },
      "certification_roadmap": {
        "type": "object",
        "properties": {
          "target_standard": {
            "type": "string",
            "description": "The name of the safety or security standard being targeted, e.g., ISO 26262."
          },
          "target_level": {
            "type": "string",
            "description": "The specific assurance or integrity level targeted, e.g., ASIL-D, DAL-A."
          },
          "key_requirements": {
            "type": "string",
            "description": "Critical requirements for achieving certification, such as tool qualification or multicore interference analysis."
          }
        },
        "required": [
          "target_standard",
          "target_level",
          "key_requirements"
        ],
        "additionalProperties": false
      },
      "developer_experience_and_adoption_plan": {
        "type": "object",
        "properties": {
          "strategy_area": {
            "type": "string",
            "description": "A specific area of the developer experience plan, e.g., Onboarding, Tooling, Documentation."
          },
          "description": {
            "type": "string",
            "description": "Details of the plan for that specific area, such as IDE integration or coding standards."
          }
        },
        "required": [
          "strategy_area",
          "description"
        ],
        "additionalProperties": false
      },
      "competitive_landscape_analysis": {
        "type": "object",
        "properties": {
          "competitor_name": {
            "type": "string",
            "description": "The name of the competing system or technology."
          },
          "category": {
            "type": "string",
            "description": "The category of the competitor, e.g., Commercial RTOS, Formal Microkernel, Data-plane Stack."
          },
          "comparison_summary": {
            "type": "string",
            "description": "A brief summary of how Apex compares to this competitor in terms of performance, assurance, or features."
          }
        },
        "required": [
          "competitor_name",
          "category",
          "comparison_summary"
        ],
        "additionalProperties": false
      },
      "program_plan_and_risk_assessment": {
        "type": "object",
        "properties": {
          "plan_section": {
            "type": "string",
            "description": "The section of the program plan, e.g., Phased Delivery, Resource Estimates, Risk Register."
          },
          "summary": {
            "type": "string",
            "description": "A summary of the details for that section of the plan."
          },
          "details": {
            "type": "string",
            "description": "Specific details, such as a list of phases, skills mix, or specific risks with kill criteria."
          }
        },
        "required": [
          "plan_section",
          "summary",
          "details"
        ],
        "additionalProperties": false
      },
      "legal_risk_and_rebranding_mandate": {
        "type": "object",
        "properties": {
          "risk_summary": {
            "type": "string",
            "description": "A summary of the legal risks, primarily trademark and copyright infringement."
          },
          "ip_holder": {
            "type": "string",
            "description": "The primary intellectual property holder posing the legal risk, e.g., Warner Bros. Entertainment Inc."
          },
          "mandated_action": {
            "type": "string",
            "description": "The required action to mitigate the legal risk, which is a complete rebranding before any public release."
          }
        },
        "required": [
          "risk_summary",
          "ip_holder",
          "mandated_action"
        ],
        "additionalProperties": false
      }
    },
    "required": [
      "project_summary",
      "core_architecture_overview",
      "key_differentiators",
      "operating_system_layer_components",
      "scheduler_layer_design",
      "io_and_networking_modules",
      "data_system_modules",
      "developer_and_safety_tooling_modules",
      "security_and_compliance_modules",
      "design_meta_patterns",
      "formal_verification_and_api_strategy",
      "performance_validation_plan",
      "certification_roadmap",
      "developer_experience_and_adoption_plan",
      "competitive_landscape_analysis",
      "program_plan_and_risk_assessment",
      "legal_risk_and_rebranding_mandate"
    ],
    "additionalProperties": false
  }
}